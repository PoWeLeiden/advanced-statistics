[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistische analyse en presentatie met R",
    "section": "",
    "text": "Voorwoord\nDit boek bevat het R-materiaal voor de cursus Statistiek II.\nWe hebben het boek in drie delen verdeeld:\nDe drie onderdelen presenteren de belangrijkste syntax om de aangeleerde analysemethoden uit te voeren. De syntax wordt stapsgewijs uitgelegd en de logica van de verschillende functies wordt toegelicht. We voorzien de syntax ook van bijkomende commentaar waar nodig (in tekst met grijze achtergrond of in commentaarvakjes die je ziet als je met je computermuis hierop staat). Een voorbeeld:\n# Packages\nlibrary(tidyverse)   #voor data management en grafieken\n\n# Een linear regressiemodel\n1model1 &lt;- lm(mpg ~ drat, data = mtcars)\n\n\n1\n\nSommige opmerkingen zetten we in deze tekstvakjes, vooral als ze wat langer zijn of wanneer ze zaken die al behandeld zijn herhalen.\nDit overzicht bevat ook algemene richtlijnen over hoe de resultaten van statistische analyses te presenteren en te rapporteren. Je vindt de resultaten (‘output’) van analyses en bijkomende uitleg in volgende tekstvakken:\nHet laatste deel van het boek bevat twee bijlagen met bijkomende informatie. Appendix A geeft een overzicht van veel voorkomende fouten (‘Common Errors’) bij het uitvoeren van de analyses en bij het omzetten van een R Markdown bestand naar een html bestand (nodig voor de opdrachten). Appendix B geeft een overzicht van de R ‘libraries’ of ‘packages’ (en hun functies) die we gebruiken in deze cursus en de week waarin ze worden geïntroduceerd, en bevat ook het script waarmee je alle packages in 1 keer op je computer kunt installeren.",
    "crumbs": [
      "Voorwoord"
    ]
  },
  {
    "objectID": "index.html#statistiek-i-boek",
    "href": "index.html#statistiek-i-boek",
    "title": "Statistische analyse en presentatie met R",
    "section": "Statistiek I Boek",
    "text": "Statistiek I Boek\nDe inhoud van dit boek bouwt verder op de leerstof van Statistiek 1. Data management (bv. filteren, hercoderen van variabelen, ontbrekende waarden aanduiden) blijft ook van belang voor dit vak. Deze leerstof kun je raadplegen in het Statistiek 1 boek. Soms verwijzen we in dit boek ook naar specifieke onderdelen van Statistiek 1 waar dit relevant is.",
    "crumbs": [
      "Voorwoord"
    ]
  },
  {
    "objectID": "index.html#overzicht-per-week",
    "href": "index.html#overzicht-per-week",
    "title": "Statistische analyse en presentatie met R",
    "section": "Overzicht per week",
    "text": "Overzicht per week\nVoor elke week in de cursus moet je relevante hoofdstukken lezen. In 2025-2026 is dit:\n\n\n\n\n\n\n\n\nWeek\nSectie\nHoofdstukken\n\n\n\n\n1\nLineaire Modellen\n1  Relaties tussen Continue Variabelen ; 8  Rapporteren en Presenteren van Resultaten (8.2 & 8.3)\n\n\n2\nLineaire Modellen\n2  Bivariate Regressie met Binaire en Categorische Predictoren ; 3  Statistische Significantie ; 5  Voorspellingen en Fouten (5.1 & 5.2) ; 8  Rapporteren en Presenteren van Resultaten (8.4)\n\n\n3\nLineaire Modellen\n4  Meervoudige Lineaire Regressie ; 5  Voorspellingen en Fouten (5.3) ; 6  Model Fit en Modellen Vergelijken ; 8  Rapporteren en Presenteren van Resultaten (8.4 - 8.7)\n\n\n4\nLineaire Modellen\n7  OLS Assumpties\n\n\n5\nLogistische Regressie\n9  Logistische Regressie & Odds Ratios ; 10  Marginale Effecten ; 11  Voorspelde kansen ; 14  Rapporteren en Presenteren van Resultaten\n\n\n6\nLogistische Regressie\n12  Model Fit en Modellen Vergelijken ; 13  Assumpties van Logistische Regressie\n\n\n7\nInteracties\n15  Interacties in het Regressiemodel ; 16  Marginale Effecten in Interactiemodellen ; 17  Voorspelde Waarden van Interactiemodellen",
    "crumbs": [
      "Voorwoord"
    ]
  },
  {
    "objectID": "linear_01.html",
    "href": "linear_01.html",
    "title": "1  Relaties tussen Continue Variabelen",
    "section": "",
    "text": "1.1 Ter herinnering: data objecten\nWe kunnen de inhoud van een data object op verschillende manieren bekijken. Vaak gaat een dataset gepaard met een codeboek dat we kunnen inkijken, maar we kunnen ook data verder inspecteren met R. We kunnen bijvoorbeeld gewoon de naam van het data object (hier: ‘demdata’) typen om vervolgens de inhoud te printen. De ‘tibble’ transformatie maakt dit overzichtelijker:\ndemdata\n\n# A tibble: 179 × 41\n   country_name  year v2x_polyarchy v2x_libdem v2x_egaldem v2cacamps v2caviol\n   &lt;chr&gt;        &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 Mexico        2020         0.647      0.412       0.369     1.53     0.023\n 2 Suriname      2020         0.761      0.627       0.56      0.12    -0.813\n 3 Sweden        2020         0.908      0.879       0.83     -2.08    -2.37 \n 4 Switzerland   2020         0.894      0.851       0.832    -1.70    -2.66 \n 5 Ghana         2020         0.72       0.614       0.534    -0.441   -0.008\n 6 South Africa  2020         0.703      0.578       0.477     0.092    0.395\n 7 Japan         2020         0.832      0.743       0.75     -1.54    -1.95 \n 8 Myanmar       2020         0.436      0.271       0.253     0.886    1.28 \n 9 Russia        2020         0.262      0.103       0.203     0.558    0.195\n10 Albania       2020         0.485      0.409       0.358    -0.501   -0.119\n# ℹ 169 more rows\n# ℹ 34 more variables: e_peaveduc &lt;dbl&gt;, cpi &lt;dbl&gt;, e_regiongeo &lt;dbl&gt;,\n#   e_regionpol_6C &lt;dbl&gt;, v2elcomvot &lt;dbl&gt;, compulsory_voting &lt;dbl&gt;,\n#   bicameral &lt;dbl&gt;, dem_diff &lt;dbl&gt;, dem_increase &lt;dbl&gt;, dem_decrease &lt;dbl&gt;,\n#   TypeSoc2005 &lt;dbl&gt;, TypeEcon2006 &lt;dbl&gt;, HDI2005 &lt;dbl&gt;, GDP2006 &lt;dbl&gt;,\n#   TYPEDEMO1984 &lt;dbl&gt;, TYPEDEMO2007 &lt;dbl&gt;, Fragile2006 &lt;dbl&gt;,\n#   Typeregime2006 &lt;dbl&gt;, TYPEGOV2007 &lt;dbl&gt;, CPI8085 &lt;dbl&gt;, …\nDe ‘tibble’ transformatie maakt de output duidelijker. We zien nu een overzicht van de eerste variabelen in de dataset (de kolommen) en de eerste observaties (rijen).\nWe zouden ook de voorkeur kunnen geven aan een overzicht van alle variabelen in de dataset en hun kenmerken (‘attributes’). In Statistiek 1 (zie hier) werd hiervoor de str() functie gebruikt. Hier gebruiken we glimpse() als een vereenvoudigde manier om dit te doen. Het resultaat is een overzicht van alle 41 variabelen in de dataset. We doen dit hier voor een verkorte versie van de dataset om minder lange output te verkrijgen.\n#Een kleinere dataset door selectie van beperkt aantal variabelen\ndemdata_sub &lt;- demdata |&gt; \n  select(v2x_egaldem, TypeSoc2005, HDI2005, TYPEDEMO1984, gini_2019)\n\nglimpse(demdata_sub)\n\nRows: 179\nColumns: 5\n$ v2x_egaldem  &lt;dbl&gt; 0.369, 0.560, 0.830, 0.832, 0.534, 0.477, 0.750, 0.253, 0…\n$ TypeSoc2005  &lt;dbl&gt; 3, 2, 3, 3, 2, 2, 3, 2, 3, 3, 2, 2, 2, 3, 3, 3, 3, 2, 2, …\n$ HDI2005      &lt;dbl&gt; 0.829, 0.774, 0.956, 0.955, 0.553, 0.674, 0.953, 0.583, 0…\n$ TYPEDEMO1984 &lt;dbl&gt; 2, 1, 2, 2, 1, 1, 2, 1, NA, 1, 2, 1, 2, 1, 2, 2, 2, 2, 1,…\n$ gini_2019    &lt;dbl&gt; NA, NA, 26.5, 30.1, NA, NA, NA, NA, 32.5, 37.5, NA, NA, 4…\nTen slotte kunnen we de view_df() functie gebruiken uit het sjPlot package om de namen van alle variabelen te zien, hun labels (indien van toepassing), de mogelijke waarden voor deze variabelen en de labels van deze waarden (indien van toepassing). De informatie wordt in het Viewer venster (standaard rechtsonder) weergegeven. Als je klikt op “Show in new window” krijg je een grotere weergave in een tab van je browser.\nview_df(demdata_sub)\n\n\nData frame: demdata_sub\n\n\n\n\n\n\n\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\nv2x_egaldem\n\nrange: 0.0-0.9\n\n\n2\nTypeSoc2005\nType of human development, (3-cat, classified from\nHDI) (UNDP 2008)\n1\n2\n3\nLow human development\nMedium human development\nHigh human development\n\n\n3\nHDI2005\nHuman Development Index (HDI), 2005 100-pt scale\n(UNDP 2007)\nrange: 0.3-1.0\n\n\n4\nTYPEDEMO1984\nType of democracy, 1984\n1\n2\nAutocracies\nDemocracies\n\n\n5\ngini_2019\n\nrange: 22.6-48.0",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Relaties tussen Continue Variabelen</span>"
    ]
  },
  {
    "objectID": "linear_01.html#sec-recall-peeking-inside-data-objects",
    "href": "linear_01.html#sec-recall-peeking-inside-data-objects",
    "title": "1  Relaties tussen Continue Variabelen",
    "section": "",
    "text": "Output uitleg\n\n\n\nview_df() creëert output met de volgende kolommen:\n\nName: Naam van de variabele\nLabel: Label van de variabele, indien aanwezig in de dataset. Doorgaans een korte inhoudelijke beschrijving van de variabele.\nValues: Indien de variabele continu is vind je hier het minimum en maximum van de variabele in de dataset “range: X-X”. Bijvoorbeeld, de v2x_egaldem variabele reikt van 0 tot 0.9. Indien de variabele slechts enkele discrete waarden bevat, worden deze getoond (zie bv. TypeSoc2005).\nValue Labels: Sommige variabelen hebben labels voor de specifieke waarden die ze aannemen. Dit label beschrijft waar de cijferwaarde voor staat. Bijvoorbeeld, observaties met een 1 voor TYPEDEMO1984 zijn autocratieën en observaties die een 2 scoren zijn democratieën.\n\n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nview_df() is een handige functie om een overzicht van je dataset te hebben, maar als je dataset veel variabelen heeft wordt veel output geproduceerd. Voeg dus view_df(data) niet toe aan je R Markdown (.rmd) bestand wanneer je je taak inlevert. Gebruik de functie voor jezelf, maar verwijder dan deze syntax om je ingeleverde taak overzichtelijk te houden.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Relaties tussen Continue Variabelen</span>"
    ]
  },
  {
    "objectID": "linear_01.html#sec-visualizing-bivariate-relationships-with-a-scatterplot",
    "href": "linear_01.html#sec-visualizing-bivariate-relationships-with-a-scatterplot",
    "title": "1  Relaties tussen Continue Variabelen",
    "section": "1.2 Visualisatie met een scatterplot",
    "text": "1.2 Visualisatie met een scatterplot\nIn ons voorbeeld onderzoeken we de relatie tussen economische ongelijkheid en het niveau van electorale democratie in landen.\nDe variabele gini_2019 meet het niveau van economische ongelijkheid en heeft waarden tussen 0 en 100 (hogere waarden = meer ongelijkheid).1 De variabele v2x_polyarchy meet het niveau van electorale democratie in een land. De variabele is continue met een bereik tussen 0 en 1. Hogere waarden betekenen een hoger niveau van democratie.\nWe kunnen de relatie tussen deze twee continue variabelen onderzoeken met behulp van een scatterplot. Zie Hoofdstuk 8 in het Statistiek I boek voor meer informatie over ggplot(), ook over de opties om plots mooier te maken.\n\nggplot(demdata, aes(x=gini_2019, y=v2x_polyarchy)) + \n  geom_point() + \n  labs(title = \"Economische ongelijkheid en electorale democratie\", \n       x = \"Gini Coefficient (2019)\", \n       y = \"Electorale Democratie (2020)\") + \n  scale_x_continuous(breaks=seq(from=25, to=45, by=5))\n\nWarning: Removed 109 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nDe output bevat een waarschuwing: “Warning: Removed 109 rows containing missing values (`geom_point()`).”. Dit is geen reden tot zorg en komt voor omdat er observaties zijn die geen waarden hebben voor een van de variabelen of beide variabelen. Jammer genoeg geeft R wel meer waarschuwingen die weinig belang hebben.\n\n\nZo lees je bovenstaande syntax:\n\nggplot(\n\nHier vertellen we R dat we de data willen plotten met behulp van het ggplot2 package, onderdeel van het tidyverse package.\n\ndemdata\n\nDit is de naam van het data object waaruit we variabelen willen plotten. Deze naam verander je naar je eigen dataset.\n\naes(x=gini_2019, y=v2x_polyarchy)\n\nHier vertellen we R hoe de grafiek eruit moet zien (aes= “aesthetic mapping”). We plaatsen “gini_2019” op de x-as en “v2x_polyarchy” op de y-as. Het is gebruikelijk om de afhankelijke variabele op de y-as en de onafhankelijke variabele op de x-as te plaatsen.\n\ngeom_point()\n\nHier bepalen we welk plot we willen, namelijk een puntenwolk (‘point’). Elk punt op de grafiek geeft een observatie in de dataset weer. De positie van de observatie wordt bepaald door de waarden op onze twee variabelen.\n\nlabs(...)\n\nHier geven we titels aan de grafiek en assen.\n\nscale_x_continuous(breaks=seq(from=25, to=45, by=5))\n\nHier vragen we R om de x-as te laten lopen van 25 tot 45 (in lijn met de geobserveerde waarden voor gini_2019 in de dataset) en om de 5 waarden een aanduiding te maken op de as. Dit verduidelijkt de visualisatie.2\n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nIn dit voorbeeld hebben we de schaal van de x-as aangepast om een duidelijkere weergave te bekomen. Dit is niet altijd nodig, de standaard optie waarbij deze syntax-regel wordt weggelaten produceert vaak al goede resultaten. Let er ook op dat je deze syntax niet gewoon overneemt, zeker als de variabele die je op de x-as wil plotten anders geschaald is (bv. van 0 tot 10). Dit kan anders vreemde resultaten opleveren. Denk eraan bij het overnemen van syntax uit dit boek: copy, paste, en update.\n\n\nZie Paragraaf 8.2 voor verdere instructies over het maken van duidelijke scatterplots en richtlijnen om een plot te beschrijven.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Relaties tussen Continue Variabelen</span>"
    ]
  },
  {
    "objectID": "linear_01.html#covariantie",
    "href": "linear_01.html#covariantie",
    "title": "1  Relaties tussen Continue Variabelen",
    "section": "1.3 Covariantie",
    "text": "1.3 Covariantie\nIn bovenstaande figuur zagen we meer landen in de linkerbovenhoek dan in de linkeronderhoek, en meer lagere waarden voor electorale democratie naarmate we hogere waarden voor gini 2019 zien. Dit lijkt te wijzen op een negatieve relatie: landen met lage ongelijkheid scoren doorgaans hoog op democratie.\nNu gebruiken we de covariantie statistiek om de relatie tussen onze twee variabelen duidelijker te vatten en onze interpretatie van bovenstaande figuur te verifiëren. We maken gebruik van de cov() functie in R. Deze functie is ingebouwd in R en kunnen we gebruiken zonder extra packages te laden.\nWe nemen “gini_2019” als x-variabele en “v2x_polyarchy” als y-variabele in lijn met ons scatterplot. De covariantiestatistiek is echter symmetrisch en we zouden dezelfde uitkomst verkrijgen als we de variabelen zouden omdraaien.\n\ncov(x = demdata$gini_2019, \n    y = demdata$v2x_polyarchy,\n    use = \"complete.obs\")   \n\n[1] -0.560385\n\n\nDe syntax betekent het volgende:\n\ncov(\n\nDe naam van de functie. Deze wordt toegepast op de variabelen gespecificeerd tussen de haakjes.\n\nx = demdata$gini_2019,\n\nVerduidelijkt dat we de “gini_2019” variabele uit het data object “demdata” als x-variabele willen we beschouwen.\n\ny = demdata$v2x_polyarchy,\n\nVerduidelijkt dat we de “v2x_polyarchy” variabele uit het data object “demdata” als y-variabele willen we beschouwen.\n\nuse= \"complete.obs\")\n\nHier verduidelijken we dat we enkel observaties met non-missing waarden in de berekening willen meenemen.\n\n\nDe covariantie is -0.56. Dit is in lijn met onze interpretatie van het scatterplot. Er is een negatieve relatie tussen onze variabelen, hogere waarden voor ongelijkheid zijn doorgaans geassocieerd met lagere waarden voor democratie.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Relaties tussen Continue Variabelen</span>"
    ]
  },
  {
    "objectID": "linear_01.html#sec-correlation-coefficients",
    "href": "linear_01.html#sec-correlation-coefficients",
    "title": "1  Relaties tussen Continue Variabelen",
    "section": "1.4 Correlaties",
    "text": "1.4 Correlaties\nWe kunnen ook de correlatiecoëfficiënt gebruiken om de relatie tussen onze continue variabelen te onderzoeken. De correlatie is een gestandaardiseerde maatstaf in tegenstelling tot de covariantie.\nEr bestaan meerdere correlatiecoëfficiënten. Doorgaans gebruiken we de Pearson correlatiecoëfficiënt voor continue variabelen (vaak aangeduid met een schuine letter r: \\(r\\)). We maken gebruik van de cor.test() functie, die ingebouwd is in R.3 Ook de correlatie is een symmetrische maatstaf. Je krijgt dus dezelfde uitkomst wanneer je de x en y-variabelen zou omdraaien.\n\ncor.test(x = demdata$gini_2019, \n         y = demdata$v2x_polyarchy, \n         method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  demdata$gini_2019 and demdata$v2x_polyarchy\nt = -3.0433, df = 68, p-value = 0.003325\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.5374741 -0.1211040\nsample estimates:\n       cor \n-0.3462257 \n\n\nZo lees je de syntax:\n\ncor.test(\n\nDe naam van de functie. Deze wordt toegepast op de variabelen gespecificeerd tussen de haakjes.\n\nx = demdata$gini_2019\n\nVerduidelijkt dat we de “gini_2019” variabele uit het data object “demdata” als x-variabele willen we beschouwen.\n\ny = demdata$v2x_polyarchy\n\nVerduidelijkt dat we de “v2x_polyarchy” variabele uit het data object “demdata” als y-variabele willen we beschouwen.\n\nmethod = \"pearson\")\n\nVertelt R dat we de Pearson correlatiecoëfficiënt willen gebruiken. We kunnen een andere methode vragen door bijvoorbeeld “method = spearman” te typen.\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nIn R toont de output het volgende:\n\n‘t =’: de t-waarde of t-statistiek van de correlatie\n‘df =’: de vrijheidsgraden (‘degrees of freedom’)\n‘p-value =’: de p-waarde voor de schatting (i.e., de kans dat we deze of een grotere t-waarde zouden uitkomen als de nulhypothese (correlatiecoëfficënt is in werkelijkheid gelijk aan 0) waar zou zijn en de assumpties van het model correct zijn).\n‘95 percent confidence interval:’: het 95% betrouwbaarheidsinterval voor de correlatiecoëfficiënt\n‘cor’: de correlatiecoëfficiënt\n\n\n\nDe correlatiecoëfficiënt is hier -0.35 (afgerond op 2 decimalen). Hoe interpreteren we dit cijfer?\n\n\n\n\n\n\nInterpretatie\n\n\n\nCorrelatiecoëfficiënten liggen tussen -1 en +1, waarbij:\n\n-1 = een perfect negatieve lineaire relatie. Alle observaties vallen op een neerwaarts lopende lijn in een scatterplot.\n0 = geen lineaire relatie\n+1 = een perfect positieve lineaire relatie. Alle observaties vallen op een opwaarts lopende lijn in een scatterplot.\n\nEen positieve relatie houdt in dat 1 variabele stijgt als de andere stijgt. Een negatieve relatie betekent dat 1 variabele verwacht wordt te dalen als de andere variabele stijgt.\nCorrelatiecoëfficiënten geven naast de richting ook de sterkte van een relatie aan. De volgende vuistregels, gebaseerd op Cohen (1988), worden vaak gebruikt:\n\nr \\(&lt;\\) 0.1: Heel klein\n0.1 \\(&lt;=\\) 0.3: Klein\n0.3 \\(&lt;=\\) 0.5: Gemiddeld\nr \\(&gt;=\\) 0.5: Groot\n\nIn ons voorbeeld is de correlatie gemiddeld.\nTen slotte: De bovenstaande vuistregels helpen bij het interpreteren van de correlatiecoëfficiënt (en zijn voldoende voor dit vak). Besprekingen in papers moeten doorgaans diepgaander zijn (bv. sterk in vergelijking met andere studies, andere effecten enz.).\n\n\n\nCohen, Jacob. 1988. Statistical power analysis for the behavioral sciences. 2nd dr. Hillsdale, NJ: Erlbaum Associates.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Relaties tussen Continue Variabelen</span>"
    ]
  },
  {
    "objectID": "linear_01.html#bivariate-lineaire-regressie",
    "href": "linear_01.html#bivariate-lineaire-regressie",
    "title": "1  Relaties tussen Continue Variabelen",
    "section": "1.5 Bivariate lineaire regressie",
    "text": "1.5 Bivariate lineaire regressie\nDe laatste manier waarop we de bivariate relatie tussen twee continue (interval/ratio) variabelen kunnen onderzoeken is met een bivariaat regressiemodel.4.\nHier gebruiken we wederom electorale democratie als afhankelijke variabele en gini als onafhankelijke variabele. In dit geval is welke variabele we als afhankelijke en welke we als onafhankelijke beschouwen sterk bepalend voor het resultaat.\n\n1.5.1 Analyse en output\n\nm1 &lt;- lm(v2x_polyarchy ~ gini_2019, data = demdata)\n\nDe syntax lees je als volgt:\n\nm1 &lt;-\n\nWe kiezen hier de naam voor ons model: ‘m1’. Dit kun je veranderen voor eigen doeleinden. R zal de resultaten van onze regressieanalyse opslaan in een object met deze naam. In principe hoef je de resultaten niet in een data object op te slaan, maar dit is wel gebruikelijk omdat we de resultaten vaak verder gebruiken en we dan naar dit object kunnen verwijzen.\n\nlm(\n\nDit is de functie voor lineaire regressie: lm = linear (regression) model.\n\nv2x_polyarchy ~ gini_2019,\n\nDe variabele links van de tilde (“~”) is de afhankelijke variabele. Rechts vinden we de onafhankelijke variabele.\n\ndata = demdata)\n\nHier verduidelijken we welke dataset gebruikt wordt (in dit geval demdata). Dit gedeelte komt altijd aan het einde.\n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nEr is een belangrijk verschil tussen cor.test()/cov() enerzijds en lm()anderzijds. Bij de ene kun je de x en y variabelen omwisselen en dezelfde uitkomst verkrijgen, bij lm kan dit niet. De beslissing over welke variabele je afhankelijke is bij lineaire regressie, is dus belangrijk.\n\n\nWe kunnen de resultaten bekijken door de naam van ons model in de console te typen en enter te drukken:\n\nm1\n\n\nCall:\nlm(formula = v2x_polyarchy ~ gini_2019, data = demdata)\n\nCoefficients:\n(Intercept)    gini_2019  \n    1.06031     -0.01186  \n\n\nDit geeft ons de regressiecoëfficiënten voor de constante en de onafhankelijke variabele. De informatie die we krijgen is zeer beperkt.5 Het is gebruikelijker om de output te bekijken met de summary() functie aangezien deze meer informatie geeft:\n\nsummary(m1)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ gini_2019, data = demdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5389 -0.1502  0.0903  0.1668  0.3965 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.060311   0.136512   7.767  5.8e-11 ***\ngini_2019   -0.011859   0.003897  -3.043  0.00333 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2225 on 68 degrees of freedom\n  (109 observations deleted due to missingness)\nMultiple R-squared:  0.1199,    Adjusted R-squared:  0.1069 \nF-statistic: 9.262 on 1 and 68 DF,  p-value: 0.003325\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nIn R toont de output het volgende:\n\n“Call”: Het regressiemodel dat geschat is.\n“Residuals”: Informatie over de residuals van het model (behandeld in verdere hoofdstukken).\n“Coefficients”: Dit zijn de regressiecoëfficiënten voor het model, waaronder…\n\nEstimate: De coëfficiënt voor elke term in het model. Bv. voor de constante (“(Intercept)” = 1.060311) en de onfahankelijke variabele (“gini_2019” = -0.0118\nStd. Error: de standaardfout van de coëfficiënt\nt value: De t-waarde of t-statistiek van de coëfficiënt\nPr(&gt;|t|): De p-waarde die bij de t-statistiek hoort. Voor meer informatie, zie Hoofdstuk 3 .\n\nHet onderste gedeelte van de output gaan over de ‘fit’ van het model, behandeld in Hoofdstuk 6 .\n\n\n\nDe coëfficiënt voor economische ongelijkheid was negatief, net zoals de covariantie en correlatie. Alle drie vatten de statistieken op hun manier de negatieve lineaire relatie tussen de variabelen.\n\n\n\n\n\n\nInterpretatie\n\n\n\nDe Estimate kolom bevat de waarden voor de coëfficiënten van het model:\n\n(Intercept): Wat is de verwachte waarde voor de afhankelijke variabele als de onafhankelijke variabele in het model de waarde 0 aanneemt? Hier vinden we dat bij 0 ongelijkheid, de verwachte democratiescore gelijk is aan 1.06. Het intercept (of de constante) is niet altijd realistisch, bijvoorbeeld wanneer een predictor 0 niet kan aannemen in de praktijk of wanneer de schatting van de afhankelijke het werkelijke bereik ervan overschrijdt (democratiescores gemeten hier hebben een minimum van 0 en een maximum van 1)\nCoëfficiënten voor continue onafhankelijke variabelen (bv. gini_2019): De coëfficiënt geeft de verwachte verandering in de afhankelijke variabele Y weer wanneer de onafhankelijke variabele X met 1 eenheid stijgt. Hier zien we dat electorale democratie verwacht wordt met-0.01 punten te dalen als ongelijkheid met 1 punt stijgt. Zie Paragraaf 8.4 voor meer informatie over rapportage in taken en papers.\n\nDe coëfficiënt voor gini_2019 is -0.01. Wat wil dit zeggen over de sterkte van het effect? Regressiecoëfficiënten zijn niet gestandaardiseerd zoals de correlatiecoëfficiënt dus zijn er geen vuistregels te hanteren. In latere hoofdstukken bespreken we gestandaardiseerde regressiecoëfficiënten Paragraaf 4.2 en voorspelde waarden Hoofdstuk 5). Deze kunnen helpen bij de interpretatie over de sterkte van het effect, maar (zoals bij de correlatie) zal een bespreking van de sterkte ook in moeten gaan op andere studies, de context etc.\n\n\n\n\n1.5.2 Regressielijn in een scatterplot\nDe regressielijn wordt vaak toegevoegd aan een scatterplot. Dit kunnen we als volgt doen:\n\nggplot(demdata, aes(x = gini_2019, y = v2x_polyarchy)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  labs(title = \"Economische ongelijkheid en electorale democratie\", \n       x = \"Gini Coëfficiënt (2019)\", \n       y = \"Electorale Democratie (2020)\") +  \n  scale_x_continuous(breaks = seq(from = 25, to = 45, by = 5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 109 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 109 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nDe syntax is dezelfde als voor ons eerdere scatteplot met één toevoeging:\n\ngeom_smooth(method = \"lm\") +\n\nHier vragen we R om een lijn toe te voegen die de relatie tussen de twee variabelen weergeeft. We vragen hier specifiek om de lineaire regressielijn via method = \"lm\". We krijgen een lijn en ook het betrouwbaarheidsinterval voor de schatting in het grijs.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Relaties tussen Continue Variabelen</span>"
    ]
  },
  {
    "objectID": "linear_01.html#footnotes",
    "href": "linear_01.html#footnotes",
    "title": "1  Relaties tussen Continue Variabelen",
    "section": "",
    "text": "Het theoretische bereik van de variabele is van 0 tot 100, maar in de praktijk observeren we enkel waarden tussen 22.6 en 48.↩︎\nJe kunt meer leren over de seq() command als je ?seq() typt in de console en enter tikt.↩︎\nAls je meerdere correlatiecoëfficiënten tegelijkertijd wil onderzoeken zou je het correlation package kunnen gebruiken (webpage). Je hebt dit package echter niet nodig voor deze cursus.↩︎\nZoals we verder in de cursus zien kunnen we ook binaire/categorische onafhankelijke variabelen gebruiken om een continue variabele te voorspellen in een lineaire regressie.↩︎\nWe kunnen de coëfficiënten ook opvragen met de coef() functie. Bijvoorbeeld: “coef(m1)” zou ons ook gewoon de coëfficiënten geven. In verdere hoofdstukken zullen we nog een functie zien om de output te bekijken: de tidy() functie uit het broom package.↩︎",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Relaties tussen Continue Variabelen</span>"
    ]
  },
  {
    "objectID": "linear_02.html",
    "href": "linear_02.html",
    "title": "2  Bivariate Regressie met Binaire en Categorische Predictoren",
    "section": "",
    "text": "2.1 Data Management: Converteren naar een factor variabele\nVia lineaire regressieanalyse kunnen we een continue afhankelijke variabele ook voorspellen aan de hand van binaire (2 waarden) en categorische (3 of meer waarden) variabelen.\nOm deze variabelen te gebruiken in een regressiemodel moeten ze toegevoegd worden als dichotome of “dummy” variabelen. Als de variabele binair is, wordt 1 dummy gebruikt, als de variabelen meer categorieën kent, worden meerdere dummies gebruikt.1 R voegt automatisch dummies toe voor factor variabelen, dus transformeren we binaire en categorische variabelen naar factor variabelen voor we ze in een regressie analyse gebruiken.2\nIn dit voorbeeld maken we gebruik van de variabele “TYPEDEMO1984”. Deze binaire variabele toont of een land een democratie of autocratie was in het jaar 1984. De variabele is numeriek opgeslagen (dit kunnen we controleren met behulp van de functie class()). De waarde 1 staat voor autocratie, de waarde 2 voor democratie.\n#Informatie over type variabele: \nclass(demdata$TYPEDEMO1984)\n\n[1] \"numeric\"\n\n#simpele tabel\ntable(demdata$TYPEDEMO1984)\n\n\n 1  2 \n86 57\nAangezien de variabele numeriek is, transformeren we deze eerst naar een factor variabele. We kunnen dit doen met de ingebouwde factor() functie (zie Statistiek I, 1.6.3) of met de factorize() functie afkomstig uit het rio package. Deze laatste functie is vooral handig als de waarden labels hebben zoals hier het geval is ( 1 = “Autocratie”, 2 = “Democratie”). Als er geen labels zijn, moet je factor() gebruiken gezien factorize() in dat geval niet de juiste uitkomsten geeft. Zie Paragraaf A.2 voor meer informatie.\nDe labels kun je zien met behulp van de view_df() functie uit het sjPlot package (zie Paragraaf 1.1) of door gebruik te maken van de ingebouwde functie attributes() (vooraleer je transformeert naar factor): attributes(demdata$TYPEDEMO1984). Daarbij kijk je of er informatie is waar “$labels” staat.\nattributes(demdata$TYPEDEMO1984)\n\n$label\n[1] \"Type of democracy, 1984\"\n\n$format.stata\n[1] \"%10.0g\"\n\n$labels\nAutocracies Democracies \n          1           2\nWe gebruiken factorize() gezien de waarden van onze variabelen labels hebben (1 = “Autocratie”, 2 = “Democratie”). We kijken ook na of de functie gelukt is.\n# transformeren naar factor\ndemdata &lt;- demdata |&gt; \n  mutate(TYPEDEMO1984_factor = factorize(TYPEDEMO1984))\n\n#Niveaus (levels) bekijken en tabel om te checken\nlevels(demdata$TYPEDEMO1984_factor)\n\n[1] \"Autocracies\" \"Democracies\"\n\ntable(demdata$TYPEDEMO1984_factor)\n\n\nAutocracies Democracies \n         86          57\nDe syntax is eenvoudig:\nDezelfde procedure wordt gehanteerd voor een categorische variabele met 3 of meer categorieën. Bijvoorbeeld, de variabele Typeregime2006 geeft weer of een land een liberale democratie was (=1), een electorale democratie (=2), of een autocratie (=3) in het jaar 2006. Deze variabele heeft ook waarden-labels dus kunnen we opnieuw factorize() gebruiken:\n#transformeer naar factor variabele\ndemdata &lt;- demdata |&gt; \n  mutate(Typeregime2006_factor = factorize(Typeregime2006))\n\n#Werk checken\nlevels(demdata$Typeregime2006_factor)\n\n[1] \"Liberal democracy\"   \"Electoral democracy\" \"Autocracy\"          \n\ntable(demdata$Typeregime2006_factor)\n\n\n  Liberal democracy Electoral democracy           Autocracy \n                 71                  53                  41",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Bivariate Regressie met Binaire en Categorische Predictoren</span>"
    ]
  },
  {
    "objectID": "linear_02.html#data-management-converteren-naar-een-factor-variabele",
    "href": "linear_02.html#data-management-converteren-naar-een-factor-variabele",
    "title": "2  Bivariate Regressie met Binaire en Categorische Predictoren",
    "section": "",
    "text": "factorize(\n\nNaam van de functie die wordt toegepast op de variabele tussen haakjes.\n\nTYPEDEMO1984\n\nAangeduide variabele. Het laagste numerieke niveau van deze variabele zal als eerste niveau van de factor gebruikt worden en dus als referentiecategorie.\n\n\n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nWe raden aan om nieuwe variabelen aan te maken wanneer je een bestaande variabele omzet naar een factorvariabele (of wanneer je hercodeert) zoals hiervoven (bv., mutate(TYPEDEMO1984_factor = factorize(TYPEDEMO1984))). Als je een nieuwe variabele aanmaakt, overschrijf je nooit de originele. Dit kan helpen om fouten makkelijker te corrigeren (zonder dat je dataset opnieuw moet inladen en eerdere syntax runnen).\n\n\n\n2.1.1 Veranderen van de referentiecategorie\nfactorize() gebruikt de eerste numerieke waarde als referentiegroep bij het maken van een factorvariabele. factor() doet dit ook, tenzij we expliciet de volgorde van de factorniveaus (levels) aanduiden in de syntax (zie het voorbeeld in Paragraaf A.2).\nIn elk geval kunnen we de referentiecategorie veranderen als we dat willen. Dit kunnen we doen met behulp van de relevel() functie. Hieronder veranderen we de referentiecategorie voor “Typeregime2006_factor” naar “Electoral Democracy”.\n\ndemdata &lt;- demdata |&gt; \n  mutate(Typeregime2006_factor_relevel = relevel(Typeregime2006_factor, \"Electoral democracy\"))\n\n\nrelevel(\n\nNaam van de functie\n\nTyperegime2006_factor,\n\nWe gebruiken “Typeregime2006_factor” uit de “demdata” dataset.\n\n\"Electoral democracy\")\n\nWe geven de naam op van de categorie die we als referentiecategorie willen nemen tussen dubbele aanhalingstekens. We gebruiken de naam tussen aanhalingstekens omdat de variabele reeds hierboven naar een factor is omgezet, anders zou dit niet werken.\n\n\nWe checken altijd beter of alles goed is gegaan:\n\n#Checken:\nlevels(demdata$Typeregime2006_factor)\n\n[1] \"Liberal democracy\"   \"Electoral democracy\" \"Autocracy\"          \n\nlevels(demdata$Typeregime2006_factor_relevel)\n\n[1] \"Electoral democracy\" \"Liberal democracy\"   \"Autocracy\"",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Bivariate Regressie met Binaire en Categorische Predictoren</span>"
    ]
  },
  {
    "objectID": "linear_02.html#factor-variabelen-als-predictoren",
    "href": "linear_02.html#factor-variabelen-als-predictoren",
    "title": "2  Bivariate Regressie met Binaire en Categorische Predictoren",
    "section": "2.2 Factor variabelen als predictoren",
    "text": "2.2 Factor variabelen als predictoren\nWe voegen binaire en categorische onafhankelijke variabelen toe aan de regressieanalyse op dezelfde manier als bij continue variabelen:\n\n# Met binaire predictor: \nmodel_binary &lt;- lm(v2x_polyarchy ~ TYPEDEMO1984_factor, data=demdata)\nsummary(model_binary)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ TYPEDEMO1984_factor, data = demdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.51025 -0.15007 -0.00857  0.17309  0.48543 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                     0.41757    0.02333   17.90  &lt; 2e-16 ***\nTYPEDEMO1984_factorDemocracies  0.27268    0.03695    7.38 1.25e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2163 on 141 degrees of freedom\n  (36 observations deleted due to missingness)\nMultiple R-squared:  0.2786,    Adjusted R-squared:  0.2735 \nF-statistic: 54.47 on 1 and 141 DF,  p-value: 1.247e-11\n\n# Met categorische predictor: \nmodel_categorical &lt;- lm(v2x_polyarchy ~ Typeregime2006_factor, data=demdata)\nsummary(model_categorical)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ Typeregime2006_factor, data = demdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.40104 -0.09898  0.00196  0.10773  0.47773 \n\nCoefficients:\n                                         Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)                               0.75404    0.01734   43.48   &lt;2e-16\nTyperegime2006_factorElectoral democracy -0.32106    0.02653  -12.10   &lt;2e-16\nTyperegime2006_factorAutocracy           -0.50577    0.02866  -17.64   &lt;2e-16\n                                            \n(Intercept)                              ***\nTyperegime2006_factorElectoral democracy ***\nTyperegime2006_factorAutocracy           ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1461 on 162 degrees of freedom\n  (14 observations deleted due to missingness)\nMultiple R-squared:  0.6789,    Adjusted R-squared:  0.6749 \nF-statistic: 171.2 on 2 and 162 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nDe output van een model met binaire/categorische predictor is dezelfde als die van een model met een continue predictor met 1 verschil. R zal de variabelenaam bij de coëfficiënten anders weergeven als er een factor variabele is. Dan krijg je de naam van de variabele, onmiddellijk gevolgd door de categorie die de waarde 1 aanneemt in de dummy. Bijvoorbeeld: “TypeDemo1984_factorDemocracies” or “Typeregime2006_factorAutocracy.”\n\n\nEr zijn subtiele verschillen in de interpretatie als een factor variabele opgenomen wordt in het model:\n\n\n\n\n\n\nInterpretatie\n\n\n\nDe Estimate kolom toont de coëfficiënten van het regressiemodel.\nHet”(Intercept)” toont nog steeds de verwachte waarde op de afhankelijke variabele als de onafhankelijke variabele gelijk is aan 0. Als de enige onafhankelijke variabele een factor is dan toont het intercept de gemiddelde waarde op Y voor de referentiegroep (factor dummy = 0).\nHier vinden we dat de gemiddelde waarde voor v2x_polyarchy voor autocratieën (gemeten volgens de TYPEDEMO1984_factor variabele) gelijk is aan het Intercept dat we hierboven vonden.\n\ndemdata |&gt; \n1  filter(TYPEDEMO1984_factor == \"Autocracies\") |&gt;\n  summarize(mean_democracy = mean(v2x_polyarchy, na.rm=T)) |&gt; \n2  as.data.frame()\n\n\n1\n\nDe filter verwijdert observaties die niet de waarde “Autocracies” hebben voor TYPEDEMO1984_factor\n\n2\n\nDeze optie dwingt R om alle decimalen weer te geven voor een betere vergelijking met het Intercept.\n\n\n\n\n  mean_democracy\n1      0.4175698\n\n\nDe coëfficiënten voor binaire en categorische variabelen worden best gezien als het verschil in de gemiddelde score voor Y tussen de referentiecategorie en andere categorieën. De coëfficiënt voor “TYPEDEMO1984_factorDemocracies” is bijvoorbeeld 0.2726758.3 Dit betekent dat de gemiddelde score op Y voor democratieën 0.2726758 schaalpunten groter is dan de gemiddelde waarde voor autocratieën (de referentiecategorie).\nWe kunnen dit wiskundig nagaan:\n\n# Gemiddelde voor democratieën\ndemdata |&gt; \n  group_by(TYPEDEMO1984_factor) |&gt; \n  summarize(mean_democracy = mean(v2x_polyarchy, na.rm = T)) |&gt;\n  as.data.frame() \n\n  TYPEDEMO1984_factor mean_democracy\n1         Autocracies      0.4175698\n2         Democracies      0.6902456\n3                &lt;NA&gt;      0.4638056\n\n# gemiddelde democratieën - gemiddelde autocratieën\n 0.6902456 - 0.4175698\n\n[1] 0.2726758\n\n\nHetzelfde geldt voor categorische factorvariabelen. De “(Intercept)” waarde in model_categorical is de gemiddelde waarde voor de observaties in de referentiecategorie (hier: “Liberal Democracy”). De coefficiënten tonen hoe de andere groepen verschillen van dit gemiddelde. De gemiddelde 2020 democratiescore voor landen die in 2006 een “Electoral Democracy” waren is -0.32 schaalpunten lager dan de gemiddelde 2020 democratiescore voor de “Liberal Democracy” referentiegroep.\n\ndemdata |&gt; \n  group_by(Typeregime2006_factor) |&gt; \n  summarize(mean_democracy = mean(v2x_polyarchy, na.rm=T)) |&gt; \n  as.data.frame() \n\n  Typeregime2006_factor mean_democracy\n1     Liberal democracy      0.7540423\n2   Electoral democracy      0.4329811\n3             Autocracy      0.2482683\n4                  &lt;NA&gt;      0.3777143\n\n# gemiddelde Elec Democracy - gemiddelde in Lib Democracy\n0.4329811 - 0.7540423\n\n[1] -0.3210612\n\n# gemiddelde in Autocracy - gemiddelde in Lib Democracy\n0.2482683 - 0.7540423\n\n[1] -0.505774\n\n\nZie Paragraaf 8.4 voor verdere informatie over hoe de resultaten te presenteren in taken en papers.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Bivariate Regressie met Binaire en Categorische Predictoren</span>"
    ]
  },
  {
    "objectID": "linear_02.html#footnotes",
    "href": "linear_02.html#footnotes",
    "title": "2  Bivariate Regressie met Binaire en Categorische Predictoren",
    "section": "",
    "text": "We gebruiken k-1 dummies, waarbij k = aantal categorieën. Als een categorische variabele 4 categorieën heeft (Bijvoorbeeld: Noorden, Westen, Zuiden en Oosten), dan gebruiken we (4-1=) 3 dummies.↩︎\nTransformatie is niet nodig als de originele variabelen reeds opgeslaan zijn als factor in de dataset, maar misschien moet de referentiecategorie wel aangepast worden (zie verder).↩︎\nNormaal ronden we af op 2 of 3 decimalen, maar hier tonen we de hele coëfficiënt zodat deze beter vergeleken kan worden met het verschil tussen de gemiddelden.↩︎",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Bivariate Regressie met Binaire en Categorische Predictoren</span>"
    ]
  },
  {
    "objectID": "linear_03.html",
    "href": "linear_03.html",
    "title": "3  Statistische Significantie",
    "section": "",
    "text": "3.1 t- en p-waarden via summary()\nDe meeste relevant informatie over statistische significantie en onzekerheid vinden we met de summary() functie.\n#Schat model en sla op in object\nmodel_binary &lt;- lm(v2x_polyarchy ~ TYPEDEMO1984_factor, data=demdata)\n\n#Gebruik summary om de resultaten te bekijken\nsummary(model_binary)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ TYPEDEMO1984_factor, data = demdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.51025 -0.15007 -0.00857  0.17309  0.48543 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                     0.41757    0.02333   17.90  &lt; 2e-16 ***\nTYPEDEMO1984_factorDemocracies  0.27268    0.03695    7.38 1.25e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2163 on 141 degrees of freedom\n  (36 observations deleted due to missingness)\nMultiple R-squared:  0.2786,    Adjusted R-squared:  0.2735 \nF-statistic: 54.47 on 1 and 141 DF,  p-value: 1.247e-11\nDoorgaans gaan we statistische significantie na door te kijken naar de symbolen naast de waarden in de Pr(&gt;|t|) kolom. Zie Paragraaf 8.4 voor verdere informatie over hoe hierover te rapporteren.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Statistische Significantie</span>"
    ]
  },
  {
    "objectID": "linear_03.html#t--en-p-waarden-via-summary",
    "href": "linear_03.html#t--en-p-waarden-via-summary",
    "title": "3  Statistische Significantie",
    "section": "",
    "text": "Output uitleg\n\n\n\nInformatie over onzekerheid van de schattingen en statistische significantie vinden we in het gedeelte met de coëfficiënten.\n\nStd. Error: Standaardfout van de coëfficiënt\nt value: De t-waarde of t-statistiek voor de coëfficiënt (\\(t = \\frac{\\textrm{Coefficient}}{\\textrm{Std.Error}}\\))\nPr(&gt;|t|): De p-waarde voor de t-statistiek- de probabiliteit dat we deze t-waarde of een grotere krijgen als we ervanuit gaan dat de nulhypothese van geen effect correct is en de assumpties voldaan zijn.\nAsterisken en Signif. codes: Je kunt deze symbolen zien naast de waarde onder Pr(&gt;|t|), indien van toepassing. Ze geven weer of de coëfficiënt significant is en zo ja, op welk niveau. De “Signif. codes” rij legt uit waar de codes voor staan. Een enkele asterisk (*), bijvoorbeeld, toont dat de p-waarde kleiner is dan 0.05 maar groter dan 0.01. Twee asterisks (**) vertelt dat de p-waarde kleiner is dan 0.01 maar groter dan 0.001.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Statistische Significantie</span>"
    ]
  },
  {
    "objectID": "linear_03.html#betrouwbaarheidsintervallen-via-tidy",
    "href": "linear_03.html#betrouwbaarheidsintervallen-via-tidy",
    "title": "3  Statistische Significantie",
    "section": "3.2 Betrouwbaarheidsintervallen via tidy()",
    "text": "3.2 Betrouwbaarheidsintervallen via tidy()\nDe output die we verkrijgen met summary() geeft ons niet de 95% betrouwbaarheidsintervallen voor de coëfficiënten. Deze kunnen we verkrijgen met de tidy() functie vanuit het broom package (geladen aan het begin van dit hoofdstuk).\n\ntidy(model_binary, conf.int = TRUE)\n\n# A tibble: 2 × 7\n  term                  estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)              0.418    0.0233     17.9  4.02e-38    0.371     0.464\n2 TYPEDEMO1984_factorD…    0.273    0.0369      7.38 1.25e-11    0.200     0.346\n\n\n\ntidy(\n\nNaam van de functie, toegepast op model tussen haakjes.\n\nmodel_binary,\n\nNaam van het model.\n\nconf.int=TRUE)\n\nHier vragen we om de betrouwbaarheidsintervallen op te nemen in de output. Dit wordt niet standaard gedaan. We kunnen ook “conf.int=T” schrijven (“T” = “TRUE”).\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nDe tidy() functie geeft ons een tabel met resultaten van het model.\n\nterm: De termen in het model (i.e., intercept en onafhankelijke variabelen).\nestimate: coëfficiënt voor elke variabele (en voor het intercept)\nstd.error: de standaardfout voor de coëfficiënten\nstatistic: de t-waarde\np.value: de p-waarde\nconf.low & conf.high: de 95% betrouwbaarheidsintervallen met onder “conf.low” de ondergrens en onder “conf.high” de bovengrens van het interval\n\n\n\nWe kunnen het betrouwbaarheidsniveau aanpassen. Als we het 99% betrouwbaarheidsniveau willen, voegen we bijvoorbeeld “conf.level = 0.99” toe:\n\ntidy(model_binary, conf.int = T, conf.level = 0.99)\n\n# A tibble: 2 × 7\n  term                  estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)              0.418    0.0233     17.9  4.02e-38    0.357     0.478\n2 TYPEDEMO1984_factorD…    0.273    0.0369      7.38 1.25e-11    0.176     0.369\n\n\nZowel summary() als tidy() geven ons de coëfficiënten van het model. Een voordeel van tidy() is dat de output in een tidy dataframe wordt weergegeven. Dit dataframe kunnen we manipuleren (bv. hernoemen kolommen, variabelen enz.). Hier maken we in latere lessen gebruik van.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Statistische Significantie</span>"
    ]
  },
  {
    "objectID": "linear_04.html",
    "href": "linear_04.html",
    "title": "4  Meervoudige Lineaire Regressie",
    "section": "",
    "text": "4.1 Uitvoeren van de meervoudige lineaire regressie\nIn dit voorbeeld voorspellen we het niveau van electorale democratie in een land (v2x_polyarchy) aan de hand van 3 onafhankelijke variabelen (2 continue en 1 binair):\nVoor we de regressie kunnen uitvoeren, moeten we eerst de binaire variabele transformeren naar een factor:\n#omzetten naar factor variabele\ndemdata &lt;- demdata |&gt; \n  mutate(TYPEDEMO1984_factor = factorize(TYPEDEMO1984))\nVoor meervoudige regressie gebruiken we ook de lm() functie. We kunnen meerdere onafhankelijke variabelen toevoegen met een ‘+’ teken:\n#Model schatten en opslaan in data-object \nmodel_multiple &lt;- lm(v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984_factor, \n                     data=demdata)\nDe resultaten bekijken we via summary():\nsummary(model_multiple)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984_factor, \n    data = demdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.56402 -0.09376  0.01442  0.12926  0.34206 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                     0.187394   0.042634   4.395 2.19e-05 ***\ncpi                             0.006365   0.001059   6.012 1.55e-08 ***\nv2caviol                       -0.008724   0.012258  -0.712    0.478    \nTYPEDEMO1984_factorDemocracies  0.152698   0.034915   4.373 2.39e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1807 on 138 degrees of freedom\n  (37 observations deleted due to missingness)\nMultiple R-squared:  0.5068,    Adjusted R-squared:  0.4961 \nF-statistic: 47.26 on 3 and 138 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Meervoudige Lineaire Regressie</span>"
    ]
  },
  {
    "objectID": "linear_04.html#sec-performing-a-multiple-linear-regression",
    "href": "linear_04.html#sec-performing-a-multiple-linear-regression",
    "title": "4  Meervoudige Lineaire Regressie",
    "section": "",
    "text": "cpi: CPI staat voor “corruption perception index” en meet de mate van corruptie in de publieke sector van een land. Hogere waarden staan voor minder corruptie.\nv2caviol: De variabele meet de mate van politiek geweld uitgevoerd door niet-statelijke actoren. Hogere waarden betekenen meer geweld.\nTYPEDEMO1984: Binaire variabele die meet of een land in 1984 een democratie of autocratie was.\n\n\n\n\n\n\nmultiple &lt;-\n\nWe slaan de resultaten op in een data object dat we ‘multiple’ noemen. Deze naam kun je zelf bepalen.\n\nlm(v2x_polyarchy ~)\n\nWe voeren een lineaire regressie uit met de afhankelijke variabele “v2x_polyarchy”. Deze plaatsen we links van de tilde (~).\n\ncpi + v2caviol + TYPEDEMO1984,\n\nDe onafhankelijke variabelen worden rechts van de tilde toegevoegd, van elkaar gescheiden door een ‘+’ teken. De volgorde maakt geen verschil voor de resultaten (wel de volgorde van de coëfficiënten in de output).\n\ndata = demdata)\n\nDe naam van de dataset komt aan het einde van de syntax.\n\n\n\n\n\n\n\n\n\n\nInterpretatie\n\n\n\nDe interpretatie van de coëfficiënten is gelijkaardig aan die van bivariate modellen, maar we moeten wel de inclusie van meerdere predictoren in rekening brengen.\nDe “(Intercept)” waarde geeft weer welke waarde we kunnen verwachten voor de afhankelijke variabele als alle onafhankelijke variabelen de waarde 0 aannemen. We verwachten op basis van het model dat een land met score 0 op zowel cpi, v2caviol, als TYPEDEMO1984 (de referentiecategorie, namelijk een autocratie in 1984) gemiddeld een score op electorale democratie in 2020 van 0.19 zal hebben.\nDe coëfficiënten van de onafhankelijke variabelen vertellen ons nog steeds welke verandering we verwachten in de afhankelijke variabele als de predictor met 1 eenheid stijgt. Nu wordt dit effect echter “gecontroleerd op” de andere predictoren in het model. Het effect geldt als de andere variabelen constant worden gehouden (‘ceteris paribus’). Bijvoorbeeld:\n\nv2caviol: Op basis van het model verwachten we dat electorale democratiescores dalen met -0.01 eenheden als politiek geweld met 1 eenheid stijgt, met de effecten van regimestatus in 1984 en corruptie constant gehouden.\nTYPEDEMO1984_factor: Als we landen met dezelfde corruptie en politieke geweldscores vergelijken, verwachten we dat de electorale democratiescore in 2020 0.15 eenheden hoger is voor landen die in 1984 democratieën waren dan landen die autocratieën waren.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Meervoudige Lineaire Regressie</span>"
    ]
  },
  {
    "objectID": "linear_04.html#sec-standardized-coefficients",
    "href": "linear_04.html#sec-standardized-coefficients",
    "title": "4  Meervoudige Lineaire Regressie",
    "section": "4.2 Gestandaardiseerde coëfficiënten",
    "text": "4.2 Gestandaardiseerde coëfficiënten\nWe kunnen in plaats van de ongestandaardiseerde coëfficiënten ook de gestandaardiseerde coëfficiënten berekenen. We kunnen hiervoor de standardize_parameters() functie gebruiken uit het parameters package.\n\nmultiple_std &lt;- standardize_parameters(model_multiple, \n                       method = \"refit\")\n\nDe syntax lees je zo:\n\nmultiple_std &lt;-\n\nWe slaan de resultaten op in een nieuw data object “multiple_std”.\n\nstandardize_parameters(multiple,\n\nWe passen de functie toe op het model tussen haakjes\n\nmethod = 'refit')\n\nWe gebruiken de refit methode, de standaardmethode. Met deze methode worden de afhankelijke en onafhankelijke variabelen gestandaardiseerd en dan wordt het model opnieuw geschat met deze gestandaardiseerde versies.\n\n\nWe kunnen de resultaten vergelijken:\nstandardize_parameters() creëert een data frame met volgende kolommen:\n\nglimpse(multiple_std)\n\nRows: 4\nColumns: 5\n$ Parameter       &lt;chr&gt; \"(Intercept)\", \"cpi\", \"v2caviol\", \"TYPEDEMO1984_factor…\n$ Std_Coefficient &lt;dbl&gt; -0.23661987, 0.49272847, -0.05393177, 0.60000039\n$ CI              &lt;dbl&gt; 0.95, 0.95, 0.95, 0.95\n$ CI_low          &lt;dbl&gt; -0.3957424, 0.3306681, -0.2037814, 0.3287296\n$ CI_high         &lt;dbl&gt; -0.07749731, 0.65478881, 0.09591783, 0.87127121\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\n\nParameter: Naam van de term of variabele in het model\nStd_Coefficient: De waarde van de gestandaardiseerde coëfficiënt voor elke variabele\nCI: Niveau van het betrouwbaarheidsinterval voor de gestandaardiseerde coëfficiënt.\nCI_low en CI_high: De onder -en bovengrenzen van het betrouwbaarheidsinterval. Deze waarden worden gecombineerd in 1 cel als we de waarden straks printen.\n\n\n\nWe kunnen de resultaten vergelijken met het ongestandaardiseerde model. We gebruiken tidy() hier om de output te vereenvoudigen.\n\n#Oorspronkelijk model\ntidy(model_multiple)\n\n# A tibble: 4 × 5\n  term                           estimate std.error statistic      p.value\n  &lt;chr&gt;                             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept)                     0.187     0.0426      4.40  0.0000219   \n2 cpi                             0.00636   0.00106     6.01  0.0000000155\n3 v2caviol                       -0.00872   0.0123     -0.712 0.478       \n4 TYPEDEMO1984_factorDemocracies  0.153     0.0349      4.37  0.0000239   \n\n#gestandaardiseerd model\nmultiple_std\n\n# Standardization method: refit\n\nParameter                         | Std. Coef. |         95% CI\n---------------------------------------------------------------\n(Intercept)                       |      -0.24 | [-0.40, -0.08]\ncpi                               |       0.49 | [ 0.33,  0.65]\nv2caviol                          |      -0.05 | [-0.20,  0.10]\nTYPEDEMO1984 factor [Democracies] |       0.60 | [ 0.33,  0.87]\n\n\nVoor de continue variabelen geven de gestandaardiseerde coëfficiënten weer hoeveel standaardafwijkingen de afhankelijke variabele gaat veranderen als de onafhankelijke variabele met 1 standaardafwijking stijgt.1\nVoor factor variabelen ligt de interpretatie anders. De gestandaardiseerde coëfficiënt die we krijgen is de ongestandaardiseerde coëfficiënt gedeeld door de standaardafwijking van de afhankelijke variabele. De gestandaardiseerde coëfficiënten van continue en factor variabelen kunnen niet direct vergeleken worden.2\n\n\n\n\n\n\nInterpretatie\n\n\n\nWe verwachten dat democratiescores met-0.05 standaardafwijkingen dalen als politiek geweld met 1 standaardafwijking stijgt (en met de effecten van corruptie en regimestatus in het verleden constant gehouden).\nAls we landen met dezelfde corruptie en politieke geweldscores vergelijken, verwachten we dat de electorale democratiescore in 2020 0.6 standaardafwijkingen hoger is voor landen die in 1984 democratieën waren dan landen die autocratieën waren.\n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nJe zult opgemerkt hebben dat we noch summary() noch tidy() gebruikt hebben om de gestandaardiseerde coëfficiënten te printen in R. Deze functies zijn niet nodig omdat de output van standardize_parameters() reeds opgeslagen is in een dataframe.\nIndien je summary() zou gebruiken zou je samenvattende statistieken vinden voor elke kolom in het dataframe:\n\nsummary(multiple_std)\n\n  Parameter         Std_Coefficient         CI           CI_low        \n Length:4           Min.   :-0.2366   Min.   :0.95   Min.   :-0.39574  \n Class :character   1st Qu.:-0.0996   1st Qu.:0.95   1st Qu.:-0.25177  \n Mode  :character   Median : 0.2194   Median :0.95   Median : 0.06247  \n                    Mean   : 0.2005   Mean   :0.95   Mean   : 0.01497  \n                    3rd Qu.: 0.5195   3rd Qu.:0.95   3rd Qu.: 0.32921  \n                    Max.   : 0.6000   Max.   :0.95   Max.   : 0.33067  \n    CI_high        \n Min.   :-0.07750  \n 1st Qu.: 0.05256  \n Median : 0.37535  \n Mean   : 0.38612  \n 3rd Qu.: 0.70891  \n Max.   : 0.87127  \n\n\nMet tidy() krijg je een foutmelding gezien tidy() bedoeld is voor objecten die afkomstig zijn van statistische modellen:\n\ntidy(multiple_std)\n\nWarning in tidy.data.frame(multiple_std): Data frame tidiers are deprecated and\nwill be removed in an upcoming release of broom.\n\n\nWarning in mean.default(X[[i]], ...): argument is not numeric or logical:\nreturning NA\n\n\nWarning in var(if (is.vector(x) || is.factor(x)) x else as.double(x), na.rm =\nna.rm): NAs introduced by coercion\n\n\nWarning in mean.default(sort(x, partial = half + 0L:1L)[half + 0L:1L]):\nargument is not numeric or logical: returning NA\n\n\nWarning in mean.default(X[[i]], ...): argument is not numeric or logical:\nreturning NA\n\n\nWarning in mean.default(sort(x, partial = half + 0L:1L)[half + 0L:1L]):\nargument is not numeric or logical: returning NA\n\n\nError in x - stats::median(x, na.rm = na.rm): non-numeric argument to binary operator",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Meervoudige Lineaire Regressie</span>"
    ]
  },
  {
    "objectID": "linear_04.html#footnotes",
    "href": "linear_04.html#footnotes",
    "title": "4  Meervoudige Lineaire Regressie",
    "section": "",
    "text": "We zouden ook kunnen vragen enkel de onafhankelijke variabelen te standaardiseren en de schaal van de afhankelijke variabele te behouden met de optie “include_response = F” (F=False). Dit zou ons zeggen hoeveel Y verwacht wordt te veranderen op de originele schaal als de onafhankelijke variabele met 1 standaardafwijking stijgt. We kunnen dit doen als de schaal van de afhankelijke variabele zeer intuïtief is, bijvoorbeeld percentage stemmen voor een bepaalde partij.↩︎\nDe gestandaardiseerde coëfficiënten van continue en factor variabelen kunnen meer direct vergeleken worden als we de optie “two_sd = TRUE” toevoegen. De coëfficiënt van de continue onafhankelijke variabele geeft dan weer wat er gebeurt met Y als de onafhankelijke met 2 standaardafwijkingen stijgt, ongeveer het volledige bereik van de onafhankelijke variabele.↩︎",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Meervoudige Lineaire Regressie</span>"
    ]
  },
  {
    "objectID": "linear_05.html",
    "href": "linear_05.html",
    "title": "5  Voorspellingen en Fouten",
    "section": "",
    "text": "5.1 Voorspellingen en fouten voor de observaties in het model\nOp basis van het lineaire regressiemodel kunnen we voor elke observatie gebruikt in het model een voorspelling maken van de waarde voor de afhankelijke waarde. Het verschil tussen deze voorspelling en de echte waarde die we vinden in de dataset is de fout (‘error’) of ‘residual’.\nDe predictions() functie uit het marginaleffects package kan gebruikt worden om voorspellingen te maken voor elke observatie gebruikt in het model. 1\nmodel_binary_predictions &lt;- predictions(model_binary, newdata = demdata) |&gt; \n  as_tibble() #as_tibble() niet strikt nodig, zie waarschuwingsvak hieronder\nZo lees je de syntax:\nDe output kunnen we printen met behulp van de volgende code:\nmodel_binary_predictions\n\n# A tibble: 179 × 51\n   rowid estimate std.error statistic    p.value s.value conf.low conf.high\n   &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1     1    0.690    0.0287      24.1  3.16e-128    424.    0.634     0.746\n 2     2    0.418    0.0233      17.9  1.16e- 71    236.    0.372     0.463\n 3     3    0.690    0.0287      24.1  3.16e-128    424.    0.634     0.746\n 4     4    0.690    0.0287      24.1  3.16e-128    424.    0.634     0.746\n 5     5    0.418    0.0233      17.9  1.16e- 71    236.    0.372     0.463\n 6     6    0.418    0.0233      17.9  1.16e- 71    236.    0.372     0.463\n 7     7    0.690    0.0287      24.1  3.16e-128    424.    0.634     0.746\n 8     8    0.418    0.0233      17.9  1.16e- 71    236.    0.372     0.463\n 9     9   NA       NA           NA   NA             NA    NA        NA    \n10    10    0.418    0.0233      17.9  1.16e- 71    236.    0.372     0.463\n# ℹ 169 more rows\n# ℹ 43 more variables: country_name &lt;chr&gt;, year &lt;dbl&gt;, v2x_polyarchy &lt;dbl&gt;,\n#   v2x_libdem &lt;dbl&gt;, v2x_egaldem &lt;dbl&gt;, v2cacamps &lt;dbl&gt;, v2caviol &lt;dbl&gt;,\n#   e_peaveduc &lt;dbl&gt;, cpi &lt;dbl&gt;, e_regiongeo &lt;dbl&gt;, e_regionpol_6C &lt;dbl&gt;,\n#   v2elcomvot &lt;dbl&gt;, compulsory_voting &lt;dbl&gt;, bicameral &lt;dbl&gt;, dem_diff &lt;dbl&gt;,\n#   dem_increase &lt;dbl&gt;, dem_decrease &lt;dbl&gt;, TypeSoc2005 &lt;dbl&gt;,\n#   TypeEcon2006 &lt;dbl&gt;, HDI2005 &lt;dbl&gt;, GDP2006 &lt;dbl&gt;, TYPEDEMO1984 &lt;dbl&gt;, …\nWe kunnen het nieuwe dataobject gebruiken om ook de residuals te berekenen. Dit doen we door het verschil tussen echte en voorspelde waarde in een variabele op te nemen. 3\nmodel_binary_predictions &lt;- model_binary_predictions |&gt; \n  mutate(residual_value = v2x_polyarchy - estimate) #residual = echte waarde - voorspelde waarde\nDeze variabele kunnen we gebruiken om na te gaan welke observaties goed of slecht worden voorspeld. Dit kan nuttig zijn bij het nagaan of aan assumpties voldaan is, zie Hoofdstuk 7 .\nmodel_binary_predictions |&gt; \n  select(country_name, v2x_polyarchy, estimate, residual_value) \n\n# A tibble: 179 × 4\n   country_name v2x_polyarchy estimate residual_value\n   &lt;chr&gt;                &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;\n 1 Mexico               0.647    0.690        -0.0432\n 2 Suriname             0.761    0.418         0.343 \n 3 Sweden               0.908    0.690         0.218 \n 4 Switzerland          0.894    0.690         0.204 \n 5 Ghana                0.72     0.418         0.302 \n 6 South Africa         0.703    0.418         0.285 \n 7 Japan                0.832    0.690         0.142 \n 8 Myanmar              0.436    0.418         0.0184\n 9 Russia               0.262   NA            NA     \n10 Albania              0.485    0.418         0.0674\n# ℹ 169 more rows",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Voorspellingen en Fouten</span>"
    ]
  },
  {
    "objectID": "linear_05.html#voorspellingen-en-fouten-voor-de-observaties-in-het-model",
    "href": "linear_05.html#voorspellingen-en-fouten-voor-de-observaties-in-het-model",
    "title": "5  Voorspellingen en Fouten",
    "section": "",
    "text": "model_binary_predictions\n\nWe slaan de output hier op in een nieuw data object “model_binary_predictions”. Deze naam kun je zelf bepalen.\n\npredictions(model_binary,\n\nWe gebruiken de predictions functie op het model tussen haakjes.\n\nnewdata = demdata)\n\nHier verduidelijken we de originele dataset voor deze voorspellingen. Deze syntax vertelt R dat we in ons nieuwe data object de voorspellingen willen, maar ook alle variabelen uit de originele dataset, niet enkel de variabelen gebruikt in het model. Dit is nuttig als we specifieke observaties willen identificeren (bv. door te kijken naar de naam van het land). Als je dit niet specificeert krijg je een dataset zonder de overige variabelen in de originele dataset.\n\n\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\n\nestimate: Dit is de voorspelde waarde op de afhankelijke variabele voor elke observatie in het model. Observaties die niet in het model werden opgenomen (omwille van ontbrekende data) krijgen hier ‘NA’.\nstd.error, statistic, p.value, conf.low, en conf.high: de standaardfout van de voorspelling, t-statistiek, p-waarde en het 95% betrouwbaarheidsinterval. De s-waarde is een andere manier om onzekerheid weer te geven maar behoort niet tot de leerstof. 2\nDe overige kolommen bevatten de variabelen uit de originele dataset.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Voorspellingen en Fouten</span>"
    ]
  },
  {
    "objectID": "linear_05.html#voorspellingen-voor-bepaalde-waarden-van-de-onafhankelijke-variabele-bivariaat",
    "href": "linear_05.html#voorspellingen-voor-bepaalde-waarden-van-de-onafhankelijke-variabele-bivariaat",
    "title": "5  Voorspellingen en Fouten",
    "section": "5.2 Voorspellingen voor bepaalde waarden van de onafhankelijke variabele (Bivariaat)",
    "text": "5.2 Voorspellingen voor bepaalde waarden van de onafhankelijke variabele (Bivariaat)\nWe kunnen ook nagaan welke waarde op de afhankelijke we kunnen verwachten volgens het model als de onafhankelijke variabele bepaalde waarden aanneemt. Bijvoorbeeld: welke democratiescore kunnen we gemiddeld verwachten voor landen die in 1984 een autocratie waren? Of voor landen die een lage of hoge economische ongelijkheid kennen? We kunnen hier ook de predictions() functie voor gebruiken.\nEerst voorspellen we de verwachte democratiescore in 2020 voor landen die in 1984 een autocratie versus democratie waren op basis van ons bivariaat model (model_binary).\n\npredictions(model_binary, \n            by = 'TYPEDEMO1984_factor') |&gt; \n  as_tibble()  \n\n# A tibble: 2 × 10\n  rowid TYPEDEMO1984_factor estimate std.error statistic   p.value s.value\n  &lt;int&gt; &lt;fct&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1     1 Autocracies            0.418    0.0233      17.9 1.16e- 71    236.\n2     2 Democracies            0.690    0.0287      24.1 3.16e-128    424.\n# ℹ 3 more variables: conf.low &lt;dbl&gt;, conf.high &lt;dbl&gt;, rowid_dedup &lt;int&gt;\n\n\n\npredictions(model_binary,\n\nWe passen de functie toe op het model tussen haakjes.\n\nby = \"TYPEDEMO1984_factor\")\n\nHier vragen we de voorspelling voor elk niveau (level) van de factor “TYPEDEMO1984_factor”. De “by=” syntax wordt enkel gebruikt met factor variabelen. We maken geen gebruik van “newdata=” omdat we hier geen voorspellingen vragen voor alle observaties.\n\n\nWe kunnen ook voorspellingen maken op basis van een continue onafhankelijke variabele. We kunnen bijvoorbeeld de score voor electorale democratie voorspellen aan de hand van economische ongelijkheid (gini_2019). Hier gaan we na welke democratiescore we kunnen verwachten als ongelijkheid laag (25) versus hoog is (45).\n\npredictions(model_continuous, \n            newdata = datagrid(gini_2019 = c(25,45))) |&gt; \n  as_tibble()\n\n# A tibble: 2 × 10\n  rowid estimate std.error statistic  p.value s.value conf.low conf.high\n  &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     1    0.764    0.0451      16.9 3.19e-64   211.     0.675     0.852\n2     2    0.527    0.0493      10.7 1.10e-26    86.2    0.430     0.623\n# ℹ 2 more variables: gini_2019 &lt;dbl&gt;, v2x_polyarchy &lt;dbl&gt;\n\n\n\nnewdata = datagrid(gini_2019 = c(25,45))\n\nHier bepalen we de waarden van de continue onafhankelijke variabele waar we voorspellingen voor willen maken. Je kunt de naam van de variabele veranderen, alsook de waarden waarvoor je voorspellingen maakt. De rest van de syntax blijft gelijk.\n\n\nWe kunnen eventueel meerdere waarden toevoegen om voorspellingen voor te maken door de code op de volgende manier uit te breiden in het c() gedeelte van de syntax:\n\npredictions(model_continuous, \n            newdata = datagrid(gini_2019 = c(25,30,35,40,45))) |&gt; \n  as_tibble()\n\n# A tibble: 5 × 10\n  rowid estimate std.error statistic   p.value s.value conf.low conf.high\n  &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     1    0.764    0.0451      16.9 3.19e- 64   211.     0.675     0.852\n2     2    0.705    0.0316      22.3 2.20e-110   364.     0.643     0.766\n3     3    0.645    0.0267      24.2 6.30e-129   426.     0.593     0.698\n4     4    0.586    0.0345      17.0 1.04e- 64   213.     0.518     0.654\n5     5    0.527    0.0493      10.7 1.10e- 26    86.2    0.430     0.623\n# ℹ 2 more variables: gini_2019 &lt;dbl&gt;, v2x_polyarchy &lt;dbl&gt;\n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nWe eindigden de predictions() functie met as_tibble(). Deze stap is niet strikt noodzakelijk. Dit is het resultaat zonder de toevoeging:\n\npredictions(model_binary, by = 'TYPEDEMO1984_factor')\n\n\n TYPEDEMO1984_factor Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n         Autocracies    0.418     0.0233 17.9   &lt;0.001 235.6 0.372  0.463\n         Democracies    0.690     0.0287 24.1   &lt;0.001 423.5 0.634  0.746\n\nType:  response \n\n\nHet verschil zit hem in de weergave van de output in R: standaard geeft predictions() andere namen aan de kolommen (bv., Estimate i.p.v. estimate, 2.5% i.p.v. conf.low) om de zaken netter te maken, maar dit bemoeilijkt de zaken eigenlijk vaak voor ons omdat dit niet de echte variabelenamen zijn zoals ze opgeslagen worden in het object. Later in het vak gebruiken we deze variabelen om verdere bewerkingen te doen. Daarvoor moeten we de juiste variabelenamen opgeven: estimate dus en niet Estimate.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Voorspellingen en Fouten</span>"
    ]
  },
  {
    "objectID": "linear_05.html#voorspelde-waarden-meervoudige-lineaire-regressie",
    "href": "linear_05.html#voorspelde-waarden-meervoudige-lineaire-regressie",
    "title": "5  Voorspellingen en Fouten",
    "section": "5.3 Voorspelde waarden (Meervoudige Lineaire Regressie)",
    "text": "5.3 Voorspelde waarden (Meervoudige Lineaire Regressie)\nVoorspelde waarden en fouten kunnen we ook voor meervoudige regressie bekijken via de predictions() functie. De procedure om voorspelde waarden te vinden voor alle observaties in het model is dezelfde als hierboven dus herhalen we deze niet. De procedure voor voorspellingen op basis van waarden van een onafhankelijke variabele is gelijkaardig, met 1 belangrijk verschil voor factor variabelen.\n\n5.3.1 Voorspellingen voor een continue predictor\nDit waren de resultaten van ons meervoudig lineair regressiemodel:\n\ntidy(model_multiple)\n\n# A tibble: 4 × 5\n  term                           estimate std.error statistic      p.value\n  &lt;chr&gt;                             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept)                     0.187     0.0426      4.40  0.0000219   \n2 cpi                             0.00636   0.00106     6.01  0.0000000155\n3 v2caviol                       -0.00872   0.0123     -0.712 0.478       \n4 TYPEDEMO1984_factorDemocracies  0.153     0.0349      4.37  0.0000239   \n\n\ncpi meet gepercipieerde corruptie in een land op een schaal van 0 tot 100 (hogere waarden staan voor minder corruptie). In de praktijk is het bereik van de variabele in ons model 12 tot 88. Voor we voorspellingen doen gaan we het werkelijke bereik eerst na:\n\n1predictions(model_multiple) |&gt;\n2  select(cpi) |&gt;\n3  summary()\n\n\n1\n\nWe gebruiken de predictions() functie hier om enkel observaties te selecteren die gebruikt werden in het model (observaties met ontbrekende waarden op ‘NA’ worden weggefilterd).\n\n2\n\nWe selecteren de cpi variabele\n\n3\n\nEn vragen de beschrijvende statistieken voor de variabele.\n\n\n\n\n      cpi       \n Min.   :12.00  \n 1st Qu.:28.00  \n Median :39.50  \n Mean   :43.37  \n 3rd Qu.:56.75  \n Max.   :88.00  \n\n\nWe kunnen voorspelde waarden gebruiken om een inschatting te maken over het verwachte niveau van democratie bij lage en hoge corruptie. Een regressiecoëfficiënt zegt ons wat er gebeurt als corruptie met 1 eenheid stijgt, maar voorspelde waarden kunnen vaak een intuïtiever beeld geven over de sterkte van een effect. Hier gebruiken we predictions() om verwachte democratiescores te berekenen voor corruptiescores (cpi) van 20 tot 80 met verhogingen van telkens 10 eenheden.\n\npreds1 &lt;- predictions(model_multiple, \n            newdata = datagrid(cpi = c(20,30,40,50,60,70,80))) |&gt; \n  as_tibble()\n\n\npreds1 &lt;-\n\nWe slaan de resultaten op in een data object omdat we ze ook voor andere doeleinden zullen gebruiken. De naam bepaal je zelf.\n\npredictions(multiple,\n\nWe passen de functie toe op het model tussen haakjes.\n\nnewdata = datagrid(cpi = c(20,30,40,50,60,70,80))\n\nHier bepalen we voor welke onafhankelijke variabele we voorspellingen willen (cpi) en voor welke waarden (20…80). De waarden zijn numeriek en gaan niet tussen aanhalingstekens.\n\n\nWe printen de voorspellingen:\n\npreds1\n\n# A tibble: 7 × 12\n  rowid estimate std.error statistic   p.value s.value conf.low conf.high\n  &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     1    0.318    0.0278      11.4 2.41e- 30    98.4    0.264     0.373\n2     2    0.382    0.0217      17.6 3.30e- 69   227.     0.339     0.424\n3     3    0.445    0.0199      22.4 2.59e-111   367.     0.406     0.484\n4     4    0.509    0.0233      21.9 6.10e-106   350.     0.463     0.555\n5     5    0.573    0.0302      18.9 4.92e- 80   263.     0.513     0.632\n6     6    0.636    0.0389      16.4 2.78e- 60   198.     0.560     0.713\n7     7    0.700    0.0483      14.5 1.17e- 47   156.     0.605     0.795\n# ℹ 4 more variables: v2caviol &lt;dbl&gt;, TYPEDEMO1984_factor &lt;fct&gt;, cpi &lt;dbl&gt;,\n#   v2x_polyarchy &lt;dbl&gt;\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\n\nestimate: De voorspelde waarde\nkolommen “std.error” tot “conf.high”: informatie met betrekking tot onzekerheid van de schatting\n“4 more variables”: Dit zegt dat ons tidied dataframe nog 4 variabelen heeft (dit verschilt naargelang het model dat je gebruikt). De kolommen zijn genoemd naar de variabelen gebruikt in het model. Voor de onafhankelijke variabelen (hier: v2caviol, TYPEDEMO1984_factor, en cpi) tonen ze de waarden die gebruikt worden voor deze variabelen om de voorspellingen te maken.\n\n\n\nIn bovenstaand voorbeeld houdt predictions() automatisch de 2 overige onafhankelijke variabelen (v2caviol en TYPEDEMO1984_factor) constant op dezelfde waarde bij de berekening van elke voorspelde waarde. Continue predictoren worden constant gehouden op hun gemiddelde, voor factor variabelen wordt de modus (de meest voorkomende categorie) gebruikt. Dit kunnen we nagaan:\n\npreds1 |&gt; \n  select(estimate, cpi, v2caviol, TYPEDEMO1984_factor)\n\n# A tibble: 7 × 4\n  estimate   cpi v2caviol TYPEDEMO1984_factor\n     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;              \n1    0.318    20   -0.394 Autocracies        \n2    0.382    30   -0.394 Autocracies        \n3    0.445    40   -0.394 Autocracies        \n4    0.509    50   -0.394 Autocracies        \n5    0.573    60   -0.394 Autocracies        \n6    0.636    70   -0.394 Autocracies        \n7    0.700    80   -0.394 Autocracies        \n\n\n\n\n5.3.2 Voorspellingen voor een factor predictor\nWe kunnen een gelijkaardige procedure gebruiken om voorspellingen te maken voor de verschillende niveaus van factor variabelen. Dit kunnen we doen met behulp van de by= optie i.p.v newdata = datagrid().4 Om ervoor te zorgen dat we voor de overige onafhankelijke variabelen het gemiddelde of de modus nemen, moeten we hier wel nog syntax toevoegen via newdata:\n\npreds2 &lt;- predictions(model_multiple, by= \"TYPEDEMO1984_factor\", \n                      newdata = \"mean\") |&gt; \n  as_tibble()\n\n\nby=\"TYPEDEMO1984_factor\"\n\nHier verduidelijken we dat we voorspellingen willen voor elk niveau van de factor variabele.\n\nnewdata = \"mean\")\n\nHier zeggen we dat voor de overige onafhankelijke variabelen het gemiddelde of de modus aangehouden moet worden. Dit gebeurde automatisch in vorig voorbeeld, maar moet toegevoegd worden als we “by=” gebruiken.\n\n\nDe resultaten zijn als volgt:\n\npreds2\n\n# A tibble: 2 × 12\n  rowid TYPEDEMO1984_factor estimate std.error statistic   p.value s.value\n  &lt;int&gt; &lt;fct&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1     1 Autocracies            0.467    0.0205      22.8 4.94e-115    380.\n2     2 Democracies            0.620    0.0260      23.8 2.47e-125    414.\n# ℹ 5 more variables: conf.low &lt;dbl&gt;, conf.high &lt;dbl&gt;, cpi &lt;dbl&gt;,\n#   v2caviol &lt;dbl&gt;, rowid_dedup &lt;int&gt;\n\n\nOpnieuw kunnen we zien dat predictions() de andere onafhankelijke variabelen constant houdt:\n\npreds2 |&gt; \n  select(estimate, TYPEDEMO1984_factor, cpi, v2caviol)\n\n# A tibble: 2 × 4\n  estimate TYPEDEMO1984_factor   cpi v2caviol\n     &lt;dbl&gt; &lt;fct&gt;               &lt;dbl&gt;    &lt;dbl&gt;\n1    0.467 Autocracies          43.4   -0.394\n2    0.620 Democracies          43.4   -0.394\n\n\n\n\n5.3.3 Voorspellingen voor specifieke waarden van de onafhankelijke variabelen\nWe kunnen predictions() ook gebruiken om voorspellingen te maken voor specifieke, hypothetische casussen. Bijvoorbeeld, hier vragen we de voorspelde waarde voor de afhankelijke variabele electorale democratie voor een land dat: een democratie was in 1984, 88 scoort op de corruptieperceptie-index (de maximumwaarde in de dataset) en -3.429 voor politiek geweld (de minimumwaarde in de dataset).\nWe bepalen deze waarden in het newdata = datagrid() gedeelte van de syntax. Indien we een variabele niet zouden specificeren zou deze constant gehouden worden op het gemiddelde of de modus.\n\npredictions(model_multiple, \n            newdata = datagrid(cpi=c(88), \n                               v2caviol=c(-3.429), \n                               TYPEDEMO1984_factor=c(\"Democracies\"))) |&gt; \n  as_tibble()\n\n# A tibble: 1 × 12\n  rowid estimate std.error statistic   p.value s.value conf.low conf.high   cpi\n  &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     1    0.930    0.0392      23.7 1.89e-124    411.    0.853      1.01    88\n# ℹ 3 more variables: v2caviol &lt;dbl&gt;, TYPEDEMO1984_factor &lt;fct&gt;,\n#   v2x_polyarchy &lt;dbl&gt;",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Voorspellingen en Fouten</span>"
    ]
  },
  {
    "objectID": "linear_05.html#footnotes",
    "href": "linear_05.html#footnotes",
    "title": "5  Voorspellingen en Fouten",
    "section": "",
    "text": "De augment() functie uit het broom package kunnen we ook gebruiken om de residuals te bestuderen. Dit gebruiken we in een ander hoofdstuk. Hier richten we ons op predictions() omdat deze functie gemakkelijker een dataframe produceert met de voorspellingen, fouten en de overige data in de originele dataset.↩︎\nDe s-waarde is een poging om de p-waarde te vertalen naar een maat die volgens sommigen gemakkelijker te interpreteren is. In het bijzonder vertelt het ons: “Hoeveel opeenvolgende”kop”-worpen zouden dezelfde hoeveelheid bewijs (of “verrassingen”) leveren tegen de nulhypothese dat de munt eerlijk is?” Een p-waarde van 0,05 zou bijvoorbeeld een overeenkomstige s-waarde van 4,3 of zo hebben. We zouden dan kunnen zeggen dat een p-waarde van 0,05 ongeveer net zo verrassend is als vier keer een eerlijke munt opgooien en de munt alle vier de keren op kop zien landen. Zou je je gerust voelen om een verklaring af te leggen dat de munt vals is in plaats van eerlijk op basis van die reeks muntworpen? In de context van de output van predictions() (en van de slopes()-functie die we in latere hoofdstukken zien), zouden hogere s-waarden aangeven dat we steeds verraster zouden moeten zijn om onze resultaten te zien als de waarde van het ding dat we schatten eigenlijk 0 is. Deze statistiek is niet zo nuttig voor onze voorspelde waarden, maar zou nuttiger kunnen zijn om te begrijpen hoe verrassend een schatting van een coëfficiënt of “marginaal effect” is. Als je wilt, kun meer lezen over wat p-waarden zijn, enkele van de complicaties die onderzoekers tegenkomen bij het interpreteren ervan, en een discussie over wat s-waarden zijn en hoe ze kunnen helpen in deze blogpost. De s-waarde is geen onderdeel van de leerstof.↩︎\nRusland heeft hier een ‘NA’ waarde voor estimate en residual_value omdat het omwille van ontbrekende waarden niet is opgenomen in het regressiemodel.↩︎\nWe zouden technisch gezien wel newdata = datagrid() kunnen gebruiken maar dan moeten we de niveaus van de factor variabele manueel typen (bv. newdata = datagrid(TYPEDEMO1984_factor = c(\"Autocracies', \"Democracies\")). De by = functie is dus gemakkelijker.↩︎",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Voorspellingen en Fouten</span>"
    ]
  },
  {
    "objectID": "linear_06.html",
    "href": "linear_06.html",
    "title": "6  Model Fit en Modellen Vergelijken",
    "section": "",
    "text": "6.1 R2, Adjusted R2 en de F-Test\nOns voorbeeld hier is een regressiemodel waarin we de electorale democratiescore van een land in 2020 (v2x_polyarchy) voorspellen aan de hand van gepercipieerde corruptie in dat land (cpi), politiek geweld (v2caviol), en regimestatus in 1984 (TYPEDEMO1984_factor).\nmodel_multiple &lt;- lm(v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984_factor, data=demdata)\nDe meeste model fit statistieken verkrijgen we simpelweg via de summary() functie:\nsummary(model_multiple)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984_factor, \n    data = demdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.56402 -0.09376  0.01442  0.12926  0.34206 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                     0.187394   0.042634   4.395 2.19e-05 ***\ncpi                             0.006365   0.001059   6.012 1.55e-08 ***\nv2caviol                       -0.008724   0.012258  -0.712    0.478    \nTYPEDEMO1984_factorDemocracies  0.152698   0.034915   4.373 2.39e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1807 on 138 degrees of freedom\n  (37 observations deleted due to missingness)\nMultiple R-squared:  0.5068,    Adjusted R-squared:  0.4961 \nF-statistic: 47.26 on 3 and 138 DF,  p-value: &lt; 2.2e-16\nDeze output kunnen we ook verkrijgen via de glance() functie uit het broom package:\nglance(model_multiple)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.507         0.496 0.181      47.3 4.46e-21     3   43.5 -77.0 -62.3\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\nDe relevante statistieken vind je bij r.squared (R2), adj.r.squared (Adjusted R2), statistic (F-statistic), en p.value (p-waarde voor de F-statistiek) kolommen. nobs toont het aantal observaties gebruikt in het model.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model Fit en Modellen Vergelijken</span>"
    ]
  },
  {
    "objectID": "linear_06.html#r2-adjusted-r2-en-de-f-test",
    "href": "linear_06.html#r2-adjusted-r2-en-de-f-test",
    "title": "6  Model Fit en Modellen Vergelijken",
    "section": "",
    "text": "Output uitleg\n\n\n\nModel fit statistieken vinden we onderaan de output. “Multiple R-Squared” geeft de \\(R^2\\) (R kwadraat) statistiek. “Adjusted R-Squared” geeft de \\(R^2\\) gecorrigeerd voor het aantal predictoren in het model. De F-statistiek geeft informatie over de statistische significantie van het model.\n\nMultiple R-squared: Dit toont de \\(R^2\\) (R kwadraat) statistiek, die meestal geïnterpreteerd wordt in termen van % van de variatie in Y verklaard door de predictoren in het model\nAdjusted R-squared: Dit toont de \\(R^2\\) gecorrigeerd voor het aantal predictoren in het model.\nF-statistic…: De F-statistiek geeft informatie over de statistische significantie van het model. Het eerste getal is de F-statistiek zelf (47.26). Het cijfer achter “p-value:” is de p-waarde voor de F-statistiek. De nulhypothese die hierbij getest wordt is dat geen enkele van de onafhankelijke variabelen (hier: cpi, v2caviol, TYPEDEMO1984) statistisch significant is. Een statistisch signifcante F-statistiek betekent dat op z’n minst 1 predictor significant is.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model Fit en Modellen Vergelijken</span>"
    ]
  },
  {
    "objectID": "linear_06.html#sec-linear-comparing-models",
    "href": "linear_06.html#sec-linear-comparing-models",
    "title": "6  Model Fit en Modellen Vergelijken",
    "section": "6.2 Modellen vergelijken",
    "text": "6.2 Modellen vergelijken\nDe F-statistiek gaat na of het model een significant verbeterde voorspelling geeft dan een ‘nul model’ zonder predictoren, oftewel het gemiddelde van de afhankelijke variabele. We kunnen ook meerdere modellen vergelijken met elkaar. Hier vergelijken we een model met enkel cpi als onafhankelijke, dan een model met zowel cpi als v2caviol, en ten slotte een model met alle predictoren. Deze modellen zijn ‘nested’, dat wil zeggen dat meer uitgebreide modellen alle variabelen bevatten van de meer simpele modellen.\nOm deze vergelijking te maken moeten we er wel voor zorgen dat onze modellen met dezelfde observaties werken en dus dezelfde N hebben. Dit kunnen we bereiken door een nieuwe dataset aan te maken met complete waarden (non-missing) voor alle variabelen die gebruikt worden in het meest complete model.\n\ndemdata_complete &lt;- demdata |&gt; \n  filter(complete.cases(v2x_polyarchy, cpi, v2caviol, TYPEDEMO1984_factor))\n\nDeze dataset gebruiken we om onze modellen te schatten. Om een volledige vergelijking mogelijk te maken, schatten we ook een nulmodel zonder onafhankelijke variabelen met enkel een intercept (~ 1). Dit intercept bevat de gemiddelde waarde voor Y in de dataset (i.e. onze beste voorspelling zonder predictoren):\n\n#Null model\nmodel1 &lt;- lm(v2x_polyarchy ~ 1, data = demdata_complete)\n\n#Model with just cpi\nmodel2 &lt;- lm(v2x_polyarchy ~ cpi, data = demdata_complete)\n\n#Model with cpi & v2caviol\nmodel3 &lt;- lm(v2x_polyarchy ~ cpi + v2caviol, data = demdata_complete)\n\n#Model with all predictors\nmodel4 &lt;- lm(v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984_factor, data = demdata_complete)\n\nWe kunnen de R2/Adj. R-Squared van de modellen vergelijken om te bekijken welk model het beste past. Dit geeft ons echter geen significantietoets:\n\n\n\n\n\n\n\n\nModel\nR2\nAdj. R2\n\n\n\n\nModel 1\n0\n0\n\n\nModel 2\n0.437\n0.433\n\n\nModel 3\n0.438\n0.43\n\n\nModel 4\n0.507\n0.496\n\n\n\nModel 4 lijkt het beste te passen, maar om de significantietoets uit te voeren moeten we de anova() functie gebruiken. Deze is ingebouwd in R.\n\nanova(model1, model2, model3, model4)\n\nAnalysis of Variance Table\n\nModel 1: v2x_polyarchy ~ 1\nModel 2: v2x_polyarchy ~ cpi\nModel 3: v2x_polyarchy ~ cpi + v2caviol\nModel 4: v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984_factor\n  Res.Df    RSS Df Sum of Sq        F    Pr(&gt;F)    \n1    141 9.1323                                    \n2    140 5.1436  1    3.9887 122.2045 &lt; 2.2e-16 ***\n3    139 5.1285  1    0.0151   0.4614    0.4981    \n4    138 4.5043  1    0.6243  19.1269 2.392e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nanova()\n\nWe voeren de functie uit op de modellen tussen haakjes.\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nHet eerste deel van de output toont welke modellen vergeleken worden met elkaar. De onderste helft bevat het volgende:\n\nRes.Df: De residual degrees of freedom (vrijheidsgraden) van het model\nRSS: Dit staat voor “residual sum of squares”. RSS meet de variatie tussen de residuals in het model. RSS = \\(\\sum(y_{i} - \\hat{y}_{i})^2\\), waarbij \\(\\sum\\) staat voor “sum up”, \\(y_{i}\\) is de geobserveerde Y voor een observatie in het model, and \\(\\hat{y}_{i}\\) is de voorspelde waarde voor diezelfde observatie.1 RSS vertelt ons hoeveel van de variatie in Y het model niet kan verklaren of voorspellen. Een model met een lagere RSS voorspelt de Y beter, maar het verschil in RSS tussen modellen is niet altijd significant. We hebben dus nog een significantietoets nodig.\nDF: Vrijheidsgraden. In de praktijk de hoeveelheid onafhankelijke variabelen toegevoegd in vergelijking met het voorgaande model. Dit getal is 1 als er 1 predictor werd toegevoegd in vergelijking met het vorige model in bovenstaande rij.2\nSum of Sq: De model of “regression” sum of squares is gebaseerd op de volgende formule: \\(\\sum(\\hat{y}_{i} - \\bar{y})^2\\), waarbij \\(\\hat{y}_{i}\\) de voorspelde waarde is voor een observatie in het model, en \\(\\bar{y}\\) de gemiddelde waarde voor Y op basis van alle observaties in het model.3 De model sum of squares meet de variatie in Y die verklaart wordt door de predictoren in het model. De Sum of Sq in de anova() output toont de verandering in Sum of Sq ten opzichte van het voorgaande model. Hoe hoger de stijging hoe beter, maar hier moet ook een signifcantietest voor gebeuren.\nF & Pr(&gt;F): De F-statistiek en bijhorende p-waarde. De nulhypothese is dat het model in de desbetreffende rij niet beter past dan het model in de voorgaande rij. In feite test dit of tenminste 1 van de variabelen toegevoegd aan het model significant is. Indien de nulhypothese verworpen wordt, dan kunnen we zeggen dat het nieuwe model beter past.\n\n\n\nWe kunnen de output als volgt lezen: Model 2 past hier beter dan 1 (nulmodel), Model 3 past niet beter dan 2, en Model 4 past beter dan 3. We kunnen ook Modellen 1 en 2 direct met Model 4 vergelijken:\n\n#Model 4 vs. Model 2\nanova(model2, model4)\n\nAnalysis of Variance Table\n\nModel 1: v2x_polyarchy ~ cpi\nModel 2: v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984_factor\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    140 5.1436                                  \n2    138 4.5043  2   0.63935 9.7941 0.0001053 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Model 4 vs. Model 1\nanova(model1, model4)\n\nAnalysis of Variance Table\n\nModel 1: v2x_polyarchy ~ 1\nModel 2: v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984_factor\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    141 9.1323                                  \n2    138 4.5043  3     4.628 47.264 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nanova() De volgorde van de modellen is van belang voor de uitkomst. Hierboven vergelijken we telkens een complexer model met een simpeler model. Indien we schrijven “(model4, model1, model2”, “model3”), dan vergelijkt R model 1 tegen 4, model 2 tegen 1 enz.\n\nanova(model4, model1, model2, model3)\n\nAnalysis of Variance Table\n\nModel 1: v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984_factor\nModel 2: v2x_polyarchy ~ 1\nModel 3: v2x_polyarchy ~ cpi\nModel 4: v2x_polyarchy ~ cpi + v2caviol\n  Res.Df    RSS Df Sum of Sq        F Pr(&gt;F)    \n1    138 4.5043                                 \n2    141 9.1323 -3   -4.6280  47.2642 &lt;2e-16 ***\n3    140 5.1436  1    3.9887 122.2045 &lt;2e-16 ***\n4    139 5.1285  1    0.0151   0.4614 0.4981    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDe tweede rij vergelijkt nu het nulmodel (model1) met het meest complexe model (model4). We krijgen een negatieve waarde voor “DF” en “Sum of Sq” omdat Model 1 minder predictoren heeft en ook minder goed past. Het verschil is statistisch significant. Dit interpreteren we nu als: model 4 is beter dan model 1.De derde rij vergelijkt model2 (enkel cpi als predictor) met model1 (het nulmodel). De resultaten zijn dezelfde als hierboven. De resultaten voor de laatste rij zijn ook dezelfde.\nLet erop dat de namen die de anova() functie geeft aan de modellen niet noodzakelijk dezelfde zijn als de namen die je zelf geeft (model 1 voor anova is nu ons model 4).\nJe kunt de fit van bepaalde modellen testen tegenover elkaar om zo stapsgewijs het beste model te vinden. Meestal zullen we meer complexe modellen vergelijken met meer simpele modellen. In de syntax gaan we dan van meest simpel naar meest complex model.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model Fit en Modellen Vergelijken</span>"
    ]
  },
  {
    "objectID": "linear_06.html#footnotes",
    "href": "linear_06.html#footnotes",
    "title": "6  Model Fit en Modellen Vergelijken",
    "section": "",
    "text": "Deze vergelijking behoort niet tot de leerstof.↩︎\nDe DF kolom geeft op zich niet weer hoeveel extra onafhankelijke variabelen werden toegevoegd, maar wel hoeveel nieuwe coëfficiënten (of termen) werden toegevoegd. Dit is vooral van belang bij factor variabelen (zeker als ze 3 of meer categorieën hebben). Hoewel je misschien 1 factor variabele toevoegt, kun je meer dan 1 coëfficiënt (en dus DF) krijgen als je voor meerdere categorieën dummy variabelen moet toevoegen.↩︎\nDeze vergelijking behoort niet tot de leerstof.↩︎",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model Fit en Modellen Vergelijken</span>"
    ]
  },
  {
    "objectID": "linear_07.html",
    "href": "linear_07.html",
    "title": "7  OLS Assumpties",
    "section": "",
    "text": "7.1 Onafhankelijke fouten en de Durbin-Watson test\nDe assumptie van onafhankelijke fouten is gerelateerd aan de voorwaarde dat observaties onafhankelijk van elkaar geselecteerd moeten zijn. Aan deze voorwaarde is niet voldaan als er een tijdsrelatie is tussen de observaties of als er sprake is van geografische clustering (bv. gebruik van multistage sampling voor een survey).\nDe Durbin-Watson test kan gebruikt worden om na te gaan of een tijdsrelatie leidt tot een te sterke correlatie tussen de fouten (errors/residuals). De test kan niet gebruikt worden als er geen tijdsrelatie is (bv. een cross-sectionele survey). Bovendien moet de dataset geordend zijn volgens tijd: van oud naar nieuw of van nieuw naar oud.\nDe voorbeelddataset “gdp-dem, time order.csv” voldoet aan deze voorwaarden. Het bevat het BBP (“gdp”) en de democratiescore (“democracy”) voor een enkel land over de jaren heen. De dataset is fictief. Er is geen missing data, maar de syntax kan ook gebruikt worden indien er ontbrekende waarden zijn (‘NA’).\ndta &lt;- import(\"gdp-dem, time order.csv\")\nhead(dta, n = 10L) #Zodat we enkel 10 eerste rijen zien\nyear  gdp democracy\n1  1990 8400        50\n2  1991 8500        55\n3  1992 8800        60\n4  1993 8700        60\n5  1994 8600        60\n6  1995 8800        65\n7  1996 9200        65\n8  1997 9300        65\n9  1998 9500        70\n10 1999 9700        70\nIndien de dataset niet gesorteerd is, kun je dit zelf doen met behulp van de arrange functie uit het dplyr package (onderdeel van tidyverse).\n#sorteer oud-nieuw\ndta &lt;- dta |&gt;\n  arrange(year)\n\n#sort nieuw-oud\ndta &lt;- dta |&gt;\n  arrange(desc(year))\nWe voeren een bivariate regressieanalyse uit met gdp als onafhankelijke variabele en democratie als afhankelijke variabele:\ntime_model &lt;- lm(democracy ~ gdp, data = dta)\ntidy(time_model)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic      p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept) -36.2     13.9         -2.61 0.0143      \n2 gdp           0.0111   0.00148      7.50 0.0000000291\nDan gebruiken we de Durbin-Watson uit het car package.\ndurbinWatsonTest(time_model) \n\n lag Autocorrelation D-W Statistic p-value\n   1       0.5124721     0.8369625       0\n Alternative hypothesis: rho != 0\nDe D-W statistiek voor dit model is 0.84. Dit wijst op een probleem met autocorrelatie.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>OLS Assumpties</span>"
    ]
  },
  {
    "objectID": "linear_07.html#sec-linear-autocorr-DW",
    "href": "linear_07.html#sec-linear-autocorr-DW",
    "title": "7  OLS Assumpties",
    "section": "",
    "text": "dta &lt;- dta\n\nMet deze code verduidelijken we dat we willen dat de nieuwe, gesorteerde dataset, de oude overschrijft. We zouden ook een nieuwe dataset kunnen creëren zonder de oude te vervangen, maar dat is meestal niet nodig.\n\narrange(year)\n\nMet deze functie sorteren (‘arrange’) we de dataset volgens de waarden van de variabele tussen haakjes. Op deze manier wordt gesorteerd van lage (oud) naar hogere waarden (nieuw). We kunnen op meerdere variabelen sorteren door deze tussen haakjes toe te voegen, gescheiden van elkaar door een komma.\n\narrange(desc(year))\n\nMet deze syntax laten we de dataset sorteren van hoge (nieuw) naar lage (oud) waarden (“descending”).\n\n\n\n\n\n\n\ndurbinWatsonTest(modelname)\n\nWe voeren de Durbin-Watson test uit op het model tussen haakjes.\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\n\nAutocorrelation: Mate van correlatie tussen de fouten (errors of residuals)\nD-W Statistic: De Durbin-Watson statistiek. Waarden lager dan 1 en hoger dan 3 wijzen op te hoge autocorrelatie\np-waarde: p-waarde voor de nulhypothese dat de autocorrelatie niet significant van 0 verschilt, de alternatieve hypothese is dat die wel verschilt.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>OLS Assumpties</span>"
    ]
  },
  {
    "objectID": "linear_07.html#sec-linear-no-excessive-multicollinearity",
    "href": "linear_07.html#sec-linear-no-excessive-multicollinearity",
    "title": "7  OLS Assumpties",
    "section": "7.2 Beperkte multicollineariteit",
    "text": "7.2 Beperkte multicollineariteit\nVoor de andere assumptietests maken we gebruik van data zonder autocorrelatie. We gebruiken onze landendataset (demadata.rds) en schatten een meervoudig regressiemodel waarbij V-Dem polyarchy scores (v2x_polyarchy) voorspeld worden op basis van economische ongelijkheid (gini_2019), regime in het verleden (TYPEDEMO1984: democratie of autocratie in 1984, naar een factor variabele getransformeerd) en BBP in 2006 (GDP2006).\n\n#data laden\ndemdata &lt;- import(\"demdata.rds\") |&gt; \n  as_tibble()\n\n#Factor maken van binaire variabele\ndemdata &lt;- demdata |&gt; \n  mutate(TYPEDEMO1984_factor = factorize(TYPEDEMO1984))\n\n#Meervoudig model schatten en resultaten bekijken\nmodel_multiple &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984_factor + GDP2006, data = demdata)\n\nsummary(model_multiple)\n\n\n\nWarning: Missing `trust` will be set to FALSE by default for RDS in 2.0.0.\n\n\n# A tibble: 4 × 7\n  term                   estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)             6.78e-1   2.02e-1      3.36 0.00153  2.72e-1 1.08     \n2 gini_2019              -4.99e-3   4.98e-3     -1.00 0.322   -1.50e-2 0.00502  \n3 TYPEDEMO1984_factorDe…  7.00e-2   5.95e-2      1.18 0.246   -4.97e-2 0.190    \n4 GDP2006                 8.58e-6   2.70e-6      3.17 0.00261  3.14e-6 0.0000140\n\n\nDe coëfficienten voor gini_2019 (p = 0.322) en TYPEDEMO1984_factor (p = 0.246) zijn niet significant. Om te kijken of er sprake is van te hoge multicollineariteit gebruiken we opnieuw het car package, nu voor de vif() functie.\n\nvif(model_multiple)\n\n          gini_2019 TYPEDEMO1984_factor             GDP2006 \n           1.811074            1.171946            2.039059 \n\n\n\nvif(multiple)\n\nWe gebruiken de vif functie op het model tussen haakjes\n\n\nDe output geeft de VIF statistieken voor elke onafhankelijke variabele. Geen van de waarden is hoger dan 5 dus is er geen sprake van te hoge multicollineariteit.\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nIndien je een factor variabele opneemt met 3 of meer oorspronkelijke categorieën (bv. meerdere regio’s, onderwijsniveaus) dan krijg je licht andere output:\n\ndemdata &lt;- demdata |&gt; \n  mutate(Typeregime2006_factor = factorize(Typeregime2006))\n\nvif_example &lt;- lm(v2x_polyarchy ~ gini_2019 + GDP2006 + Typeregime2006_factor, data = demdata) \n\nvif(vif_example)\n\n                          GVIF Df GVIF^(1/(2*Df))\ngini_2019             1.385354  1        1.177011\nGDP2006               1.448928  1        1.203714\nTyperegime2006_factor 1.346530  2        1.077219\n\n\nvif() geeft nu een GVIF en GVIF^(1/(2*DF)). Dit zijn aanpassingen gezien categorische variabelen meerdere coëfficiënten hebben en dus vrijheidsgraden. We evalueren multicollineariteit door GVIF^(1/(2*DF)) te kwadrateren en we gebruiken dezelfde vuistregels als bij de gewone VIF. In principe kunnen we ook kijken of GVIF^(1/(2*DF)) op zich hoger is dan 2.23 (gezien 2.23²= 5).",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>OLS Assumpties</span>"
    ]
  },
  {
    "objectID": "linear_07.html#lineariteit-en-additiviteit",
    "href": "linear_07.html#lineariteit-en-additiviteit",
    "title": "7  OLS Assumpties",
    "section": "7.3 Lineariteit en additiviteit",
    "text": "7.3 Lineariteit en additiviteit\nEen lineair regressiemodel berust op de assumptie dat er een lineaire relatie is tussen de predictoren en de afhankelijke variabele. Om te onderzoeken of de assumptie niet geschonden is maken we gebruik van plots, aangemaakt via het ggResidpanel package.\nWe gaan hier eerst de assumptie na voor een simpel model waarbij electorale democratie (v2x_polyarchy) voorspeld wordt door ongelijkheid (gini_2019).\n\nbivar_model &lt;- lm(v2x_polyarchy ~ gini_2019, data=demdata)\n\nresid_panel(bivar_model, plots = c(\"resid\"))\n\n\n\n\n\n\n\n\n\nresid_panel(bivar_model,\n\nWe voeren de functie resid_panel uit op het model tussen haakjes.\n\nplots = c(\"resid\"))\n\nDe functie kan gebruikt worden voor meerdere soorten plots. Hier verduidelijken we dat we het plot van residuals tegen voorspelde waarden willen (“resid”).\n\n\nOp het plot zien we geen duidelijk patroon in de data, over het algemeen gewoon een puntenwolk. Het ontbreken van een patroon duidt erop dat de relatie tussen ongelijkheid en democratiescores als lineair kan beschouwd worden.\nWanneer je een ordinale variabele gebruikt als predictor in plaats van een echt continue variabele, dan ziet het plot er anders uit (i.e. neerwaarts gaande lijnen van residuals).\n\n7.3.1 Logaritmische functies\nWe krijgen niet altijd gewoon een puntenwolk zonder patroon te zien. Laten we het plot bekijken voor ons complexer model voor democratiescores (model_multiple).\n\nresid_panel(model_multiple, plots = c(\"resid\"))\n\n\n\n\n\n\n\n\nIn het plot zien we een lijnpatroon bij hogere waarden op de x-as. We kunnen onderzoeken welke onafhankelijke variabele dit patroon veroorzaakt door te kijken naar de partiële regressieplots via de avPlots() functie uit het car package.\n\navPlots(model_multiple)\n\n\n\n\n\n\n\n\n\navPlots(model_multiple)\n\nWe vragen R om de partiële regressieplots voor het model tussen haakjes.\n\n\nDeze partiële regressieplots (“added-variable plot”) tonen de relatie tussen de predictor en de afhankelijke variabele gecontroleerd voor de andere predictoren in het model.\nVoor de onafhankelijke variabele gini_2019, vinden we een relatief vlakke lijn (de coëfficiënt was ook niet significant). De residuals zijn vrij gelijk verspreid onder en boven de lijn dus er lijkt geen afwijking van lineariteit te zijn.\nVoor de TYPEDEMO1984_factor variabele bekijken we het plot niet gezien we slechts twee waarden voor deze variabele hebben.\nAls we de onafhankelijke variabele GDP2006 bekijken vinden we een positief hellende regressielijn (de coëfficiënt was ook significant), maar de punten zijn niet gelijk verspreid rond de lijn. Het lijkt hier eerder dat de relatie een degressieve curve volgt dan een rechte lijn.\nOm hiervoor te compenseren voeren we een logaritmische transformatie uit op GDP2006. We kunnen dit doen via mutate.\n\n#nieuwe gelogde variabele die we kunnen toevoegen aan de regressie\ndemdata &lt;- demdata |&gt;\n  mutate(LNGDP2006 = log(GDP2006))\n#gevolgd door regressie\nmultiple_ln &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984_factor + LNGDP2006, \n               data=demdata)\n\nWe kunnen nu het residual plot en de partiële regressieplots opnieuw inspecteren.\n\n#Residual Plot\nresid_panel(multiple_ln, plots = c(\"resid\"))\n\n\n\n\n\n\n\n#Partiële regressieplots\navPlots(multiple_ln)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nMet de logaritimische transformatie van een predictor verandert ook de interpretatie van de coëfficiënt. De volgende regels zijn van toepassing:\n\n1% toename in X (op originele schaal) leidt tot een verandering van coëfficiënt * log(1.01) eenheden in Y\n10% toename in X (op originele schaal) leidt tot een verandering van coëfficiënt * log(1.10) eenheden in Y\n\nBij een gelogde predictor is het echter vaak aan te raden een figuur met voorspelde waarden te maken om het effect te duiden.\nEerst kijken we naar de verdeling van de waarden van de gelogde predictor over alle observaties gebruikt in het model. We bekijken dus enkel data zonder ontbrekende waarden (‘NA’) voor een of meerdere van de variabelen gebruikt in het model.\n\n# Eerst de waarden van GDP2006 nagaan voor de gebruikte observaties\ndemdata_sub &lt;- demdata |&gt;\n  filter(complete.cases(v2x_polyarchy, gini_2019, TYPEDEMO1984_factor, LNGDP2006))\n\nsummary(demdata_sub$LNGDP2006)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  5.521   7.721   8.720   8.765  10.140  10.911 \n\n\nDan berekenen we voorspelde waarden over het bereik van de gelogde predictor. Hier willen we best veel voorspelde waarden berekenen want dan krijgen we een mooiere gecurvde lijn in onze figuur.\n\n# voorspellingen\nbbp_preds &lt;- predictions(multiple_ln, \n                         newdata = datagrid(LNGDP2006= seq(from=5.5,\n                                                           to=11,\n1                                                           by=0.5)))\n\n\n1\n\nseq() staat voor ‘sequence’. We vragen hier om voorspelde waarden te berekenen vanaf 5.5 tot 11 met tussenstappen van 0.5 eenheden.\n\n\n\n\nDan maken we een nieuwe variabele aan in de dataset om op de x-as van onze figuur te gaan plaatsen. Eigenlijk gaan we gewoon de gelogde predictor in de dataset terug transformeren naar de originele schaal door de waarden te exponentiëren via de exp() functie.\n\n#exponentiëren van gelogde predictor\nbbp_preds &lt;- bbp_preds |&gt; \n1  mutate(GDP2006 = exp(LNGDP2006))\n\n\n1\n\nexp() is het omgekeerde van log, zoals - het omgekeerde is van + etc.\n\n\n\n\nTen slotte maken we onze figuur:\n\n#figuur maken van voorspelde waarden\nggplot(bbp_preds, aes(x=GDP2006, y=estimate)) + \n  geom_line() +\n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), \n              alpha = 0.1) +\n  labs(title = \"Voorspelde electorale democratiescore op basis van BBP 2006\",\n       x = \"BBP 2006\",   \n       y = \"Voorspelde waarde\") +  \n  scale_y_continuous(limits=c(0,1))\n\n\n\n\n\n\n\n\nInterpretaties veranderen ook als je de afhankelijke variabele log-transformeert. Voor verdere mogelijkheden met logaritmische transformaties, verwijzen we ja naar deze en deze pagina.\n\n\n\n\n7.3.2 Kwadratische functies\nEen andere niet-lineaire relatie die we kunnen tegenkomen is de kwadratische of curvilineaire relatie. Bij wijze van voorbeeld hier inspireren we ons op de ‘meer geweld in het midden’-these, namelijk het idee dat landen met hybride regimes (gemiddelde democratiescores) meer geweld en instabiliteit ervaren dan zowel autoritaire systemen (lage democratiescores) als democratische systemen (hoge democratiescores).\nDe variabele voor politiek geweld en instabiliteit is hier pve en is gebaseerd of de 2021 World Governance Indicators. Hogere waarden staan voor minder geweld en instabiliteit. Hier gebruiken we electorale democratie (v2x_polyarchy) als onafhankelijke variabele.\nWe inspecteren hier eerst de empirische, bivariate relatie met behulp van een scatterplot.\n\nggplot(demdata, aes(x = v2x_polyarchy, y = pve)) + \n  geom_point() + \n  geom_smooth(method = \"loess\") +\n  labs(title = \"Politiek geweld en democratie\", \n       x = \"Electorale democratie (2020)\", \n       y = \"Afwezigheid van politiek geweld en instabiliteit (2021)\")\n\n\n\n\n\n\n\n\nDe syntax lijkt sterk op wat we eerder gezien hebben (Paragraaf 1.2), met 1 belangrijk verschil:\n\ngeom_smooth(method = \"loess\")\n\nHier vragen we R om een lijn te tekenen om de relatie tussen de 2 variabelen te vatten. We vragen hier niet om een rechte lijn (method=“lm”), maar een ‘locally estimated scatterplot smoothing’ (loess) lijn (method = “loess”). Deze lijn volgt de data zo nauwgezet mogelijk om de relatie tussen de variabelen weer te geven. De loess methode is de standaard (default) methode om de lijn te tekenen. We zouden dus ook gewoon geom_smooth() kunnen schrijven om dezelfde uitkomst te verkrijgen.\n\n\nZoals we kunnen zien als we naar het scatterplot kijken is er enige steun voor een curvilineaire relatie. We schatten nu eerst een lineair regressiemodel:\n\n#schat het model\nViolence_linmodel &lt;- lm(pve ~ v2x_polyarchy, data = demdata)\n\n#bekijk resultaten\ntidy(Violence_linmodel, conf.int = TRUE)\n\n# A tibble: 2 × 7\n  term          estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)      -1.34     0.135     -9.90 2.36e-18    -1.60     -1.07\n2 v2x_polyarchy     2.19     0.233      9.38 5.75e-17     1.73      2.65\n\n\nDe niet-lineaire relatie kun je soms zien uit het residuals plot, in de vorm van een gebogen patroon, maar dit is visueel minder zichtbaar hier:\n\nresid_panel(Violence_linmodel, plots = c(\"resid\"))\n\n\n\n\n\n\n\n\nOm te onderzoeken of de relatie beter als kwadratisch wordt gevat voegen we een kwadratische term toe aan het model. We kunnen deze variabele eerst maken en dan toevoegen aan het model, samen met de originele variabele. We kunnen de transformatie ook in de regressielijn zelf toevoegen via de I() functie. Dit is iets eenvoudiger gezien we de variabele niet moeten maken. Bovendien werkt deze methode beter met functies van het marginaleffects package die we gebruiken om modellen te interpreteren (bv. de predictions() functie).\n\n#gewadrateerde variabele maken\ndemdata &lt;- demdata |&gt; \n  mutate(v2x_polyarchy_sq = v2x_polyarchy^2)\n\n#nieuw model schatten\nViolence_sqmodel &lt;- lm(pve ~ v2x_polyarchy + v2x_polyarchy_sq, \n               data=demdata)\n\n#transformatie toepassen in regressie\nViolencesqmodel &lt;- lm(pve ~ v2x_polyarchy + I(v2x_polyarchy^2), \n                      data=demdata)\n\nsummary(Violencesqmodel)\n\n\nCall:\nlm(formula = pve ~ v2x_polyarchy + I(v2x_polyarchy^2), data = demdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.98053 -0.34138  0.08204  0.43420  2.14095 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         -0.5888     0.2430  -2.423 0.016507 *  \nv2x_polyarchy       -1.7306     1.0980  -1.576 0.116943    \nI(v2x_polyarchy^2)   3.8288     1.0505   3.645 0.000361 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.741 on 161 degrees of freedom\n  (15 observations deleted due to missingness)\nMultiple R-squared:  0.4013,    Adjusted R-squared:  0.3939 \nF-statistic: 53.96 on 2 and 161 DF,  p-value: &lt; 2.2e-16\n\ntidy(Violence_sqmodel, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term             estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        -0.589     0.243     -2.42 0.0165      -1.07    -0.109\n2 v2x_polyarchy      -1.73      1.10      -1.58 0.117       -3.90     0.438\n3 v2x_polyarchy_sq    3.83      1.05       3.64 0.000361     1.75     5.90 \n\n\nWe vinden hier dat de kwadratische variabele significant is (p &lt; 0.001) en dus dat de relatie tussen v2x_polyarchy en pve beter als curvilineair dan lineair te beschrijven is.\nWe kunnen dan het residuals plot opnieuw inspecteren (zie onder).\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nBij een kwadratische predictor is de interpretatie van de coëfficiënten (want de originele en gekwadrateerde variabelen horen samen) best moeilijk. De volgende regels zijn van toepassing:\n\nAls de coëfficiënt voor X positief is en die voor X2 negatief, dan is de relatie tussen X en Y concaaf (omgekeerde U)\nAls de coëfficiënt voor X negatief is en die voor X2 positief, dan is de relatie tussen X en Y convex (U-vorm)\nAls beide coëfficiënten dezelfde richting hebben (beiden positief of beiden negatief), dan wordt het effect van X op Y sterker als X hogere waarden aanneemt.\n\nWederom is het vaak beter om de relatie visueel te verduidelijken. Om dit te doen kijken we eerste naar de waarden die de predictor aanneemt voor de observaties gebruikt bij de schatting van het model:\n\n#waarden van X nagaan voor de gebruikte observaties\ndemdata_sub2 &lt;- demdata |&gt;\n  filter(complete.cases(v2x_polyarchy , pve))\nsummary(demdata_sub2$v2x_polyarchy)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0150  0.2865  0.5425  0.5191  0.7625  0.9080 \n\n\nWe berekenen vervolgens voorspelde waarden via predictions(). Hier willen we best veel voorspelde waarden berekenen want dan krijgen we een mooiere gecurvde lijn in onze figuur.\n\n# voorspellingen maken op basis van de waarden\npve_preds &lt;- predictions(Violencesqmodel, \n                         newdata = datagrid(v2x_polyarchy= seq(from=0, to=0.9, by=0.05)))\n\nTen slotte maken we onze figuur:\n\n#figuur maken van voorspelde waarden\nggplot(pve_preds, aes(x=v2x_polyarchy, y=estimate)) + \n  geom_line() +\n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), \n              alpha = 0.1) + \n  labs(title = \"Voorspelde afwezigheid van geweld en instabiliteit\",\n       x = \"Electorale democratie\",   \n       y = \"Voorspelde waarde\")",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>OLS Assumpties</span>"
    ]
  },
  {
    "objectID": "linear_07.html#homoskedasticiteit",
    "href": "linear_07.html#homoskedasticiteit",
    "title": "7  OLS Assumpties",
    "section": "7.4 Homoskedasticiteit",
    "text": "7.4 Homoskedasticiteit\nOm te onderzoeken of de assumptie van homoskedasticiteit geschonden is maken we opnieuw gebruik van het residuals plot (scatterplot van voorspelde waarden en residuals). Hier vinden we bijvoorbeeld heteroskedasticiteit voor het kwadratische model (Violence_sqmodel):\n\nresid_panel(Violence_sqmodel, plots = c(\"resid\"))\n\n\n\n\n\n\n\n\nOpnieuw zien we liever een wolk van toevallig verspreide punten (homoskedasticiteit) eerder daan een trechter-vorm (heteroskedasticiteit). De trechter-vorm in het plot wijst erop dat de assumptie geschonden is.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>OLS Assumpties</span>"
    ]
  },
  {
    "objectID": "linear_07.html#normaal-verdeelde-errors",
    "href": "linear_07.html#normaal-verdeelde-errors",
    "title": "7  OLS Assumpties",
    "section": "7.5 Normaal verdeelde errors",
    "text": "7.5 Normaal verdeelde errors\nWe onderzoeken of de assumptie van normaal verdeelde errors is geschonden met behulp van 2 mogelijke plots uit het ggResidpanel package: een histogram van de fouten en een kwartielplot (qq-plot) van de fouten.\nHier gaan we na of de assumptie geschonden is voor ons meervoudig regressiemodel met gelogde GDP predictor (multiple_ln):\n\nresid_panel(multiple_ln, plots = c(\"hist\", \"qq\"))\n\n\n\n\n\n\n\n\n\nplots = c(\"hist\", \"qq\"))\n\nHier vragen we om het histogram (“hist”) samen met het qq-plot (“qq”).\n\n\nWe zouden ook het residuals plot (“resid”) kunnen toevoegen indien we meerdere assumpties vlug samen willen testen:\n\nresid_panel(multiple_ln, plots = c(\"resid\", \"hist\", \"qq\"))",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>OLS Assumpties</span>"
    ]
  },
  {
    "objectID": "linear_07.html#beperkte-impact-outliers-en-influential-cases",
    "href": "linear_07.html#beperkte-impact-outliers-en-influential-cases",
    "title": "7  OLS Assumpties",
    "section": "7.6 Beperkte impact outliers en influential cases",
    "text": "7.6 Beperkte impact outliers en influential cases\nWe gebruiken de augment() functie uit het broom package op de meervoudig regressie met gelogde GDP predictor (multiple_ln). De statistieken worden in een nieuwe dataset opgeslagen in onderstaande code.\n\n#augment gebruiken en resultaten opslaan in nieuw object\ndemdata_multln &lt;- augment(multiple_ln)\n\n\ndemdata_multln &lt;-augment(multiple_ln)\n\nWe gebruiken de augment functie op het model tussen haakjes en slaan de resultaten op in een nieuw data object (demdata_multln).\n\n\nDe gegevens in het dataobject zien er als volgt uit:\n\ndemdata_multln\n\n# A tibble: 53 × 11\n   .rownames v2x_polyarchy gini_2019 TYPEDEMO1984_factor LNGDP2006 .fitted\n   &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;                   &lt;dbl&gt;   &lt;dbl&gt;\n 1 3                 0.908      26.5 Democracies             10.3    0.857\n 2 4                 0.894      30.1 Democracies             10.5    0.881\n 3 10                0.485      37.5 Autocracies              7.38   0.480\n 4 13                0.652      48   Democracies              7.75   0.559\n 5 14                0.632      29.3 Autocracies              8.62   0.625\n 6 15                0.678      47.6 Democracies              8.31   0.632\n 7 16                0.807      38.7 Democracies             10.5    0.906\n 8 17                0.882      32.1 Democracies              9.32   0.733\n 9 18                0.577      37.3 Democracies              7.68   0.530\n10 20                0.327      40.7 Democracies              6.99   0.447\n# ℹ 43 more rows\n# ℹ 5 more variables: .resid &lt;dbl&gt;, .hat &lt;dbl&gt;, .sigma &lt;dbl&gt;, .cooksd &lt;dbl&gt;,\n#   .std.resid &lt;dbl&gt;\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\naugment() creëert een dataframe met alle observaties die gebruikt zijn om het model te schatten. Je vindt de volgende kolommen terug:\n\n.rownames: Di is het rijnummer van de observatie zoals je die vindt in de originele dataset (zonder eventuele missing waarden)\nv2x_polyarchy tot en met LNGDP2006: Dit zijn de variabelen gebruikt in het model met de waarden die elke observatie ervoor heeft.\n.fitted: De voorspelde (‘fitted’) waarden op basis van de schattingen in het model.\nresid: De residuals (fouten/errors) voor elke observatie, waarbij Residual = Observed - Fitted/Predicted. Hier: Residual = v2x_polyarchy - .fitted\n.hat: Diagonaal van de hat matrix (te negeren).\n.sigma: Geschatte standaardafwijking van de fouten als de observatie uit het model zou worden verwijderd (te negeren)\n.cooksd: De Cook’s D waarde voor de observatie. Zie onder.\n.std.resid: Niet getoond in de output hierboven maar aanwezig in de dataset. Deze kolom bevat de gestandaardiseerde residuals van het model. Zie onder.\n\n\n\nWe gebruiken de gestandaardiseerde residuals (.std.resid) om eerst outliers te onderzoeken. Vervolgens gebruiken we de Cook’s D waarden (.cooksd) om influential cases te onderzoeken.\n\n7.6.1 Outliers analyseren\nOm te beginnen bekijken we de descriptieve statistieken voor de gestandaardiseerde residuals (opgeslagen in het data object demdata_multln) . We kijken specifiek naar de minimum- en maximum waarden als eerste check voor outliers. We bekijken in het bijzonder of gestandaardiseerde residuals hoger zijn dan de drempelwaarden van (|1.96|, |2.58|, en zeker |3.29|).\n\nsummary(demdata_multln$.std.resid)\n\n      Min.    1st Qu.     Median       Mean    3rd Qu.       Max. \n-3.1281471 -0.2252984  0.2109869 -0.0007828  0.5831831  1.7394397 \n\n\nWe vinden waarden die zorgwekkend kunnen zijn. Zo is er al zeker 1 observatie waarvan de gestandaardiseerde residual een absolute waarde hoger dan 2.58 heeft (aangezien het minimum -3.128 is). Maar we moeten nog nagaan hoeveel observaties precies de drempelwaarden overschrijden.\nWe doen dit door 3 dummy variabelen aan te maken in onze dataset: SRE1.96, SRE2.58, SRE3.29. Deze dummy variabelen nemen de waarde ‘1’ aan als de gestandaardiseerde residual van een observatie hoger is dan de drempelwaarde in de naam van de variabele. Als de waarde van de gestandaardiseerde residual lager is, neemt de dummy de waarde ‘0’ aan. We gebruiken hier de case when functie (uit dplyr) voor de hercodering. Zie Statistiek I, 5.1\nOnderstaande code kun je grotendeels onaangepast laten in je eigen voorbeelden, enkel de naam van de dataset (hier: demdata_multln) moet aangepast worden voor eigen toepassingen.\n\ndemdata_multln &lt;- demdata_multln |&gt;\n  mutate(SRE1.96 = case_when(\n    .std.resid &gt; 1.96 | .std.resid &lt; -1.96  ~ 1,\n    .std.resid &gt; -1.96 & .std.resid &lt; 1.96 ~ 0),\n         SRE2.58 = case_when(\n    .std.resid &gt; 2.58 | .std.resid &lt; -2.58  ~ 1,\n    .std.resid &gt; -2.58 & .std.resid &lt; 2.58 ~ 0),\n        SRE3.29 = case_when(\n    .std.resid &gt; 3.29 | .std.resid &lt; -3.29  ~ 1,\n    .std.resid &gt; -3.29 & .std.resid &lt; 3.29 ~ 0\n  ))\n\n\ndemdata_multln &lt;- demdata_multln |&gt;\n\nDe nieuwe variabelen maken gebruik van de demdata_multln dataset (voor de .std.resid variabele), en worden ook zelf opgeslagen in deze dataset.\n\nmutate(SRE1.96 = case_when(\n\nWe creëren hier de nieuwe variabele SRE1.96. De waarden worden bepaald door de case_when functie.\n\n.std.resid &gt; 1.96 | .std.resid &lt; -1.96 ~ 1,\n\nHier duiden we aan dat wanneer gestandaardiseerde residuals groter dan 1.96 of (de streep ‘|’ staat symbool voor ‘of’ ) lager dan -1.96 zijn, de SRE1.96 variabele de waarde 1 aanneemt (~). Let erop dat de variabele .std.resid twee keer geschreven moet worden.\n\n.std.resid &gt; -1.96 & .std.resid &lt; 1.96 ~ 0),\n\nHier duiden we aan dat wanneer gestandaardiseerde residuals groter dan -1.96 en (de ‘&’ staat hier voor ‘en’) lager dan 1.96 zijn, de SRE1.96 variabele de waarde 0 aanneemt (~).\n\n\nNu we de dummies aangemaakt hebben kunnen we frequentietabellen voor elk van hen bekijken. We maken gebruik van de fre() functie uit het expss package.\nDe code hieronder kun je wederom grotendeels gebruiken voor eigen voorbeelden; enkel de naam van de dataset (hier: demdata_multln) dient veranderd te worden voor eigen toepassingen.\n\nfre(demdata_multln$SRE1.96)\n\n\n\n\ndemdata_multln$SRE1.96\n Count \n Valid percent \n Percent \n Responses, % \n Cumulative responses, % \n\n\n\n\n 0 \n49\n92.5\n92.5\n92.5\n92.5\n\n\n 1 \n4\n7.5\n7.5\n7.5\n100.0\n\n\n #Total \n53\n100\n100\n100\n\n\n\n &lt;NA&gt; \n0\n\n0.0\n\n\n\n\n\n\nfre(demdata_multln$SRE2.58)\n\n\n\n\ndemdata_multln$SRE2.58\n Count \n Valid percent \n Percent \n Responses, % \n Cumulative responses, % \n\n\n\n\n 0 \n51\n96.2\n96.2\n96.2\n96.2\n\n\n 1 \n2\n3.8\n3.8\n3.8\n100.0\n\n\n #Total \n53\n100\n100\n100\n\n\n\n &lt;NA&gt; \n0\n\n0.0\n\n\n\n\n\n\nfre(demdata_multln$SRE3.29)\n\n\n\n\ndemdata_multln$SRE3.29\n Count \n Valid percent \n Percent \n Responses, % \n Cumulative responses, % \n\n\n\n\n 0 \n53\n100\n100\n100\n100\n\n\n #Total \n53\n100\n100\n100\n\n\n\n &lt;NA&gt; \n0\n\n0\n\n\n\n\n\n\n\nWe vinden hier dat meer dan 5% van de observaties een gestandaardiseerde residual heeft met een absolute waarde hoger dan 1.96, meer dan 1% heeft een gestandaardiseerde residual met een absolute waarde hoger dan 2.58. Er is geen enkele observatie met een absolute waarde hoger dan 3.29 (dit konden we reeds aflezen uit de descriptieve statistieken).\nOm te onderzoeken of de outliers ook een invloed hebben op de resultaten van het model vergelijken we de resultaten van ons model met die van een nieuw model zonder outliers. Hier doen we dit voor outliers met gestandaardiseerde residuals met absolute waarde hoger dan 1.96. De SRE1.96 variabele kan vervangen worden met de SRE2.58 en SRE3.29 variabelen om alternatieve manieren om outliers uit te sluiten te onderzoeken.\n\nmultiple_ln1.96 &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984_factor + LNGDP2006,\n               data = subset(demdata_multln, SRE1.96 == 0))\n\n\ndata = subset(demdata_multln, SRE1.96 == 0))\n\nMet deze code gebruiken we de demdata_multln dataset gecreëerd met augment, maar we behouden enkel observaties die voor de variabele SRE1.96 de waarde 0 hebben.\n\n\nAls we de modellen met en zonder outliers vergelijken gaan we na of de coëfficiënten en hun significantie substantieel veranderd zijn. Let wel, outliers kunnen niet zomaar verwijderd worden om om de model fit te verbeteren. Er moet een gemotiveerde, theoretische reden zijn voor uitsluiting van observaties.\n\n\n7.6.2 Influential cases analyseren\nOm influential cases te onderzoeken gaan we na of er observaties zijn in de dataset met hoge Cook’s D waarden:\n\nwaarden hoger dan 1 zijn over het algemeen zorgwekkend;\nwaarden hoger dan 0.5 moeten nader bestudeerd worden en kunnen een risico vormen;\nwaarden die veel hoger zijn dan de andere Cook’s D waarden behoeven ook verdere aandacht.\n\nWe bekijken eerst de overzichtsstatistieken voor de Cook’s D waarden.\n\nsummary(demdata_multln$.cooksd)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n0.0000036 0.0007700 0.0035030 0.0292621 0.0162039 0.6608136 \n\n\nHet overzicht toont dat er minstens 1 observatie is met een hoge Cook’s D waarde. De maximum waarde is 0.66 en deze waarde is substantieel hoger dan de andere waarden. De waarde voor het 3de kwartiel is slechts 0.016, wat betekent dat 75% van de observaties een waarde lager hebben dan 0.016.\nWe kunnen ook een visualisatie maken van de Cook’s D waarden met het ggResidpanel package:\n\nresid_panel(multiple_ln, plots = c(\"cookd\"))\n\n\n\n\n\n\n\n\n\nplots = c(\"cookd\"))\n\nWe vragen hier om een plot met Cook’s D waarden op de y-as. Het rijnummer van de observatie in de dataset komt op de x-as.\n\n\nDe grafiek toont dat er slechts 1 case is om ons zorgen over te maken. Dit is de case met de maximumwaarde van 0.66.\nWe kunnen deze case verwijderen uit het model om na te gaan of de resultaten beïnvloed worden:\n\nmultiple_lncook &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984_factor + LNGDP2006,\n               data = subset(demdata_multln, .cooksd &lt; 0.65))\n\n\ndata = subset(demdata_multln, .cooksd &lt; 0.65))\n\nWe gebruiken de demdata_multln dataset maar vragen om een subset van de data met enkel die observaties met een waarde lager dan 0.65 voor .cooksd. We kiezen deze waarde hier omdat de case die we willen uitsluiten een waarde van 0.66 heeft. In principe hadden we ook 0.66 zelf, 0.64 enz. kunnen kiezen, zolang het een grenswaarde is die de mogelijk invloedrijke casus uitsluit.\n\n\nWe kunnen ook outliers en influential cases tegelijk uitsluiten als we in de syntax gebruik maken van het ‘&’ teken:\n\nmultiple_ln_excl &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984_factor + LNGDP2006,\n               data = subset(demdata_multln,\n                             SRE1.96==0 & .cooksd &lt; 0.65))\n\n\n\n7.6.3 Specifieke probleemgevallen analyseren\nWat we in vorige analyses niet bekeken hebben is welke specifieke observaties outliers of influential cases waren. Om dit te kunnen doen moeten we de gestandaardiseerde residuals en Cook’s D waarden toevoegen aan onze originele dataset, waar we de country name variabele hebben.\nIndien er missende waarden zijn, zoals hier het geval is, kunnen we deze statistieken niet zomaar met augment toevoegen aan de originele dataset. Een oplossing is om eerst een dataset te creëren met niet-missende waarden voor de variabelen gebruikt in het model en dan met augment de statistieken aan deze ‘complete cases’ dataset toe te voegen:\n\n# subset van de dataset zonder 'NA' waarden\ndemdata_complete &lt;- demdata |&gt;\n  filter(complete.cases(v2x_polyarchy, gini_2019, TYPEDEMO1984_factor, LNGDP2006))\n\n# model opnieuw geschat met nieuwe dataset\nmultiple_ln &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984_factor + LNGDP2006, \n               data=demdata_complete)\n\n# augment gebruiken om statistieken toe te voegen\ndemdata_complete &lt;-augment(multiple_ln, data=demdata_complete)\n\nNu kunnen we specifieke outliers onderzoeken met de volgende code:\n\ndemdata_complete |&gt; \n  filter(.std.resid &gt; 1.96 | .std.resid &lt; -1.96) |&gt;\n  select(country_name, .std.resid)\n\n# A tibble: 4 × 2\n  country_name .std.resid\n  &lt;chr&gt;             &lt;dbl&gt;\n1 Thailand          -2.17\n2 Venezuela         -2.68\n3 China             -2.53\n4 Singapore         -3.13\n\n\n\nfilter(.std.resid &gt; 1.96 | .std.resid &lt; -1.96)\n\nHier willen we outliers vinden, dus we filteren voor observaties met gestandaardiseerde residual hoger dan 1.96 of lager dan -1.96.\n\nselect(country_name.std.resid)\n\nHier vragen we R om de namen van de landen en hun specifieke gestandaardiseerde residual.\n\n\nDe influential case vinden we op een gelijkaardige manier:\n\ndemdata_complete |&gt; \n  filter(.cooksd &gt; 0.65) |&gt;\n  select(country_name, .cooksd)\n\n# A tibble: 1 × 2\n  country_name .cooksd\n  &lt;chr&gt;          &lt;dbl&gt;\n1 Singapore      0.661",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>OLS Assumpties</span>"
    ]
  },
  {
    "objectID": "linear_08.html",
    "href": "linear_08.html",
    "title": "8  Rapporteren en Presenteren van Resultaten",
    "section": "",
    "text": "8.1 Beschrijvende Statistieken\nVooraleer we beginnen aan het onderzoeken van verbanden tussen variabelen, is het gebruikelijk om alle variabelen op zich te onderzoeken: wat zijn de minima en maxima, het gemiddelde, en de standaardafwijking (voor continue variabelen) of de frequenties (voor binaire/categorische variabelen)? In een onderzoekspaper vind je dan ook vaak een tabel met deze descriptieve statistieken (ofwel in de tekst zelf, ofwel in Appendix). Deze tabel geeft de lezer (en de onderzoeker!) meer inzicht in de gebruikte variabelen.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Rapporteren en Presenteren van Resultaten</span>"
    ]
  },
  {
    "objectID": "linear_08.html#sec-report-descriptives",
    "href": "linear_08.html#sec-report-descriptives",
    "title": "8  Rapporteren en Presenteren van Resultaten",
    "section": "",
    "text": "8.1.1 Continue variabelen\nWe kunnen gemakkelijk een descriptieve tabel maken met het modelsummary package en de datasummary functie binnen dat package:\n\ndatasummary(v2x_polyarchy + gini_2019\n            ~ Mean + SD + Min + Max + N, data = demdata)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Mean\n                SD\n                Min\n                Max\n                N\n              \n        \n        \n        \n                \n                  v2x_polyarchy\n                  0.51\n                  0.25\n                  0.01\n                  0.91\n                  179\n                \n                \n                  gini_2019\n                  34.36\n                  6.87\n                  22.60\n                  48.00\n                  70\n                \n        \n      \n    \n\n\n\nZo lees je de syntax:\n\ndatasummary(\n\nWe gebruiken de datasummaryfunctie op de variabelen tussen haakjes\n\nv2x_polyarchy + gini_2019\n\nDit zijn de variabelen die we willen opnemen in de tabel. Meerdere variabelen kunnen toegevoegd worden met behulp van een + teken. Voor een tabel met alle variabelen uit de dataset kun je All(naam dataset)gebruiken. Dit doe je doorgaans enkel als de dataset niet veel variabelen bevat.\n\n~ Mean + SD + Min + Max + N,\n\nWe geven hier na de tilde ~ weer welke statistieken we precies willen. De statistieken gevraagd hier zijn het meest gebruikelijk.\n\ndata = demdata\n\nWe geven hier aan uit welk dataobject de variabelen afkomstig zijn.\n\n\nDe tabel geeft reeds alle nodige informatie aan de lezer. Zo kan je uit de N afleiden dat een bivariate analyse van deze twee variabelen gebruik zal maken van veel minder cases dan beschikbaar in v2x_polyarchyomdat er best was ontbrekende waarden zijn bij gini_2019.\n\n\n8.1.2 Binaire en categorische variabelen\nWe kunnen ook binaire en categorische variabelen toevoegen aan een tabel, maar hier geef je doorgaans andere statistieken: de N en het percentage observaties in de dataset. We nemen de voorbeelden TYPEDEMO1984 en Typeregime2006.\n\n# transformeren naar factor\ndemdata &lt;- demdata |&gt; \n  mutate(TYPEDEMO1984_factor = factorize(TYPEDEMO1984))\ndemdata &lt;- demdata |&gt; \n  mutate(Typeregime2006_factor = factorize(Typeregime2006))\n\n#tabel met percentage en N\ndatasummary(TYPEDEMO1984_factor + Typeregime2006_factor \n            ~ N + Percent(), data = demdata)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                  \n                N\n                Percent\n              \n        \n        \n        \n                \n                  Type of democracy, 1984\n                  Autocracies\n                  86\n                  48.04\n                \n                \n                  \n                  Democracies\n                  57\n                  31.84\n                \n                \n                  Type of regime 2006 (3 cat)\n                  Liberal democracy\n                  71\n                  39.66\n                \n                \n                  \n                  Electoral democracy\n                  53\n                  29.61\n                \n                \n                  \n                  Autocracy\n                  41\n                  22.91\n                \n        \n      \n    \n\n\n\n\n~ N + Percent(),\n\nWe geven hier na de tilde ~ weer welke statistieken we precies willen. In het geval van factorvariabelen zijn deze gebruikelijk. Let erop dat het percentage dat wordt gegeven ook NA waarden gebruikt in de berekening. Hieronder tonen we hoe je dit kan aanpassen.\n\n\nDe verschillende syntax suggereert dat we voor continue en binaire/categorische variabelen best aparte tabellen maken. Toch is dit niet nodig. In een analyse transformeert R achter de schermen een factorvariabele in meerdere dummy-variabelen. Deze 0-1 variabelen kunnen we opnemen samen met continue variabelen in een tabel. Het gemiddelde geeft dan de proportie weer van observaties in deze categorie, terwijl de N het aantal valide cases voor de variabele als geheel weergeeft.\nWe kunnen de dummy variabelen zelf aanmaken via mutate maar het kan sneller met het fastdummies package.\n\n#laad het package (meestal aan het begin van je script)\nlibrary(fastDummies)\n\n#dummy variabelen aanmaken voor alle categorieën van de variabelen\ndemdata &lt;- dummy_cols(demdata, \n                      select_columns = \n                        c(\"TYPEDEMO1984\", \"Typeregime2006\"))\n\n\ndummy_cols(demdata\n\nwe passen de functie dummy_colstoe en duiden eerst de dataset aan die van toepassing is.\n\nselect_columns = c(\"TYPEDEMO1984\", \"Typeregime2006\"))\n\nNu creëeren we dummy-variabelen voor alle categorieën (inclusief NA) van de aangeduide categorische variabelen van de dataset.1 De nieuwe dummy-variabelen worden toegevoegd aan de dataset met de demdata &lt;- syntax. De naam wordt automatisch gegenereerd: de naam van de variabele met daaraan gelinkt de numerieke code (of tekst-code indien de variabele niet numeriek is). De niet-gefactorde versie van TYPEDEMO1984 in dit voorbeeld neemt 2 mogelijke waarden aan: 1 = democratie and 2 = autocratie.2 De functie creëert de volgende dummies: TYPEDEMO1984_1 (observaties met de waarde ‘1’ scoorden ‘1’ op de originele variabele; observaties met score ‘0’ scoorden ‘2’ op de originele variabele) en TYPEDEMO1984_2 (observaties met de waarde ‘1’ scoorden ‘2’ op de originele variabele; observaties met score ‘0’ scoorden ‘1’ op de originele variabele). We kunnen dit beter zien in de kruistabel hieronder.\n\n\n\n# Crosstab of original variable and dummies via dummy_cols()\ntable(demdata$TYPEDEMO1984, demdata$TYPEDEMO1984_1)\n\n   \n     0  1\n  1  0 86\n  2 57  0\n\ntable(demdata$TYPEDEMO1984, demdata$TYPEDEMO1984_2)\n\n   \n     0  1\n  1 86  0\n  2  0 57\n\n\nWe kunnen de dummyvariabelen toevoegen aan de datasummary functie samen met de continue variabelen.\n\n# tabel maken voor dummies alsof het continue variabelen zijn\ndatasummary(v2x_polyarchy + gini_2019+\n            TYPEDEMO1984_1 + TYPEDEMO1984_2 +\n            Typeregime2006_1 + \n            Typeregime2006_2 +\n            Typeregime2006_3 \n            ~ Mean + SD + Min + Max + N, data = demdata)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Mean\n                SD\n                Min\n                Max\n                N\n              \n        \n        \n        \n                \n                  v2x_polyarchy\n                  0.51\n                  0.25\n                  0.01\n                  0.91\n                  179\n                \n                \n                  gini_2019\n                  34.36\n                  6.87\n                  22.60\n                  48.00\n                  70\n                \n                \n                  TYPEDEMO1984_1\n                  0.60\n                  0.49\n                  0.00\n                  1.00\n                  143\n                \n                \n                  TYPEDEMO1984_2\n                  0.40\n                  0.49\n                  0.00\n                  1.00\n                  143\n                \n                \n                  Typeregime2006_1\n                  0.43\n                  0.50\n                  0.00\n                  1.00\n                  165\n                \n                \n                  Typeregime2006_2\n                  0.32\n                  0.47\n                  0.00\n                  1.00\n                  165\n                \n                \n                  Typeregime2006_3\n                  0.25\n                  0.43\n                  0.00\n                  1.00\n                  165\n                \n        \n      \n    \n\n\n\nDe gemiddelden voor de dummy-variabelen geven de proportie van observaties met de score ‘1’ weer. De berekening negeert ontbrekende ‘NA’ waarden in tegenstelling tot de methode hierboven zonder dummies. De waarden zijn dus correcter. In deze tabel hebben we all dummies opgenomen. In de praktijk laten we bij binaire variabelen vaak de referentiecategorie weg (bv., enkelTYPEDEMO1984_2 in de tabel).\n\n\n8.1.3 Presentatie: Descriptieve tabellen\nVoorgaande tabellen gebruiken nog de naam van de variabelen in de dataset. Deze zijn vaak niet intuïtief voor een lezer. We zullen de namen dan ook veranderen vooraleer we een tabel presenteren. Dit doen we met behulp van de rename functie.\n\n# we maken een nieuwe, kleinere dataset met hernoemde variabelen\ntable_data &lt;- demdata |&gt; \n  select(v2x_polyarchy, gini_2019, \n         TYPEDEMO1984_1, TYPEDEMO1984_2,\n         Typeregime2006_1, Typeregime2006_2, Typeregime2006_3) |&gt; \n  rename(\"Polyarchiescore (2020)\" = v2x_polyarchy, \n         \"Economische ongelijkheid (2019)\" = gini_2019,\n         \"Autocratie (1984)\"  = TYPEDEMO1984_1,\n         \"Democratie (1984)\" = TYPEDEMO1984_2,\n         \"Liberale democratie (2006)\" = Typeregime2006_1, \n         \"Electorale democratie (2006)\" = Typeregime2006_2,\n         \"Autocratie (2006)\" = Typeregime2006_3)\n\n#we vragen een datatabel voor alle variabelen in de nieuwe dataset\ndatasummary(All(table_data)\n            ~ Mean + SD + Min + Max + N, data = table_data)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Mean\n                SD\n                Min\n                Max\n                N\n              \n        \n        \n        \n                \n                  Polyarchiescore (2020)\n                  0.51\n                  0.25\n                  0.01\n                  0.91\n                  179\n                \n                \n                  Economische ongelijkheid (2019)\n                  34.36\n                  6.87\n                  22.60\n                  48.00\n                  70\n                \n                \n                  Autocratie (1984)\n                  0.60\n                  0.49\n                  0.00\n                  1.00\n                  143\n                \n                \n                  Democratie (1984)\n                  0.40\n                  0.49\n                  0.00\n                  1.00\n                  143\n                \n                \n                  Liberale democratie (2006)\n                  0.43\n                  0.50\n                  0.00\n                  1.00\n                  165\n                \n                \n                  Electorale democratie (2006)\n                  0.32\n                  0.47\n                  0.00\n                  1.00\n                  165\n                \n                \n                  Autocratie (2006)\n                  0.25\n                  0.43\n                  0.00\n                  1.00\n                  165\n                \n        \n      \n    \n\n\n\nDe modelsummary website geeft nog andere manieren weer om variabelen te hernamen binnen de functie zelf; zie deze link.\n\n\n8.1.4 Opslaan als Word document\nDeze tabel kunnen we naar Word exporteren met onderstaande syntax. Voor een tabel in een Nederlandse paper, verander je het woord ‘mean’ naar ‘gemiddelde’ in Word.\n\ndatasummary(All(table_data)\n            ~ Mean + SD + Min + Max + N, data = table_data,\n  output = \"descr_tabel.docx\")\n\n\noutput = 'descr_tabel.docx'\n\nHier vragen we om een Word document (.docx) genaamd “descr_tabel” op te slaan. Dit bestand vind je terug in je R project folder. Je kan ook een subfolder aanduiden, bv. “Output folder/descr_tabel.docx”. Let erop dat je het Word document niet geopend hebt als je de syntax opnieuw wil gebruiken met aanpassingen, anders kun je een foutmelding krijgen.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Rapporteren en Presenteren van Resultaten</span>"
    ]
  },
  {
    "objectID": "linear_08.html#sec-report-scatterplots",
    "href": "linear_08.html#sec-report-scatterplots",
    "title": "8  Rapporteren en Presenteren van Resultaten",
    "section": "8.2 Puntenwolken of Scatterplots",
    "text": "8.2 Puntenwolken of Scatterplots\nWe kunnen een visuele weergave tonen van de bivariate relatie tussen twee continue variabelen in een puntenwolk of scatterplot. Hieronder is een voorbeeld voor de variabelen gini_2019 en v2x_polyarchy:\n\nggplot(demdata, aes(x = gini_2019, y = v2x_polyarchy)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  labs(x = \"Economische Ongelijkheid\", \n       y = \"Electorale Democratie\", \n       title = \"Economische Ongelijkheid en Electorale Democratie\")\n\n\n\n\n\n\n\n\n\n8.2.1 Rapportage\nDe volgende zaken kun je best benoemen wanneer je een scatterplot bespreekt:\n\nDe richting van de relatie, alsook de sterkte (maar let op dat je best ook de correlatiecoëfficiënt bekijkt gezien visuele weergaven ook misleidend kunnen zijn).\nPatronen of trends in het plot.\nCases die extreme waarden hebben of cases die als outliers kunnen beschreven worden.\n\n\n\n8.2.2 Instructies\n\nZorg ervoor de je informatieve labels hebt voor de x -en y-as en een duidelijke titel.\nJe kan de regressielijn toevoegen aan het plot om de interpretatie te verduidelijken. Dit kan je doen met de syntax method = \"lm\". Je kunt de syntax veranderen naar method = \"loess\" om een ‘locally estimated scatterplot smoothing’ line te plotten. Dit is handig voor het spotten van niet-lineaire patronen in de data. Zie Paragraaf 7.3.2\nLet op de tekstgrootte op de assen en zorg dat de tekst goed leesbaar is. De grootte van het lettertype kun je aanpassen met de syntax om het visuele thema van de figuur te veranderen, bv. door het volgende toe te voegen: + theme_grey(14) of + theme_bw(18). Het nummer tussen haakjes bepaalt de grootte van het lettertype.Je kunt een lijst met de ingebouwde visuele ggplot schema’s hier vinden. Bijkomende opties zijn beschikbaar in het ggthemes package. Meer complexe veranderingen, zoals verschillende tekstgroottes voor titel en astitels, kun je uitvoeren via theme(), maar dit behandelen we niet in dit document.\nBovenstaand plot toont de bivariate relatie tussen twee continue variabelen met toevoeging van de regressielijn. We kunnen ook de formule van de lijn toevoegen met geom_text(). Dit doen we door een + toe te voegen na labs() en de volgende regel toe te voegen: geom_text(x = 40, y=0.1, label=\"Dem Score = 1.06 + (-0.012 * Inequality)\") . De formule vind je met lm(zie onder). De x= en y=gedeelten geven de waarden (coördinaten) weer waar het label in het plot moet komen. Het kan nodig zijn de waarden stelselmatig aan te passen om een mooie weergave te bereiken. Bepaalde packages in R kunnen dit proces vergemakkelijken, zoals deze functie uit het ggpubr package. Dit package behoort niet tot de leerstof.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Rapporteren en Presenteren van Resultaten</span>"
    ]
  },
  {
    "objectID": "linear_08.html#correlaties",
    "href": "linear_08.html#correlaties",
    "title": "8  Rapporteren en Presenteren van Resultaten",
    "section": "8.3 Correlaties",
    "text": "8.3 Correlaties\nVoor dit voorbeeld berekenen we de Pearson correlatie tussen economische ongelijkheid (hogere waarden = meer ongelijk; gini_2019) en electorale democratie (hogere waarden = meer democratie; v2x_polyarchy).\n\ncor1 &lt;- cor.test(x = demdata$gini_2019, \n                 y = demdata$v2x_polyarchy, \n                 method = 'pearson')\n\ncor1\n\n\n    Pearson's product-moment correlation\n\ndata:  demdata$gini_2019 and demdata$v2x_polyarchy\nt = -3.0433, df = 68, p-value = 0.003325\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.5374741 -0.1211040\nsample estimates:\n       cor \n-0.3462257 \n\n\nZie Paragraaf 1.4 voor richtlijnen over de interpretatie van correlatiecoëfficiënten.\n\n8.3.1 Rapportage\nDe volgende zaken neem je best op in je rapportage:\n\nDe specifieke correlatie je gebruikt hebt (bv. Pearson).\nEen bespreking van de richting van de relatie (positief, negatief, geen relatie), waarbij ook aandacht is voor de codering van gebruikte variabelen.\nEen bespreking van de statistische significantie:\n\nSignificantie hebben we meestal op de niveaus van 95% (p &lt; 0.05), 99% (p &lt; 0.01), en 99.9% (p &lt; 0.001) 3\nRaporteer op basis van het hoogste signficantieniveau dat de p-waarde aangeeft:\n\nAls p = 0.04, dan p &lt; 0.05 (significant op 95% niveau)\nAls p = 0.02, dan p &lt; 0.01 (significant op 99% niveau)\nAls p = 0.0000005, dan p &lt; 0.001 (significant op 99.9% niveau)\n\nWe rapporteren meestal niet hoger dan 99.9% of p &lt; 0.001 (bv., we zeggen niet p &lt; 0.000001, maar p &lt; 0.001). We schrijven ook nooit p &lt; 0.000.\n\nEen bespreking van de sterkte van de relatie. (zie Paragraaf 1.4)\n\n\n\n\n\n\n\nVoorbeeld rapportage\n\n\n\nHogere waarden voor economische ongelijkheid hangen samen met lagere waarden voor electorale democratie (\\(r\\) = -0.35). De associatie heeft een gemiddelde sterkte en is statistisch significant (p \\(&lt;\\) 0.01).\n\n\n\n\n8.3.2 Presentatie: Correlatietabellen\nWanneer we slechts de correlatie tussen twee variabelen beschrijven, kunnen we deze discussie gewoon in onze tekst opnemen zoals hierboven. Wanneer we echter analyses doen met meerdere continue variabelen is het een goede praktijk om een correlatietabel op te stellen die de correlatie tussen deze variabelen weergeeft. Deze tabel kan in de hoofdtekst van een paper of in een appendix worden opgenomen. De tabel kan aangemaakt worden met de datasummary_correlation() functie uit het modelsummary package. Hier is een voorbeeld met 4 variabelen:\n\ndemdata |&gt; \n  select(v2x_polyarchy, gini_2019, cpi, gdp_ppp) |&gt; \n  rename(\"Electorale democratie\" = v2x_polyarchy, \n         \"Economische ongelijkheid\" = gini_2019, \n         \"Corruptie\" = cpi, \n         \"BBP\" = gdp_ppp) |&gt; \n  datasummary_correlation(method = \"pearson\",\n                          title = \"Relatie continue variabelen\")\n\n\n\n    \n\n    \n    \n      \n        \n        Relatie continue variabelen\n              \n                 \n                Electorale democratie\n                Economische ongelijkheid\n                Corruptie\n                GDP per capita, PPP (constant 2017 international $)\n              \n        \n        \n        \n                \n                  Electorale democratie\n                  1\n                  .\n                  .\n                  .\n                \n                \n                  Economische ongelijkheid\n                  -.35\n                  1\n                  .\n                  .\n                \n                \n                  Corruptie\n                  .66\n                  -.53\n                  1\n                  .\n                \n                \n                  GDP per capita, PPP (constant 2017 international $)\n                  .40\n                  -.52\n                  .79\n                  1\n                \n        \n      \n    \n\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nElke cel bevate een correlatiecoëfficiënt voor 2 gepaarde variabelen. De correlatie tussen corruptie en economische ongelijkheid is bijvoorbeeld -0,53, terwijl de correlatie tussen GDP en corruptie 0,79 is.\nOpmerking: De titel wordt in dit document onderaan de tabel weergegeven, maar wordt bovenaan afgedrukt bij het opslaan in een Word-document (zie hieronder), wat de meer conventionele plaatsing is.\n\n\nZo lees je de syntax:\n\ndemdata |&gt; select(…)\n\nHier selected we de dataset (demdata) en de variabelen waartussen we de correlaties willen berekenen. Zonder select(…) berekent R de correlaties tussen alle variabelen in de dataset!\n\nrename(…)\n\nWe geven de variabelen een andere naam zodat presentatie van de variabelen in de tabel duidelijker is voor lezers.\n\ndatasummary_correlation(method = \"pearson\", title = \"...\")\n\nHier duiden we aan welke correlatie we precies willen en geven we een duidelijke titel (Pearson correlation: method = “pearson”; Spearman: method = “spearman”).\n\n\nWe kunnen deze tabel naar een Microsoft Word bestand exporteren zodat we de tabel kunnen gebruiken in eigen papers met volgende syntax toevoeging (Je ziet de tabel nu wel niet langer in R verschijnen):\n\ndemdata |&gt; \n  select(v2x_polyarchy, gini_2019, cpi, gdp_ppp) |&gt; \n  rename(\"Electorale democratie\" = v2x_polyarchy, \n         \"Economische ongelijkheid\" = gini_2019, \n         \"Corruptie\" = cpi, \n         \"BBP\" = gdp_ppp) |&gt; \n  datasummary_correlation(method = \"pearson\",\n                          title = \"Relatie continue variabelen\",\n                          output = \"correlatietabel.docx\")\n\n\noutput = \"correlatietabel.docx\"\n\nHier vragen we de output te exporteren naar een Word (.docx) bestand. De naam van het bestand bepaal je zelf. Het bestand is terug te vinden in je projectfolder of de folder waar je syntax bestand (script of Markdown) zich in bevindt. In Word kunnnen nog verdere aanpassingen worden gedaan. 4\n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nJe kunt problemen tegenkomen met deze syntax indien je je Word-bestand met tabel open hebt in Word en de syntax nogmaals runt, bijvoorbeeld om een foutje te corrigeren. We raden aan het Word bestand altijd te sluiten voor je de syntax opnieuw runt.\n\n\n\n8.3.2.1 Instructies\n\nDoorgaans plaatsen we de afhankelijke variabele op de eerste rij in een correlatietabel. Dit doe je door de variabele als eerste te noemen in de select() regel van de syntax hierboven.\nDe variabelen hernoem je zodat het duidelijk is voor de lezer wat ze inhouden. Gebruik dus niet gewoon de naam van de variabelen zoals ze opgeslagen zijn in de dataset.\nGeef de tabel een informatieve titel.\nHet is gebruikelijk om asterisks te plaatsen in de tabel om statistische significantie weer te geven (*** = p &lt; 0.01, ** = p &lt; 0.01, * = p &lt; 0.05). Jammergenoeg kan datasummary_correlation() dit niet automatisch toevoegen. Wel kun je deze symbolen manueel (op basis van cor.test) toevoegen aan een tabel in een .docx (Word) bestand.\nCorrelatie (en regressie) tabellen gemaakt met modelsummary kun je verder aanpassen met instructies op deze webpagina. Dit is echter niet nodig voor dit vak.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Rapporteren en Presenteren van Resultaten</span>"
    ]
  },
  {
    "objectID": "linear_08.html#sec-reporting-linear-regression",
    "href": "linear_08.html#sec-reporting-linear-regression",
    "title": "8  Rapporteren en Presenteren van Resultaten",
    "section": "8.4 OLS Regressiemodellen",
    "text": "8.4 OLS Regressiemodellen\nLineaire regressie, oftewel OLS (Ordinary Least Squares) regressie modelleert veranderingen in het gemiddelde van een afhankelijke variabele als lineaire functie van een of meerdere onafhankelijke variabelen. We gebruiken hier de demdata dataset en voorspellen electorale democratiescores in het jaar 2020 als functie van economische ongelijkheid (gini_2019), de status van het regime van een land in 1984 (TYPEDEMO1984) en regio van de wereld waarin een land is gesitueerd (1 = Europa, 2 = Afrika, 3 = Azië, 4 = Amerikas).\nHieronder vind je de syntax en output in R. Deze output neem je niet rechtstreeks op in een paper. In de plaats daarvan maak je een formele tabel of een coëfficiëntenplot (zie onder).\n\n#Factor maken categorische variabelen\ndemdata &lt;- demdata |&gt; \n  mutate(TYPEDEMO1984 = factorize(TYPEDEMO1984), \n         region = factor(region, \n                    levels=c(2,3,1,4), #Ref. groep eerst inde rij\n                    labels=c(\"Afrika\", \"Azië\", \"Europa\", \"Amerika's\")))\n\n#model schatten en opslaan\nexample_model &lt;- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984 + region, \n                    data=demdata)\n\n#Resultaten\nsummary(example_model)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ gini_2019 + TYPEDEMO1984 + region, \n    data = demdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.52522 -0.06736  0.03585  0.09521  0.37555 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)              0.899777   0.271068   3.319  0.00175 **\ngini_2019               -0.013400   0.005693  -2.354  0.02282 * \nTYPEDEMO1984Democracies  0.067402   0.061709   1.092  0.28028   \nregionAzië               0.040365   0.149003   0.271  0.78765   \nregionEuropa             0.244037   0.157307   1.551  0.12753   \nregionAmerika's          0.253473   0.150635   1.683  0.09907 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1893 on 47 degrees of freedom\n  (126 observations deleted due to missingness)\nMultiple R-squared:  0.4378,    Adjusted R-squared:  0.378 \nF-statistic:  7.32 on 5 and 47 DF,  p-value: 3.842e-05\n\n\nVoor interpretatierichtlijnen, zie Paragraaf 4.1.\n\n8.4.1 Rapportage\nJe rapport bevat best de volgende zaken:\n\nEen bespreking van de richting van de relatie (positief/negatief) en een inhoudelijke interpretatie van wat dit concreet betekent op basis van hoe de variabelen gemeten zijn en welke schaal zij hebben.\n\nBij een multiple regressie is het belangrijk te verduidelijken dat het effect dat je vindt voor een onafhankelijke variabele gecontroleerd is op de andere onafhankelijke variabelen in het model. Deze worden ‘constant gehouden’ (oftewel ‘ceteris paribus’).\n\nEen bespreking van de statistische significantie (verwerpen of niet nulhypothese?) met vermelding van p-waarde en/of het betrouwbaarheidsinterval.\n\nCoëfficiënten met p-waarden groter dan 0.05 worden meestal niet als statistisch significant of als statistisch significant bij conventionele niveaus beschouwd.5 Rapporteer op basis van het hoogste signficantieniveau dat de p-waarde aangeeft:\n\nAls p = 0.04, dan p &lt; 0.05 (significant op 95% niveau)\nAls p = 0.02, dan p &lt; 0.01 (significant op 99% niveau)\nAls p = 0.0000005, dan p &lt; 0.001 (significant op 99.9% niveau)\nWe rapporteren meestal niet hoger dan 99.9% of p &lt; 0.001 (bv., we zeggen niet p &lt; 0.000001, maar p &lt; 0.001). We schrijven ook nooit p &lt; 0.000.\n\nHet betrouwbaarheidsinterval kan ook gebruikt worden om statistische significantie te bespreken en de onzekerheid rond de geschatte coëfficiënten aan te duiden. Als je het betrouwbaarheidsinterval bespreekt, kun je dit tussen haakjes toevoegen na de coëfficiënt, bv. “De coëfficiënt voor economische ongelijkheid is 0.8 (95% CI: 0.5, 1.1)”.\nHet is minder gebruikelijk de t-statistiek concreet te benoemen, maar het is ook geen probleem als je dit doet. Indien de t-waarde wordt opgenomen, zet je deze bij de p-waarde: “(t = 1.98, p &lt; 0.05)”.\n\n\nHier vind je uitgewerkte voorbeelden voor gini_2019 (een continue variabele) en TYPEDEMO1984 (een binaire variabele).\n\n\n\n\n\n\nReport\n\n\n\ngini_2019: We verwachten dat het niveau van electorale democratie lager is als economische ongelijkheid stijgt, gecontroleerd op de effecten van regimestatus in het verleden en regio in de wereld. Gebaseerd op het model verwachten we dat electoral democratie met -0.01 eenheden daalt als economische ongelijkheid met 1 eenheid stijgt. Dit effect is statistisch signifcant (p &lt; 0.05).\nTYPEDEMO1984: Het regressiemodel toont dat landen die als democratie werden beschouwd in 1984 ook vandaag democratischer zijn. Gemiddeld genomen scoren deze landen 0.07 eenheden hoger op electorale democratie in 2020 dan landen die in 1984 geen democratie waren, gecontroleerd op ongelijkheid en regio in de wereld. Het verschil is echter niet statistisch significant (p &gt; 0.05).\n\n\nBijkomende tips:\n\nIn een bespreking van een onderzoek kun je behalve een discussie van de coëfficiënten ook een bespreking van voorspelde waarden opnemen (bv. welk niveau van democratie verwacht je bij hoge en lage ongelijkheid volgens je model). Een plot van voorspelde waarden kan de bespreking verder verduidelijken. Zie Paragraaf 8.7 voor meer informatie.\nAls je onderzoek vooral gericht is op de relatie tussen een specifieke onafhankelijke variabele en de afhankelijke variabele dan is een discussie van de coëfficiënten van de controlevariabelen doorgaans niet nodig.\nHet intercept wordt zelden vermeld in onderzoekspapers. In een bivariaat model waarbij de predictor binair is, is het intercept wel inhoudelijk interessant, want dan staat de 0 voor de gemiddelde score op de afhankelijke variabele voor de referentiecategorie. In een experiment zou je bijvoorbeeld scores vergelijken van de controlegroep (X=0) en de experimentele groep (x=1).\nWees voorzichting in je bespreking van de relatie tussen de variabelen. Causaliteit is moeilijk te bepalen en is onderhevig aan sterke voorwaarden. Je schrijft bijgevolg dus meestal niet het “effect van X op Y” , maar “deze verandering in X is geassocieerd met deze verandering in Y”.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Rapporteren en Presenteren van Resultaten</span>"
    ]
  },
  {
    "objectID": "linear_08.html#sec-presenting-linear-regression-regression-tables",
    "href": "linear_08.html#sec-presenting-linear-regression-regression-tables",
    "title": "8  Rapporteren en Presenteren van Resultaten",
    "section": "8.5 Lineaire Regressietabellen",
    "text": "8.5 Lineaire Regressietabellen\nEen gebruikelijke methode om de resultaten van regressiemodellen te presenteren is met behulp van een tabel. Via het modelsummarypackage (en functie met dezelfde naam) kunnen we R gebruiken om zo’n tabel aan te maken.\n\n8.5.1 Regressietabel voor 1 model\nAls voorbeeld maken we hier een regressietabel voor een model waarin de score voor electorale democratie voorspeld wordt aan de hand van 1 onafhankelijke variabele: de corruptieperceptie-index (cpi). Hieronder vinden we de standaard output zonder toevoegingen:\n\n#Schatten en opslaan van het model\nmodel1 &lt;- lm(v2x_polyarchy ~ cpi, data = demdata)\n\n#basisfunctie voor regressietabel\nmodelsummary(model1)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  0.140\n                \n                \n                  \n                  (0.036)\n                \n                \n                  cpi\n                  0.009\n                \n                \n                  \n                  (0.001)\n                \n                \n                  Num.Obs.\n                  174\n                \n                \n                  R2\n                  0.438\n                \n                \n                  R2 Adj.\n                  0.435\n                \n                \n                  AIC\n                  -78.1\n                \n                \n                  BIC\n                  -68.6\n                \n                \n                  Log.Lik.\n                  42.061\n                \n                \n                  F\n                  134.123\n                \n                \n                  RMSE\n                  0.19\n                \n        \n      \n    \n\n\n\n\nmodelsummary(\n\nNaamn van de functie\n\nmodel1,\n\nnaam van het model waarvan we de resultaten in een tabel willen presenteren.\n\n\nDeze tabel kan verbeterd worden. Ten eerste kunnen we de statistische significantie van de coëfficiënten aanduiden met een asterisk (*) of andere symbolen. Ten tweede kunnen we onze variabelen duidelijkere labels geven. Ten derde kunnen we model fit statistieken die minder interessant zijn weglaten uit de tabel. Ten slotte kunnen we een titel en onderschrift toevoegen.\nDit doen we met volgende syntax:\n\nmodelsummary(model1, \n1             stars = TRUE,\n2             coef_rename = c(\n               \"(Intercept)\" = \"Constante\",\n               \"cpi\" = \"Corruptieperceptie-index\"), \n3             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"),\n4             title = \"Electorale Democratie voorspeld door corruptie\",\n5             notes = \"Lineaire regressiecoëfficiënten met standaardfouten tussen haakjes\")\n\n\n1\n\nVoegt “stars” of asterisks toe voor statistische significantie.\n\n2\n\nWe hernoemen de variabeln voor de duidelijkheid coef_rename()\n\n3\n\nWe selecteren de fit statistieken die we willen rapporteren gof_map()\n\n4\n\nWe geven een titel aan de table title =\n\n5\n\nEn ten slotte geven we informatie aan de lezer over wat we precies weergeven notes =\n\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        Electorale Democratie voorspeld door corruptie\n              \n                 \n                (1)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nLineaire regressiecoëfficiënten met standaardfouten tussen haakjes\n        \n                \n                  Constante\n                  0.140***\n                \n                \n                  \n                  (0.036)\n                \n                \n                  Corruptieperceptie-index\n                  0.009***\n                \n                \n                  \n                  (0.001)\n                \n                \n                  Num.Obs.\n                  174\n                \n                \n                  R2\n                  0.438\n                \n                \n                  R2 Adj.\n                  0.435\n                \n        \n      \n    \n\n\n\n\nstars = TRUE,\n\nMet deze optie voegen we symbolen voor statistische significantie toe. De legende voor de symbolen wordt automatisch toegevoegd aan de tabel.\n\ncoef_rename = c(...)\n\nMet deze functie kunnen we de namen van de onafhankelijke variabelen hernoemen. We doen dit voor het intercept en voor cpi. Voor zowel de originele naam als de nieuwe naam gebruik je dubbele (of enkele) aanhalingstekens.\n\ngof_map = c(...)\n\nHier geven we aan welke “goodness of fit” (gof) statistieken we willen. We voegen hier de statistieken die we willen toe: het aantal observaties (“nobs”), de R² (“r.squared”), en de adjusted R² (“adj.r.squared”). De andere statistieken worden dan weggelaten.6\n\ntitle = ...\n\nTitel voor de tabel.\n\nnotes = (...)\n\nOnderschrift voor de tabel. Hier verduidelijk je aan de lezer wat er precies af te lezen valt: de lineaire regressiecoëfficiënten met standaardfouten tussen haakjes.\n\n\n\n\n8.5.2 Regressietabel met meerdere modellen\nWe kunnen modelsummary() ook gebruiken om een regressietabel met meerdere modellen te maken. Bijvoorbeeld, een model met enkel cpi en een model met alle predictors. We kunnen de modellen eerst in een lijst (‘list’) opslaan en dan modelsummary() op de lijst gebruiken. De rest van de syntax blijft grotendeels hetzelfde behalve de toevoeging van de andere onafhankelijke variabelen in het coef_rename() gedeelte.\n\n#model met 3 predictors\nmodel2 &lt;- lm(v2x_polyarchy ~ cpi + v2caviol + region, data = demdata)\n\n#lijst maken\nmodel_list &lt;- list(model1, model2)\n\n#lijst gebruiken in modelsummary()\nmodelsummary(model_list, \n             stars = TRUE, \n             coef_rename = c(\n               \"(Intercept)\" = \"Constante\",\n               \"cpi\" = \"Corruptieperceptie-index\", \n               \"v2caviol\" = \"Politiek geweld\",\n               \"regionAsia\" = \"Azië\",\n               \"regionEurope\" = \"Europa\", \n               \"regionAmericas\" = \"Amerika's\"), \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"), \n             title = \"Electorale democratie voorspeld door corruptie, politiek geweld en regio\", \n             notes = \"Lineaire regressiecoëfficiënten met standaardfouten tussen haakjes. Referentiegroep regio = Afrika\")\n\n\n\n    \n\n    \n    \n      \n        \n        Electorale democratie voorspeld door corruptie, politiek geweld en regio\n              \n                 \n                (1)\n                (2)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nLineaire regressiecoëfficiënten met standaardfouten tussen haakjes. Referentiegroep regio = Afrika\n        \n                \n                  Constante\n                  0.140***\n                  0.178***\n                \n                \n                  \n                  (0.036)\n                  (0.038)\n                \n                \n                  Corruptieperceptie-index\n                  0.009***\n                  0.007***\n                \n                \n                  \n                  (0.001)\n                  (0.001)\n                \n                \n                  Politiek geweld\n                  \n                  -0.009\n                \n                \n                  \n                  \n                  (0.010)\n                \n                \n                  regionAzië\n                  \n                  -0.090**\n                \n                \n                  \n                  \n                  (0.034)\n                \n                \n                  regionEuropa\n                  \n                  0.108*\n                \n                \n                  \n                  \n                  (0.042)\n                \n                \n                  regionAmerika's\n                  \n                  0.145***\n                \n                \n                  \n                  \n                  (0.041)\n                \n                \n                  Num.Obs.\n                  174\n                  174\n                \n                \n                  R2\n                  0.438\n                  0.559\n                \n                \n                  R2 Adj.\n                  0.435\n                  0.546\n                \n        \n      \n    \n\n\n\nDe functie zal standaard het eerste model ‘Model 1’ noemen en het tweede ‘Model 2’. We kunnen dit desgewenst veranderen met behulp van onze lijst, waarin we dan niet alleen de namen van de objecten aangegeven maar ook de naam die we aan het model willen geven (door middel van: ‘naam model in tabel’ = object):\n\n#lijst met namen\nmodel_list_named &lt;- list(\n  'Enkel Corruptie' = model1, \n  'Alle predictoren' = model2)\n\n#tabel maken\nmodelsummary(model_list_named, \n             stars = TRUE, \n             coef_rename = c(\n               \"(Intercept)\" = \"Constante\",\n               \"cpi\" = \"Corruptieperceptie-index\", \n               \"v2caviol\" = \"Politiek geweld\",\n               \"regionAsia\" = \"Azië\",\n               \"regionEurope\" = \"Europa\", \n               \"regionAmericas\" = \"Amerika's\"), \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"), \n             title = \"Electorale democratie voorspeld door corruptie, politiek geweld en regio\", \n             notes = \"Lineaire regressiecoëfficiënten met standaardfouten tussen haakjes. Referentiegroep regio = Afrika\")\n\n\n\n    \n\n    \n    \n      \n        \n        Electorale democratie voorspeld door corruptie, politiek geweld en regio\n              \n                 \n                Enkel Corruptie\n                Alle predictoren\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nLineaire regressiecoëfficiënten met standaardfouten tussen haakjes. Referentiegroep regio = Afrika\n        \n                \n                  Constante\n                  0.140***\n                  0.178***\n                \n                \n                  \n                  (0.036)\n                  (0.038)\n                \n                \n                  Corruptieperceptie-index\n                  0.009***\n                  0.007***\n                \n                \n                  \n                  (0.001)\n                  (0.001)\n                \n                \n                  Politiek geweld\n                  \n                  -0.009\n                \n                \n                  \n                  \n                  (0.010)\n                \n                \n                  regionAzië\n                  \n                  -0.090**\n                \n                \n                  \n                  \n                  (0.034)\n                \n                \n                  regionEuropa\n                  \n                  0.108*\n                \n                \n                  \n                  \n                  (0.042)\n                \n                \n                  regionAmerika's\n                  \n                  0.145***\n                \n                \n                  \n                  \n                  (0.041)\n                \n                \n                  Num.Obs.\n                  174\n                  174\n                \n                \n                  R2\n                  0.438\n                  0.559\n                \n                \n                  R2 Adj.\n                  0.435\n                  0.546\n                \n        \n      \n    \n\n\n\n\n\n8.5.3 Opslaan als Word document\nWe kunnen de regressietabellen gemaakt met modelsummary() ook opslaan in een Word document door de optie ‘output’ te gebruiken:\n\nmodelsummary(model_list_named, \n             stars = TRUE, \n             coef_rename = c(\n               \"(Intercept)\" = \"Constante\",\n               \"cpi\" = \"Corruptieperceptie-index\", \n               \"v2caviol\" = \"Politiek geweld\",\n               \"regionAsia\" = \"Azië\",\n               \"regionEurope\" = \"Europa\", \n               \"regionAmericas\" = \"Amerika's\"), \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"), \n             title = \"Electorale democratie voorspeld door corruptie, politiek geweld en regio\", \n             notes = \"Lineaire regressiecoëfficiënten met standaardfouten tussen haakjes. Referentiegroep regio = Afrika\", \n             output = 'regressie_tabel.docx') \n\n\noutput = 'regressie_tabel.docx'\n\nHier vragen we om een Word document (.docx) genaamd “regressie_tabel” op te slaan. Dit bestand vind je terug in je R project folder. Je kan ook een subfolder aanduiden, bv. “Output folder/regressie_tabel.docx”. Let erop dat je het Word document niet geopend hebt als je de syntax opnieuw wil gebruiken met aanpassingen, anders kun je een foutmelding krijgen. In Word zelf krijg je vaak een lange, uitgerekte tabel. Dit kun je verhelpen door in Word naar de tab ‘Indeling van tabel’ te gaan en op ‘AutoAanpassen naar venster’ te klikken.\n\n\n\n\n8.5.4 Instructies\n\nHet is gebruikelijk de ongestandaardiseerde coëfficiënt weer te geven met standaardfouten tussen haakjes onder de coëfficiënt. Dit is de standaardoutput voor de modelsummary functie. Standaard worden drie decimalen gebruikt. Dit is ook de conventie in de literatuur, maar het aantal decimalen kan aangepast worden met syntax. Standaardfouten kunnen echter ook tussen haakjes naast de coëfficiënt gezet worden.\nVoorzie de tabel van een informatieve titel, duidelijke namen voor de variabelen en een notitie onderaan die verduidelijkt welke informatie precies wordt weergegeven.\nVoor categorische variabelen kun je de referentiegroep op verschillende manieren verduidelijken: 1) je kunt deze informatie opnemen in de notitie zoals in het voorbeeld; 2) je kunt de referentiegroep aanduiden in de benaming van de variabele bv. “Azië (ref.: Afrika”; 3) je kunt de referentiegroep ook opnemen in een aparte rij in de tabel. Deze optie wordt beschreven op de modelsummary webpagina. De webpagina bevat ook verdere informatie om je tabel aan te passen naar voorkeur.\nStandaard nummert modelsummary de modellen in de tabel (bv. (1), (2), etc.). Je kan echter ook een specifieke kolomnaam geven. Dit is bijvoorbeeld handig als modellen een andere afhankelijke variabele hebben.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Rapporteren en Presenteren van Resultaten</span>"
    ]
  },
  {
    "objectID": "linear_08.html#sec-presenting-linear-regression-coefficient-plots",
    "href": "linear_08.html#sec-presenting-linear-regression-coefficient-plots",
    "title": "8  Rapporteren en Presenteren van Resultaten",
    "section": "8.6 Plotten van coëfficiënten",
    "text": "8.6 Plotten van coëfficiënten\nDe resultaten van regressiemodellen kunnen ook in de vorm van een “coefficient plot” (plot van coëfficiënten) weergegeven worden. Deze plot bevat de coëfficiënten en hun betrouwbaarheidsintervallen (doorgaans op het 95% niveau). De constante wordt doorgaans niet opgenomen in de figuur.\nBij wijze van voorbeeld plotten we hier de resultaten van een model dat electorale democratie voorspelt op basis van corruptie, politiek geweld en regimestatus in 1984. We maken gebruik van de tidy() functie uit het broom package en de ggplot() functie uit het tidyverse package.\n\n\n#Model\nplot_model &lt;- lm(v2x_polyarchy ~ cpi + v2caviol + TYPEDEMO1984, data = demdata)\n\n#Oslaan van resultaten in tidy dataframe\n#MOET betrouwbaarheidsintervallen bevatten\nplot_model_tidied &lt;- tidy(plot_model, conf.int = TRUE)\n\n#resultaat bekijken\nplot_model_tidied\n\n# A tibble: 4 × 7\n  term                   estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)             0.187     0.0426      4.40  2.19e-5  0.103     0.272  \n2 cpi                     0.00636   0.00106     6.01  1.55e-8  0.00427   0.00846\n3 v2caviol               -0.00872   0.0123     -0.712 4.78e-1 -0.0330    0.0155 \n4 TYPEDEMO1984Democraci…  0.153     0.0349      4.37  2.39e-5  0.0837    0.222  \n\n\nWe kunnen met deze data een figuur maken met ggplot() maar eerst doen we nog wat data management. We geven bijvoorbeeld andere namen aan de variabelen (opgeslaan in term) om duidelijker de resultaten te presenteren. 7\n\n#duidelijkere namen:\nplot_model_tidied &lt;- plot_model_tidied |&gt; \n  mutate(term = recode(term, \n                       \"cpi\" = \"Corruptieperceptie-Index\", \n                       \"v2caviol\" = \"Politiek geweld\",  \n                       \"TYPEDEMO1984Democracies\" = \"Democratie in 1984?\"))\n\nplot_model_tidied\n\n# A tibble: 4 × 7\n  term                   estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)             0.187     0.0426      4.40  2.19e-5  0.103     0.272  \n2 Corruptieperceptie-In…  0.00636   0.00106     6.01  1.55e-8  0.00427   0.00846\n3 Politiek geweld        -0.00872   0.0123     -0.712 4.78e-1 -0.0330    0.0155 \n4 Democratie in 1984?     0.153     0.0349      4.37  2.39e-5  0.0837    0.222  \n\n\nDan maken we het plot:\n\nplot_model_tidied |&gt; \n1  filter(term != \"(Intercept)\") |&gt;\n  ggplot(aes(x = estimate, y = term)) +  \n  geom_pointrange(aes(xmin = conf.low, \n                      xmax = conf.high)) + \n  labs(title = \"OLS coëfficiënten voor electorale democratie\", \n       x = \"OLS coëfficiënt\", \n       y = \"Onafhankelijke variabele\") + \n2  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"red\") +\n3  geom_text(aes(label = round(estimate, 2)), vjust = -0.5, hjust = -0.5)\n\n\n1\n\nfilter intercept weg uit dataframe\n\n2\n\nVoeg lijn toe bij x = 0\n\n3\n\nVoeg de coëfficiënten toe aan het plot, afgerond op 2 decimalen\n\n\n\n\n\n\n\n\n\n\n\n\nplot_model_tidied |&gt; filter(term != \"(Intercept)\") |&gt;\n\nWe gebruiken het data object dat we eerder aangemaakt hebben (plot_model_tidied) en filteren het intercept uit de data gezien die doorgaans niet geplot wordt.\n\nggplot(aes(x=estimate, y=term)) +\n\nWe gebruiken ggplot() en bepalen welke variabelen op de x–as (hier: ‘estimate’, de waarde voor de coëfficiënten) en de y-as (hier: de variabele term met de naam van onze variabelen) komen. De variabelen kunnen gewisseld worden van as, maar de getoonde manier levert meestal een betere visualisatie (anders zouden de namen van de variabelen kunnen overlappen).\n\ngeom_pointrange(aes(xmin=conf.low, xmax=conf.high))\n\nHier vragen we om de coefficiënten aan te duiden met een punt (“point”). Vervolgens vragen we om een lijn door het punt te tekenen om de reikwijdte (“range”) van de betrouwbaarheidsintervallen voor te stellen. De xmin and xmax delen van de syntax bepalen de reikwijdte.8 Hier gebruiken we conf.low and conf.high, de variabelen waarin de ondergrens en bovengrens van de intervallen is opgeslaan.\n\nlabs(...)\n\nWe geven hier namen aan de assen en geven ook een titel.\n\ngeom_vline(xintercept=0, linetype=\"dashed\", color=\"red\")\n\nHier vragen we R om een verticale referentielijn te tekenen (“geom_vline”) waar x = 0. Deze lijn helpt met het bepalen van de significantie, aangezien overlap van het betrouwbaarheidsinterval met de lijn wijst op een niet-significante coëfficiënt.\n\ngeom_text(aes(label = round(estimate, 2)), vjust = -0.5, hjust = -0.5)\n\nHier vragen we om ook de waarde van de coëfficiënt weer te geven op de plot met geom_text(). De tekst die op het plot komt wordt bepaald met “label =”. Hier vragen we om de ‘estimate’ (de coëfficiënt), maar afgerond (“round”) tot 2 decimalen voor de duidelijkheid.\n\n\nMet vjust = -0.5 bepalen we waar de tekst komt (“vertical justification”). Dit kunnen we gebruiken om overlap tussen tekst en geplotte waarden te voorkomen. Negatieve waarden plaatsen de tekst hoger, positieve waarden plaatsen de tekst lager.\nMet hjust = -0.5 (“horizontal justification”) kunnen we de tekst naar links (positieve waarden) of rechts (negatieve waarden) bewegen. In de praktijk kan het zijn dat je hier wat moet spelen met de waarden voor vjust en hjust om je plot goed te presenteren.\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nStandaard plot ggplot coëfficiënten van variabelen in alfabetische volgorde (is to order the coefficients by the alphabetical order of the variable that contains the variable names (named)zoals opgeslaan in de term variabele in het dataframe geproduceerd door tidy()). Dit is niet altijd ideaal, bijvoorbeeld wanneer categorieën van een factor variabele niet bij elkaar komen te staan of wanneer we vooral geïnteresseerd zijn in 1 bepaalde predictor en niet willen dat die in het midden komt te staan in plaats van prominent bovenaan.\nEen voorbeeld:\n\n#Model met categorische variabele\ncat_model &lt;- lm(v2x_polyarchy ~ cpi + v2caviol + region, data = demdata)\n\n#Tidy met simpel plot\ntidy(cat_model, conf.int = TRUE) |&gt; \n  filter(term != \"(Intercept)\") |&gt; \n  mutate(term = recode(term, \n                       \"cpi\" = \"Corruptieperceptie\", \n                       \"v2caviol\" = \"Politiek geweld\",\n                       \"regionAsia\" = \"Azië\",\n                       \"regionEurope\" = \"Europa\", \n                       \"regionAmericas\" = \"Amerika's\")) |&gt; \n    ggplot(aes(x = estimate, y=term)) + \n    geom_pointrange(aes(xmin = conf.low, xmax = conf.high)) +\n    labs(title = \"OLS coëfficiënten voor electorale democratie\", \n       x = \"OLS coëfficiënt\", \n       y = \"Onafhankelijke variabele\")\n\n\n\n\n\n\n\n\nDe coëfficiënten van de categorische regio variable staan niet bij elkaar. We kunnen dit aanpassen door van termeen factor te maken en dan de volgorde van de niveaus aan te passen met relevel.\n\ntidy(cat_model, conf.int = TRUE) |&gt; \n1  filter(term != \"(Intercept)\") |&gt;\n  mutate(term = factor(term,\n                       levels = c(\"regionEurope\", \"regionAsia\", \n                                  \"regionAmericas\", \"v2caviol\",\n2                                  \"cpi\"),\n                       labels = c(\"Europa\", \"Azië\", \n                                  \"Amerika's\", \"Pol. geweld\",\n                                  \"Corruptieperceptie\"))) |&gt; \n    ggplot(aes(x = estimate, y=term)) + \n    geom_pointrange(aes(xmin = conf.low, xmax = conf.high))+\n    labs(title = \"OLS coëfficiënten voor electorale democratie\", \n       x = \"OLS coëfficiënt\", \n       y = \"Onafhankelijke variabele\")\n\n\n1\n\nOmzetten naar een factor doe je nadat het intercept is weggefilterd. Dat kan in 1 stap zoals in het voorbeeld of in 2 aparte syntax-stappen.\n\n2\n\nggplot() zal het eerste niveau als onderste variabele plotten, het laatste niveau wordt de bovenste enzovoort.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.6.1 Instructies\n\nMeestal plaats je de coëfficiënt op de x-as en de naam van de variabele op de y-as. Het is mogelijk dit te veranderen met de ggplot syntax, maar dan kunnen de variabelenamen makkelijker overlappen. Lange variabelennamen leiden wel vaker tot problemen met de visualisatie (in deze blog vind je enkele tips).\nHet toevoegen van de (afgeronde) coëfficiënt-waarde kan lezers helpen de resultaten beter te vatten.\nMeestal plotten we de 95% betrouwbaarheidsintervallen, maar dit kan aangepast worden (we kunnen tidy om andere niveaus vragen).\nIn een rapport voeg je best een notitie onderaan de figuur toe, bv. “Notitie: OLS coëfficiënten met 95% betrouwbaarheidsinterval”.\nHet is handig en gebruikelijk een referentielijn toe te voegen die nul aanduidt want dan kan statistische significantie (hier: bij p &lt; 0.05) onmiddellijk afgelezen worden\nStandaard plot ggplot de coëfficiënten in alfabetische volgorde. Dit kan ervoor zorgen dat variabelen die bij elkaar horen (bv. meerdere dummies van 1 onderliggende categorische variabele) niet bij elkaar staan in het plot. We kunnen de volgorde aanpassen als we de term variabele omzetten in een factor variabele en de volgorde van de levels zelf bepalen. Zie het ‘waarschuwing’-vak hiervoven.\nGelman en Stern (2006) maakte de welbekende uitspraak (althans onder statistici) dat “het verschil tussen ‘significant’ en ‘niet significant’ op zichzelf ‘niet significant’ is”. Dit betekent dat je op basis van de betrouwbaarheidsintervallen van coëfficiënten en hun overlap niet kunt bepalen of coefficiënten significant van elkaar verschillen, je kan enkel bepalen of een coëfficiënt verschillend is van 0 (de nulhypothese).\n\n\nGelman, Andrew, en Hal Stern. 2006. ‘The difference between “significant” and “not significant” is not itself statistically significant’. The American Statistician 60 (4): 328331.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Rapporteren en Presenteren van Resultaten</span>"
    ]
  },
  {
    "objectID": "linear_08.html#sec-presenting-linear-regression-predicted-values-plots",
    "href": "linear_08.html#sec-presenting-linear-regression-predicted-values-plots",
    "title": "8  Rapporteren en Presenteren van Resultaten",
    "section": "8.7 Voorspelde waarden plotten",
    "text": "8.7 Voorspelde waarden plotten\nRegressietabellen en coëfficiëntenplots presenteren de coëfficiënten voor de onafhankelijke variabelen in een model: wat is de verwachte gemiddelde waarde van de DV wanneer alle predictors = 0 (entercept of constante) en wat is de verwachte verandering in Y gegeven als X met één eenheid stijgt (coëfficiënten van onafhankelijke variabelen). We kunnen ook voorspelde waarden en grafieken van die voorspelde waarden gebruiken om discussies over coëfficiënten aan te vullen en meer te kunnen zeggen over het substantiële belang van de geschatte relatie.\nHet proces is gelijkaardig dan dat van coëfficiëntenplots, maar nu maken we gebruik van de predictions() functie in plaats van tidy(). We werken immers met voorspellingen nu en niet de coëfficiënten. Zie Hoofdstuk 5 voor meer informatie over de predictions() functie.\nHieronder geven we voorbeelden voor plots van voorspelde waarden op basis van continue en binaire/categorische onafhankelijke variabelen.\n\n8.7.1 Continue onafhankelijke variabele\nVoor dit voorbeeld gebruiken we heet eerder geschatte plot_model, waarbij electorale democratiescores voorspeld worden aan de hand van de corruptieperceptie-index, politiek geweld, en regimestatus in het verleden. Stel nu dat corruptie (cpi) als continue predictor ons specifiek interesseert. We willen weten hoe demoratieniveau verandert op verschillende niveaus van corruptie. we gebruiken predictions() om de verwachte waarde voor v2x_polyarchy te berekenen wanneer corruptie waarden tussen 20 en 80 aanneemt (de andere onafhankelijke variabelen worden constant gehouden op hun gemiddelde of modus).\n\n#Voorspellingen berekenen\ncpi_preds &lt;- predictions(plot_model, \n                         newdata = datagrid(cpi = c(20, 30, 40, 50, 60, 70, 80)))\n\n#en bekijken\ncpi_preds\n\n\n cpi Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n  20    0.318     0.0278 11.4   &lt;0.001  98.4 0.264  0.373\n  30    0.382     0.0217 17.6   &lt;0.001 227.5 0.339  0.424\n  40    0.445     0.0199 22.4   &lt;0.001 367.4 0.406  0.484\n  50    0.509     0.0233 21.9   &lt;0.001 349.5 0.463  0.555\n  60    0.573     0.0302 18.9   &lt;0.001 263.5 0.513  0.632\n  70    0.636     0.0389 16.4   &lt;0.001 197.8 0.560  0.713\n  80    0.700     0.0483 14.5   &lt;0.001 155.9 0.605  0.795\n\nType:  response \n\n\nDeze data kunnen we invoeren in ggplot() om een plot te maken.\n\n1ggplot(cpi_preds, aes(x = cpi, y = estimate)) +\n2       geom_line () +\n3       geom_ribbon(aes(ymin = conf.low, ymax = conf.high),\n                   alpha = 0.2) +  \n4       labs(title = \"Voorspelde electorale democratiescore op basis van corruptieperceptie\",\n            x = \"Corruptieperceptie-index (Hoger = Minder corrupt)\",   \n            y = \"Voorspelde waarde\") +  \n5       scale_y_continuous(limits=c(0,1))\n\n\n1\n\nDuidt aan welke data en welk plot we willen gebruiken\n\n2\n\nDuidt aan dat we een lijn willen die voorspelde waarden verbindt\n\n3\n\nDuidt aan dat we een betrouwbaarheidsinterval willen en hoe donker dit interval geplot wordt\n\n4\n\nInformatieve titel en labels\n\n5\n\nDe y-as zetten we van 0 tot 1 gezien dit het theoretisch bereik is van de afhankelijke variabele. Niet altijd nodig dit te doen.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(\n\n: We gebruiken ggplot op het data object tussen haakjes.\n\ncpi_preds, aes(x = cpi, y = estimate)) +\n\ndataobject (cpi_preds) en de variabelen die we willen plotten op elke as.\n\ngeom_line() +\n\nWe vragen ggplot hier een lijn te trekken tussen de voorspelde waarden. Dit is gebruikelijk voor een continue onafhankelijke variabele.\n\ngeom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2) +\n\nHier vragen we om een band (‘ribbon’) rond de lijn te tekenen om de betrouwbaarheidsintervallen voor de voorspelde waarden weer te geven. Via aes() bepalen we welke variabelen de ligging van de band bepalen: de ondergrens (ymin) en bovengrens (ymax) van de betrouwbaarheidsintervallen. Met alpha=0.2 bepalen we hoe donker de band is. Hogere waarden zijn donkerder en kunnen de zichtbaarheid van de lijn zelf hinderen.\n\nlabs(...)\n\nWe voegen titel en astitels toe.\n\nscale_y_continuous(limits = c(0,1))\n\nWe bepalen met deze syntax de limieten van de y-as, hier tussen 0 en 1.\n\n\nDe limieten van de as zelf bepalen kan handig zijn om data duidelijker te visualiseren. We kunnen ervoor kiezen om de as het volledige theoretische bereik van de afhankelijke variabele te laten aannemen, zoals we hier doen met een y-as van 0 tot 1. Door het volledige bereik van de afhankelijke variabele te gebruiken lijken de effecten ook niet groter dan ze zijn. Echter kan deze benadering er soms wel voor zorgen dat een grafiek veel wit bevat en minder visueel aantrekkelijk is. Zie this webpage voor voorbeelden van wat er mis kan gaan. In de praktijk maken we een afweging. Wat we wel willen vermijden is dat de schaal groter is dan het theoretische bereik van de afhankelijke variabele.9\n\n\n8.7.2 Binaire/categorische onafhankelijke variabele\nOm voorspelde waarden voor een factor variabele te plotten is de procedure gelijkaardig. Hier plotten we de voorspelde waarden voor electoral democratie voor de verschillende niveaus van TYPEDEMO1984.\n\n#Voorspelde waarden berekenen\ndemo_preds &lt;- predictions(plot_model, \n                          by = 'TYPEDEMO1984', \n1                          newdata = 'mean')\n\n#en bekijken: \ndemo_preds\n\n\n1\n\nHoudt de andere onafhankelijke variabelen op hun gemiddelde of modus\n\n\n\n\n\n TYPEDEMO1984 Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n  Autocracies    0.467     0.0205 22.8   &lt;0.001 379.7 0.427  0.507\n  Democracies    0.620     0.0260 23.8   &lt;0.001 413.9 0.569  0.671\n\nType:  response \n\n\nDit data object voeren we door naar de ggplot() functie. We maken gebruik van geom_pointrange() zoals eerder voor het coëfficiëntenplot.\n\nggplot(demo_preds, aes(x = TYPEDEMO1984, y = estimate)) + \n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) + \n  labs(title = \"Voorspelde democratiescore aan de hand van regime in het verleden\", \n       y = \"Voorspelde waarde\", \n       x = \"Regime in 1984\") + \n  scale_y_continuous(limits = c(0,1)) +\n  scale_x_discrete(labels = c(\"Autocracies\" = \"Autocratie\", \"Democracies\" = \"Democratie\"))\n\n\n\n\n\n\n\n\n\nscale_x_discrete(labels = c(...)\n\nWe veranderen de labels voor de categorische variabele naar het Nederlands.\n\n\nWe kunnen hier ook de effectieve voorspelde waarden toevoegen aan het plot met geom_text. We kunnen de positie van de tekst weer bepalen met vjust en/of hjust. Dit doen we vooral met categorische variabelen en niet met continue predictors.\n\nggplot(demo_preds, aes(x=TYPEDEMO1984, y=estimate)) + \n  geom_pointrange(aes(ymin=conf.low, ymax=conf.high)) + \n  labs(title = \"Voorspelde democratiescore aan de hand van regime in het verleden\", \n       y = \"Voorspelde waarde\", \n       x = \"Regime in 1984\") + \n  geom_text(aes(label = round(estimate, 2)), hjust = -0.25)+\n  scale_x_discrete(labels = c(\"Autocracies\" = \"Autocratie\", \"Democracies\" = \"Democratie\"))\n\n\n\n\n\n\n\n\n\n\n8.7.3 Instructies\n\nWelke variabelen en waarden plot je?\n\nAls de variabele binair/categorisch is, gebruik je alle categorieën die relevant zijn voor de discussie. (zie Week 3 R materialen voor een plot met categorieën).\nAls de variabele continue is gebruik je het minimum en maximum met redelijke tussenintervallen. Om het minimum en maximum te bepalen kijk je naar de data voor de observaties gebruikt in het model (dit is niet noodzakelijk de volledige dataset gezien observaties kunnen wegvallen door missing waarden). Met de predictions() kun je gemakkelijk een dataset aanmaken met alle observaties gebruikt in het model en vervolgens gebruik je summary om minimum en maximum te bepalen (zie Paragraaf 5.3.1).\n\nEen lijn met 95% betrouwbaarheidsintervallen past bij een continue predictor, geom_pointrange() (of geom_errorbar()) bij een binaire/categorische variabele.\nDe y-schaal verdient bijzonder aandacht bij dit soort plots. In het voorbeeld wordt scale_y_continuous() gebruikt om ervoor te zorgen dat het plot het volledige bereik van de afhankelijke variabele (democratiescore) omvat. Soms maakt ggplot() zelf de schaal kleiner (om ongebruikte ruimte weg te laten), maar dan kan een effect groter lijken dan het is. Deze aanpak heeft ook wel nadelen, bijvoorbeeld juist veel ongebruikte ruimte in een plot en minder duidelijke visualisatie. Socioloog Kieran Healy geeft een verdere bespreking over deze verschillende manieren om de schaal vorm te geven in zijn boek over datavisualisatie.",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Rapporteren en Presenteren van Resultaten</span>"
    ]
  },
  {
    "objectID": "linear_08.html#footnotes",
    "href": "linear_08.html#footnotes",
    "title": "8  Rapporteren en Presenteren van Resultaten",
    "section": "",
    "text": "De functie creëert ook een dummy-variabele voor ontbrekende waarden als die er zijn. We vinden bijvoorbeeld ook een TYPEDEMO1984_NA variabele waarbij ‘1’ observaties aanduidt met een NA waarde voor de originele variabele en ‘0’ observaties met een valide waarde (‘1’ of ‘2’ hier). Deze dummy-variabele wordt genegeerd bij de creatie van tabellen.↩︎\nWe gebruiken hier de originele, niet-gefactorde versies van de variabelen in dit voorbeeld. De functie werkt in principe ook met de gefactorde versie. Dan zou je bijvoorbeeld de volgende dummies krijgen voor TYPEDEMO1984: TYPEDEMO1984_factor_Autocracies en TYPEDEMO1984__factor_Democracies. Deze aanpak kan echter complicaties met zich meebrengen als labels meerder woorden bevatten zoals ‘Electoral Democracy’ met een spatie tussen de woorden. R kan hier niet altijd goed mee omgaan en dergelijke variablen zullen ingesloten zijn door backticks (`). Bijvoorbeeld: `Typeregime2006_factor_Electoral Democracy`. Indien je deze variabele wil gebruiken in verdere toepassingen moet je de backticks gebruiken en dat is niet altijd handig.↩︎\nEen 90% betrouwbaarheidsniveau kan passend zijn indien het model een lage N heeft.↩︎\nWe willen bijvoorbeeld misschien asteriks toevoegen voor statistische significantie. Dit lukt niet gemakkelijk vanzelf met datasummary_correlation (De website van het package beschrijft wel deze methode).Je kunt ook altijd cor.testgebruiken om significantie na te gaan.↩︎\nEen 90% betrouwbaarheidsniveau kan passend zijn indien het model een lage N heeft.↩︎\nHet alternatief is om gof_omit() te gebruiken en die statistieken die we niet willen te specificeren.↩︎\nWe kunnen ook de volgorde waarin de variabelen verschijnen in het plot aanpassen. We doen dit door van termeen factor te maken en dan de volgorde van de niveaus aan te passen met relevel.↩︎\nAls we de coëfficiënten op de y-as plaatsen moeten we hier ymin en ymax aanduiden.↩︎\nSocioloog Kieran Healy bespreekt meer in de diepte hoe data te inspecteren in zijn boek “Data Visualization”, gratis beschikbaar hier. Zie in het bijzonder sectie 6 in Hoofdstuk 1, “Problems of honesty and good judgment”.↩︎",
    "crumbs": [
      "Lineaire Statistische Modellen",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Rapporteren en Presenteren van Resultaten</span>"
    ]
  },
  {
    "objectID": "logit_01.html",
    "href": "logit_01.html",
    "title": "9  Logistische Regressie & Odds Ratios",
    "section": "",
    "text": "9.1 Logistische regressieanalyse",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistische Regressie & Odds Ratios</span>"
    ]
  },
  {
    "objectID": "logit_01.html#logistische-regressieanalyse",
    "href": "logit_01.html#logistische-regressieanalyse",
    "title": "9  Logistische Regressie & Odds Ratios",
    "section": "",
    "text": "9.1.1 Data Management\nIn dit voorbeeld zullen we eerst onderzoeken of gender (gndr) opkomst bij verkiezingen bepaalt (vote).\nWe kijken eerst of data management nodig is:\n\n#Variabele attributen\nESS9NL |&gt; \n  select(gndr, vote) |&gt; \n  view_df()\n\n\nData frame: select(ESS9NL, gndr, vote)\n\n\n\n\n\n\n\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\ngndr\nGender\n1\n2\n9\nMale\nFemale\nNo answer\n\n\n2\nvote\nVoted last national election\n1\n2\n3\n7\n8\n9\nYes\nNo\nNot eligible to vote\nRefusal\nDon't know\nNo answer\n\n\n\n\n#Tabellen\ntable(ESS9NL$gndr)\n\n\n  1   2 \n833 840 \n\ntable(ESS9NL$vote)\n\n\n   1    2    3 \n1291  247  130 \n\n\nDe onafhankelijke variabele heeft 2 categorieën en moet in een factor variabele worden omgezet. De afhankelijke variabele heeft 3 categorieën (Yes, No, Not Eligible). We maken hier een binaire factor variabele van door eerst de “Not Eligible” categorie op NA te zetten:\n\n#Factor maken\nESS9NL &lt;- ESS9NL |&gt;\n1  mutate(gndr_F = factorize(gndr),\n2         vote_F = factorize(vote))\n\n#not eligible op NA\nESS9NL &lt;- ESS9NL |&gt;\n  mutate(vote_F = na_if(vote_F,\"Not eligible to vote\"))\n\n\n1\n\nDe categorie met de laagste numerieke waarde wordt hierbij de referentiecategorie. We gebruiken factorize gezien datawaarden labels hebben.\n\n2\n\nWe maken hier geen nieuwe variabele aan voor de gehercodeerde variabelen maar overschrijven de originele variabelen. Dit is doorgaans niet aangeraden voor studenten, gelukkig weten wij meestal wel waar we mee bezig zijn.\n\n\n\n\nWe checken de niveaus van de variabelen, in het bijzonder van de vote variabele:\n\nlevels(ESS9NL$vote_F)\n\n[1] \"Yes\"                  \"No\"                   \"Not eligible to vote\"\n[4] \"Refusal\"              \"Don't know\"           \"No answer\"           \n\ntable(ESS9NL$vote_F)\n\n\n                 Yes                   No Not eligible to vote \n                1291                  247                    0 \n             Refusal           Don't know            No answer \n                   0                    0                    0 \n\n\nDe vote variabele is nu een factor variabele met “Yes” als de referentiecategorie. Dit is niet wat we willen gezien we stemmen willen voorspellen. Als we de variabele zo laten voorspelt het model of een persoon niet heeft gestemd. We veranderen dit met de relevel functie (zie Paragraaf 2.1.1).1\n\n#Relevel de variabele\nESS9NL &lt;- ESS9NL |&gt; \n  mutate(vote_F = relevel(vote_F, \"No\"))\n\n#en controleer het resultaat\nlevels(ESS9NL$vote_F)\n\n[1] \"No\"                   \"Yes\"                  \"Not eligible to vote\"\n[4] \"Refusal\"              \"Don't know\"           \"No answer\"           \n\n\n\nmutate(vote_F = relevel(vote_F, \"No\"))\n\nWe gebruiken de relevel functie op de vote variabele. We creëren hier geen nieuwe variabele, maar overschrijven de oude. Je zou er ook voor kunnen kiezen een nieuwe variabele te maken. De categorie tussen dubbele aanhalingstekens zal de eerste categorie worden en dus de referentiecategorie in de regressie. We gebruiken het label “No” omdat de variabele reeds tot factor is getransformeerd (en dus niet de originele numerieke waarde ‘2’).\n\n\nLaten we nu kijken naar de gndr_F variabele:\n\ntable(ESS9NL$gndr_F)\n\n\n     Male    Female No answer \n      833       840         0 \n\nlevels(ESS9NL$gndr_F)\n\n[1] \"Male\"      \"Female\"    \"No answer\"\n\n\nAls we de niveaus bekijken zien we dat ‘Male’ als referentie zal worden genomen. Dit is prima, maar bij wijze van voorbeeld veranderen we dit hieronder naar ‘Female’. We zien ook een derde categorie ‘No answer’. Dit label werd gegeven aan de waarde in de variabele maar is leeg. R zal deze dus verwijderen in de analyses.\n\nESS9NL &lt;- ESS9NL |&gt; \n  mutate(gndr_F = relevel(gndr_F, \"Female\"))\n\n#controleer je codering\nlevels(ESS9NL$gndr_F)\n\n[1] \"Female\"    \"Male\"      \"No answer\"\n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nDe afhankelijke variabele voor een logistische regressie is een (factor) binaire variabele. Zorg ervoor dat de referentiecategorie de uitkomst is die je niet wil voorspellen en de hoogste categorie net die is die je wil voorspellen. Anders zal je interpretatie foutief zijn.\n\n\n\n\n9.1.2 Logistische regressie uitvoeren\nHet uitvoeren van logistische regressie in R is gelijkaardig aan lineare regressie. In plaats van de ingebouwde functie lm(), gebruiken we de eveneens ingebouwde glm() functie. De afkorting staat voor ‘generalized linear model’.\n\n#Schat het model\nVote_model &lt;- glm(vote_F ~ gndr_F, \n                data = ESS9NL, family = \"binomial\")\n\n\nVote_model &lt;-\n\nWe slaan de resultaten op in een data object met naam naar keuze.\n\nglm(vote_F ~ gndr_F,\n\nWe voeren de glm functie uit met gefactoriseerde vote als afhankelijke variabele, voorspeld (~) door onze enige onafhankelijke variabele: gndr (gefactoriseerd). We kunnen meerdere onafhankelijke variabelen toevoegen, gescheiden van elkaar met een ‘+’ teken.\n\ndata = ESS9NL,\n\nWe geven aan welke dataset gebruikt wordt.\n\nfamily = \"binomial\")\n\nWe verduidelijken de familie van modellen voor ons generalized linear model. Voor logistische regressie is dit “binomial”. Dit gedeelte van de code blijft onveranderd. Zie de Veelvoorkomende Fouten appendix ( Paragraaf A.3) voor een error die je kunt tegenkomen als je dit gedeelte vergeet.\n\n\nDe resultaten bekijken we weer met de summary() functie:\n\nsummary(Vote_model)\n\n\nCall:\nglm(formula = vote_F ~ gndr_F, family = \"binomial\", data = ESS9NL)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.56485    0.09535  16.412   &lt;2e-16 ***\ngndr_FMale   0.18359    0.13925   1.318    0.187    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1355.5  on 1537  degrees of freedom\nResidual deviance: 1353.7  on 1536  degrees of freedom\n  (135 observations deleted due to missingness)\nAIC: 1357.7\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nDe output is gelijkaardig aan die van de lineaire regressie met lm().\n\nCall: Het model dat geschat werd\nDeviance Residuals: beschrijvende statistieken over de residuals van het model.\nCoefficients: De logistische regressiecoëfficiënten (Estimate), hun standaardfouten (Std. Error), en de teststatistiek (z-waarde; de Z-statistiek is gelijk aan \\(\\frac{\\textrm{Coefficient}}{\\textrm{Std. Error}}\\)), en de p-waarde voor de z-statistiek (Pr(&gt;|z|). Symbolen m.b.t. statistische significantie vind je rechts van de p-waarde waar van toepassing. De interpretatie van de symbolen wordt uitgelegd in de legende onder de coëfficiënten (“Signif. Codes:”).\n(Dispersion parameter…): Te negeren.\nArea that begins with Null deviance: Informatie over de fit van het model, besproken in een volgend hoofdstuk.\nNumber of Fisher Scoring Iterations: Aantal iteraties van het algoritme.\n\n\n\nWe kunnen meerdere predictoren toevoegen aan het model op een gelijkaardige manier als bij lineaire regressie: door ze te scheiden met een + teken. Hier voegen we leeftijd (agea), vertrouwen in politici (trstplt), en links-rechts positie (lrscale) toe. Datamanagement voor deze variabelen is niet nodig: ze zijn continue en missing waarden zijn reeds als NA aangeduid.\n\n#Schat het model\nVote_model_mp &lt;- glm(vote_F ~ gndr_F + agea + trstplt + lrscale, \n                data = ESS9NL, family = \"binomial\")\n\n#Bekijk de output\nsummary(Vote_model_mp)\n\n\nCall:\nglm(formula = vote_F ~ gndr_F + agea + trstplt + lrscale, family = \"binomial\", \n    data = ESS9NL)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.284194   0.380455  -0.747    0.455    \ngndr_FMale   0.043281   0.154201   0.281    0.779    \nagea         0.018349   0.004503   4.075 4.61e-05 ***\ntrstplt      0.195020   0.038706   5.039 4.69e-07 ***\nlrscale      0.029257   0.039306   0.744    0.457    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1173.9  on 1424  degrees of freedom\nResidual deviance: 1135.3  on 1420  degrees of freedom\n  (248 observations deleted due to missingness)\nAIC: 1145.3\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n\n\n\n\nInterpretatie\n\n\n\nLogistische regressiecoëfficiënten geven een schatting van de verandering in de log van de odds dat Y=1 als X met 1 eenheid stijgt. Ze zijn dus niet makkelijk direct te interpreteren. We kunnen ze wel gebruiken om iets over de richting van de relatie te zeggen. Een positieve coëfficiënt toont dat de kans dat Y=1 stijgt als de onafhankelijke variabele stijgt. Een negatieve coëfficiënt toont dat de kans dat Y=1 daalt als de onafhankelijke variabele stijgt. Voor verdere interpretatie maak je best gebruik van de odds ratios (in minder mate), de gemiddelde marginale effecten (average marginal effects) (zie Hoofdstuk 10) of de voorspelde kansen (zie Hoofdstuk 11) .\nVoor dit voorbeeld:\n\nMannen hebben een grotere kans om te stemmen dan vrouwen, maar het verschil is niet statistisch significant (p = 0.28).\nOudere respondenten hebben een grotere kans om te gaan stemmen en dit verband is statistisch significant (p &lt; 0.001).\nRespondenten met meer vertrouwen in politici hebben een grotere kans om te gaan stemmen. deze relatie is statistisch significant (p &lt; 0.001).\nStemmen is meer waarschijnlijk naarmate respondenten zich rechtser positioneren op de ideologieschaal, maar dit effect is niet statistisch significant (p = 0.74).",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistische Regressie & Odds Ratios</span>"
    ]
  },
  {
    "objectID": "logit_01.html#odds-ratios",
    "href": "logit_01.html#odds-ratios",
    "title": "9  Logistische Regressie & Odds Ratios",
    "section": "9.2 Odds Ratios",
    "text": "9.2 Odds Ratios\nLogistische regressiecoëfficiënten kunnen omgezet worden in odds ratios die (iets) intuïtiever zijn om te interpereteren.\nWe kunnen de odds ratios en 95% betrouwbaarheidsintervallen verkrijgen met de tidy functie uit het broom package:\n\n# logistische regressiecoëfficiënten en hun betrouwbaarheidsintervallen\ntidy(Vote_model_mp, conf.int = TRUE)\n\n# A tibble: 5 × 7\n  term        estimate std.error statistic     p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)  -0.284    0.380      -0.747 0.455       -1.03       0.463 \n2 gndr_FMale    0.0433   0.154       0.281 0.779       -0.259      0.346 \n3 agea          0.0183   0.00450     4.07  0.0000461    0.00958    0.0272\n4 trstplt       0.195    0.0387      5.04  0.000000469  0.119      0.271 \n5 lrscale       0.0293   0.0393      0.744 0.457       -0.0480     0.106 \n\n# odds ratios (i.e. 'exponentiële coëfficiënten') en hun betrouwbaarheidsintervallen\ntidy(Vote_model_mp, conf.int = TRUE, exp = TRUE)\n\n# A tibble: 5 × 7\n  term        estimate std.error statistic     p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    0.753   0.380      -0.747 0.455          0.357      1.59\n2 gndr_FMale     1.04    0.154       0.281 0.779          0.772      1.41\n3 agea           1.02    0.00450     4.07  0.0000461      1.01       1.03\n4 trstplt        1.22    0.0387      5.04  0.000000469    1.13       1.31\n5 lrscale        1.03    0.0393      0.744 0.457          0.953      1.11\n\n\nZo lees je de syntax:\n\ntidy(Vote_model_mp\n\nWe gebruiken de tidy functie op het model tussen haakjes.\n\nconf.int = TRUE\n\nWe vragen R om de betrouwbaarheidsintervallen weer te geven. We kunnen ‘FALSE’ schrijven of deze code weglaten als we de betrouwbaarheidsintervallen niet willen.\n\nexp = TRUE)\n\nWe vragen hier om de exponentiële (exponentiated) logistische regressiecoëfficiënten, oftewel de odds ratios. We kunnen ‘FALSE’ schrijven of deze code weglaten als we de logistische regressiecoëfficiënten willen.\n\n\n\n\n\n\n\n\nInterpretatie\n\n\n\nVoor de interpretatie van odds ratios zijn er 3 zaken waar je op moet letten.\nTen eerste, odds ratios vertellen ons iets over de relatieve odds dat Y = 1 (bv. iemand gaat stemmen). Dit is verschillend van de coëfficiënten. de coefficiënten zijn de gelogde versies van de relatieve odds..\nTen tweede, odds ratios zijn multiplicatief en worden geïnterpreteerd in termen van 1 in plaats van 0. Een odds ratio groter dan 1 betekent een hogere kans dat Y=1. Een odds ratio lager dan 1 betekent een lagere kans dat Y=1. Een odds ratio van 1 betekent dat er geen effect is. Een betrouwbaarheidsinterval voor een odds ratio waar 1 niet in voorkomt duidt een statistisch significant effect aan. Een odds ratio kan niet negatief zijn.\nTen derde interpreteren we ook de odds ratios met een multiplicatieve logica. In het voorbeeld vinden we dat de odds om te stemmen 1.04 keer groter zijn voor mannelijke respondenten dan vrouwelijke respondenten, ceteris paribus. Het effect is wel niet significant. De odds om te stemmen vermenigvuldigen met 1.02 telkens leeftijd met 1 eenheid omhoog gaat (de andere onafhankelijke variabelen constant gehouden).",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistische Regressie & Odds Ratios</span>"
    ]
  },
  {
    "objectID": "logit_01.html#footnotes",
    "href": "logit_01.html#footnotes",
    "title": "9  Logistische Regressie & Odds Ratios",
    "section": "",
    "text": "Met factor() zouden we direct in de syntax de volgorde van de niveaus aan kunnen duiden: mutate(vote_binary = factor(vote, levels = c(2, 1), labels = c(\"Did not vote\", \"Voted\")). Het gebruik van factor vermijdt een veelvoorkomnde fout besproken in volgend hoofdstuk.↩︎",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistische Regressie & Odds Ratios</span>"
    ]
  },
  {
    "objectID": "logit_02.html",
    "href": "logit_02.html",
    "title": "10  Marginale Effecten",
    "section": "",
    "text": "10.1 Data Management, voorbeeldmodel, en problemen met factorize()\nWe maken gebruiken van eenzelfde model dat we gebruikt hebben in vorig hoofdstuk. Daarin voorspelden we stemmen op basis van gender, leeftijd, vertouwen in politici en linsk-rechtsideologie. We herhalen eerst een paar data management stappen:\n#Datamanagement\nESS9NL &lt;- ESS9NL |&gt;\n  #Factor maken van categorische variabelen\n1  mutate(gndr_F = factorize(gndr),\n         vote_F = factorize(vote))  |&gt; \n  #Not Eligible op missing zetten\n  mutate(vote_F = na_if(vote_F,\"Not eligible to vote\")) |&gt;\n  #Relevel van variabelen\n  mutate(vote_F = relevel(vote_F, \"No\"), \n         gndr_F = relevel(gndr_F, \"Female\"))\n\n#Het model\nVote_model_mp &lt;- glm(vote_F ~ gndr_F + agea + trstplt + lrscale, \n                data = ESS9NL, family = \"binomial\")\n\n#Resultaten printen\nsummary(Vote_model_mp)\n\n\n1\n\nWe zouden ook deze 3 mutate() stappen in 1 stap kunnen combineren.\n\n\n\n\n\nCall:\nglm(formula = vote_F ~ gndr_F + agea + trstplt + lrscale, family = \"binomial\", \n    data = ESS9NL)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.284194   0.380455  -0.747    0.455    \ngndr_FMale   0.043281   0.154201   0.281    0.779    \nagea         0.018349   0.004503   4.075 4.61e-05 ***\ntrstplt      0.195020   0.038706   5.039 4.69e-07 ***\nlrscale      0.029257   0.039306   0.744    0.457    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1173.9  on 1424  degrees of freedom\nResidual deviance: 1135.3  on 1420  degrees of freedom\n  (248 observations deleted due to missingness)\nAIC: 1145.3\n\nNumber of Fisher Scoring iterations: 4\nHet marginaleffectspackage is niet volledig compatibel met de factorize functie die we hierboven hebben gebruikt voor gender. Laten we even kijken naar de gndr_Fvariabele:\nlevels(ESS9NL$gndr_F)\n\n[1] \"Female\"    \"Male\"      \"No answer\"\n\ntable(ESS9NL$gndr_F)\n\n\n   Female      Male No answer \n      840       833         0\nEr zijn 3 niveaus of levels voor gndr_F: “Female”, “Male”, en “No Answer”. Er vallen echter 0 respondenten onder “No Answer”. In dergelijke situaties zal onderstaande functie een error geven omdat de functie zoekt naar een derde niveau dat er niet is.\nOm dit te voorkomen kunnen we gebruik maken van de droplevels() functie om lege niveaus te verwijderen. Of we gebruiken factor() ipv factorizeom gndr een factor variabele te maken. Zie. Paragraaf A.4 in de Veelvoorkomende Fouten Appendix voor meer informatie.\n#Drop levels: verwijderen van categorieën zonder observaties\nESS9NL &lt;- ESS9NL |&gt;\n  mutate(gndr_F = droplevels(gndr_F))\n\n#Checken van syntax\nlevels(ESS9NL$gndr_F)\n\n[1] \"Female\" \"Male\"  \n\ntable(ESS9NL$gndr_F)\n\n\nFemale   Male \n   840    833",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Marginale Effecten</span>"
    ]
  },
  {
    "objectID": "logit_02.html#gemiddelde-marginale-effecten-ame",
    "href": "logit_02.html#gemiddelde-marginale-effecten-ame",
    "title": "10  Marginale Effecten",
    "section": "10.2 Gemiddelde Marginale Effecten (AME)",
    "text": "10.2 Gemiddelde Marginale Effecten (AME)\nDe eerste soort marginale effecten die we bekijken zijn de gemiddelde marginale effecten: de Average Marginal Effects (AME). We gebruiken hiervoor de avg_slopes() functie uit marginaleffects. De AME geeft de gemiddelde verandering in probabiliteit dat Y=1 weer (in termen van percentpunten) als de onafhankelijke met 1 eenheid omhoog gaat (dy/dx). We bereken het marginale effect voor elke observatie en elke variabele in het model en nemen dan het gemiddelde per variabele. Deze figuur beschrijft het proces (uit Heiss (2022)):\n\n\n\nAME berekening door avg_slopes\n\n\nLaten we kijken naar de AMEs van ons model:\n\n#Schatten van AMEs obv model\nAME &lt;- avg_slopes(Vote_model_mp,\n                  conf_level = 0.95)\n\nDe syntax lees je zo\n\nAME &lt;- avg_slopes(Vote_model_mp,\n\nWe gebruiken de functie avg_slopes op het model tussen haakjes. De resultaten slaan we op in een nieuw data object (AME).\n\nconf_level = 0.95)\n\nStandaard wordt een betrouwbaarheidsniveau van 95% gebruikt, dus deze code kan weggelaten worden als dit het gewenste niveau is. Met de code kun je het niveau ook veranderen (bv. 0.99).\n\n\nDit is de output:\n\n1tibble(AME)\n\n\n1\n\nWe zouden AME kunnen typen eerder dan tibble(AME) maar dit geeft andere kolomnamen. We gebruiken tibble() om de kolomnamen te zien zoals ze ook in de dataset zijn opgeslagen. Zie de waarschuwing hiervover in Hoofdstuk 5 Hoofdstuk 5.\n\n\n\n\n# A tibble: 4 × 9\n  term  contrast estimate std.error statistic p.value s.value conf.low conf.high\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 agea  dY/dX     0.00220  0.000538     4.08  4.47e-5  14.4    0.00114   0.00325\n2 gndr… Male - …  0.00518  0.0185       0.281 7.79e-1   0.360 -0.0310    0.0414 \n3 lrsc… dY/dX     0.00350  0.00470      0.744 4.57e-1   1.13  -0.00571   0.0127 \n4 trst… dY/dX     0.0233   0.00460      5.07  3.92e-7  21.3    0.0143    0.0323 \n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\n\nterm: bevat de namen van de variabelen (bv., agea, gndr_F, etc.).\ncontrast: Het ‘contrast’ duidt aan welke vergelijking gemaakt wordt: 1 eenheid toename voor continue variabelen, een verandering van categorie voor factor variabelen.\nestimate: De AME\nstd.error t.e.m. conf.high: Informatie over de onzekerheid van de schatting.\n\n\n\n\n\n\n\n\n\nInterpretatie\n\n\n\nDe gemiddelde marginale effecten (AMEs) geven weer wat de gemiddelde verandering is in de probabiliteit dat Y=1 (in percentpunten) als X met 1 eenheid stijgt. De percentpunten verkrijg je door de AME schatting te vermenigvuldigen met 100. Bijvoorbeeld:\n\nDe kans om te stemmen is gemiddeld 0.5 percentpunten hoger voor een mannelijke respondent dan voor een vrouwelijke respondent.\nDe kans om te stemmen stijgt gemiddeld met 2.3 percentpunten met elke eenheid dat respondenten meer vertrouwen hebben in politici.",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Marginale Effecten</span>"
    ]
  },
  {
    "objectID": "logit_02.html#effecten-op-gemiddelde-waarden-van-de-predictors-mem",
    "href": "logit_02.html#effecten-op-gemiddelde-waarden-van-de-predictors-mem",
    "title": "10  Marginale Effecten",
    "section": "10.3 Effecten op gemiddelde waarden van de predictors (MEM)",
    "text": "10.3 Effecten op gemiddelde waarden van de predictors (MEM)\nWe raden aan om AME te gebruiken als je marginale effecten op basis van een logistische regressie interpreteert. Echter zie je ook soms onderzoek waarin men gebruik maakt van “effecten op gemiddelde waarden”: “marginal effect at the mean” of MEM. Daarmee berekenen we het effect op de probabiliteit dat Y=1 wanneer predictors hun gemiddelde waarden aannemen, of de modus bij categorische variabelen. Deze figuur beschrijft de berekening (uit Heiss (2022)):\n\nHeiss, Andrew. 2022. ‘Marginalia: A Guide to Figuring Out What the Heck Marginal Effects, Marginal Slopes, Average Marginal Effects, Marginal Effects at the Mean, and All These Other Marginal Things Are’. 20 mei 2022. https://doi.org/10.59350/40xaj-4e562.\n\n\n\nHe avg_slopes de MEM berekent\n\n\nDe syntax wordt licht aangepast voor de MEM;\n\nMEM &lt;- slopes(Vote_model_mp, \n              conf_level = 0.95,\n              newdata = datagrid()\n              )\n\n\nnewdata = datagrid()\n\nWe maken een nieuwe dataset voor de berekening waarin alle onafhankelijke variabelen op hun gemiddelde of modus worden gehouden.\n\n\nLaten we kijken naar de resultaten:\n\ntibble(MEM)\n\n# A tibble: 4 × 18\n  rowid term    contrast   estimate std.error statistic p.value s.value conf.low\n  &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1     1 agea    dY/dX       0.00210  0.000519     4.05  5.07e-5  14.3    0.00109\n2     1 gndr_F  Male - Fe…  0.00504  0.0180       0.281 7.79e-1   0.360 -0.0302 \n3     1 lrscale dY/dX       0.00336  0.00453      0.742 4.58e-1   1.13  -0.00551\n4     1 trstplt dY/dX       0.0224   0.00447      5.00  5.67e-7  20.8    0.0136 \n# ℹ 9 more variables: conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;,\n#   predicted &lt;dbl&gt;, gndr_F &lt;fct&gt;, agea &lt;dbl&gt;, trstplt &lt;dbl&gt;, lrscale &lt;dbl&gt;,\n#   vote_F &lt;fct&gt;\n\n\nBehalve estimate, standaardfout, test statistiek, p-waarde, en onder- en bovengrens van de betrouwbaarheidsintervallen, bevat de MEM dataset ook de gemiddelden en/of modus waarden voor de predictoren.\n\nMEM |&gt; \n  select(gndr_F, agea, trstplt, lrscale) |&gt; \n  as_tibble()\n\n# A tibble: 4 × 4\n  gndr_F  agea trstplt lrscale\n  &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Male    50.7    5.34    5.15\n2 Male    50.7    5.34    5.15\n3 Male    50.7    5.34    5.15\n4 Male    50.7    5.34    5.15\n\n\n\n\n\n\n\n\nInterpretatie\n\n\n\nDe interpretatie van MEMs is gelijkaardig aan die van AME: Welke gemiddelde verandering in de kans dat Y=1 verwachten we als X 1 eenheid stijgt? Vermenigvuldigen met 100 leidt tot een interpretatie in termen van percentpunten. De gemiddelde verandering is nu wel berekend wanneer onafhankelijke variabelen hun gemiddelde waarden aannemen. Dit moet gerapporteerd worden. Bijvoorbeeld: mannelijke respondenten hebben een 0.5 percentpunten hogere kans om te stemmen dan vrouwelijke respondenten, als leeftijd, ideologie, en vertrouwen in politici constant worden gehouden op hun gemiddelde waarde.",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Marginale Effecten</span>"
    ]
  },
  {
    "objectID": "logit_03.html",
    "href": "logit_03.html",
    "title": "11  Voorspelde kansen",
    "section": "",
    "text": "11.1 Voorspelde kans voor individuele observaties\nOm op basis van het logistische regressiemodel de kans dat de afhankelijke variabele Y gelijk is aan 1 (hier: dat een respondent heeft gestemd) te voorspellen voor elke observatie in het model maken we gebruik van de predictions functie. De resultaten worden altijd opgeslaan in een nieuwe dataset, die je een naam geeft naar keuze (hier: Vote_pred).\n#Resultaten opslaan in nieuw object\nVote_pred &lt;- predictions(Vote_model_mp,\n                         conf_level = 0.95, \n                         newdata = ESS9NL)\n\n#tibble() gebruiken voor overzicht\ntibble(Vote_pred)\n\n# A tibble: 1,673 × 580\n   rowid estimate   p.value s.value conf.low conf.high name    essround edition\n   &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;  \n 1     1    0.835  6.13e-35   114.     0.796     0.867 ESS9e03        9 3      \n 2     2    0.910  1.71e-56   185.     0.884     0.931 ESS9e03        9 3      \n 3     3    0.904  4.26e-45   147.     0.874     0.928 ESS9e03        9 3      \n 4     4   NA     NA           NA     NA        NA     ESS9e03        9 3      \n 5     5    0.864  9.71e-39   126.     0.828     0.894 ESS9e03        9 3      \n 6     6    0.912  7.81e-53   173.     0.884     0.933 ESS9e03        9 3      \n 7     7    0.800  1.32e-12    39.5    0.731     0.854 ESS9e03        9 3      \n 8     8    0.914  9.43e-31    99.7    0.877     0.941 ESS9e03        9 3      \n 9     9    0.877  1.88e-47   155.     0.845     0.903 ESS9e03        9 3      \n10    10    0.944  2.64e-39   128.     0.917     0.963 ESS9e03        9 3      \n# ℹ 1,663 more rows\n# ℹ 571 more variables: proddate &lt;chr&gt;, idno &lt;dbl&gt;, cntry &lt;chr&gt;, nwspol &lt;dbl&gt;,\n#   netusoft &lt;dbl&gt;, netustm &lt;dbl&gt;, ppltrst &lt;dbl&gt;, pplfair &lt;dbl&gt;, pplhlp &lt;dbl&gt;,\n#   polintr &lt;dbl&gt;, psppsgva &lt;dbl&gt;, actrolga &lt;dbl&gt;, psppipla &lt;dbl&gt;,\n#   cptppola &lt;dbl&gt;, trstprl &lt;dbl&gt;, trstlgl &lt;dbl&gt;, trstplc &lt;dbl&gt;, trstplt &lt;dbl&gt;,\n#   trstprt &lt;dbl&gt;, trstep &lt;dbl&gt;, trstun &lt;dbl&gt;, vote &lt;dbl&gt;, prtvtcat &lt;dbl&gt;,\n#   prtvtdbe &lt;dbl&gt;, prtvtdbg &lt;dbl&gt;, prtvtgch &lt;dbl&gt;, prtvtbcy &lt;dbl&gt;, …\nDit is de syntax-uitleg:",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Voorspelde kansen</span>"
    ]
  },
  {
    "objectID": "logit_03.html#voorspelde-kans-voor-individuele-observaties",
    "href": "logit_03.html#voorspelde-kans-voor-individuele-observaties",
    "title": "11  Voorspelde kansen",
    "section": "",
    "text": "Vote_pred &lt;-\n\nNieuw data object met voorspelde kansen.\n\npredictions(Vote_model_mp,\n\nWe voeren de predictions functie uit op het model tussen haakjes.\n\nconf_level = 0.95,\n\nStandaard betrouwbaarheidsniveau. De waarde kan veranderd worden (bv. conf_level = 0.99).\n\nnewdata = ESS9NL)\n\nWe kopiëren de variabelen uit de originele dataset. Dit gedeelte kan weggelaten worden als je dit niet nodig acht.",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Voorspelde kansen</span>"
    ]
  },
  {
    "objectID": "logit_03.html#gemiddelde-voorspelde-kansen",
    "href": "logit_03.html#gemiddelde-voorspelde-kansen",
    "title": "11  Voorspelde kansen",
    "section": "11.2 Gemiddelde voorspelde kansen",
    "text": "11.2 Gemiddelde voorspelde kansen\nWe kunnen de predictions() functie ook gebruiken om de gemiddelde voorspelde kans dat Y=1 te berekenen voor specifieke waarden van een onafhankelijke variabele. De andere onafhankelijke variabelen worden constant gehouden op hun gemiddelde (continue variabelen) of modus (factor variabelen). Deze voorspellingen kunnen we ook weergeven in een figuur zoals besproken in Paragraaf 14.5 .\n\n11.2.1 Continue onafhankelijke variabele\nDe volgende code gebruiken we als de predictor die ons interesseert continu is. Hier berekenen we de gemiddelde voorspelde kans om te stemmen als vertrouwen in politici (trstplt) verandert.\n\nESS9NL |&gt; \n  select(trstplt) |&gt; \n  view_df()\n\n\nData frame: select(ESS9NL, trstplt)\n\n\n\n\n\n\n\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\ntrstplt\nTrust in politicians\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n77\n88\n99\nNo trust at all\n1\n2\n3\n4\n5\n6\n7\n8\n9\nComplete trust\nRefusal\nDon't know\nNo answer\n\n\n\n\ntable(ESS9NL$trstplt)\n\n\n  0   1   2   3   4   5   6   7   8   9  10 \n 43  41  68  90 173 292 457 375  87  16   8 \n\n\nDe variabele loopt van 0 tot 10 dus deze waarden gebruiken we als minimum en maximum. We berekenen verder de kans per interval van 2 eenheden (missing waarden zijn reeds op NA gezet). We zouden ook voor elke eenheid de kans kunnen berekenen maar dit geeft vrij veel output, wellicht meer dan we nodig hebben. We zouden in plaats van deze intervallen ook minimum, 1ste kwartiel, mediaan, 3rde kwartiel en maximum van de variabele kunnen gebruiken (zie Paragraaf 5.3.1 voor het proces om deze waarden te verkrijgen).\n\n#Voorspellingen in nieuw object\nPred_conts &lt;- predictions(Vote_model_mp,\n                          newdata = datagrid(trstplt = seq(from = 0, to = 10, by = 2))) \n\n\nnewdata = datagrid(trstplt\n\nAlle predictoren in het model worden op hun gemiddelde/modus gehouden behalve de predictor die tussen haakjes staat.\n\n= seq(from=0,to=10,by=2)))\n\nWe vragen hier voorspellingen voor een sequentie (seq) van waarden: van (from) het minimum tot (to) het maximum met tussenstappen (by) van 2. We zouden als alternatief deze code kunnen gebruiken: trstplt = c(0,2,4,6,8,10)).\n\n\nLaten we de voorspellingen bekijken:\n\n1tibble(Pred_conts)\n\n\n1\n\ntibble() wordt gebruikt om de onderliggende data beter te kunnen zien.\n\n\n\n\n# A tibble: 6 × 11\n  rowid estimate  p.value s.value conf.low conf.high gndr_F  agea lrscale\n  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1     1    0.699 9.37e- 5    13.4    0.603     0.779 Male    50.7    5.15\n2     2    0.774 1.09e-15    49.7    0.717     0.822 Male    50.7    5.15\n3     3    0.835 1.61e-46   152.     0.802     0.863 Male    50.7    5.15\n4     4    0.882 1.29e-64   212.     0.856     0.904 Male    50.7    5.15\n5     5    0.917 6.30e-48   157.     0.889     0.938 Male    50.7    5.15\n6     6    0.942 3.65e-34   111.     0.912     0.962 Male    50.7    5.15\n# ℹ 2 more variables: trstplt &lt;dbl&gt;, vote_F &lt;fct&gt;\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nDe output is gelijkaardig aan die voor voorspellingen voor lineaire regressiemodellen (zie Hoofdstuk 5):\n\nDe estimate kolom bevat de voorspelde kans. We doen dit getal *100 om de kans in percent uit te drukken. bv. Voor iemand met een score van ‘0’ op de schaal trstplt verwachten we een kans om te stemmen van 69,86%.\nDe p.value t.e.m. conf.high kolommen geven de onzekerheid van de schatting weer.\nWe kunnen ook de kolommen zien voor de andere onafhankelijke variabelen in het model (gndr_F, agea, lrscale) . Deze kolommen tonen de waarde waarop deze variabelen constant worden gehouden. De predictions() functie houdt continue variabelen op hun gemiddelde en factor variabelen op hun modus als je newdata = datagrid() gebruikt zoals we hierboven gedaan hebben.\nDe laatste 2 kolommen tonen trstplt, met de waarden gebruikt om de voorspelling te berekenen en een kolom (niet zichtbaar hier) met de Y (vote_F) die toont welke categorie voorspeld wordt.\n\n\n\n\n\n11.2.2 Factor onafhankelijke variabele\nDe code voor categorische variabelen is licht anders. We gebruiken hier de by= optie. In dit voorbeeld berekenen we de gemiddelde voorspelde kans voor mannen en vrouwen (met andere predictoren constant gehouden op hun gemiddelde).\n\n#voorspellingen in nieuw object\nPred_cat &lt;- predictions(Vote_model_mp,\n              by=\"gndr_F\", \n              newdata = \"mean\") \n\n#tibble voor overzicht\ntibble(Pred_cat)\n\n# A tibble: 2 × 13\n  rowid gndr_F estimate std.error statistic p.value s.value conf.low conf.high\n  &lt;int&gt; &lt;fct&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     1 Female    0.863    0.0133      65.1       0     Inf    0.837     0.889\n2     2 Male      0.868    0.0127      68.2       0     Inf    0.843     0.893\n# ℹ 4 more variables: agea &lt;dbl&gt;, trstplt &lt;dbl&gt;, lrscale &lt;dbl&gt;,\n#   rowid_dedup &lt;int&gt;\n\n\n\nby=\"gndr_F\"\n\nMet deze optie duiden we aan dat we voor elk niveau van de factor variabele een voorspelde kans willen berekenen.\n\nnewdata = \"mean\"\n\nDeze optie moeten we toevoegen om duidelijk te maken dat andere predictoren op hun gemiddelde/modus gehouden moeten worden. Deze optie moet samen met by= gebruikt worden.",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Voorspelde kansen</span>"
    ]
  },
  {
    "objectID": "logit_03.html#voorspelde-kansen-voor-specifieke-waarden-van-predictoren",
    "href": "logit_03.html#voorspelde-kansen-voor-specifieke-waarden-van-predictoren",
    "title": "11  Voorspelde kansen",
    "section": "11.3 Voorspelde kansen voor specifieke waarden van predictoren",
    "text": "11.3 Voorspelde kansen voor specifieke waarden van predictoren\nTen slotte kunnen we de voorspelde kans op Y berekenen als een observatie bepaalde, hypothetische waarden zou aannemen.\nBijvoorbeeld, hier berekenen we de voorspelde kans om te stemmen voor een man (gndr), die 33 jaar oud is (agea), een score van 2 heeft voor vertrouwen in politici (trstplt) en een score van 8 heeft op de links-rechts schaal (lrscale). We moeten hiervoor de waarden voor alle predictoren verduidelijken tussen haakjes bij newdata=datagrid.\n\n#Berekenen en opslaan in object\nPred_specific &lt;- predictions(Vote_model_mp,\n1                             newdata = datagrid(gndr_F=c(\"Male\"),\n                                                agea=c(33),   \n                                                trstplt=c(2), \n                                                lrscale=c(8)))\n#bekijken\nPred_specific\n\n\n1\n\nWe gebruiken haakjes omdat dit een factor variabele is met labels voor categorieën.\n\n\n\n\n\n gndr_F agea trstplt lrscale Estimate Pr(&gt;|z|)    S 2.5 % 97.5 %\n   Male   33       2       8    0.729   &lt;0.001 20.2 0.645  0.799\n\nType:  invlink(link)",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Voorspelde kansen</span>"
    ]
  },
  {
    "objectID": "logit_04.html",
    "href": "logit_04.html",
    "title": "12  Model Fit en Modellen Vergelijken",
    "section": "",
    "text": "12.1 Fit statistieken met summary()\nLaten we teruggaan naar het logistisch model waar we ook in vorige hoofdstukken mee werkten: wat is de kans dat iemand gaat stemmen op basis van informatie over gender, leeftijd, vertouwen in politici en links-rechtsideologie?\n#Data management\nESS9NL &lt;- ESS9NL |&gt;\n  #Factor maken van categorische variabelen\n  mutate(gndr_F = factorize(gndr), \n         vote_F = factorize(vote))  |&gt; \n  #Not Eligible op missing zetten\n  mutate(vote_F = na_if(vote_F,\"Not eligible to vote\")) |&gt; \n  #Relevel van variabelen\n  mutate(vote_F = relevel(vote_F, \"No\"), \n         gndr_F = relevel(gndr_F, \"Female\"))\n\n#Het model\nVote_model_mp &lt;- glm(vote_F ~ gndr_F + agea + trstplt + lrscale, \n                data = ESS9NL, family = \"binomial\")\n\n#Resultaten printen\nsummary(Vote_model_mp)\n\n\nCall:\nglm(formula = vote_F ~ gndr_F + agea + trstplt + lrscale, family = \"binomial\", \n    data = ESS9NL)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.284194   0.380455  -0.747    0.455    \ngndr_FMale   0.043281   0.154201   0.281    0.779    \nagea         0.018349   0.004503   4.075 4.61e-05 ***\ntrstplt      0.195020   0.038706   5.039 4.69e-07 ***\nlrscale      0.029257   0.039306   0.744    0.457    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1173.9  on 1424  degrees of freedom\nResidual deviance: 1135.3  on 1420  degrees of freedom\n  (248 observations deleted due to missingness)\nAIC: 1145.3\n\nNumber of Fisher Scoring iterations: 4",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Model Fit en Modellen Vergelijken</span>"
    ]
  },
  {
    "objectID": "logit_04.html#fit-statistieken-met-summary",
    "href": "logit_04.html#fit-statistieken-met-summary",
    "title": "12  Model Fit en Modellen Vergelijken",
    "section": "",
    "text": "Output uitleg\n\n\n\nZoals bij een lineair model (lm), zal de summary() functie in het onderste gedeelte van de output informatie bevatten over model fit. We krijgen informatie over de “Null” en “Residual Deviance” statistieken. De Residual Deviance statistiek duidt het verschil (“deviance”) aan tussen het geschatte model en een “perfect’ model dat precies bij de data past. De Null Deviance statistiek doet dezelfde vergelijking, maar ten opzichte van een nulmodel dat enkel het intercept bevat.\nKleinere Residual Deviance waarden duiden beter passende modellen aan. Echter is het niet gewenst om de deviance statistiek op zich te interpreteren gezien de schaal onduidelijk is en er geen maximumwaarde is. Daarom maken we gebruik van andere statistieken en een test gebaseerd op de deviance statistiek (zie onder).",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Model Fit en Modellen Vergelijken</span>"
    ]
  },
  {
    "objectID": "logit_04.html#modellen-vergelijken-likelihood-ratio-test",
    "href": "logit_04.html#modellen-vergelijken-likelihood-ratio-test",
    "title": "12  Model Fit en Modellen Vergelijken",
    "section": "12.2 Modellen vergelijken: Likelihood Ratio Test",
    "text": "12.2 Modellen vergelijken: Likelihood Ratio Test\nWe kunnen de likelihood ratio test gebruiken om verschillende logistische regressiemodellen te vergelijken met elkaar en na te gaan welke beter past. De LRT berekent de ratio tussen de deviance statistieken van de modellen en gaat na of er een significant verschil is.\nAls we modellen willen verglijken moeten we net zoals bij lineaire regressie (zie Paragraaf 6.2) zorgen dat de modellen een gelijke N hebben en dat complexere modellen alle predictors bevatten van simpelere modellen (nested). We zorgen dat we eerst een dataset maken met complete observaties voor het meest complexe model (alle predictors).\n\nESS9NL_glm &lt;- ESS9NL |&gt;\n  filter(complete.cases(vote_F,  gndr_F,  agea,  trstplt,  lrscale))\n\nDan schatten we een reeks modellen waaraan we telkens 1 van de onafhankelijke varaibelen toevoegen. We beginnen met een nulmodel dat enkel het intercept bevat. Het model met 1 onafhankelijke variabele kan daar dan mee vergeleken worden.\n\n#Nulmodel\nVote_model0 &lt;- glm(vote_F ~ 1,\n                      data = ESS9NL_glm, family = \"binomial\")\n# + gndr\nVote_model1 &lt;- glm(vote_F ~ gndr_F , \n                data = ESS9NL_glm, family = \"binomial\")\n# + agea\nVote_model2 &lt;- glm(vote_F ~ gndr_F + agea , \n                data = ESS9NL_glm, family = \"binomial\")\n\n# + trst\nVote_model3 &lt;- glm(vote_F ~ gndr_F + agea + trstplt, \n                data = ESS9NL_glm, family = \"binomial\")\n\n# + lrscale\nVote_model4 &lt;- glm(vote_F ~ gndr_F + agea + trstplt + lrscale, \n                data = ESS9NL_glm, family = \"binomial\")\n\nNu kunnen we de likelihood ratios van deze modellen met elkaar vergelijken en significantietoetsen uitvoeren. We gebruiken het performance package met de test_likelihoodratio functie. De test vergelijkt de deviance statistiek (-2LL) van elk model, de verandering in vrijheidsgraden (df= degrees of freedom) per model, en gebruikt een Chi2 (\\(\\chi^2\\)) toets.\n\ntest_likelihoodratio(Vote_model0,\n                     Vote_model1,\n                     Vote_model2,\n                     Vote_model3,\n                     Vote_model4)\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName        | Model | df | df_diff |  Chi2 |      p\n---------------------------------------------------\nVote_model0 |   glm |  1 |         |       |       \nVote_model1 |   glm |  2 |       1 |  0.11 |  0.744\nVote_model2 |   glm |  3 |       1 | 13.59 | &lt; .001\nVote_model3 |   glm |  4 |       1 | 24.38 | &lt; .001\nVote_model4 |   glm |  5 |       1 |  0.55 |  0.457\n\n\n\ntest_likelihoodratio(\n\n: We voeren de likelihood ratio test uit op de modellen tussen haakjes. Er moeten minstens twee modellen aangeduid zijn en de volgorde bepaalt welke vergelijking gemaakt wordt.\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nDe output lees je als volgt:\n\nName: naam van het object waarin het model is opgeslagen\nModel: informatie over het type model. Te negeren.\ndf: Geeft weer hoeveel termen gebruikt werden in het model. Vote_model0 heeft een df van 1 gezien er maar 1 term is: het intercept. Vote_model4 heeft 5 df omdat er 5 termen zijn: het intercept en de coëfficiënten voor de 4 onafhankelijke variabelen.\ndf_diff: Geeft weer hoeveel het model verschilt van het vorige model in termen van df. Dit is telkens 1 hier omdat we telkens maar 1 nieuwe predictor hebben toegevoegd.\nChi2 & p: Dit is de Chi2 statistiek en bijhorende p-waarde. De test gaat na of de fit van een model beter is dan de fit van het model in de rij erboven. De nulhypothese is dat er geen verschil is in fit. Een significante toets betekent dat het model beter past.\n\n\n\nIn dit voorbeeld:\n\nModel 1 heeft geen significant betere fit dan een nulmodel (vote_model0)\nModel 2 heeft een betere fit dan Model 1\nModel 3 heeft een betere fit dan Model 1 Model 2\nModel 4 heeft geen significant betere fit dan Model 3.\n\nWe kunnen concluderen dat Model 3 (vote_model3) het best passende model is zonder inclusie van nietszeggende variabelen (i.e. het model is het meest ‘parsimonious’).\nZoals het geval was voor de anova() functie bij lineaire regressie kun je ook specifieke groepen van modellen vergelijken:\n\n#Past Model 4 beter dan Model 1?: Ja!\ntest_likelihoodratio(Vote_model1, Vote_model4)\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName        | Model | df | df_diff |  Chi2 |      p\n---------------------------------------------------\nVote_model1 |   glm |  2 |         |       |       \nVote_model4 |   glm |  5 |       3 | 38.53 | &lt; .001\n\n#Past Model 3 beter dan een nulmodel?: Ja!\ntest_likelihoodratio(Vote_model0, Vote_model3)\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName        | Model | df | df_diff |  Chi2 |      p\n---------------------------------------------------\nVote_model0 |   glm |  1 |         |       |       \nVote_model3 |   glm |  4 |       3 | 38.08 | &lt; .001\n\n\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nDe volgorde waarin we onze modellen aanduiden in de test_likelihoodratio() syntax bepaalt welke modellen precies vergeleken worden net zoals met anova() bij lineaire regressie ( Paragraaf 6.2). Bij een verkeerde volgorde krijg je een error in R. Een juiste volgorde houdt in dat je van minder naar meer complex gaat:\n\ntest_likelihoodratio(Vote_model0,\n                     Vote_model4,\n                     Vote_model2,\n                     Vote_model1,\n                     Vote_model3)\n\nError: The models are not nested, which is a prerequisite for\n  `test_likelihoodratio()`.\n  See the 'Details' section.\n  You may try `test_vuong()` instead.\n\n\nAls we 2 modellen testen en de eerste in de syntax is de meest complexe, dan krijgen we dezelfde Chi2 en p-waarde vergeleken met een juiste volgorde, maar de df_diff zal negatief zijn (-3 ipv +3 in dit voorbeeld). Op zich is dit geen probleem, zolang we maar weten wat we precies aan het vergelijken zijn zodat we geen interpretatiefouten maken.\n\ntest_likelihoodratio(Vote_model4, Vote_model1)\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName        | Model | df | df_diff |  Chi2 |      p\n---------------------------------------------------\nVote_model4 |   glm |  5 |         |       |       \nVote_model1 |   glm |  2 |      -3 | 38.53 | &lt; .001",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Model Fit en Modellen Vergelijken</span>"
    ]
  },
  {
    "objectID": "logit_04.html#pseudo-r2",
    "href": "logit_04.html#pseudo-r2",
    "title": "12  Model Fit en Modellen Vergelijken",
    "section": "12.3 Pseudo R2",
    "text": "12.3 Pseudo R2\nBij een lineair regressiemodel beoordelen we fit met de R2 waarde. Een logistisch model is anders geschat en dus hebben we deze waarde niet. Verschillende zogenaamde pseudo R2 statistieken werden ontwikkeld om meer intuïtief inzicht te verkrijgen in de verklarende kracht van een model. De pseudo R2 maatstaven zijn gebaseerd op de likelihood ratio test en kunnen niet als ‘proportie verklaarde variantie’ geïnterpreteerd worden.\nHier gebruiken we de Nagelkerke R². De waarde van deze maatstaf ligt tussen 0 en 1. Lage waarden wijzen op een lage verklarende kracht, hoge waarden op een hoge verklarende kracht.\nWe kunnen de Nagelkerke R² statistiek opvragen met de r2_nagelkerke() functie uit het performance package.\n\n# Nagelkerke R2: Model 3\nr2_nagelkerke(Vote_model3)\n\nNagelkerke's R2 \n     0.04698189 \n\n# Nagelkerke R2: Model 4\nr2_nagelkerke(Vote_model4)\n\nNagelkerke's R2 \n     0.04765513 \n\n\n\nr2_nagelkerke(\n\nDeze functie berekent de Nagelkerke R2 voor het model tussen haakjes. Er kan slecht 1 model opgegeven worden.\n\n\nDe Nagelkerke R2 is hoger voor Model 4 dan Model 3. Echter is een likelihood ratio test nodig om te weten of dit verschil significant is. Zoals we hierboven zagen is dit niet het geval.\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nEr bestaan verschillende pseudo R2 statistieken om de fit van logistische regressiemodellen te helpen interpreteren. Geen enkele van hen kan geïnterpreteerd worden in termen van ‘proprotie verklaarde variantie’.",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Model Fit en Modellen Vergelijken</span>"
    ]
  },
  {
    "objectID": "logit_05.html",
    "href": "logit_05.html",
    "title": "13  Assumpties van Logistische Regressie",
    "section": "",
    "text": "13.1 Beperkte multicollineariteit\nWe kunnen nagaan of ons model onderhevig is aan te sterke multicollineariteit met de vif() functie uit het car package. Dit is gelijkaardig aan wat we deden voor lineaire regressie ( Paragraaf 7.2). Dezelfde vuistregels zijn van toepassing. Voor logistische regressiemodellen wordt een ‘generalized VIF’ berekend.\nvif(Vote_model4)\n\n  gndr_F     agea  trstplt  lrscale \n1.013505 1.018080 1.019284 1.013647\nDe resultaten duiden op geen problemen met multicollineariteit.",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Assumpties van Logistische Regressie</span>"
    ]
  },
  {
    "objectID": "logit_05.html#lineariteit-van-de-logit",
    "href": "logit_05.html#lineariteit-van-de-logit",
    "title": "13  Assumpties van Logistische Regressie",
    "section": "13.2 Lineariteit van de logit",
    "text": "13.2 Lineariteit van de logit\nLogistische regressie veronderstelt dat veranderingen in de log odds (de logit) lineair geassocieerd zijn met Y=1. Om de assumptie te checken gebruiken we de augment() functie uit het broom package. Deze functie creëert een dataframe met de variabelen gebruikt in het model, alsook belangrijke statistieken om assumpties te testen:\n\naugment(Vote_model4)\n\n# A tibble: 1,425 × 11\n   vote_F gndr_F  agea trstplt lrscale .fitted .resid    .hat .sigma   .cooksd\n   &lt;fct&gt;  &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n 1 Yes    Female    32       6       5    1.62  0.601 0.00238  0.894 0.0000947\n 2 No     Male      57       7       5    2.32 -2.20  0.00175  0.893 0.00356  \n 3 Yes    Female    45       8       5    2.25  0.448 0.00220  0.894 0.0000467\n 4 Yes    Female    34       7       5    1.85  0.540 0.00237  0.894 0.0000749\n 5 Yes    Male      67       6       6    2.33  0.430 0.00188  0.894 0.0000365\n 6 No     Female    85       5       4    2.37 -2.22  0.00330  0.893 0.00710  \n 7 Yes    Female    40       7       5    1.96  0.513 0.00199  0.894 0.0000561\n 8 Yes    Male      71       8       7    2.83  0.339 0.00245  0.894 0.0000292\n 9 Yes    Female    84       5       5    2.38  0.421 0.00310  0.894 0.0000577\n10 Yes    Male      24       7       5    1.71  0.576 0.00360  0.894 0.000131 \n# ℹ 1,415 more rows\n# ℹ 1 more variable: .std.resid &lt;dbl&gt;\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\n\nvote_F t.e.m. lrscale: Deze kolommen bevatten de geobserveerde waarden op de betreffende variabelen voor alle observaties gebruikt in het model.\n.fitted: De voorspelde (‘fitted’) waarden op basis van de schattingen in het model in ‘logit’ vorm en dus niet in probabiliteiten.\n.resid: De residuals (fouten/errors) voor elke observatie. Ook gekend als de “deviance residuals”.\n.hat: Diagonaal van de hat matrix (te negeren).\n.sigma: Geschatte standaardafwijking van de fouten als de observatie uit het model zou worden verwijderd (te negeren)\n.cooksd: Cook’s D waarden (zie onder).\n.std.resid: gestandaardiseerde residuals (zie onder).\n\n\n\nWe zullen verder werken met de augment statistieken hier en voor outliers en influential cases dus maken we een nieuw dataobject met de resultaten:\n\nmodel4_augmented &lt;- augment(Vote_model4, data = ESS9NL_glm)\n\n\naugment(Vote_model4, data=ESS9NL_glm)\n\nWe voegen deze syntax toe aan de functie: data = ESS9NL_glm. De reden is dat we zo een dataobject creëren met de augment-statistieken, de variabelen gebruikt in het model, en alle overige variabelen in de originele ESS9 dataset. Dit kan nuttig zijn voor bepaalde handelingen. We kunnen enkel de overige variabelen toevoegen als de datasets evenveel rijen hebben. Dit is niet het geval als er missing waarden zijn en het model minder observaties heeft dan de originele dataset. Vandaar dat we eerst een complete.cases-data subset hebben gemaakt hierboven.\n\n\nOm lineariteit te checken plotten we de logit die augment heeft berekend telkens tegenover de onafhankelijke variabelen in het model, specifiek de continue onafhankelijke variabelen. We maken een scatterplot met een loess-lijn en .fitted geplot op de y-as.\n\n# Leeftijd\nggplot(model4_augmented, aes(x = agea, y = .fitted)) + \n  geom_point() + \n  geom_smooth(method = 'loess')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Vertrouwen in politici\nggplot(model4_augmented, aes(x = trstplt, y = .fitted)) + \n  geom_point() + \n  geom_smooth(method = 'loess')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# LR-ideologie\nggplot(model4_augmented, aes(x = lrscale, y = .fitted)) + \n  geom_point() + \n  geom_smooth(method = 'loess')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nWe gaan na of de loess-lijn sterke afwijkingen van een lineaire relatie vertoont. Dit lijkt hier niet het geval.",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Assumpties van Logistische Regressie</span>"
    ]
  },
  {
    "objectID": "logit_05.html#beperkte-impact-outliers-en-influential-cases",
    "href": "logit_05.html#beperkte-impact-outliers-en-influential-cases",
    "title": "13  Assumpties van Logistische Regressie",
    "section": "13.3 Beperkte impact outliers en influential cases",
    "text": "13.3 Beperkte impact outliers en influential cases\nMet de augment functie hebben we reeds de gestandaardiseerde residuals en Cook’s D waarden opgeslagen in een dataobject. We kijken eerst naar outliers, dan naar invloedrijke casussen\n\n13.3.1 Outliers\nWe bekijken eerst de descriptieve statistieken voor de gestandaardiseerde residuals:\n\nsummary(model4_augmented$.std.resid)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-2.3983  0.4104  0.5040  0.1870  0.5916  1.0319 \n\n\nDe output helpt ons na te gaan of er observaties zijn die de drempelwaarden (|1.96|, |2.58|, |3.29|) overschrijden. We zien dat de hoogste drempelwaarden (|2.58|, |3.29|) niet overschreden worden maar de laagste van 1.96 wel (het minimum is -2.398). Nu moeten we nog weten hoeveel observaties deze waarde overschrijden.\nDit kunnen we nagaan door net zoals bij lineaire regressie een dummy variabele te maken (0 = .std.resid &lt; |1.96|, 1 = .std.resid &gt; |1.96|) en de frequentietabel te inspecteren. 1 (zie Paragraaf 7.6.1 voor de syntax voor de andere drempelwaarden)\n\n#dummy variabele maken: \nmodel4_augmented &lt;- model4_augmented |&gt;\n  mutate(SRE1.96 = case_when(\n    .std.resid &gt; 1.96 | .std.resid &lt; -1.96  ~ 1,\n    .std.resid &gt; -1.96 & .std.resid &lt; 1.96 ~ 0\n  ))\n\n#proportie opzoeken \nfre(model4_augmented$SRE1.96)\n\n\n\n\nmodel4_augmented$SRE1.96\n Count \n Valid percent \n Percent \n Responses, % \n Cumulative responses, % \n\n\n\n\n 0 \n1344\n94.3\n94.3\n94.3\n94.3\n\n\n 1 \n81\n5.7\n5.7\n5.7\n100.0\n\n\n #Total \n1425\n100\n100\n100\n\n\n\n &lt;NA&gt; \n0\n\n0.0\n\n\n\n\n\n\n\n5.7% van de observaties liggen buiten het +/- 1.96 interval. Om te onderzoeken of deze outliers de parameters van het model beïnvloeden, kunnen we het model opnieuw schatten zonder deze observaties. We doen dit door in onze dataset enkel observaties met een waarde van ‘0’ op SRE1.96 op te nemen. We zouden dan de resultaten van het model met en het model zonder outliers vergelijken:\n\nVote_model41.96 &lt;- glm(vote_F ~ gndr_F + agea + trstplt + lrscale, \n                data = subset(model4_augmented, SRE1.96 == 0), \n                family = \"binomial\")\n\n\n\n13.3.2 Influential cases\nOm te onderzoeken of er invloedrijke casussen aanwezig zijn inspecteren we de Cook’s D waarden van de observaties in het model. We kunnen de descriptieve statistieken bekijken en het Cook’s D plot via de resid_panel() funtie uit het ggResidpanel package. We hanteren dezelfde vuistregels als voor lineaire regressie (zie Paragraaf 7.6.2).\n\n#Summary of the Cook's D values\nsummary(model4_augmented$.cooksd)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n2.331e-05 5.117e-05 8.959e-05 7.085e-04 2.442e-04 1.668e-02 \n\n#Plot\nresid_panel(Vote_model4, plots = c('cookd'))\n\nWarning in helper_plotly_label(model): NAs introduced by coercion\nWarning in helper_plotly_label(model): NAs introduced by coercion\n\n\n\n\n\n\n\n\n\nBeide methoden wijzen op lage Cook’s D waarden; de maximum waarde is slechts 0.017. Indien we hogere waarden zouden vinden, zouden we deze observaties uit de dataset kunnen filteren en het model opnieuw schatten om resultaten met en zonder invloedrijke casussen te vergelijken.",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Assumpties van Logistische Regressie</span>"
    ]
  },
  {
    "objectID": "logit_05.html#footnotes",
    "href": "logit_05.html#footnotes",
    "title": "13  Assumpties van Logistische Regressie",
    "section": "",
    "text": "We zouden ook het gemiddelde van de 0/1 variabele kunnen berekenen gezien dit ons de proportie zou geven voor de ‘1’ cases.↩︎",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Assumpties van Logistische Regressie</span>"
    ]
  },
  {
    "objectID": "logit_06.html",
    "href": "logit_06.html",
    "title": "14  Rapporteren en Presenteren van Resultaten",
    "section": "",
    "text": "14.1 Rapportage\nEen rapport van een logistisch regressiemodel bevat best de volgende zaken:\nHieronder vind je een voorbeeld voor gndr_F (binaire factor) en trstplt (continue predictor) op basis van het hierboven geschatte model. Zie vorige hoofdstukken voor de berekening van de AME en odds ratio waarden voor deze variabelen.\nBijkomende richtlijnen voor besprekingen in papers:",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Rapporteren en Presenteren van Resultaten</span>"
    ]
  },
  {
    "objectID": "logit_06.html#rapportage",
    "href": "logit_06.html#rapportage",
    "title": "14  Rapporteren en Presenteren van Resultaten",
    "section": "",
    "text": "Een bespreking van de richting van de relatie en wat dit concreet betekent (de codering van de variabelen inachtgenomen).\n\nBij een multiple regressie is het belangrijk te verduidelijken dat het effect dat je vindt voor een onafhankelijke variabele gecontroleerd is op de andere onafhankelijke variabelen in het model. Deze worden ‘constant gehouden’ (oftewel ‘ceteris paribus’).\n\nEen bespreking van de AMEs of voorspelde waarden om de sterkte van de associatie te duiden.\nEen bespreking van de statistische significantie (verwerpen of niet nulhypothese?) met vermelding van z-statistiek en p-waarde en/of het betrouwbaarheidsinterval.\n\nCoëfficiënten met p-waarden groter dan 0.05 worden meestal niet als statistisch significant of als statistisch significant bij conventionele niveaus beschouwd.1 Rapporteer op basis van het hoogste signficantieniveau dat de p-waarde aangeeft:\n\nAls p = 0.04, dan p &lt; 0.05 (significant op 95% niveau)\nAls p = 0.02, dan p &lt; 0.01 (significant op 99% niveau)\nAls p = 0.0000005, dan p &lt; 0.001 (significant op 99.9% niveau)\nWe rapporteren meestal niet hoger dan 99.9% of p &lt; 0.001 (bv., we zeggen niet p &lt; 0.000001, maar p &lt; 0.001). We schrijven ook nooit p &lt; 0.000.\n\nHet betrouwbaarheidsinterval kan ook gebruikt worden om statistische significantie te bespreken en de onzekerheid rond de geschatte AMEs/voorspellingen aan te duiden. Als je het betrouwbaarheidsinterval bespreekt, kun je dit tussen haakjes toevoegen, bv. “het gemiddelde marginale effect van leeftijd is 0.004 (95% CI: -0.006, 0.013)”.\nHet is minder gebruikelijk de z-statistiek concreet te benoemen, maar het is ook geen probleem als je dit doet. Indien de z-waarde wordt opgenomen, zet je deze bij de p-waarde: “(z = 1.18, p &gt; 0.05)”.\n\n\n\n\n\n\n\n\n\nRapportagevoorbeeld\n\n\n\ntrstplt (AME): De kans dat iemand gaat stemmen is hoger als vertrouwen in politici hoger is. De kans neemt gemiddeld genomen met 2.3 percentpunten toe als vertouwen met 1 eenheid stijgt. De relatie is statistisch significant (p &lt; 0.001).\ngndr (AME): De kans om te stemmen is gemiddeld 0.5 percentpunten hoger voor mannen dan voor vrouwen. Deze relatie is echter niet statistisch significant (p = 0.78).\ngndr (Odds Ratio): De odds om te stemmen voor mannen zijn 1.04 keer hoger dan die voor vrouwen. Het verschil is echter niet statistisch significant (p = 0.78).\n\n\n\n\nIn je rapportage kun je ook een bespreking van de voorspelde waarden opnemen (bv. wat is de voorspelde kans dat iemand gaat stemmen bij lage en hoge niveaus van vetrouwen in politici?) Een plot van voorspelde waarden kan de bespreking verder verduidelijken. Zie Paragraaf 14.5 voor meer informatie.\nAls je onderzoek vooral gericht is op de relatie tussen een specifieke onafhankelijke variabele en de afhankelijke variabele dan is een discussie over de controlevariabelen doorgaans niet nodig.\nHet intercept wordt zelden besproken bij logistische regressies. Hte intercept is de odds op Y als alle predictoren gelijk zijn aan nul.\nWees voorzichting in je bespreking van de relatie tussen de variabelen. Causaliteit is moeilijk te bepalen en is onderhevig aan sterke voorwaarden. Je schrijft bijgevolg dus meestal niet het “effect van X op Y” , maar “de verandering in X is geassocieerd met de verandering in Y”.",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Rapporteren en Presenteren van Resultaten</span>"
    ]
  },
  {
    "objectID": "logit_06.html#sec-presentation-regression-tables-logit",
    "href": "logit_06.html#sec-presentation-regression-tables-logit",
    "title": "14  Rapporteren en Presenteren van Resultaten",
    "section": "14.2 Presentatie: Regressietabellen",
    "text": "14.2 Presentatie: Regressietabellen\nWe gebruiken de modelsummary() functie uit het modelsummary package om regressietabellen te produceren. De procedure en syntax is gelijkaardig aan die voor lineaire regressietabellen (zie Paragraaf 8.5). Het belangrijkste verschil zit in de model fit statistieken.\n\nmodelsummary(Vote_model_mp,\n             stars = TRUE,\n             coef_rename = c(\"(Intercept)\" = \"Constante\",\n                             \"agea\" = \"Leeftijd\",\n                             \"gndr_FMale\" = \"Man\",\n                             \"trstplt\"= \"Vertrouwen in politici\",\n                             \"lrscale\" = \"links-recht positie\"),\n             gof_map = c(\"nobs\", \"logLik\"),\n             title = \"Opkomst in Nederland (ESS9)\",\n             notes = (\"Logistische regressiecoëfficiënten met standaardfouten tussen haakjes\"))\n\n\n\n    \n\n    \n    \n      \n        \n        Opkomst in Nederland (ESS9)\n              \n                 \n                (1)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nLogistische regressiecoëfficiënten met standaardfouten tussen haakjes\n        \n                \n                  Constante\n                  -0.284\n                \n                \n                  \n                  (0.380)\n                \n                \n                  Man\n                  0.043\n                \n                \n                  \n                  (0.154)\n                \n                \n                  Leeftijd\n                  0.018***\n                \n                \n                  \n                  (0.005)\n                \n                \n                  Vertrouwen in politici\n                  0.195***\n                \n                \n                  \n                  (0.039)\n                \n                \n                  links-recht positie\n                  0.029\n                \n                \n                  \n                  (0.039)\n                \n                \n                  Num.Obs.\n                  1425\n                \n                \n                  Log.Lik.\n                  -567.653\n                \n        \n      \n    \n\n\n\n\ngof_map = c(\"nobs\", \"logLik\")\n\nWe kunnen verschillende goodness-of-fit statistieken toevoegen aan de tabel. Hier beperken we ons tot het aantal observaties en de log likelihood. We kunnen alle statistieken weglaten met gof_map = NA. Het is meestal een goed idee een Pseudo R2 maatstaf als goodness-of-fit statistiek toe te voegen aan de tabel. modelsummary() voegt echter niet automatisch de Nagelkerke R2 toe. We kunnen deze wel manueel toevoegen aan de tabel in Word in een rij onder ‘Log.Lik.’.\n\n\n\n14.2.1 Tabellen met Odds Ratios\nOm odds ratios en hun betrouwbaarheidsintervallen in de regressietabel te presenteren moeten een aantal elementen toegevoegd worden. Vergeet in dit geval ook niet het onderschrift (notes) te veranderen.\n\nmodelsummary(Vote_model_mp,\n1             exponentiate = TRUE, conf_level=0.95,\n2             statistic = 'conf.int',\n             stars = TRUE,\n             coef_rename = c(\"(Intercept)\" = \"Constante\",\n                             \"agea\" = \"Leeftijd\",\n                             \"gndr_FMale\" = \"Man\",\n                             \"trstplt\"= \"Vertrouwen in politici\",\n                             \"lrscale\" = \"links-recht positie\"),\n             gof_map = c(\"nobs\", \"logLik\"),\n             title = \"Opkomst in Nederland (ESS9)\",\n             notes = (\"Odds ratios met 95% betrouwbaarheidsintervallen\"))\n\n\n1\n\nVraagt modelsummary() de logistische coëfficiënten te exponentiëren, wat de odds ratios oplevert.\n\n2\n\nVraagt modelsummary() de 95% betrouwbaarheidsintervallen te produceren. Dit is gebruikelijk bij odds ratios.\n\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        Opkomst in Nederland (ESS9)\n              \n                 \n                (1)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nOdds ratios met 95% betrouwbaarheidsintervallen\n        \n                \n                  Constante\n                  0.753\n                \n                \n                  \n                  [0.357, 1.588]\n                \n                \n                  Man\n                  1.044\n                \n                \n                  \n                  [0.772, 1.413]\n                \n                \n                  Leeftijd\n                  1.019***\n                \n                \n                  \n                  [1.010, 1.028]\n                \n                \n                  Vertrouwen in politici\n                  1.215***\n                \n                \n                  \n                  [1.126, 1.311]\n                \n                \n                  links-recht positie\n                  1.030\n                \n                \n                  \n                  [0.953, 1.112]\n                \n                \n                  Num.Obs.\n                  1425\n                \n                \n                  Log.Lik.\n                  -567.653\n                \n        \n      \n    \n\n\n\n\nexponentiate = TRUE,\n\nMet deze code vragen we om de exponentiële coëfficiënten, i.e., de odds ratios.\n\nconf_level=0.95,\n\nMet deze code kunnen we het betrouwbaarheidsniveau aanpassen. Standaard is dit niveau 0.95. Als dit het gewenste niveau is, kan deze code ook worden weggelaten.\n\nstatistic = 'conf.int'\n\nMet deze code vragen we om betrouwbaarheidsintervallen te presenteren en niet de standaardfouten (de default).",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Rapporteren en Presenteren van Resultaten</span>"
    ]
  },
  {
    "objectID": "logit_06.html#presentatie-plots-van-coëfficiënten-en-odds-ratios",
    "href": "logit_06.html#presentatie-plots-van-coëfficiënten-en-odds-ratios",
    "title": "14  Rapporteren en Presenteren van Resultaten",
    "section": "14.3 Presentatie: Plots van coëfficiënten (en odds ratios)",
    "text": "14.3 Presentatie: Plots van coëfficiënten (en odds ratios)\nWe kunnen de output ook presenteren in de vorm van een coëfficiëntenplot (eventueel met de volledige regressietabel in Appendix), net zoals bij lineaire regressiemodellen. De procedure wordt beschreven in Paragraaf 8.6 . Hier is een voorbeeld op basis van bovenstaand model:\n\n1tidy(Vote_model_mp, conf.int = TRUE) |&gt;\n2  filter(term != \"(Intercept)\") |&gt;\n3  mutate(term = recode(term,\n                       \"gndr_FMale\" = \"Man\",\n                       \"agea\" = \"Leeftijd\",\n                       \"trstplt\" = \"Vertrouwen in politici\",\n                       \"lrscale\" = \"Links-rechts positie\")) |&gt;\n  ggplot(aes(x= estimate, y= term)) +\n  geom_pointrange(aes(xmin=conf.low, \n                      xmax=conf.high)) +\n  labs(title = \"Opkomst in Nederland (ESS9)\", \n       y = \"Variabele\", \n       x = \"Logistische regressiecoëfficiënt\") + \n  geom_vline(xintercept=0, linetype=\"dashed\", color=\"red\") +\n  geom_text(aes(label = round(estimate, 2)), vjust = -0.5, hjust = -0.1)\n\n\n1\n\nWe produceren het plot in 1 stap, gebruikmakend van de |&gt; operator. Je zou de syntax echter kunnen opbreken in meerdere stappen: (1) tidyresultaten opslaan in nieuw object; (2) Hercoderen van de term variabelen in dat object; en (3) plot maken.\n\n2\n\nHet intercept wordt doorgaans niet getoond.\n\n3\n\nWe zouden i.p.v. recode() ook eerst een factor kunnen maken van de termvariabele met factor(). Daarmee zouden we labels kunnen toevoegen en de volgorde waarin de variabelen verschijnen kunnen aanpassen. Zie Paragraaf 8.6.\n\n\n\n\n\n\n\n\n\n\n\nAls we odds ratios willen plotten vragen we eerts dat tidy() odds ratios produceert en vervolgens zetten we de referentielijn voor statistische significantie op 1. We veranderen ook het label op de x-as.:\n\n1tidy(Vote_model_mp, conf.int = TRUE, exponentiate = TRUE) |&gt;\n  filter(term != \"(Intercept)\") |&gt; \n  mutate(term = recode(term, \n                       \"gndr_FMale\" = \"Man\",\n                       \"agea\" = \"Leeftijd\",\n                       \"trstplt\" = \"Vertrouwen in politici\",\n                       \"lrscale\" = \"Links-rechts positie\")) |&gt;\n  ggplot(aes(x= estimate, y= term)) +\n  geom_pointrange(aes(xmin=conf.low, \n                      xmax=conf.high)) +\n  labs(title = \"Opkomst in Nederland (ESS9)\", \n       y = \"Variabele\", \n       x = \"Odds Ratio\") + \n2  geom_vline(xintercept = 1, linetype = 'dashed', color ='red') +\n  geom_text(aes(label = round(estimate, 2)), vjust = -0.5)\n\n\n1\n\nexponentiate = TRUE voor de odds ratios\n\n2\n\nOdds ratios zijn multiplicatief. Daarom moet de referentielijn op 1 komen te staan\n\n\n\n\n\n\n\n\n\n\n\n\n14.3.1 Instructies\n\nMeestal plaats je de coëfficiënt op de x-as en de naam van de variabele op de y-as. Het is mogelijk dit te veranderen met de ggplot syntax, maar dan kunnen de variabelenamen makkelijker overlappen. Lange variabelennamen leiden wel vaker tot problemen met de visualisatie (in deze blog vind je enkele tips).\nStandaard plot ggplot de coëfficiënten in alfabetische volgorde. Dit kan ervoor zorgen dat variabelen die bij elkaar horen (bv. meerdere dummies van 1 onderliggende categorische variabele) niet bij elkaar staan in het plot (zoals in het voorbeeld hierboven). We kunnen de volgorde aanpassen als we de term variabele omzetten in een factor variabele en de volgorde van de levels zelf bepalen. Zie Paragraaf 8.6\nHet toevoegen van de (afgeronde) coëfficiënt-waarde kan lezers helpen de resultaten beter te vatten.\nMeestal plotten we de 95% betrouwbaarheidsintervallen, maar dit kan aangepast worden (we kunnen tidy om andere niveaus vragen).\nIn een rapport voeg je best een notitie onderaan de figuur toe, bv. “Notitie: OLS coëfficiënten met 95% betrouwbaarheidsinterval”.\nHet is handig en gebruikelijk een referentielijn toe te voegen die nul aanduidt want dan kan statistische significantie (hier: bij p &lt; 0.05) onmiddellijk afgelezen worden.",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Rapporteren en Presenteren van Resultaten</span>"
    ]
  },
  {
    "objectID": "logit_06.html#presentatie-ame-plots",
    "href": "logit_06.html#presentatie-ame-plots",
    "title": "14  Rapporteren en Presenteren van Resultaten",
    "section": "14.4 Presentatie: AME Plots",
    "text": "14.4 Presentatie: AME Plots\nWe kunnen ook de gemiddelde marginale effect ( average marginal effects, AME) plotten. Dit kan het meest informatieve zijn voor lezers gezien deze waarden in termen van probabiliteiten geïnterpreteerd kunnen worden. De procedure is gelijkaardig aan die voor coëfficiëntenplots, maar in plaats van tidy() gebruiken we de avg_slopes() functie uit het marginaleffects package:\n\n1avg_slopes(Vote_model_mp) |&gt;\n2  mutate(term = recode(term,\n3                       \"gndr_F\" = \"Man\",\n                       \"agea\" = \"Leeftijd\",\n                       \"trstplt\" = \"Vertrouwen in politici\",\n                       \"lrscale\" = \"Links-rechts positie\")) |&gt;\n  ggplot(aes(x = estimate, y = term)) + \n  geom_pointrange(aes(xmin = conf.low, xmax = conf.high)) + \n  labs(title = \"Opkomst in Nederland (ESS9)\", \n       y = \"Variabele\", \n       x = \"Gemiddelde Marginale Effect\") + \n  geom_vline(xintercept = 0, linetype = 'dashed', color ='red') + \n  geom_text(aes(label = round(estimate, 2)), vjust = -0.5)\n\n\n1\n\nWe produceren het plot in 1 stap, gebruikmakend van de |&gt; operator. Je zou de syntax echter kunnen opbreken in meerdere stappen: (1) avg_slopesresultaten opslaan in nieuw object; (2) Hercoderen van de term variabelen in dat object; en (3) plot\n\n2\n\nWe zouden i.p.v. recode() ook eerst een factor kunnen maken van de termvariabele met factor(). Daarmee zouden we labels kunnen toevoegen en de volgorde waarin de variabelen verschijnen kunnen aanpassen. Zie Paragraaf 8.6.\n\n3\n\navg_slopes() combineert niet de variabelenaam en de categorielabel bij factor variabelen in term (bv. het toont gndr in plaats van gndrMale).\n\n\n\n\n\n\n\n\n\n\n\nBovenstaand voorbeeld plot probabiliteiten lopende van 0 tot 1. Met de afronding op 2 decimalen vinden we gewoon een waarde van 0 voor links-rechtspositie en leeftijd. Dit is niet zo handig. We kunnen de resultaten ook in percentpunten uitdrukken wanneer we de AME (estimate) en de betrouwbaarheidsintervallen (conf.low, conf.high) met 100 vermenigvuldigen:\n\navg_slopes(Vote_model_mp) |&gt; \n   mutate(term = recode(term,\n                       \"gndr_F\" = \"Man\",\n                       \"agea\" = \"Leeftijd\",\n                       \"trstplt\" = \"Vertrouwen in politici\",\n                       \"lrscale\" = \"Links-rechts positie\"), \n         estimate = estimate * 100, \n         conf.low = conf.low * 100,\n         conf.high = conf.high * 100) |&gt; \n  ggplot(aes(x = estimate, y = term)) + \n  geom_pointrange(aes(xmin = conf.low, xmax = conf.high)) + \n  labs(title = \"Opkomst in Nederland (ESS9)\", \n       y = \"Variabele\", \n       x = \"Gemiddelde Marginale Effect (Percentpunten)\") + \n  geom_vline(xintercept = 0, linetype = 'dashed', color ='red') + \n  geom_text(aes(label = round(estimate, 2)), vjust = -0.5)\n\n\n\n\n\n\n\n\n\n14.4.1 Instructies\nDe richtlijnen voor coëfficiënteplots worden ook hier gehanteerd (zie boven en Paragraaf 8.6).",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Rapporteren en Presenteren van Resultaten</span>"
    ]
  },
  {
    "objectID": "logit_06.html#sec-presentation-predicted-probability-plots",
    "href": "logit_06.html#sec-presentation-predicted-probability-plots",
    "title": "14  Rapporteren en Presenteren van Resultaten",
    "section": "14.5 Presentatie: Plots van Voorspelde Waarden",
    "text": "14.5 Presentatie: Plots van Voorspelde Waarden\nTen slotte kunnen we de resultaten van een model ook grafisch presenteren met behulp van voorspelde waarden. We zagen eerder hoe we de voorspelde waarden plotten voor specifieke waarden van een continue of categorische onafhankelijke variabele in een lineair regressiemodel (see Paragraaf 8.7). Nu doen we hetzelfde voor logistische modellen.\n\n14.5.1 Continue onafhankelijke variabele\nDe output van het model toonde dat stemmen waarschijnlijker wordt naarmate mensen meer vertouwen hebben in politici. De AME toonde dat de stijging gemiddeld 2.3 percentpunten was per eenheid vertrouwen. Maar hoeveel impact heeft dit dan echt op stemgedrag? Gaat men van heel onwaarschijnlijk tot zeer waarschijnlijk om te stemmen? Een plot kan helpen dit te verduidelijken.\nWe beginnen met de predictions() functie om de voorspelde kansen te berekenen bij verschillende waarden van vertrouwen in politici (trstplt).\n\n#Voorspellingen opslaan\nPred_conts &lt;- predictions(Vote_model_mp, \n1                          newdata = datagrid(trstplt = seq(from = 0, to = 10, by = 2)))\n#en bekijken\ntibble(Pred_conts)\n\n\n1\n\nWe zouden predictions() ook intervallen van 1pt kunnen laten berekenen, maar dit is doorgaans niet nodig. ggplot() verbindt de punten in een lijn.\n\n\n\n\n# A tibble: 6 × 11\n  rowid estimate  p.value s.value conf.low conf.high gndr_F  agea lrscale\n  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1     1    0.699 9.37e- 5    13.4    0.603     0.779 Male    50.7    5.15\n2     2    0.774 1.09e-15    49.7    0.717     0.822 Male    50.7    5.15\n3     3    0.835 1.61e-46   152.     0.802     0.863 Male    50.7    5.15\n4     4    0.882 1.29e-64   212.     0.856     0.904 Male    50.7    5.15\n5     5    0.917 6.30e-48   157.     0.889     0.938 Male    50.7    5.15\n6     6    0.942 3.65e-34   111.     0.912     0.962 Male    50.7    5.15\n# ℹ 2 more variables: trstplt &lt;dbl&gt;, vote_F &lt;fct&gt;\n\n\nWe voeren deze data door naar ggplot() zoals we voorheen ook bij lineaire regressie deden:\n\n1ggplot(Pred_conts, aes(x = trstplt, y = estimate)) +\n2  geom_line() +\n3  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = 0.2) +\n4  labs(title = \"Vertrouwen en opkomst in Nederland\",\n             x = \"Vertrouwen in politici\", \n       y = \"Voorspelde kans om te stemmen\")\n\n\n1\n\nZegt ggplot() welke data te gebruiken (Pred_conts) en wat op de x- (trstplt) en y-as (estimate) te zetten.\n\n2\n\nZegt ggplot() dat we een verbindingslijn willen tussen de voorspellingen.\n\n3\n\nZegt ggplot() dat we een band met betrouwbaarheidsintervallen willen en hoe donker de kleur daarvan mag zijn (alpha = 0.2).\n\n4\n\nInformatieve labels.\n\n\n\n\n\n\n\n\n\n\n\nWe zouden ook de schaal van y kunnen aanpassen om het volledige theoretische bereik van probabiliteiten (0 tot 1) weer te geven, indien we denken dat resultaten misleidend kunnen zijn zonder deze aanpassing:\n\nggplot(Pred_conts, aes(x = trstplt, y = estimate)) +   \n  geom_line() +                                        \n  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = 0.2) +  \n  labs(title = \"Vertrouwen en opkomst in Nederland\",\n             x = \"Vertrouwen in politici\", \n       y = \"Voorspelde kans om te stemmen\") + \n  scale_y_continuous(limits = c(0,1))\n\n\n\n\n\n\n\n\n\n\n14.5.2 Factor onafhankelijke variabele\nWe kunnen deze syntax gebruiken voor predictors die factors zijn:\n\n#Voorspellingen opslaan\nPred_cat &lt;- predictions(Vote_model_mp, by = \"gndr_F\", newdata = \"mean\") \n\n#en bekijken\ntibble(Pred_cat)\n\n# A tibble: 2 × 13\n  rowid gndr_F estimate std.error statistic p.value s.value conf.low conf.high\n  &lt;int&gt; &lt;fct&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     1 Female    0.863    0.0133      65.1       0     Inf    0.837     0.889\n2     2 Male      0.868    0.0127      68.2       0     Inf    0.843     0.893\n# ℹ 4 more variables: agea &lt;dbl&gt;, trstplt &lt;dbl&gt;, lrscale &lt;dbl&gt;,\n#   rowid_dedup &lt;int&gt;\n\n\nDe data wordt dan naar een plot overgezet:\n\nggplot(Pred_cat, aes(x= gndr_F, y= estimate)) +   \n  geom_pointrange(aes(ymin=conf.low, ymax=conf.high)) +  \n  labs(title = \"Gender en opkomst in Nederland\", \n       x = \"Gender\",\n       y = \"Voorspelde kans om te stemmen\") +\n  geom_text(aes(label = round(estimate, 2)), hjust = -0.25) +\n  scale_x_discrete(labels = c(\"Male\" = \"Man\", \"Female\" = \"Vrouw\"))\n\n\n\n\n\n\n\n\n\n\n14.5.3 Instructies\n\nWelke variabelen en waarden plot je?\n\nAls de variabele binair/categorisch is, gebruik je alle categorieën die relevant zijn voor de discussie.\nAls de variabele continue is gebruik je het minimum en maximum met redelijke tussenintervallen. Om het minimum en maximum te bepalen kijk je naar de data voor de observaties gebruikt in het model (dit is niet noodzakelijk de volledige dataset gezien observaties kunnen wegvallen door missing waarden). Met de predictions() kun je gemakkelijk een dataset aanmaken met alle observaties gebruikt in het model en vervolgens gebruik je summary om minimum en maximum te bepalen (zie Paragraaf 5.3.1).\n\nWe gebruiken een lijn met betrouwbaarheidsintervallen voor continue predictoren; voor categorische doen we beroep op geom_pointrange() of geom_errorbar().\nDe y-schaal verdient bijzonder aandacht bij dit soort plots. In het eerste voorbeeld (continue predictor) wordt scale_y_continuous() gebruikt om ervoor te zorgen dat het plot het volledige bereik van de afhankelijke variabele (kans om te stemmen) omvat. Het tweede voorbeeld (categorische predictor) laat de keuze aan ggplot(). Soms maakt ggplot() de schaal kleiner om ongebruikte ruimte weg te laten, maar dan kan een effect groter lijken dan het is. Deze aanpak heeft ook wel nadelen, bijvoorbeeld juist veel ongebruikte ruimte in een plot en minder duidelijke visualisatie. Socioloog Kieran Healy geeft een verdere bespreking over deze verschillende manieren om de schaal vorm te geven in zijn boek over datavisualisatie.",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Rapporteren en Presenteren van Resultaten</span>"
    ]
  },
  {
    "objectID": "logit_06.html#footnotes",
    "href": "logit_06.html#footnotes",
    "title": "14  Rapporteren en Presenteren van Resultaten",
    "section": "",
    "text": "Als de N van het model laag is, kan eventueel een 90% niveau gebruikt worden.↩︎",
    "crumbs": [
      "Logistische Regressiemodellen",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Rapporteren en Presenteren van Resultaten</span>"
    ]
  },
  {
    "objectID": "interaction_01.html",
    "href": "interaction_01.html",
    "title": "15  Interacties in het Regressiemodel",
    "section": "",
    "text": "15.1 Een interactie in het regressiemodel\nZowel bij lineaire (lm) als logistische (glm) regressie kunnen we meerdere onafhankelijke variabelen toevoegen door gebruik te maken van het ‘+’ teken. We kunnen een interactie tussen twee onafhankelijke variabelen toevoegen door het ‘*’ teken in plaats van de ‘+’ te gebruiken.\nIn het volgende lineaire regressiemodel voorspellen we hoe respondenten kandidaat en uitdager Joe Biden evalueren op een schaal van 0 (‘heel koud of ongunstig’) tot 100 (‘heel warm of gunstig’) door gebruik te maken van 3 predictors:\n#Model schatten en resultaten opslaan\nbiden_model &lt;- lm(biden ~ pid + right_track + rural_urban, data = anes)\n\n#Overzicht resultaten\nsummary(biden_model)\n\n\nCall:\nlm(formula = biden ~ pid + right_track + rural_urban, data = anes)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-83.656 -13.349   0.771  16.344  90.722 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 93.9170     0.6543 143.537  &lt; 2e-16 ***\npid                        -10.2606     0.1364 -75.245  &lt; 2e-16 ***\nright_trackRight Direction -12.8153     0.6993 -18.326  &lt; 2e-16 ***\nrural_urbanRural            -4.1666     0.8219  -5.070 4.09e-07 ***\nrural_urbanSmall Town       -2.9846     0.7011  -4.257 2.10e-05 ***\nrural_urbanCity             -0.3076     0.6713  -0.458    0.647    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.88 on 7141 degrees of freedom\n  (1133 observations deleted due to missingness)\nMultiple R-squared:  0.602, Adjusted R-squared:  0.6018 \nF-statistic:  2161 on 5 and 7141 DF,  p-value: &lt; 2.2e-16\nBiden wordt minder positief ingeschat als partij-identificatie meer richting Republikeinen gaat en als respondenten vinden dat het de goede richting uitgaat met het land (onder Trump). Er zijn ook verschillen voor locatie. 1\nStel dat we op basis van theorie denken dat er een interactie is tussen partij-identificatie en de evaluatie dat het land in de goede/slechte richting gaat. We kunnen denken dat het effect van pid op de evaluatie van Biden anders is als men vindt dat het land in de slechte richting in plaats van de goede richting beweegt. Of we denken dat het effect van right_track anders is voor (overtuigde) Democraten en Republikeinen. Beide hypotheses onderzoeken we door dezelfde interactieterm toe te voegen aan het model. We verbinden hiervoor 2 onafhankelijke variabelen met een (‘*’) in plaats van een (‘+’) teken.\n#Model schatten en resultaten opslaan\nbiden_int &lt;- lm(biden ~ pid * right_track + rural_urban, data = anes)\n\n#Overzicht resultaten\nsummary(biden_int)\n\n\nCall:\nlm(formula = biden ~ pid * right_track + rural_urban, data = anes)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-84.834 -13.186   0.166  15.166  87.299 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                     95.6585     0.6730 142.146  &lt; 2e-16 ***\npid                            -10.8243     0.1468 -73.744  &lt; 2e-16 ***\nright_trackRight Direction     -33.1885     2.1600 -15.365  &lt; 2e-16 ***\nrural_urbanRural                -4.0838     0.8163  -5.003 5.79e-07 ***\nrural_urbanSmall Town           -2.8082     0.6965  -4.032 5.60e-05 ***\nrural_urbanCity                 -0.3202     0.6667  -0.480    0.631    \npid:right_trackRight Direction   3.7144     0.3729   9.961  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.73 on 7140 degrees of freedom\n  (1133 observations deleted due to missingness)\nMultiple R-squared:  0.6075,    Adjusted R-squared:  0.6072 \nF-statistic:  1842 on 6 and 7140 DF,  p-value: &lt; 2.2e-16\nVoor een logistisch model wordt hetzelfde principe gevolgd. Hier voorspellen we of een persoon vindt dat de VS de goede (1) of verkeerde (0) richting uitgaat met de variabele right_track. We gebruiken de volgende predictoren: vote2016, voor wie gestemd werd in 2016 (Hillary Clinton = 0, Donald Trump = 1); age, leeftijd in jaren; en rural_urban, locatie. We voegen een interactie toe tussen vote2016 en age in dit voorbeeld.\n#Model schatten en resultaten opslaan\nrighttrack_int &lt;- glm(right_track ~ vote2016 * age + rural_urban, \n                      family = \"binomial\", data = anes)\n#Overzicht resultaten\nsummary(righttrack_int)\n\n\nCall:\nglm(formula = right_track ~ vote2016 * age + rural_urban, family = \"binomial\", \n    data = anes)\n\nCoefficients:\n                        Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -2.952141   0.344679  -8.565  &lt; 2e-16 ***\nvote2016Trump Vote      2.820292   0.373350   7.554 4.22e-14 ***\nage                    -0.009465   0.006296  -1.503   0.1328    \nrural_urbanRural        0.208129   0.111289   1.870   0.0615 .  \nrural_urbanSmall Town   0.110962   0.101173   1.097   0.2727    \nrural_urbanCity         0.160473   0.110704   1.450   0.1472    \nvote2016Trump Vote:age  0.012914   0.006823   1.893   0.0584 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5929.4  on 5132  degrees of freedom\nResidual deviance: 4033.5  on 5126  degrees of freedom\n  (3147 observations deleted due to missingness)\nAIC: 4047.5\n\nNumber of Fisher Scoring iterations: 6\n::: callout-warning #### Interpretatie\nWanneer we een interactie testen, vragen we ons eigenlijk af of het effect van een bepaalde predictor (X) op de afhankelijke variable (Y) anders is wanneer een tweede predictor (Z) andere waarden aanneemt.\nDe coëfficiënt van de interactie vertelt ons of dit het geval is. In het lineaire “biden_int” model, bijvoorbeeld, vinden we dat de coëfficiënt statistisch significant is: de relatie tussen partij-identificatie en hoe een respondent Biden evalueert, hangt af van de opinie van de respondent over de richting dat het land uitgaat.2 De interactievariabele in het logistische “righttrack_int” model is echter niet statistisch significant (we gebruiken hier een standaard 95% betrouwbaarheidsniveau). Dit betekent dat bijvoorbeeld de relatie tussen leeftijd en opinie over het land hetzelfde is ongeacht of respondenten in 2016 op Clinton of Trump hebben gestemd.\nOm interactietermen beter te begrijpen, kunnen we R gebruiken om:",
    "crumbs": [
      "Interacties in Lineaire en Logistische Regressiemodellen",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Interacties in het Regressiemodel</span>"
    ]
  },
  {
    "objectID": "interaction_01.html#een-interactie-in-het-regressiemodel",
    "href": "interaction_01.html#een-interactie-in-het-regressiemodel",
    "title": "15  Interacties in het Regressiemodel",
    "section": "",
    "text": "pid: ‘partisan identity’ of partij-identificatie, een continue variabele die loopt van 1 ‘Overtuigd Democraat’ tot 7 ‘Overtuigd Republikein’;\nright_track: een binaire, factor variabele waarbij ‘0’ betekent dat een respondent vindt dat het de verkeerde richting uitgaat met het land en ‘1’ dat het de goede richting uitgaat met het land;\nrural_urban: een categorische variabele die aangeeft in welk soort locatie een respondent woont, met ‘suburb’ als referentiecategorie.\n\n\n\n\n\n\n\n\n\n\n\nOutput uitleg\n\n\n\nDe structuur van de output is dezelfde als bij lineaire regressiemodellen zonder interactie, behalve dat een nieuwe term werd toegevoegd: pid:right_trackRight Direction.\nWanneer we 2 predictoren verbinden met het ‘*’ teken, voegt R de beide variabelen toe en daarnaast ook de interactieterm, oftewel de vermenigvuldiging van de variabelen. De naam die we terugvinden voor de interactieterm voegt de 2 predictoren samen met een dubbelpunt (pid:right_trackRight Direction).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHet marginale effect van 1 onafhankelijke variabele (X) op Y te berekenen bij verschillende waarden van de andere onafhankelijke (Z) (Hoofdstuk 16).\nDe voorspelde waarden voor Y te berekenen voor verschillende combinaties van waarden van de 2 onafhankelijke variabelen (Hoofdstuk 17).",
    "crumbs": [
      "Interacties in Lineaire en Logistische Regressiemodellen",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Interacties in het Regressiemodel</span>"
    ]
  },
  {
    "objectID": "interaction_01.html#sec-interaction-term-in-a-regression-table",
    "href": "interaction_01.html#sec-interaction-term-in-a-regression-table",
    "title": "15  Interacties in het Regressiemodel",
    "section": "15.2 Regressietabellen",
    "text": "15.2 Regressietabellen\nIn de volgende 2 hoofdstukken gaan we dieper in op hoe je interactie-effecten best kan begrijpen en communiceren met plot. Hier lichten we kort toe hoe ze te presenteren in regressietabellen. We maken hiervoor weer gebruik van de modelsummary() functie uit het modelsummary package. De basisprincipes zijn dezelfde als degene die we bespraken in eerdere hoofdstukken (lineaire regressietabellen: Paragraaf 8.5; logistische regressietabellen: Paragraaf 14.2).\nWe zullen de resultaten van het model zonder en het model met interactie naast elkaar presenteren. Zo ziet de lezer onmiddellijk het verschil tussen beide modellen.\n\n# Lijst van modellen\n1interaction_lm_models &lt;- list(\n  biden_model, biden_int\n)\n\n#Tabel maken\nmodelsummary(interaction_lm_models, \n2             stars = T,\n3             coef_rename = c(\n               \"(Intercept)\" = \"Constante\", \n               \"pid\" = \"Partij-Identificatie (PID)\", \n               \"right_trackRight Direction\" = \"Land gaat in de goede richting\", \n               \"rural_urbanCity\" = \"Stad (Ref. Stedelijke buitenwijk)\",\n               \"rural_urbanRural\" = \"Landelijk gebied (Ref. Stedelijke buitenwijk)\",\n               \"rural_urbanSmall Town\" = \"Kleine stad (Ref. Stedelijke buitenwijk)\", \n               \"pid:right_trackRight Direction\" = \"PID x Juiste Richting\"), \n4             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"),\n5             title = \"Evaluatie van kandidaat Biden\",\n6             notes = \"OLS coëfficiënten met standaardfouten tussen haakjes\")\n\n\n1\n\nLijst van modellen om te gebruiken in de tabel\n\n2\n\nToevoegen van stersymbolen voor statistische significantie\n\n3\n\nDuidelijke namen geven aan variabelen coef_rename()\n\n4\n\nModel fit statistieken selecteren gof_map()\n\n5\n\nInformatieve titel met title =\n\n6\n\nDuidelijke notitie over wat we precies weergeven in de tabel notes =\n\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        Evaluatie van kandidaat Biden\n              \n                 \n                (1)\n                (2)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nOLS coëfficiënten met standaardfouten tussen haakjes\n        \n                \n                  Constante\n                  93.917***\n                  95.659***\n                \n                \n                  \n                  (0.654)\n                  (0.673)\n                \n                \n                  Partij-Identificatie (PID)\n                  -10.261***\n                  -10.824***\n                \n                \n                  \n                  (0.136)\n                  (0.147)\n                \n                \n                  Land gaat in de goede richting\n                  -12.815***\n                  -33.188***\n                \n                \n                  \n                  (0.699)\n                  (2.160)\n                \n                \n                  Landelijk gebied (Ref. Stedelijke buitenwijk)\n                  -4.167***\n                  -4.084***\n                \n                \n                  \n                  (0.822)\n                  (0.816)\n                \n                \n                  Kleine stad (Ref. Stedelijke buitenwijk)\n                  -2.985***\n                  -2.808***\n                \n                \n                  \n                  (0.701)\n                  (0.697)\n                \n                \n                  Stad (Ref. Stedelijke buitenwijk)\n                  -0.308\n                  -0.320\n                \n                \n                  \n                  (0.671)\n                  (0.667)\n                \n                \n                  PID x Juiste Richting\n                  \n                  3.714***\n                \n                \n                  \n                  \n                  (0.373)\n                \n                \n                  Num.Obs.\n                  7147\n                  7147\n                \n                \n                  R2\n                  0.602\n                  0.607\n                \n                \n                  R2 Adj.\n                  0.602\n                  0.607\n                \n        \n      \n    \n\n\n\nWat we hier nog zouden willen veranderen is de interactieterm dichter bij de hoofdvariabelen van de interactie zetten in plaats van standaard onderaan de tabel. Dit kunnen we door i.p.v. coef_rename gebruik te maken van coef_map. Zo kunnen we ook de volgorde van de variabelen bepalen.\n\nmodelsummary(interaction_lm_models, \n             stars = T, \n1             coef_map = c(\n              \"(Intercept)\" = \"Constante\", \n               \"pid\" = \"Partij-Identificatie (PID)\", \n               \"right_trackRight Direction\" = \"Land gaat in de goede richting\", \n2               \"pid:right_trackRight Direction\" = \"PID x Juiste Richting\",\n               \"rural_urbanCity\" = \"Stad (Ref. Stedelijke buitenwijk)\",\n               \"rural_urbanRural\" = \"Landelijk gebied (Ref. Stedelijke buitenwijk)\",\n               \"rural_urbanSmall Town\" = \"Kleine stad (Ref. Stedelijke buitenwijk)\"),\n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"), \n             title = \"Evaluatie van kandidaat Biden\", # \n             notes = \"OLS coëfficiënten met standaardfouten tussen haakjes\") \n\n\n1\n\nVerander coef_rename naar coef_map\n\n2\n\nInteractieterm dichter bij hoofdvariabelen.\n\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        Evaluatie van kandidaat Biden\n              \n                 \n                (1)\n                (2)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nOLS coëfficiënten met standaardfouten tussen haakjes\n        \n                \n                  Constante\n                  93.917***\n                  95.659***\n                \n                \n                  \n                  (0.654)\n                  (0.673)\n                \n                \n                  Partij-Identificatie (PID)\n                  -10.261***\n                  -10.824***\n                \n                \n                  \n                  (0.136)\n                  (0.147)\n                \n                \n                  Land gaat in de goede richting\n                  -12.815***\n                  -33.188***\n                \n                \n                  \n                  (0.699)\n                  (2.160)\n                \n                \n                  PID x Juiste Richting\n                  \n                  3.714***\n                \n                \n                  \n                  \n                  (0.373)\n                \n                \n                  Stad (Ref. Stedelijke buitenwijk)\n                  -0.308\n                  -0.320\n                \n                \n                  \n                  (0.671)\n                  (0.667)\n                \n                \n                  Landelijk gebied (Ref. Stedelijke buitenwijk)\n                  -4.167***\n                  -4.084***\n                \n                \n                  \n                  (0.822)\n                  (0.816)\n                \n                \n                  Kleine stad (Ref. Stedelijke buitenwijk)\n                  -2.985***\n                  -2.808***\n                \n                \n                  \n                  (0.701)\n                  (0.697)\n                \n                \n                  Num.Obs.\n                  7147\n                  7147\n                \n                \n                  R2\n                  0.602\n                  0.607\n                \n                \n                  R2 Adj.\n                  0.602\n                  0.607\n                \n        \n      \n    \n\n\n\nMet deze syntax zetten we de interactieterm net onder de twee variabelen waaruit de interactie bestaat (pid en right_track).\n\n\n\n\n\n\nWaarschuwing!\n\n\n\ncoef_map is handig maar is gevoelig aan het juist typen van de variabelenamen. Waar coef_rename bij een typfout gewoon de oude naam geeft, doet coef_map de variabele in z’n geheel verdwijnen. Laten we bij wijze van voorbeeld 2 typfouten maken. We schrijven “right_trackRight direction” i.p.v. “right_trackRight Direction” en “rural_urbancity” i.p.v. “rural_urbanCity”:\n\nmodelsummary(interaction_lm_models, \n             stars = T, \n             coef_map = c(\n              \"(Intercept)\" = \"Constante\", \n               \"pid\" = \"Partij-Identificatie (PID)\", \n1               \"right_trackRight direction\" = \"Land gaat in de goede richting\",\n               \"pid:right_trackRight Direction\" = \"PID x Juiste Richting\",  \n2               \"rural_urbancity\" = \"Stad (Ref. Stedelijke buitenwijk)\",\n               \"rural_urbanRural\" = \"Landelijk gebied (Ref. Stedelijke buitenwijk)\",\n               \"rural_urbanSmall Town\" = \"Kleine stad (Ref. Stedelijke buitenwijk)\"), \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"), \n             title = \"Evaluatie van kandidaat Biden\", # \n             notes = \"OLS coëfficiënten met standaardfouten tussen haakjes\")  \n\n\n1\n\nDirection naar direction\n\n2\n\nCity naar city\n\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        Evaluatie van kandidaat Biden\n              \n                 \n                (1)\n                (2)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nOLS coëfficiënten met standaardfouten tussen haakjes\n        \n                \n                  Constante\n                  93.917***\n                  95.659***\n                \n                \n                  \n                  (0.654)\n                  (0.673)\n                \n                \n                  Partij-Identificatie (PID)\n                  -10.261***\n                  -10.824***\n                \n                \n                  \n                  (0.136)\n                  (0.147)\n                \n                \n                  PID x Juiste Richting\n                  \n                  3.714***\n                \n                \n                  \n                  \n                  (0.373)\n                \n                \n                  Landelijk gebied (Ref. Stedelijke buitenwijk)\n                  -4.167***\n                  -4.084***\n                \n                \n                  \n                  (0.822)\n                  (0.816)\n                \n                \n                  Kleine stad (Ref. Stedelijke buitenwijk)\n                  -2.985***\n                  -2.808***\n                \n                \n                  \n                  (0.701)\n                  (0.697)\n                \n                \n                  Num.Obs.\n                  7147\n                  7147\n                \n                \n                  R2\n                  0.602\n                  0.607\n                \n                \n                  R2 Adj.\n                  0.602\n                  0.607\n                \n        \n      \n    \n\n\n\nDe coëfficiënten voor deze variabelen zijn nu verdwenen uit de tabel. Je krijgt geen waarschuwing dus moet je extra opletten. Meer info over coef_map vind je op de modelsummary website.",
    "crumbs": [
      "Interacties in Lineaire en Logistische Regressiemodellen",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Interacties in het Regressiemodel</span>"
    ]
  },
  {
    "objectID": "interaction_01.html#footnotes",
    "href": "interaction_01.html#footnotes",
    "title": "15  Interacties in het Regressiemodel",
    "section": "",
    "text": "De dataset bevat ook een variabele voor hoe respondenten Donald Trump evalueren (also has a measure of evaluations of Donald Trump (the variable named (trump). Mensen die vinden dat het land de slechte richting op gaat zijn negatiever voor Trump dan mensen die vinden dat het land de goede richting uitgaat.↩︎\nInteracties zijn symmetrisch, dus we kunnen ook stellen dat het effect van ‘right_track’ op Biden score verschilt naarmate respondenten een andere patij-identificatie hebben. Welke variabele als hoofdvariabele (X) en welke als moderator (Z) wordt beschouwd is aan de onderzoeker.↩︎",
    "crumbs": [
      "Interacties in Lineaire en Logistische Regressiemodellen",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Interacties in het Regressiemodel</span>"
    ]
  },
  {
    "objectID": "interaction_02.html",
    "href": "interaction_02.html",
    "title": "16  Marginale Effecten in Interactiemodellen",
    "section": "",
    "text": "16.1 Binaire X Continue Interactie",
    "crumbs": [
      "Interacties in Lineaire en Logistische Regressiemodellen",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Marginale Effecten in Interactiemodellen</span>"
    ]
  },
  {
    "objectID": "interaction_02.html#binaire-x-continue-interactie",
    "href": "interaction_02.html#binaire-x-continue-interactie",
    "title": "16  Marginale Effecten in Interactiemodellen",
    "section": "",
    "text": "16.1.1 Berekening en interpretatie\nWe bekijken eerst hoe we de marginale effecten berekenen voor een interactie tussen een binaire en continue variabele. Dit was het geval voor ons ‘biden_int’ model waarin een interactie werd toegevoegd tussen partij-identificatie (pid, loopt van 1 ‘Overtuigd Democraat’ tot 7 ‘Overtuigd Republikein’) en right_track (waarbij ‘0’ betekent dat een respondent vindt dat het de verkeerde richting uitgaat met het land en ‘1’ dat het de goede richting uitgaat met het land).\nHier gebruiken we de slopes() functie om het effect van pid op Biden scores te berekenen voor elke waarde van right_track. Wanneer de moderator (Z) een factor variabele is, zoals hier het geval is, gebruiken we de volgende code:\n\nslopes(biden_int, \n       variables = \"pid\", \n       by = \"right_track\")\n\n\n     right_track Estimate Std. Error     z Pr(&gt;|z|)     S  2.5 % 97.5 %\n Wrong Track       -10.82      0.147 -73.7   &lt;0.001   Inf -11.11 -10.54\n Right Direction    -7.11      0.344 -20.7   &lt;0.001 312.7  -7.78  -6.44\n\nTerm: pid\nType:  response \nComparison: dY/dX\n\n\n\nslopes(biden_int,\n\nWe passen de functie slopes toe op het model tussen haakjes.\n\nvariables = \"pid\"\n\nWe duiden hier de onafhankelijke variabele aan waarvoor we de verschillende marginale effecten willen berekenen. Voor eigen toepassingen voeg je hier je eigen continue variabele toe.\n\nby = \"right_track\"\n\nHier wordt de moderator variabele aangeduid. De code kan enkel gebruikt worden als de moderator een factor is.\n\n\nDe helling van de regressielijn voor pid als right_track = ‘Right Direction’” is -7.11. De helling van pid wanneer right_track = ‘Wrong Track’ is -10.82. Het effect van partij-identificatie op de score voor Biden is sterker (negatiever) als respondenten vinden dat het de verkeerde richting uitgaat met het land. Dit effect is ook statistisch significant (p &lt; 0.001). Dit zien we aan de p-waarde voor de interactie-term (zie onder). We kunnen de nulhypothese verwerpen dat het effect van pid niet verschilt naargelang right_track andere waarden aanneemt.\nJe ziet ook dat het effect van pid als right_track = ‘Wrong Track’ gelijk is aan de coëfficiënt van pid in het model (dit effect geldt als moderator 0 is). Het verschil tussen de 2 marginale effecten is gelijk aan de waarde van de interactiecoëfficiënt.\n\n#resultaten om coëfficiënten en significantie te tonen\ntidy(biden_int) |&gt; select(term, estimate, p.value)\n\n# A tibble: 7 × 3\n  term                           estimate  p.value\n  &lt;chr&gt;                             &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                      95.7   0       \n2 pid                             -10.8   0       \n3 right_trackRight Direction      -33.2   1.93e-52\n4 rural_urbanRural                 -4.08  5.79e- 7\n5 rural_urbanSmall Town            -2.81  5.60e- 5\n6 rural_urbanCity                  -0.320 6.31e- 1\n7 pid:right_trackRight Direction    3.71  3.20e-23\n\n#Marginaal effect (Right Direction) - Marginaal effect (Wrong Track) = coëfficiënt van de interactieterm\n-7.11 - (-10.82)\n\n[1] 3.71\n\n\nWe kunnen ook onderzoeken hoe het effect van de factor variabele right_track op de afhankelijke variabele anders is voor verschillende waarden van partij-identificatie. We kiezen er hier voor de effecten te berekenen voor elke waarde van pid gezien er maar 7 waarden zijn.\n\nslopes(biden_int, \n       variables = \"right_track\", \n       newdata = datagrid(pid = c(1,2,3,4,5,6,7)))\n\n\n pid Estimate Std. Error      z Pr(&gt;|z|)     S  2.5 % 97.5 %\n   1   -29.47      1.811 -16.28   &lt;0.001 195.4 -33.02 -25.92\n   2   -25.76      1.473 -17.48   &lt;0.001 224.9 -28.65 -22.87\n   3   -22.05      1.158 -19.04   &lt;0.001 266.0 -24.32 -19.78\n   4   -18.33      0.888 -20.64   &lt;0.001 311.9 -20.07 -16.59\n   5   -14.62      0.718 -20.37   &lt;0.001 303.9 -16.02 -13.21\n   6   -10.90      0.721 -15.13   &lt;0.001 169.4 -12.31  -9.49\n   7    -7.19      0.895  -8.03   &lt;0.001  49.9  -8.94  -5.43\n\nTerm: right_track\nType:  response \nComparison: Right Direction - Wrong Track\n\n\n\nnewdata = datagrid(pid = c(1,2,3,4,5,6,7)))\n\nWe geven hier de waarden op van de moderator waarvoor marginale effecten van de andere predictor berekend moeten worden. De waarden dien je te veranderen voor eigen toepassingen. We gebruiken “newdata = datagrid()” omdat pid hier als continue variabele wordt gebruikt.\n\n\nDe output hierboven toont dat het effect van right_ direction'_trackongeveer -29.47 punten is voor overtuigde Democraten (pid=1), -25.76 punten voor minder overtuigde Democraten (pid = 2), en -7.19 punten voor overtuigde Republikeinen (pid=7). Het effect van de right_track variabele daalt met 3.71 eenheden telkens als pidmet 1 eenheid stijgt: dit is de waarde van de interactiecoëfficiënt.\n\n##resultaten om coëfficiënten en significantie te tonen\ntidy(biden_int) |&gt; select(term, estimate, p.value)\n\n# A tibble: 7 × 3\n  term                           estimate  p.value\n  &lt;chr&gt;                             &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                      95.7   0       \n2 pid                             -10.8   0       \n3 right_trackRight Direction      -33.2   1.93e-52\n4 rural_urbanRural                 -4.08  5.79e- 7\n5 rural_urbanSmall Town            -2.81  5.60e- 5\n6 rural_urbanCity                  -0.320 6.31e- 1\n7 pid:right_trackRight Direction    3.71  3.20e-23\n\n#Marginaal effect (PID = 2) - Marginaal effect (PID = 1) = coëfficiënt van de interactieterm\n-25.76 - (-29.47)\n\n[1] 3.71\n\n#Marginaal effect (PID = 7) - Marginaal effect (PID = 6) = coëfficiënt van de interactieterm\n-7.19 - (-10.90)\n\n[1] 3.71\n\n\nDe statistisch significante interactieterm leidt ertoe dat we de nulhypothese verwerpen dat het effect van right_track gelijk blijft als pid verandert.\n\n\n16.1.2 Plotten\nMarginale effecten worden vaak gevisualiseerd in een grafiek. De y-as in deze grafieken is het geschatte marginale effect van X op Y en de x-as is de waarde die de moderator aanneemt. We bekijken eerst het voorbeeld waarbij de factor variabele de moderator is. De ggplot code hebben we gebruikt in eerdere weken. Belangrijk: we gebruiken geom_pointrange wanneer de moderator een factor is (hier: right_track).\n\n1slopes(biden_int,\n       variables = \"pid\",  \n       by = \"right_track\") |&gt; \n  ggplot(aes(x = right_track, y = estimate)) + \n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) + \n  labs(title = \"Marginaal effect van partij-identificatie op Biden score\", \n       y = \"Effect van partij-identificatie (pid)\", \n       x = \"Land gaat goede of verkeerde richting uit?\")  + \n  geom_text(aes(label = round(estimate, 2)), hjust = -0.2) +\n   geom_hline(yintercept = 0, linetype = 'dashed', color = 'red') +\n  scale_x_discrete(labels = c(\"Wrong Track\" = \"Verkeerde richting\", \"Right Direction\" = \"Goede richting\"))\n\n\n1\n\nIn dit voorbeeld nemen we de output van slopes() onmiddellijk op met ggplot() via de pipe operator. We zouden ook de resultaten van slopes() in een data object kunnen opslaan en die resultaten gebruiken voor een nieuwe ggplot() functie.\n\n\n\n\n\n\n\n\n\n\n\nEn hier is het voorbeeld waarbij de continue variabele de moderator is. We gebruiken nu geom_line() in combinatie met geom_ribbon:\n\n#Effect van right_track bij verschillende waarden pid\nslopes(biden_int, \n       variables = \"right_track\", \n       newdata = datagrid(pid = c(1,2,3,4,5,6,7))) |&gt; \n  ggplot(aes(x=pid, y=estimate)) + \n  geom_line() + \n  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = 0.2) + \n  labs(title = \"Marginaal effect van perceptie over de richting van het land\" ,\n       y = \"Verkeerde richting (0) - Goede richting (1)\", \n       x = \"Partij-identificatie (hogere waarden: meer Republikeins)\") + \n  geom_hline(yintercept = 0, linetype = 'dashed', color = 'red') + \n1  scale_x_continuous(breaks=c(1,2,3,4,5,6,7))\n\n\n1\n\nZonder deze regel zou ggplot() enkel ticks tonen bij 2, 4, and 6. Dit is vaak voldoende maar hier is het handig het volledige bereik van de continue variabele te kunnen plotten (1 tot 7).",
    "crumbs": [
      "Interacties in Lineaire en Logistische Regressiemodellen",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Marginale Effecten in Interactiemodellen</span>"
    ]
  },
  {
    "objectID": "interaction_02.html#continue-x-continue-interactie",
    "href": "interaction_02.html#continue-x-continue-interactie",
    "title": "16  Marginale Effecten in Interactiemodellen",
    "section": "16.2 Continue X Continue Interactie",
    "text": "16.2 Continue X Continue Interactie\nDe code voor de berekening van marginale effecten bij een interactie tussen 2 continue variabelen volgt dezelfde principes. In het voorbeeld hier voorspellen we de score voor Biden op basis van de volgende onafhankelijke variabelen: age (leeftijd), socialists (evaluatie van socialisten op een schaal van 0 (‘heel koud of ongunstig’) tot 100 (‘heel warm of gunstig’), en rural_urban als controlevariabele.\n\n#Model schatten en resultaten opslaan in object\nbiden_int2 &lt;- lm(biden ~ socialists * age + rural_urban, data = anes)\n\n#Resultaten printen\ntidy(biden_int2)\n\n# A tibble: 7 × 5\n  term                   estimate std.error statistic  p.value\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)            30.0      2.00        15.0   4.68e-50\n2 socialists              0.197    0.0381       5.17  2.46e- 7\n3 age                    -0.0752   0.0345      -2.18  2.95e- 2\n4 rural_urbanRural      -10.9      1.08       -10.1   9.02e-24\n5 rural_urbanSmall Town  -7.04     0.924       -7.62  3.00e-14\n6 rural_urbanCity         0.455    0.883        0.516 6.06e- 1\n7 socialists:age          0.00980  0.000699    14.0   6.21e-44\n\n\nHet interactie-effect is statistisch significant. We kunnen dit effect op twee manieren onderzoeken. We kunnen de marginale effecten berekenen van leeftijd op Biden score bij verschillende waarden voor socialisten. Of we berekenen de marginale effecten van socialisten op Biden score bij verschillende leeftijden. In beide gevallen moeten we waarden voor de continue moderator aanduiden in de syntax. We kiezen hier logische waarden in lijn met de schaal van de variabelen.\n\n#Marginaal effect van leeftijd bij socialists = 0, 10, 20...100\nslopes(biden_int2, \n       variables = \"age\", \n       newdata = datagrid(socialists = seq(from = 0, to = 100, by = 10))) \n\n#Marginaal effect van socialists bij leeftijd = 20,30,40...80\nslopes(biden_int2, \n       variables = \"socialists\", \n1       newdata = datagrid(age = seq(from = 20, to = 80, by = 10)))\n\n\n1\n\nLeeftijd reikt van 18 tot 80 in de dataset (respondenten ouder dan 80 krijgen gewoon de score 80).\n\n\n\n\n\n socialists Estimate Std. Error      z Pr(&gt;|z|)     S   2.5 %   97.5 %\n          0  -0.0752     0.0345 -2.177   0.0295   5.1 -0.1429 -0.00751\n         10   0.0228     0.0292  0.781   0.4350   1.2 -0.0344  0.07990\n         20   0.1207     0.0247  4.895   &lt;0.001  20.0  0.0724  0.16907\n         30   0.2187     0.0215 10.156   &lt;0.001  78.1  0.1765  0.26090\n         40   0.3167     0.0204 15.528   &lt;0.001 178.2  0.2767  0.35664\n         50   0.4146     0.0216 19.239   &lt;0.001 271.6  0.3724  0.45688\n         60   0.5126     0.0247 20.724   &lt;0.001 314.5  0.4641  0.56108\n         70   0.6106     0.0293 20.841   &lt;0.001 318.0  0.5532  0.66799\n         80   0.7085     0.0346 20.457   &lt;0.001 306.6  0.6407  0.77643\n         90   0.8065     0.0405 19.919   &lt;0.001 290.9  0.7272  0.88587\n        100   0.9045     0.0467 19.373   &lt;0.001 275.3  0.8130  0.99599\n\nTerm: age\nType:  response \nComparison: dY/dX\n\n\n age Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n  20    0.393     0.0253 15.6   &lt;0.001 178.7 0.343  0.442\n  30    0.491     0.0195 25.2   &lt;0.001 463.6 0.453  0.529\n  40    0.589     0.0147 40.1   &lt;0.001   Inf 0.560  0.618\n  50    0.687     0.0123 55.9   &lt;0.001   Inf 0.663  0.711\n  60    0.785     0.0136 57.8   &lt;0.001   Inf 0.758  0.811\n  70    0.883     0.0178 49.7   &lt;0.001   Inf 0.848  0.917\n  80    0.981     0.0233 42.0   &lt;0.001   Inf 0.935  1.026\n\nTerm: socialists\nType:  response \nComparison: dY/dX\n\n\nWe kunnen in de output zien dat het effect van leeftijd negatief en statistisch signficant is als de socialists variabele de waarde 0 aanneemt (-0.0752 [95% CI: -0.143, -0.008]). Dit is gelijk aan de coëfficiënt voor age. Het effect van leeftijd wordt steeds positiever als socialists hogere waarden aanneemt. We zien ook dat het effect van socialists positief is voor jonge mensen (bv., het effect voor respondenten van 20 jaar is 0.39 [0.34, 0.44]). Dit effect wordt positiever naarmate mensen ouder zijn.3\nOm te plotten gebruiken we de code voor wanneer de moderator een continue variabele is (zie boven, Paragraaf 16.1.2).",
    "crumbs": [
      "Interacties in Lineaire en Logistische Regressiemodellen",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Marginale Effecten in Interactiemodellen</span>"
    ]
  },
  {
    "objectID": "interaction_02.html#binaire-x-binaire-interactie",
    "href": "interaction_02.html#binaire-x-binaire-interactie",
    "title": "16  Marginale Effecten in Interactiemodellen",
    "section": "16.3 Binaire x Binaire Interactie",
    "text": "16.3 Binaire x Binaire Interactie\nWanneer de interactievariabele een vermenigvuldiging is van 2 binaire factor variabelen zijn wederom dezelfde principes van toepassing. Hier voorspellen we de score voor Biden met een interactie tussen right_track en vote2016 (met rural_urban als controlevariabele).\n\n#Model schatten en resultaten opslaan\nbiden_int3 &lt;- lm(biden ~ right_track * vote2016 + rural_urban, data = anes)\n\n#Overzicht resultaten\nsummary(biden_int3)\n\n\nCall:\nlm(formula = biden ~ right_track * vote2016 + rural_urban, data = anes)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-78.83 -13.61  -0.28  14.27  84.72 \n\nCoefficients:\n                                              Estimate Std. Error t value\n(Intercept)                                    78.3730     0.5811 134.877\nright_trackRight Direction                    -25.2460     2.1072 -11.981\nvote2016Trump Vote                            -51.6157     0.7699 -67.039\nrural_urbanRural                               -2.7666     0.9071  -3.050\nrural_urbanSmall Town                          -1.6706     0.7850  -2.128\nrural_urbanCity                                 0.4524     0.7534   0.601\nright_trackRight Direction:vote2016Trump Vote  13.7690     2.2780   6.044\n                                              Pr(&gt;|t|)    \n(Intercept)                                    &lt; 2e-16 ***\nright_trackRight Direction                     &lt; 2e-16 ***\nvote2016Trump Vote                             &lt; 2e-16 ***\nrural_urbanRural                                0.0023 ** \nrural_urbanSmall Town                           0.0334 *  \nrural_urbanCity                                 0.5482    \nright_trackRight Direction:vote2016Trump Vote 1.61e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 20.89 on 5195 degrees of freedom\n  (3078 observations deleted due to missingness)\nMultiple R-squared:  0.6608,    Adjusted R-squared:  0.6604 \nF-statistic:  1687 on 6 and 5195 DF,  p-value: &lt; 2.2e-16\n\n\nDe marginale effecten worden als volgt berekend:\n\n#right_track als moderator\nslopes(biden_int3, \n       variables = \"vote2016\", \n       by = \"right_track\")\n\n\n     right_track Estimate Std. Error     z Pr(&gt;|z|)     S 2.5 % 97.5 %\n Wrong Track        -51.6       0.77 -67.0   &lt;0.001   Inf -53.1  -50.1\n Right Direction    -37.8       2.15 -17.6   &lt;0.001 227.0 -42.1  -33.6\n\nTerm: vote2016\nType:  response \nComparison: Trump Vote - Clinton Vote\n\n#vote2016 als moderator\nslopes(biden_int3, \n       variables = \"right_track\", \n       by = \"vote2016\")\n\n\n     vote2016 Estimate Std. Error     z Pr(&gt;|z|)     S 2.5 % 97.5 %\n Clinton Vote    -25.2      2.107 -12.0   &lt;0.001 107.5 -29.4 -21.12\n Trump Vote      -11.5      0.866 -13.2   &lt;0.001 130.7 -13.2  -9.78\n\nTerm: right_track\nType:  response \nComparison: Right Direction - Wrong Track\n\n\nDe eerste resultaten tonen dat 2016 Trump kiezers een slechtere indruk van Biden hebben dan 2016 Clinton kiezers, ongeacht wat ze vinden van het land. Maar het verschil is groter voor respondenten die vinden dat het land de verkeerde richting opgaat (verschil = -51.6) dan zij die vinden dat het de goede kant uitgaat (-37.80). Dit verschil is gelijk aan de interactiecoëfficiënt. Deze coëfficiënt was ook statistisch significant.\nOm dit te plotten gebruiken we de code voor wanneer de moderator een factor variabele is (zie boven Paragraaf 16.1.2).",
    "crumbs": [
      "Interacties in Lineaire en Logistische Regressiemodellen",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Marginale Effecten in Interactiemodellen</span>"
    ]
  },
  {
    "objectID": "interaction_02.html#logistische-regressie-voorbeeld",
    "href": "interaction_02.html#logistische-regressie-voorbeeld",
    "title": "16  Marginale Effecten in Interactiemodellen",
    "section": "16.4 Logistische regressie: voorbeeld",
    "text": "16.4 Logistische regressie: voorbeeld\nBij logistische regressie worden de marginale effecten met dezelfde code berekend. Hier geven deze effecten de gemiddelde verandering in voorspelde kans weer in percentpunten (zie Hoofdstuk 10).\nWe hebben reeds een righttrack_int model berekend, waarin we een interactie tussen age en vote2016 hebben toegevoegd. We bekijken de resultaten nogmaals:\n\n#Het model\ntidy(righttrack_int)\n\n# A tibble: 7 × 5\n  term                   estimate std.error statistic  p.value\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)            -2.95      0.345       -8.56 1.08e-17\n2 vote2016Trump Vote      2.82      0.373        7.55 4.22e-14\n3 age                    -0.00946   0.00630     -1.50 1.33e- 1\n4 rural_urbanRural        0.208     0.111        1.87 6.15e- 2\n5 rural_urbanSmall Town   0.111     0.101        1.10 2.73e- 1\n6 rural_urbanCity         0.160     0.111        1.45 1.47e- 1\n7 vote2016Trump Vote:age  0.0129    0.00682      1.89 5.84e- 2\n\n\nDe interactie is tussen age (continue variabele) en vote2016 (binaire factor variabelen). We berekenen de marginale effecten als volgt:\n\n# age als moderator op = 20, 30...80\nslopes(righttrack_int, \n       variables = \"vote2016\", \n       newdata = datagrid(age = seq(from = 20, to = 80, by = 10))) \n\n\n age Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n  20    0.443     0.0300 14.8   &lt;0.001 161.9 0.384  0.502\n  30    0.455     0.0244 18.7   &lt;0.001 255.6 0.407  0.503\n  40    0.467     0.0199 23.4   &lt;0.001 400.7 0.428  0.506\n  50    0.479     0.0173 27.7   &lt;0.001 558.2 0.445  0.513\n  60    0.490     0.0172 28.6   &lt;0.001 593.7 0.456  0.524\n  70    0.501     0.0195 25.7   &lt;0.001 481.7 0.463  0.539\n  80    0.512     0.0235 21.8   &lt;0.001 347.1 0.466  0.558\n\nTerm: vote2016\nType:  response \nComparison: Trump Vote - Clinton Vote\n\n# vote2016 als moderator\nslopes(righttrack_int, \n       variables = \"age\", \n       by = \"vote2016\")\n\n\n     vote2016  Estimate Std. Error     z Pr(&gt;|z|)   S     2.5 %   97.5 %\n Clinton Vote -0.000312   0.000209 -1.49    0.136 2.9 -0.000723 9.84e-05\n Trump Vote    0.000854   0.000650  1.31    0.189 2.4 -0.000421 2.13e-03\n\nTerm: age\nType:  response \nComparison: dY/dX\n\n\nWe verwachten dat mensen die op Trump gestemd hebben in 2016 een grotere kans hebben om te zeggen dat het land de goede richting uitgaat dan mensen die Clinton stemden. Dit effect geldt al voor jonge mensen maar wordt sterker met leeftijd. Voor respondenten die 30 jaar oud zijn is de kans om te zeggen dat het land de goede richting uitgaat 45.5 percentpunten hoger voor Trump kiezers. Voor respondenten van 80 jaar is dit 51.2 percentpunten.4\nZie eerder secties voor instructies over plotten.",
    "crumbs": [
      "Interacties in Lineaire en Logistische Regressiemodellen",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Marginale Effecten in Interactiemodellen</span>"
    ]
  },
  {
    "objectID": "interaction_02.html#footnotes",
    "href": "interaction_02.html#footnotes",
    "title": "16  Marginale Effecten in Interactiemodellen",
    "section": "",
    "text": "Onze pid variabele heeft een bereik van 1 tot 7 en kent dus geen nulwaarde. Het effect wordt geëxtrapoleerd alsof er een nulwaarde zou zijn. Dit vormt niet echt een probleem.↩︎\nWe tonen geen voorbeeld voor een interactie met een categorische variabele met 3 of meer categorieën maar dezelfde principes als binaire variabelen worden gevolgd hiervoor.↩︎\nHier hebben we intervallen van 10 gebruikt voor de moderator (age = 20, 30, 40…). Als we telkens intervallen van 1 eenheid hadden gekozen, dan hadden we gezien dat het verschil in marginale effecten gelijk is aan de interactiecoëfficiënt. Het effect van socialists is 0.393 wanneer age = 20 en 0.403 wanneer age =21. 0.403 - 0.393 = 0.01 is gelijk aan de interactieterm (met afrondingen bij berekening).↩︎\nHier berekenen we effecten voor respondenten die 20 jaar oud zijn. Deze respondenten konden echter nog niet stemmen in 2016. Het effect dat we hier vinden voor deze respondenten is niet betekenisvol. We moeten hiervoor blijven oppassen als we interpretaties maken.↩︎",
    "crumbs": [
      "Interacties in Lineaire en Logistische Regressiemodellen",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Marginale Effecten in Interactiemodellen</span>"
    ]
  },
  {
    "objectID": "interaction_03.html",
    "href": "interaction_03.html",
    "title": "17  Voorspelde Waarden van Interactiemodellen",
    "section": "",
    "text": "17.1 Binaire X Continue Interactie\nWe hebben reeds een model geschat waarbij scores voor kandidaat Biden voorspeld worden met een interactie van partij-identificatie (pid) en perceptie over de richting dat het land uitgaat (right_track).\nOp basis van dit model (biden_int), berekenen we nu met predictions() de voorspelde waarden voor elke combinatie van waarden voor de 2 onafhankelijke variabelen in de interactie (bv. pid = 1 & right_track = “Right Direction”, pid = 1 & right_track = “Wrong Track”, pid = 2 & right_track = “Right Direction”…). Als er te veel waarden zouden zijn om realistisch op deze manier te werk te gaan dan kiezen we voorspellingen op basis van een subset van waarden (bv. minimum, gemiddelde, maximum).\nAndere onafhankelijke variabelen in het model worden op hun gemiddelde (continue variabelen) of modus (factor variabelen) gehouden.\n#Voorspelde waarden berekenen en opslaan in data object\nbiden_int_preds &lt;- predictions(biden_int, \n            newdata = datagrid(pid = c(1,2,3,4,5,6,7), \n                               right_track = c(\"Right Direction\", \"Wrong Track\")))\nDe dataset die we verkrijgen heeft 14 rijen met voorspelde waarden: 7 (waarden voor pid) * 2 (waarden voor right_track).\n# print resultaten\nbiden_int_preds\n\n\n pid     right_track Estimate Std. Error     z Pr(&gt;|z|)      S 2.5 % 97.5 %\n   1 Right Direction     55.4      1.808  30.6   &lt;0.001  681.6  51.8   58.9\n   1 Wrong Track         84.8      0.581 146.0   &lt;0.001    Inf  83.7   86.0\n   2 Right Direction     48.3      1.493  32.3   &lt;0.001  759.2  45.3   51.2\n   2 Wrong Track         74.0      0.515 143.7   &lt;0.001    Inf  73.0   75.0\n   3 Right Direction     41.1      1.193  34.5   &lt;0.001  863.3  38.8   43.5\n   3 Wrong Track         63.2      0.486 130.1   &lt;0.001    Inf  62.2   64.1\n   4 Right Direction     34.0      0.925  36.8   &lt;0.001  982.0  32.2   35.8\n   4 Wrong Track         52.4      0.500 104.8   &lt;0.001    Inf  51.4   53.3\n   5 Right Direction     26.9      0.724  37.2   &lt;0.001 1002.1  25.5   28.3\n   5 Wrong Track         41.5      0.554  75.0   &lt;0.001    Inf  40.5   42.6\n   6 Right Direction     19.8      0.656  30.2   &lt;0.001  662.9  18.5   21.1\n   6 Wrong Track         30.7      0.638  48.2   &lt;0.001    Inf  29.5   32.0\n   7 Right Direction     12.7      0.757  16.8   &lt;0.001  207.4  11.2   14.2\n   7 Wrong Track         19.9      0.741  26.8   &lt;0.001  524.2  18.4   21.3\n\nType:  response\nDe voorspellingen kunnen we visueel presenteren in een plot. Het proces dat we volgen is vrijwel hetzelfde als wat we doen voor een model zonder interactie (zie Paragraaf 8.7). Er is echter een belangrijke toevoeging: het linetype gedeelte van de syntax, dat enkel gebruikt kan worden indien er een factor variabele is.\nVoor we het plot produceren veranderen we de waarden voor right_track naar het Nederlands zodat ze correct worden weergegeven op het plot. Net zoals bij marginale effecten zouden we de code voor predictions (hierboven) ook kunnen combineren met de ggplot code via de pipe operator.\nbiden_int_preds |&gt;\n  mutate(right_track = recode(right_track, \n                       \"Wrong Track\" = \"Verkeerde richting\",\n                       \"Right Direction\" = \"Goede richting\")) |&gt;\nggplot(aes(x=pid, y=estimate, linetype = right_track)) + \n  geom_line() + \n  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = 0.2) + \n  labs(title = \"Voorspelde score voor Biden\", \n       x = \"Partij-identificatie\", \n       y = \"Voorspelde waarden\", \n       linetype = \"Richting land\" ) + \n  scale_x_continuous(breaks=c(1,2,3,4,5,6,7))",
    "crumbs": [
      "Interacties in Lineaire en Logistische Regressiemodellen",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Voorspelde Waarden van Interactiemodellen</span>"
    ]
  },
  {
    "objectID": "interaction_03.html#binaire-x-continue-interactie",
    "href": "interaction_03.html#binaire-x-continue-interactie",
    "title": "17  Voorspelde Waarden van Interactiemodellen",
    "section": "",
    "text": "biden_int_preds &lt;- predictions(biden_int,\n\nWe passen de functie ‘predictions’ toe op het model tussen haakjes en slaan de resultaten op in een data object (“biden_int_preds”) dat we later weer kunnen gebruiken.\n\nnewdata = datagrid(pid = c(1,2,...7), right_track = c(\"Right Direction\", \"Wrong Track\")))\n\nWe duiden de gewenste waarden van de predictoren aan waarvoor voorspellingen berekend zullen worden met de “newdata = datagrid()” optie. We duiden alle waarden voor pid aan (1 tot 7) en de 2 mogelijke waarden voor right_track (Right Direction or Wrong Track).1 In eigen toepassingen wordt dit aangepast volgens de eigen variabelen.\n\n\n\n\n\n\n\n\nggplot(..., linetype = right_track)) + geom_line() + geom_ribbon(...) +\n\nDit gedeelte van de syntax is grotendeels ook al gebruikt in eerdere weken. Een belangrijke toevoeging is linetype = right_track. Zo vragen we ggplot() om de voorspelde waarden voor elke categorie van “right_track” weer te geven als verschillende lijnen. We zouden de voorspellingen ook kunnen onderscheiden op een andere manier, bv. met kleur (color = right_track). De linetype (en color) functies werken enkel met factor variabelen. De variabele right_trackis hier reeds een factor dus we hebben geen verdere data management stappen moeten ondernemen. Zie Paragraaf A.5 voor meer informatie.",
    "crumbs": [
      "Interacties in Lineaire en Logistische Regressiemodellen",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Voorspelde Waarden van Interactiemodellen</span>"
    ]
  },
  {
    "objectID": "interaction_03.html#continue-x-continue-interactie",
    "href": "interaction_03.html#continue-x-continue-interactie",
    "title": "17  Voorspelde Waarden van Interactiemodellen",
    "section": "17.2 Continue X Continue Interactie",
    "text": "17.2 Continue X Continue Interactie\nOm voorspelde waarden voor interacties tussen continue variabelen te berekenen en te plotten, is het proces iets ingewikkelder, omdat er veel mogelijke combinaties van waarden zijn om voorspellingen voor te maken.\nIn het vorige hoofdstuk hebben we het biden_int2 model gebruikt om Biden scores te voorspellen met een interactie tussen age en socialists. We schatten dat model opnieuw hieronder.\n\n#Model schatten en resultaten opslaan\nbiden_int2 &lt;- lm(biden ~ socialists * age + rural_urban, data = anes)\n\n#resultaten bekijekn\ntidy(biden_int2)\n\n# A tibble: 7 × 5\n  term                   estimate std.error statistic  p.value\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)            30.0      2.00        15.0   4.68e-50\n2 socialists              0.197    0.0381       5.17  2.46e- 7\n3 age                    -0.0752   0.0345      -2.18  2.95e- 2\n4 rural_urbanRural      -10.9      1.08       -10.1   9.02e-24\n5 rural_urbanSmall Town  -7.04     0.924       -7.62  3.00e-14\n6 rural_urbanCity         0.455    0.883        0.516 6.06e- 1\n7 socialists:age          0.00980  0.000699    14.0   6.21e-44\n\n\nBeide variabelen kunnen veel mogelijke waarden aannemen. We zouden voorspellingen kunnen maken voor waarden van 0 tot 100 voor socialists met intervallen van 10, en van 20 tot 80 voor agemet intervallen van 10. Dit zou ons echter veel waarden opleveren die we moeilijk zouden kunnen plotten (en begrijpen).\nWat vaak gebeurt in de praktijk is dat we 1 van de 2 predictoren kiezen en voorspellingen maken voor 3 waarden: het gemiddelde, 1 standaarddeviatie (SD) onder het gemiddelde en 1 standaarddeviatie (SD) boven het gemiddelde. De continue variabele zal eigenlijk getransformeerd worden in een factor met 3 waarden. Zo kunnen we een plot maken met 3 lijnen. We transformeren doorgaans de moderator (Z).\nVoor het ‘biden_int2’ model, nemen we nu (bij wijze van voorbeeld) socialists als de moderator. Eerst berekenen we de drie relevante waarden (gemiddelde, 1 SD daaronder, 1 SD daarboven). Deze statistieken moeten we berekenen op basis van de observaties gebruikt in het model. Dit zijn niet altijd het aantal observaties in de dataset door missende waarden op andere variabelen. Als tussenstap gebruiken we hier de predictions() functie van het marginaleffects package gezien deze functie een nieuwe dataset creëert met alle complete observaties. 2\n\npredictions(biden_int2) |&gt;   #nieuw dataobject met complete observaties\n  summarise(\n    mean_below = mean(socialists) - sd(socialists), #1 SD onder gemiddelde\n    mean = mean(socialists),                        #gemiddelde\n    mean_above = mean(socialists) + sd(socialists)) #1 SD boven gemiddelde\n\n  mean_below     mean mean_above\n1   9.716161 38.33639   66.95661\n\n\nNu kunnen we de voorspelde waarden berekenen op basis van de waarden voor socialists die we net berekend hebben. Voor leeftijd vragen we ook geen voorspellingen over de hele schaal, maar voor de leeftijden van 20 tot 80 met tussenstappen van 10 jaar.\n\n#voorspelde waarden\nbiden_int2_preds &lt;- predictions(biden_int2, \n            newdata = datagrid(\n              socialists = c(9.72, 38.34, 66.96), \n              age = c(20,30,40,50,60,70,80))) \n\n#print resultaten\nbiden_int2_preds\n\n\n socialists age Estimate Std. Error     z Pr(&gt;|z|)     S 2.5 % 97.5 %\n       9.72  20     32.3      1.208  26.8   &lt;0.001 522.3  30.0   34.7\n       9.72  30     32.5      0.983  33.1   &lt;0.001 796.8  30.6   34.5\n       9.72  40     32.7      0.802  40.8   &lt;0.001   Inf  31.2   34.3\n       9.72  50     32.9      0.703  46.9   &lt;0.001   Inf  31.6   34.3\n       9.72  60     33.1      0.718  46.1   &lt;0.001   Inf  31.7   34.6\n       9.72  70     33.3      0.843  39.6   &lt;0.001   Inf  31.7   35.0\n       9.72  80     33.5      1.037  32.3   &lt;0.001 759.7  31.5   35.6\n      38.34  20     43.6      0.891  48.9   &lt;0.001   Inf  41.8   45.3\n      38.34  30     46.6      0.755  61.7   &lt;0.001   Inf  45.1   48.1\n      38.34  40     49.6      0.657  75.5   &lt;0.001   Inf  48.3   50.9\n      38.34  50     52.6      0.612  86.0   &lt;0.001   Inf  51.4   53.8\n      38.34  60     55.6      0.633  87.8   &lt;0.001   Inf  54.4   56.8\n      38.34  70     58.6      0.715  82.0   &lt;0.001   Inf  57.2   60.0\n      38.34  80     61.6      0.839  73.5   &lt;0.001   Inf  60.0   63.3\n      66.96  20     54.8      1.083  50.6   &lt;0.001   Inf  52.7   57.0\n      66.96  30     60.6      0.892  68.0   &lt;0.001   Inf  58.9   62.4\n      66.96  40     66.4      0.756  87.9   &lt;0.001   Inf  65.0   67.9\n      66.96  50     72.3      0.709 102.0   &lt;0.001   Inf  70.9   73.6\n      66.96  60     78.1      0.766 101.9   &lt;0.001   Inf  76.6   79.6\n      66.96  70     83.9      0.909  92.2   &lt;0.001   Inf  82.1   85.7\n      66.96  80     89.7      1.105  81.2   &lt;0.001   Inf  87.5   91.8\n\nType:  response \n\n\nDeze dataset heeft 21 observaties: 7 waarden voor age * 3 waarden voor socialists.\nWe plotten de voorspelde waarden zoals hiervoor met het linetype statement. We moeten de socialist variabele in de predictions dataset wel veranderen in een factor om het statement te kunnen gebruiken. We gebruiken hier de ‘factor’ functie gezien de data numeriek is en niet gelabeld (bij labels gebruiken we doorgaans factorize).\n\n#Class variabele\nclass(biden_int2_preds$socialists)\n\n[1] \"numeric\"\n\n#factor maken\nbiden_int2_preds &lt;- biden_int2_preds |&gt; \n  mutate(socialists = factor(socialists, \n                             levels = c(9.72, 38.34, 66.96), \n                             labels = c(\"1SD &lt; Gemiddelde\", \"Gemiddelde\", \"1SD &gt; Gemiddelde\")))\n\nWe kunnen dan de plot maken op een vergelijkbare manier als eerder:\n\nggplot(biden_int2_preds, aes(x=age, y=estimate, linetype=socialists)) + \n  geom_line() + \n  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = .2) + \n  labs(title = \"Voorspelde score voor Biden\", \n       y = \"Voorspelde score\", \n       x = \"Leeftijd\", \n       linetype= \"Voorkeur socialisten (hoger = meer voorkeur)\")",
    "crumbs": [
      "Interacties in Lineaire en Logistische Regressiemodellen",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Voorspelde Waarden van Interactiemodellen</span>"
    ]
  },
  {
    "objectID": "interaction_03.html#binaire-x-binaire-interactie",
    "href": "interaction_03.html#binaire-x-binaire-interactie",
    "title": "17  Voorspelde Waarden van Interactiemodellen",
    "section": "17.3 Binaire x Binaire Interactie",
    "text": "17.3 Binaire x Binaire Interactie\nVoor een interactie met twee binaire variabelen gelden gelijkaardige principes.\nEen dergelijke interactie gebruiken we in het biden_int3-model, namelijk een interactie tussen (right_track) en vote2016 (Clinton kiezer = 0, Trump kiezer = 1). Als controlevariabele voegen we rural_urban toe.\n\n#Model schatten en resultaten oplsaan\nbiden_int3 &lt;- lm(biden ~ right_track * vote2016 + rural_urban, data = anes)\n\n#resultaten printen\ntidy(biden_int3)\n\n# A tibble: 7 × 5\n  term                                     estimate std.error statistic  p.value\n  &lt;chr&gt;                                       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                                78.4       0.581   135.    0       \n2 right_trackRight Direction                -25.2       2.11    -12.0   1.20e-32\n3 vote2016Trump Vote                        -51.6       0.770   -67.0   0       \n4 rural_urbanRural                           -2.77      0.907    -3.05  2.30e- 3\n5 rural_urbanSmall Town                      -1.67      0.785    -2.13  3.34e- 2\n6 rural_urbanCity                             0.452     0.753     0.601 5.48e- 1\n7 right_trackRight Direction:vote2016Trum…   13.8       2.28      6.04  1.61e- 9\n\n\nWe gebruiken predictions() om voor alle combinaties van deze twee variabelen voorspelde waarden te berekenen. Dit resulteert in 4 voorspelde waarden: Clinton voter & “right direction”, Clinton voter & “wrong track”, Trump voter & “right direction”, en Trump voter & “wrong track”.\n\npredictions(\n  biden_int3, \n  by = c(\"right_track\", \"vote2016\"), \n  newdata = \"mean\")\n\n\n     right_track     vote2016 Estimate Std. Error     z Pr(&gt;|z|)     S 2.5 %\n Wrong Track     Clinton Vote     78.4      0.581 134.9   &lt;0.001   Inf  77.2\n Wrong Track     Trump Vote       26.8      0.775  34.5   &lt;0.001 864.8  25.2\n Right Direction Clinton Vote     53.1      2.119  25.1   &lt;0.001 458.6  49.0\n Right Direction Trump Vote       15.3      0.737  20.7   &lt;0.001 314.8  13.8\n 97.5 %\n   79.5\n   28.3\n   57.3\n   16.7\n\nType:  response \n\n\n\nby = c(\"right_track\", \"vote2016\")\n\nOm voorspelde waarden te verkrijgen voor alle categorieën van een binaire/categorische variabele kunnen we gebruik maken van de by = “variable name” optie. Gezien beide predictoren factor variabelen zijn duiden we ze beiden aan.\n\nnewdata = \"mean\")\n\nDeze optie hebben we hier nodig (gezien we het ‘by’ statement gebruiken) om de overige onafhankelijke variabelen op hun gemiddelde of modus te houden.\n\n\nDe resultaten kunnen we in een plot visualiseren. De syntax is vrijwel hetzelfde als die voor plots van voorspelde waarden voor 1 factor variable (Paragraaf 8.7). We moeten gebruikmaken van geom_pointrange(). Nieuw is dat we voorspellingen onderscheiden van elkaar op basis van de waarden van de moderator via de shape = optie. Deze vertelt aan ggplot verschillende vormen te gebruiken voor de voorspelde waarden.[^interaction_03-3]\nVoor we plotten vertalen we de labels voor vote2016 naar het Nederlands.\n[^interaction_03-3] Dit zou eventueel ook kunnen via kleuren (bv. color = vote2016). Let er wel op dat niet iedereen kleuren kan zien (R heeft wel color-bind palettes beschikbaar). Bovendien kan een plot met kleuren onduidelijk worden afgedrukt in zwart/wit.\n\n1predictions(\n  biden_int3, \n  by = c(\"right_track\", \"vote2016\"), \n  newdata = \"mean\") |&gt; \n  ggplot(aes(x = right_track, y=estimate, shape = vote2016)) + \n2  geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) +\n  geom_text(aes(label = round(estimate, 2), hjust=-0.2)) + \n  labs(title = \"Voorspelde score voor Biden\", \n       x = \"Richting van het land\", \n       y = \"Voorspelde score Biden\", \n       shape = \"Stemkeuze 2016\") + \n3  scale_y_continuous(limits = c(0 , 100)) +\n    scale_x_discrete(labels = c(\"Wrong Track\" = \"Verkeerde richting\", \"Right Direction\" = \"Goede richting\"))\n\n\n1\n\nWe doen hier alles in 1 syntax-stap. We zouden dit in meerdere stappen kunnen opspitsen: eerst voorspellingen maken en oplsaan in data-object, dan data doorvoeren naar ggplot().\n\n2\n\nIndien voorspelde waarden gelijkaardig zijn dan kunnen de markers overlappen. Om dit te verhelpen kun je de markers wat verplaatsen door , position = position_dodge(width = 0.2) toe te voegen aan het geom_pointrange() gedeelte, na het aes() gedeelte. De waarde waarmee markers verschoven worden (hier: 0.2) kun je veranderen.\n\n3\n\nWe zetten de y-as op een schaal van 0 tot 100. Dit is niet strikt nodig, maar kan de figuur duidelijker maken.",
    "crumbs": [
      "Interacties in Lineaire en Logistische Regressiemodellen",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Voorspelde Waarden van Interactiemodellen</span>"
    ]
  },
  {
    "objectID": "interaction_03.html#logistische-regressie-voorbeeld",
    "href": "interaction_03.html#logistische-regressie-voorbeeld",
    "title": "17  Voorspelde Waarden van Interactiemodellen",
    "section": "17.4 Logistische regressie: voorbeeld",
    "text": "17.4 Logistische regressie: voorbeeld\nBovenstaande syntax is ook van toepassing voor logistische regressie. Hier voorspellen we probabiliteiten in plaats van scores. In dit voorbeeld gebruiken we een rightrack_int model waarin we rightrack voorspellen en een interactie hebben tussen vote2016 en age.\n\ntidy(righttrack_int)\n\n# A tibble: 7 × 5\n  term                   estimate std.error statistic  p.value\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)            -2.95      0.345       -8.56 1.08e-17\n2 vote2016Trump Vote      2.82      0.373        7.55 4.22e-14\n3 age                    -0.00946   0.00630     -1.50 1.33e- 1\n4 rural_urbanRural        0.208     0.111        1.87 6.15e- 2\n5 rural_urbanSmall Town   0.111     0.101        1.10 2.73e- 1\n6 rural_urbanCity         0.160     0.111        1.45 1.47e- 1\n7 vote2016Trump Vote:age  0.0129    0.00682      1.89 5.84e- 2\n\n\nWe berekenen de voorspelde kans dat een respondent vindt dat het land de goede richting uitgaat met combinaties van waarden voor age en vote2016. We maken voorspellingen, vertalen de labels en maken het plot:\n\nright_track_int_preds &lt;-predictions(righttrack_int, \n            newdata = datagrid(age = seq(from=20,to=80, by=10), \n                               vote2016 = c(\"Trump Vote\", \"Clinton Vote\"))) |&gt;\n  mutate(vote2016 = recode(vote2016, \n                       \"Clinton Vote\" = \"Clinton Stem\",\n                       \"Trump Vote\" = \"Trump Stem\"))\n  ggplot(right_track_int_preds, aes(x=age, y=estimate, linetype=vote2016)) + \n  geom_line() + \n  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = 0.2) + \n  labs(title = \"Voorspelde kans dat respondent vindt dat het land de goede richting uitgaat\", \n       y = \"Voorspelde kans\", \n       x = \"Leeftijd\", \n       linetype = \"2016 Stemkeuze\") + \n  scale_y_continuous(limits=c(0,1))",
    "crumbs": [
      "Interacties in Lineaire en Logistische Regressiemodellen",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Voorspelde Waarden van Interactiemodellen</span>"
    ]
  },
  {
    "objectID": "interaction_03.html#footnotes",
    "href": "interaction_03.html#footnotes",
    "title": "17  Voorspelde Waarden van Interactiemodellen",
    "section": "",
    "text": "De waarden voor pid zouden we ook als volgt kunnen aanduiden: pid = c(1:7).↩︎\nWe zouden ook de originele dataset (anes) kunnen nemen, missing waarden voor de variabelen gebruikt in het model wegfilteren en de juiste statistieken berekenen: anes \\|\\&gt; filter(complete.cases(biden, socialists, age, rural_urban)) \\|\\&gt; summarize(...).predictions() combineert deze stappen voor ons.↩︎",
    "crumbs": [
      "Interacties in Lineaire en Logistische Regressiemodellen",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Voorspelde Waarden van Interactiemodellen</span>"
    ]
  },
  {
    "objectID": "common_errors.html",
    "href": "common_errors.html",
    "title": "Bijlage A — Veelgemaakte fouten in R",
    "section": "",
    "text": "A.1 Your R assignment file (.rmd) won’t knit to an html file\nThe scenario: you have been successfully working through an R assignment in the .rmd file that was provided to you. However, you receive an error message such as “No such file or directory” when you try and “knit” the file to an html (i.e., ask R to convert the .rmd file into an html file). More generally, everything works while working in R Studio until you try to knit the final file.\nThere are a variety of potential causes for this problem. They perhaps share a common root though: when you ask R to “knit” a file, R will essentially from a blank slate and begin working downwards through your .rmd file. By blank slate, we mean that R will act as if you have not loaded any libraries or imported data or stored regression results (etc.) in the Environment and start running all the syntax that you have created to do these things. Here we’ll discuss three ways this could short circuit the ‘knitting’ process. First, though, we’ll note a general piece of advice:\nIf you have had difficulties knitting a document before, we suggest “knitting as you go”. Specifically, knit your .rmd file (convert it into an html) after every major section (e.g., after loading packages and your data, after question 1, after question 2…). Doing so may enable you to more quickly find, and troubleshoot, the specific problem affecting your file. For instance, if you can successfully knit your document after the first three questions of an assignment but have a problem after the fourth, then this implies that it is something specifically about the fourth question that is derailing the process. This can help you avoid spending unnecessary time and effort working through the earlier portions of the file.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Veelgemaakte fouten in R</span>"
    ]
  },
  {
    "objectID": "common_errors.html#your-r-assignment-file-.rmd-wont-knit-to-an-html-file",
    "href": "common_errors.html#your-r-assignment-file-.rmd-wont-knit-to-an-html-file",
    "title": "Bijlage A — Veelgemaakte fouten in R",
    "section": "",
    "text": "The Problem\n\n\n\nYou are trying to knit your assignment and you receive an error such as “No such file or directory”; more generally, you cannot knit to an html\n\n\n\n\n\n\n\n\n\n\nAdvice\n\n\n\nKnit as you go!\n\n\n\n\nA.1.1 Incorrectly Specifying the “yaml”\n\n\n\n\n\n\nThe Cause\n\n\n\nThe “yaml” has been incorrectly specified\n\n\nAll .rmd documents begin with something called the “yaml”. This is the portion of the document that lays out the basic attributes of the file you are trying to create: its title, author information, and other basic formatting details. Here is an example:\n\nThe “yaml” is the first thing that R deals with when knitting your file, so if there is a mistake here then the file won’t be produced. We have seen three types of error in student submissions on this front:\n\nRemoving quotation marks: the title, author, and date information should all be enclosed within quotation marks. Removing them will lead to an error.\nAdding information in the “sys.date()” area: “r sys.date()” is a specific snippet of syntax that tells R to use the date on your computer as the date in the html that is being produced. This general syntax is nice because it means we do not need to constantly update this line if we are working with a file over time. However, if you add information here (e.g., “r sys.date(27-09-2023”), then R will grind to a halt because this is not how the syntax works. In fact, we had to take special care formatting this bullet point because a mistake with writing out the “sys.date” information initially prevented this file from knitting to an html!\nAdding additional options: For instance, we have seen students add something like “pdf: default” to the format area. R can knit to pdf files, but this requires some additional packages be installed to handle the conversion from an .rmd file to a .pdf file. Creating .pdf files can also be a little finicky as well. Adding this information can thus produce errors.\n\n\n\n\n\n\n\nThe Solution\n\n\n\nUh…don’t do those things!\n\n\nMore specifically, you should only make one change to the “yaml” area - you should update the author information to include your name and your student number while making sure that this information is provided in quotation marks. Everything else should be left as is.\nAs an example:\n\n\n\nA.1.2 Not Properly Importing Your Data\n\n\n\n\n\n\nThe Cause\n\n\n\nYou are manually loading data via the Files window rather than using syntax\n\n\nWe load data into the R Environment, thereby enabling us to work with it, via syntax. Specifically, we use the import() function from the rio package:\n\nlibrary(rio)\ness &lt;- import(\"ess_nl.sav\")\n\nWe have seen some students take a different, and worse, route to this same end. Specifically, there is a “Files” window in R Studio that is typically presented in the bottom/right of the R Studio window, as so:\n\nHere we can see that there are some data files within the working directory containing this .rmd file (e.g., “ess_nl.sav” or “demdata.rds”). We may be able to load this data by double clicking on the file and using the “Import Dataset” option that pops up. However, this is a bad idea. Remember that R begins working downwards within your .rmd file as it tries to knit it to an html. If you take this route to loading the data, then R will move through the yaml and fail to find the necessary syntax to load the rio package or to load your data via import(). It won’t know that you have loaded the file manually because it is, per above, working in a type of blank slate environment. This is will almost certainly lead to lots of errors as R works through your file because you will be asking it to do things with data that it doesn’t know exists since you are not including the necessary information within the .rmd file itself.\n\n\n\n\n\n\nThe Solution\n\n\n\nProperly load your data.\n\n\nThe solution is simple: use the appropriate syntax to load your data.\n\n\nA.1.3 Not loading libraries within the .rmd file\n\n\n\n\n\n\nThe Problem\n\n\n\nPerforming operations outside of the .rmd file that are required for your analyses\n\n\nThis is a more general version of the previous issue. For instance, perhaps you have loaded the rio library and correctly imported your data via syntax … just not in the .rmd file (e.g., you may have entered these commands directly in the Console portion of R Studio or perhaps have run them from within an R Script that is separate from your .rmd file). The same problem would emerge: you would have access to the libraries and functions in question to work with while completing your assignment, but R wouldn’t when it started to knit your document because it’s not in the set of commands you’re directly sending it.\nOne tip off here may be in the error message that R provides you. Consider the following error message taken from a student’s error-prone .rmd file last year:\n\nIn this instance, the student is running into an issue with knitting. R provides us with information about the specific input that is causing a problem (“Error in import(….)”) and the specific problem (“could not find function ‘import’”). One way this error could emerge is if rio were loaded outside of the .rmd file (that is: the .rmd file does not contain library(rio) to load the library for use) such that R will have no idea where to find this command. (Another potential explanation for this error is below.)\n\n\n\n\n\n\nThe Solution\n\n\n\nKeep all your steps in the same .rmd file\n\n\nThis is a type of problem that can readily emerge, but also one that can be readily fixed: make sure you have included all of the relevant syntax in the .rmd file.\n\n\nA.1.4 Library/Package Conflicts\n\n\n\n\n\n\nThe Cause\n\n\n\nTwo or more R libraries conflict with one another and have been loaded in such a way that this grinds R to a halt; packages loaded in an order that creates issues\n\n\nR libraries may sometimes feature identically named commands (e.g., both the tidyverse/dplyr and car libraries contain a function named recode()). In such instances, R will use the function from the library loaded most recently/last. This can create problems down the line; see SECTION for more on this particular conflict.\nAnother way this could emerge is if the syntax for loading the library and syntax for using it are mis-ordered. This, for instance, would lead to an error:\n\ndemdata &lt;- import(\"demdata.rds\")\n\nError in import(\"demdata.rds\"): could not find function \"import\"\n\nlibrary(rio)\n\nWarning: package 'rio' was built under R version 4.4.3\n\n\nR would try and use the import function here, but an error would emerge because the library from which this command originates has not been loaded at that point and, hence, R will not know how to act.\n\n\n\n\n\n\nThe Solution\n\n\n\nLoad relevant libraries at the start of the R document and pay attention to potential conflicts\n\n\nWe recommend you begin your assignment by reading it in full to understand all of the steps that you will need to accomplish and then loading all of the relevant libraries at the start of the document so that R will know what it has accessible to use in later portions. This should be done in a way that does not introduce conflicts. Here we note two particular sources of conflict, both with the tidyverse library:\n\nexpss\ncar\n\nWe recommend loading these libraries before loading the tidyverse library to avoid conflicts (or, if necessary, taking one of the other strategies for avoiding conflict discussed in SECTION).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Veelgemaakte fouten in R</span>"
    ]
  },
  {
    "objectID": "common_errors.html#sec-not-seeing-the-right-number-of-categories-for-factor-variables-in-regression-models",
    "href": "common_errors.html#sec-not-seeing-the-right-number-of-categories-for-factor-variables-in-regression-models",
    "title": "Bijlage A — Veelgemaakte fouten in R",
    "section": "A.2 Not seeing the right number of categories for factor variables in regression models",
    "text": "A.2 Not seeing the right number of categories for factor variables in regression models\n\n\n\n\n\n\nThe Problem\n\n\n\nYou tried to convert a categorical variable into a factor variable but only one coefficient is present in the regression output\n\n\nWe include categorical variables in a regression model by first converting the variable into a factor variable. R will then include the appropriate number of indicators in the model for us. For instance, if we have a categorical variable with four levels, then R will include three indicators in the model if we successfully convert the variable into a factor variable.\nSuppose we have a numeric variable in our dataset corresponding to the gross domestic product in a country where countries are sorted into one of three groups: “low” GDP (value of 1), medium GDP (value of 2), and “high” GDP (value of 3). We would include this variable in our model by converting it into a factor variable. We should then see two indicators for this variable in the model (with the left out group acting as the reference category). For instance:\n\n#Distribution of Variable\ntable(dta$gdp_3cat)\n\n\n 1  2  3 \n40 78 40 \n\n#Convert to factor variable\ndta &lt;- dta |&gt; \n  mutate(gdp_3cat_factor = factorize(gdp_3cat))\n\n#Run and summarize the regression\nmodel1 &lt;- lm(v2x_polyarchy ~ gdp_3cat_factor, data=dta)\nsummary(model1)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ gdp_3cat_factor, data = dta)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.67320 -0.15257  0.04909  0.17964  0.36359 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      0.24184    0.05264   4.594 8.91e-06 ***\ngdp_3cat_factor  0.14879    0.02480   6.000 1.33e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2218 on 156 degrees of freedom\n  (21 observations deleted due to missingness)\nMultiple R-squared:  0.1875,    Adjusted R-squared:  0.1823 \nF-statistic:    36 on 1 and 156 DF,  p-value: 1.329e-08\n\n\nWe only have one indicator in our model for the factor variable. Why?1\n\n\n\n\n\n\nThe Cause\n\n\n\nYou used factorize() with non-labelled data.\n\n\nWe can convert a variable into a factor variable in either of two ways in R:\n\nfactor(): This is a built in function that will work with any type of data.\nfactorize(): This function comes from the rio package.\n\nfactorize() is a handy tool but it only works with variables that have value labels stored within the dataset. In these instances, factorize() will automatically attach each numeric value with its corresponding value. While labelled data is common (but not universal) when the dataset in question is either a .dta or .sav file format, it is not common with .csv for .xlsx file formats. Note that by labelled data we mean situations where the labels are included within the datset itself rather than only being found in a separate codebook.\nWe can use the following function to obtain information as to whether a variable has value labels associated with it in the dataset that we are using: attr(dataset$varname, \"labels\"). Here is an example with two variables: one labelled and one unlabelled:\n\n#Unlabelled\nattr(dta$gdp_3cat, \"labels\")\n\nNULL\n\n#Labelled\nattr(dta$Fragile2006, \"labels\")\n\n     Fragile Intermediate       Stable \n           1            2            3 \n\n\nIn the former case, we observe the value of “NULL” meaning that no value labels are stored in the metadata for this variable. factorize() works by applying stored labels to numeric values, but there is nothing here to apply.\nOn the other hand, we see values reported in the latter case. The variable in question is a numeric variable with three values: 1 (associated with the label “Fragile”), 2 (associated with the label “Intermediate”), and 3 (associated with the label “Stable”). We can use factorize() in this instance with the resulting model reporting the correct number of terms in the model.2\n\ndta &lt;- dta |&gt; \n  mutate(fragile = factorize(Fragile2006))\n\nmodel2 &lt;- lm(v2x_polyarchy ~ fragile, data=dta)\nsummary(model2)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ fragile, data = dta)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.64836 -0.14467  0.03116  0.15945  0.43393 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          0.36907    0.02915  12.662  &lt; 2e-16 ***\nfragileIntermediate  0.14954    0.03975   3.762 0.000236 ***\nfragileStable        0.36028    0.04345   8.291  4.2e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2162 on 161 degrees of freedom\n  (15 observations deleted due to missingness)\nMultiple R-squared:  0.2996,    Adjusted R-squared:  0.2909 \nF-statistic: 34.44 on 2 and 161 DF,  p-value: 3.539e-13\n\n\n\n\n\n\n\n\nSolution\n\n\n\nUsing factor() instead of factorize()\n\n\nThe built in factor() command will be more useful in this type of situation. Here we specify the levels of the factor variable (with the reference group being the first category provided in levels=c()) and its associated labels.\n\ndta &lt;- dta |&gt; \n  mutate(gdp_3cat_correct = factor(gdp_3cat, \n                                   levels=c(1,2,3), \n                                   labels=c(\"Low\", \"Medium\", \"High\")))\n\nmodel3 &lt;- lm(v2x_polyarchy ~ gdp_3cat_correct, data=dta)\nsummary(model3)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ gdp_3cat_correct, data = dta)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.70363 -0.13534  0.06887  0.15537  0.39479 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             0.42105    0.03484  12.086  &lt; 2e-16 ***\ngdp_3cat_correctMedium  0.08716    0.04285   2.034   0.0437 *  \ngdp_3cat_correctHigh    0.29757    0.04927   6.040  1.1e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2203 on 155 degrees of freedom\n  (21 observations deleted due to missingness)\nMultiple R-squared:  0.2034,    Adjusted R-squared:  0.1931 \nF-statistic: 19.79 on 2 and 155 DF,  p-value: 2.224e-08",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Veelgemaakte fouten in R</span>"
    ]
  },
  {
    "objectID": "common_errors.html#sec-glm-factor",
    "href": "common_errors.html#sec-glm-factor",
    "title": "Bijlage A — Veelgemaakte fouten in R",
    "section": "A.3 “Error in glm.fit…NA/NAN/Inf in ‘y’” and “not meaningful for factors”",
    "text": "A.3 “Error in glm.fit…NA/NAN/Inf in ‘y’” and “not meaningful for factors”\n\n\n\n\n\n\nThe Problem\n\n\n\nWe’re trying to perform a logistic model where our DV is a factor variable but are running into a message saying “Error in glm.fit(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, : NA/NaN/Inf in ‘y’” and “In Ops.factor(y, mu) : ‘-’ not meaningful for factors”\n\n\nSuppose that we wish to predict a binary outcome for whether a person reports being close to a political party or not based on their age. We would use create a factor variable of the binary outcome variable and then use the glm() function, rather than lm() to do so. However, if we ran the following syntax, we would run into an error:\n\n#Factorize the variable\ness &lt;- ess |&gt; \n  mutate(close_party = factor(clsprty, \n                              levels = c(2, 1), \n                              labels = c(\"Not Close\", \"Close to Party\")))\n\n#Run the model\nglm(close_party ~ agea, data = ess)\n\nWarning in Ops.factor(y, mu): '-' not meaningful for factors\n\n\nWarning in Ops.factor(eta, offset): '-' not meaningful for factors\n\n\nWarning in Ops.factor(y, mu): '-' not meaningful for factors\n\n\nError in glm.fit(x = structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, : NA/NaN/Inf in 'y'\n\n\n\n\n\n\n\n\nThe Cause\n\n\n\nWe haven’t specified a “family” for the model.\n\n\nThe glm() function can be used to fit a variety of different models depending on the nature of the dependent variable. We specify the type of model (and hence the nature of the DV) via a family= option. If we do not specify a family option, then glm() will default to attempting to perform a linear model, which creates an error when the DV is a factor variable.3\n\n\n\n\n\n\nSolution\n\n\n\nSpecify the correct family, here: “family =”binomial”\n\n\n\nglm(close_party ~ agea, data = ess, family = 'binomial')\n\n\nCall:  glm(formula = close_party ~ agea, family = \"binomial\", data = ess)\n\nCoefficients:\n(Intercept)         agea  \n   -0.64393      0.01825  \n\nDegrees of Freedom: 1646 Total (i.e. Null);  1645 Residual\n  (26 observations deleted due to missingness)\nNull Deviance:      2260 \nResidual Deviance: 2214     AIC: 2218",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Veelgemaakte fouten in R</span>"
    ]
  },
  {
    "objectID": "common_errors.html#sec-slopes-error",
    "href": "common_errors.html#sec-slopes-error",
    "title": "Bijlage A — Veelgemaakte fouten in R",
    "section": "A.4 “Unable to compute predicted values with this model”",
    "text": "A.4 “Unable to compute predicted values with this model”\n\n\n\n\n\n\nThe Problem\n\n\n\nWe’re using avg_slopes() to try and find the slope for a variable but are running into an error: “Unable to compute predicted values with this model”\n\n\nSuppose we have a binary dependent variable that we wish to predict with a binary or category independent variable. For instance, we might want to know if the chances of voting are higher/lower among men versus women. We would convert both variables to factor variables and perform a logistic model. The syntax below walks through this process by first investigating the variables (e.g., what labels are associated with each category); converting both variables to factors; and then running the model and reporting the results.\n\n#Value Values\n1attr(ess$vote,\"labels\")\nattr(ess$gndr, \"labels\")\n\n#Distribution\ntable(ess$vote)\ntable(ess$gndr)\n\n#Convert into factor\n  #Vote: 0 = did not vote, 1 = voted\n  #Gender: 0 = male, 1 = female\n\ness &lt;- ess |&gt; \n  mutate(voted = factor(vote, levels=c(2,1), \n                        labels=c(\"Did Not Vote\", \"Voted\")), \n         gender = factorize(gndr))\n\n#Model and Summary\name_example &lt;- glm(voted ~ gender, data=ess, family=\"binomial\")\nsummary(ame_example)\n\n\n1\n\nattr(data$variable, \"labels\") is a shortened version of attributes(data$variable) that only shows whether there are value labels associated with the variable.\n\n\n\n\n                 Yes                   No Not eligible to vote \n                   1                    2                    3 \n             Refusal           Don't know            No answer \n                   7                    8                    9 \n     Male    Female No answer \n        1         2         9 \n\n   1    2    3 \n1291  247  130 \n\n  1   2 \n833 840 \n\nCall:\nglm(formula = voted ~ gender, family = \"binomial\", data = ess)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    1.7484     0.1015  17.229   &lt;2e-16 ***\ngenderFemale  -0.1836     0.1392  -1.318    0.187    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1355.5  on 1537  degrees of freedom\nResidual deviance: 1353.7  on 1536  degrees of freedom\n  (135 observations deleted due to missingness)\nAIC: 1357.7\n\nNumber of Fisher Scoring iterations: 4\n\n\nThe coefficient for our IV is negative, which indicates that female respondents have a lower chance of reporting that they turned out to vote than men (although this difference is not statistically significant). This coefficient is on the log of the odds (logit) scale, which is hard to interpret. We may want to look at the average difference in the probability of turning out between women and men to more clearly communicate the difference between the two groups. We can do this by using the avg_slopes() function from the marginaleffects package. However, in this instance we receive an error message:\n\navg_slopes(ame_example)\n\nError: Unable to compute predicted values with this model. This error can arise\n  when `insight::get_data()` is unable to extract the dataset from the\n  model object, or when the data frame was modified since fitting the\n  model. You can try to supply a different dataset to the `newdata`\n  argument.\n  \n  In addition, this error message was raised:\n  \n  Error in model.frame.default(Terms, newdata, na.action = na.action, xlev\n  = object$xlevels): factor gender has new levels No answer\n\n  \n  Bug Tracker:\n  https://github.com/vincentarelbundock/marginaleffects/issues\n\n\n\n\n\n\n\n\nThe Cause\n\n\n\nThere is a category with no observations.\n\n\nLet’s take a look at the gender variable we created earlier compared with its original form:\n\n#Original Variable\nattr(ess$gndr, \"labels\")\n\n     Male    Female No answer \n        1         2         9 \n\ntable(ess$gndr)\n\n\n  1   2 \n833 840 \n\n#Recoded\nlevels(ess$gender)\n\n[1] \"Male\"      \"Female\"    \"No answer\"\n\ntable(ess$gender)\n\n\n     Male    Female No answer \n      833       840         0 \n\n\nThe gndr variable has three labels associated with it: Male (=1), Female (=2), and No Answer (=9). However, no observations have a value of 9 on this original variable. Regardless, factorize() will still port over the label for “No Answer”. The issue is that avg_slopes() is expecting there to be observations with a label of “No Answer” - when it finds none, it crashes.\n\n\n\n\n\n\nSolution\n\n\n\nUse droplevels() to removing categories with no observations or use factor() to create the variable to begin with\n\n\nWe can avoid this issue in either of two ways. First, we could use droplevels() to drop levels (and their associated labels) that have no observations. Second, we can preempt the problem by simply using factor() and only including the categories we care about.\n\n#Recoding Using the Two Options\ness &lt;- ess |&gt; \n  mutate(\n    #Option 1: droplevels()\n    gender_opt1 = factorize(gndr), \n    gender_opt1 = droplevels(gender_opt1), \n    #Option 2: factor() from the beginning\n    gender_opt2 = factor(gndr,\n                         levels=c(1,2), \n                         labels=c(\"Male\", \"Female\")))\n\n#Levels\nlevels(ess$gender_opt1)\n\n[1] \"Male\"   \"Female\"\n\nlevels(ess$gender_opt2)\n\n[1] \"Male\"   \"Female\"\n\n#Option 1: \name_example_opt1 &lt;- glm(voted ~ gender_opt1, data=ess, family=\"binomial\")\navg_slopes(ame_example_opt1)\n\n\n Estimate Std. Error     z Pr(&gt;|z|)   S   2.5 % 97.5 %\n  -0.0247     0.0187 -1.32    0.187 2.4 -0.0614  0.012\n\nTerm: gender_opt1\nType:  response \nComparison: Female - Male\n\n#Option 2\name_example_opt2 &lt;- glm(voted ~ gender_opt2, data=ess, family=\"binomial\")\navg_slopes(ame_example_opt2)\n\n\n Estimate Std. Error     z Pr(&gt;|z|)   S   2.5 % 97.5 %\n  -0.0247     0.0187 -1.32    0.187 2.4 -0.0614  0.012\n\nTerm: gender_opt2\nType:  response \nComparison: Female - Male",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Veelgemaakte fouten in R</span>"
    ]
  },
  {
    "objectID": "common_errors.html#sec-linetype-error",
    "href": "common_errors.html#sec-linetype-error",
    "title": "Bijlage A — Veelgemaakte fouten in R",
    "section": "A.5 “A continuous variable cannot be mapped to the linetype aesthetic”",
    "text": "A.5 “A continuous variable cannot be mapped to the linetype aesthetic”\n\n\n\n\n\n\nThe Problem\n\n\n\nWe’re trying to create a predicted values plot from a model with an interaction involving a continuous variable and see the error “A continuous variable cannot be mapped to the linetype aesthetic”\n\n\nSuppose we predict a country’s democracy score with a continuous measure of gross domestic product (gdp_ppp), a continuous measure of corruption (cpi), and their interaction:\n\ninter_model &lt;- lm(v2x_polyarchy ~ gdp_ppp*cpi, data=dta)\nsummary(inter_model)\n\n\nCall:\nlm(formula = v2x_polyarchy ~ gdp_ppp * cpi, data = dta)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.58552 -0.09686  0.02947  0.13111  0.30958 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  8.250e-02  5.643e-02   1.462    0.146    \ngdp_ppp     -1.902e-06  3.092e-06  -0.615    0.539    \ncpi          1.203e-02  1.463e-03   8.220 8.34e-14 ***\ngdp_ppp:cpi -2.524e-08  4.370e-08  -0.578    0.564    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1833 on 152 degrees of freedom\n  (23 observations deleted due to missingness)\nMultiple R-squared:  0.4538,    Adjusted R-squared:  0.443 \nF-statistic: 42.09 on 3 and 152 DF,  p-value: &lt; 2.2e-16\n\n\nInterpreting coefficients in a model with an interaction can be tricky and especially so when both variables are continuous variables. One solution is to use predictions() function to obtain predicted values across the range of our main variable for different values of our moderator (e.g., “low”, “medium”, and “high”). For instance:\n\ninter_preds &lt;- predictions(inter_model, \n                           newdata = datagrid(\n                             cpi = c(12,30,40,43.94,56,88), \n                             gdp_ppp = c(711.4, 20309.8, 111751.3)))\n\ninter_preds\n\n\n  cpi gdp_ppp Estimate Std. Error       z Pr(&gt;|z|)     S   2.5 % 97.5 %\n 12.0     711   0.2253     0.0405  5.5659   &lt;0.001  25.2  0.1459  0.305\n 12.0   20310   0.1821     0.0479  3.8040   &lt;0.001  12.8  0.0883  0.276\n 12.0  111751  -0.0196     0.2732 -0.0717   0.9429   0.1 -0.5550  0.516\n 30.0     711   0.4415     0.0248 17.8188   &lt;0.001 233.5  0.3929  0.490\n 30.0   20310   0.3893     0.0282 13.7902   &lt;0.001 141.3  0.3340  0.445\n 30.0  111751   0.1462     0.1995  0.7325   0.4639   1.1 -0.2449  0.537\n 40.0     711   0.5616     0.0251 22.3295   &lt;0.001 364.5  0.5123  0.611\n 40.0   20310   0.5045     0.0210 23.9895   &lt;0.001 420.0  0.4633  0.546\n 40.0  111751   0.2382     0.1608  1.4820   0.1383   2.9 -0.0768  0.553\n 43.9     711   0.6089     0.0275 22.1578   &lt;0.001 359.0  0.5550  0.663\n 43.9   20310   0.5499     0.0199 27.6463   &lt;0.001 556.5  0.5109  0.589\n 43.9  111751   0.2745     0.1463  1.8768   0.0605   4.0 -0.0122  0.561\n 56.0     711   0.7537     0.0392 19.2345   &lt;0.001 271.5  0.6769  0.831\n 56.0   20310   0.6887     0.0241 28.5995   &lt;0.001 595.2  0.6415  0.736\n 56.0  111751   0.3856     0.1071  3.5986   &lt;0.001  11.6  0.1756  0.596\n 88.0     711   1.1380     0.0810 14.0449   &lt;0.001 146.4  0.9792  1.297\n 88.0   20310   1.0572     0.0588 17.9733   &lt;0.001 237.5  0.9419  1.173\n 88.0  111751   0.6802     0.1107  6.1456   &lt;0.001  30.2  0.4633  0.897\n\nType:  response \n\n\nThere is a lot of data here to try and read/interpret. However, we can create a nice plot to summarize the predictions. Unfortunately, we run into the following error when running this syntax:\n\nggplot(inter_preds, aes(x=cpi, y=estimate, linetype = gdp_ppp)) + \n  geom_line() + \n  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = 0.2)\n\nError in `geom_line()`:\n! Problem while computing aesthetics.\nℹ Error occurred in the 1st layer.\nCaused by error in `scale_f()`:\n! A continuous variable cannot be mapped to the linetype aesthetic.\nℹ Choose a different aesthetic or use `scale_linetype_binned()`.\n\n\n\n\n\n\n\n\nThe Cause\n\n\n\nThe variable being used to specify linetype (or color, etc.) is numeric in value.\n\n\nWe created three sets of predictions above: one where gdp_ppp = 711.4 and cpi took on one of five values from across its range; one where gdp_ppp = 20309.8 and cpi took on one of those five values; and one where cpi = 111751.3 and cpitook on one of those values. We can visually differentiate between these different predictions by telling ggplot() to use a different type of line for each set (or, perhaps, a different color). But, the linetype function requires the variable in question to be a factor.\n\n\n\n\n\n\nSolution\n\n\n\nConvert the problematic numeric variable to a factor and then run the ggplot() command.\n\n\nWe can avoid this issue by converting the offending variable to a factor variable using the factor() function.\n\n#Convert to factor\ninter_preds &lt;- inter_preds |&gt; \n  mutate(\n    gdp_ppp = factor(gdp_ppp, \n                     levels=c( 711.4, 20309.8, 111751.3), \n                     labels=c(\"Low\", \"Medium\", \"High\")))\n\n#Create the plot\nggplot(inter_preds, aes(x=cpi, y=estimate, linetype = gdp_ppp)) + \n  geom_line() + \n  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha = 0.2)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Veelgemaakte fouten in R</span>"
    ]
  },
  {
    "objectID": "common_errors.html#footnotes",
    "href": "common_errors.html#footnotes",
    "title": "Bijlage A — Veelgemaakte fouten in R",
    "section": "",
    "text": "There could an additional culprit: missing data. Suppose that you have 1 DV and two IVs, one of which is a categorical variable with three levels (low, middle, and high) and the other a continuous variable. R will automatically drop observations from the model that have missing data on at least one of the variables in the model (DV and IV). Suppose that all of the observations with a classification of “high” on the categorical variable have missing (NA) values on the continuous variable - in that instance, R would not have the necessary data to estimate a coefficient for the “high” category and, as a result, you would likely only get indicators for one category of the categorical variable (comparing it to the reference group) and one for the continuous variable.↩︎\nOf course, in practice we might want to follow the factorize() step with a subsequent step where we relevel the variable, i.e., change the reference group. Alternatively we could simply use factor() in this instance as well and handle the levelling and labelling all at once.↩︎\nWhat if the DV was simply coded 0/1 and not converted to a factor? The syntax in this example would run but a different problem would emerge: the glm() command would fit a linear model (i.e., a linear regression model) to the data rather than a logistic model. This is another reason to explicitly specify the family to be used when using the glm() function.↩︎",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Veelgemaakte fouten in R</span>"
    ]
  },
  {
    "objectID": "package_overview.html",
    "href": "package_overview.html",
    "title": "Bijlage B — Overzicht R Packages",
    "section": "",
    "text": "B.1 Alle packages installeren\nOm alle gebruikte packages in één keer te installeren, kun je onderstaande code gebruiken:\npackage_list &lt;- c(\"tidyverse\", \"rio\", \"summarytools\", \"DescTools\", \"skimr\",\n                  \"correlation\", \"parameters\", \"performance\", \"effectsize\",\n                  \"see\", \"marginaleffects\", \" bromo\", \"ggResidpanel\", \"rms\",\n                  \"car\", \"modelsummary\", \"gt\", \"gtsummary\", \"kableExtra\",\n                  \"knitr\", \"rmarkdown\",\"huxtable\", \"flextable\", \"lmtest\" ,\n                  \"openintro\", \"statsr\", \"tidymodels\", \"tinytex\",\n                  \"visdat\", \"patchwork\", \"ggpubr\", \"cowplot\", \"expss\",\n                  \"effsize\", \"foreign\", \"haven\",\n                  \"ggstance\", \"ggrepel\", \"ggsignif\", \"naniar\", \"openxlsx\",\n                  \"sjmisc\", \"crosstable\", \"sjlabelled\", \"psych\", \"dice\",\n                  \"pwr\", \"visualize\", \"infer\" , \"sandwich\", \"sjPlot\",\n                  \"scales\", \"fastDummies\")\n\ninstall.packages(package_list)\nMoest er een probleem optreden bij de installatie van het marginaleffects package, probeer dan volgende syntax:\ninstall.packages(\"marginaleffects\", type=\"binary\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Overzicht R Packages</span>"
    ]
  },
  {
    "objectID": "Formulas.html",
    "href": "Formulas.html",
    "title": "Bijlage C — Formules",
    "section": "",
    "text": "C.1 Covariance and Correlation\n(Sample) Covariance\n\\[cov(x,y) = \\frac{\\sum (x_{i} - \\bar{x})(y_{i} - \\bar{y})}{n-1}\\]\nPearson Correlation\n\\[r = \\frac{cov(x,y)}{SD(x) * SD(y)}\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Formules</span>"
    ]
  },
  {
    "objectID": "Formulas.html#linear-regression",
    "href": "Formulas.html#linear-regression",
    "title": "Bijlage C — Formules",
    "section": "C.2 Linear Regression",
    "text": "C.2 Linear Regression\nLinear Regression Equation\n\\[y_{i} = b_{0} + b_{1}x_{1i} + b_{2}x_{2i} + ... + b_{k}x_{ki} + \\epsilon_{i}\\]\nSimple Linear Regression: Slope\n\\[b_{1} = \\frac{\\sum(x_{i} - \\bar{x})(y_{i} - \\bar{y})}{\\sum(x_{i} - \\bar{x})^2}\\]\nSimple Linear Regression: Intercept/Constant\n\\[b_{0} = \\bar{y} - b_{1}\\bar{x}\\]\nRegression Model with Interaction\n\\[y = b_{0} + b_{1}x_{1} + b_{2}x_{2} + b_{3}(x_{1}x_{2}) + \\epsilon\\]\nMarginal Effects in Interaction Model\n\\[b_{1} + (x2 * b_{3})\\] \\[b_{2} + (x1 * b_{3})\\]\nt-test for regression coefficients\n\\[t = \\frac{b}{SE_{b}}\\]\nConfidence Interval: Coefficient\n\\[CI = b \\pm (t_{df} * SE)\\]\nRegression Sum of Squares (Also called: Model Sum of Squares)\n\\[SS_{Regression} = \\sum(\\hat{y} - \\bar{y})^2\\]\nResidual Sum of Squares\n\\[SS_{Residual} = \\sum(y_{i} - \\hat{y})^2\\]\nTotal Sum of Squares\n\\[SS_{Total} = \\sum(y_{i} - \\bar{y})^2\\]\nR2\n\\[R^2 = \\frac{SS_{Regression}}{SS_{Total}}\\]\n\\[R^2 = 1 - \\frac{SS_{Residual}}{SS_{Total}} \\]\nMean Squares: Residual\n\\[MS_{Residual} = \\frac{SS_{Residual}}{\\textrm{df}_{Residual}}\\] \\[\\textrm{df}_{Residual} = n-k\\] Mean Squares: Regression Model\n\\[MS_{Model} = \\frac{SS_{Regression}}{df_{Model}}\\]\n\\[df_{Model} = k\\] F\n\\[F = \\frac{MS_{Model}}{MS_{Residual}}\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Formules</span>"
    ]
  },
  {
    "objectID": "Formulas.html#logistic-regression",
    "href": "Formulas.html#logistic-regression",
    "title": "Bijlage C — Formules",
    "section": "C.3 Logistic Regression",
    "text": "C.3 Logistic Regression\nLogistic Regression Model with Single Explanatory Variable\n\\[\\textrm{log(Odds)} = b_0 + b_1x_{1i} + b_2x_{2i}...\\]\n\\[P(Y_{i} = 1) = \\frac{1}{1 + e^{-(b_{0} + b_{1}x_{1i})}}\\]\nOdds and Probabiilty\n\\[odds = \\frac{p}{1 - p}\\]\n\\[p = \\frac{odds}{1 + odds}\\]\nOdds Ratio\n\\[e^{b}\\]\nz statistic\n\\[z = \\frac{b}{se}\\]\nLikelihood Ratio\n\\[\\chi^2 = (-2LL_{baseline}) - (-2LL_{new})\\]\n\\[\\textrm{df} = k_{new} - k_{baseline}\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Formules</span>"
    ]
  },
  {
    "objectID": "Formulas.html#appendix-critical-values-of-t-distribution",
    "href": "Formulas.html#appendix-critical-values-of-t-distribution",
    "title": "Bijlage C — Formules",
    "section": "C.4 Appendix: Critical Values of t-distribution",
    "text": "C.4 Appendix: Critical Values of t-distribution\n\n\n\nCritical Values of the t-distribution (Two-Tailed Test)\n\n\ndf\n0.05\n0.01\n\n\n\n\n1\n12.71\n63.66\n\n\n2\n4.30\n9.92\n\n\n3\n3.18\n5.84\n\n\n4\n2.78\n4.60\n\n\n5\n2.57\n4.03\n\n\n6\n2.45\n3.71\n\n\n7\n2.36\n3.50\n\n\n8\n2.31\n3.36\n\n\n9\n2.26\n3.25\n\n\n10\n2.23\n3.17\n\n\n11\n2.20\n3.11\n\n\n12\n2.18\n3.05\n\n\n13\n2.16\n3.01\n\n\n14\n2.14\n2.98\n\n\n15\n2.13\n2.95\n\n\n16\n2.12\n2.92\n\n\n17\n2.11\n2.90\n\n\n18\n2.10\n2.88\n\n\n19\n2.09\n2.86\n\n\n20\n2.09\n2.85\n\n\n21\n2.08\n2.83\n\n\n22\n2.07\n2.82\n\n\n23\n2.07\n2.81\n\n\n24\n2.06\n2.80\n\n\n25\n2.06\n2.79\n\n\n26\n2.06\n2.78\n\n\n27\n2.05\n2.77\n\n\n28\n2.05\n2.76\n\n\n29\n2.05\n2.76\n\n\n30\n2.04\n2.75\n\n\n35\n2.03\n2.72\n\n\n40\n2.02\n2.70\n\n\n45\n2.01\n2.69\n\n\n50\n2.01\n2.68\n\n\n60\n2.00\n2.66\n\n\n70\n1.99\n2.65\n\n\n80\n1.99\n2.64\n\n\n90\n1.99\n2.63\n\n\n100\n1.98\n2.63\n\n\n∞\n1.96\n2.58",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Formules</span>"
    ]
  },
  {
    "objectID": "errors.html",
    "href": "errors.html",
    "title": "Bijlage D — Assumptieschendingen oplossen",
    "section": "",
    "text": "D.1 Assumpties over de fouten (residuals) in OLS modellen\n\\[\ny_{i} = b_{0} + b_{1} * x_{1} + b_{2} * x_{2} ... b_{k} * x_{k} + e_{i}\n\\]\nDe \\(e_{i}\\) term in bovenstaande vergelijking staat voor de ‘error’, fout, of residual in een linear regressiemodel. Er zijn drie assumpties over deze fouten:1\nSchendingen van deze assumpties hebben belangrijke gevolgen voor statistische significantietests. Ernstige schendingen leiden tot onbetrouwbare schattingen van de standaardfout van een coëfficiënt en, als gevolg daarvan, tot onjuiste oordelen over statistische significantie.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Assumptieschendingen oplossen</span>"
    ]
  },
  {
    "objectID": "errors.html#assumpties-over-de-fouten-residuals-in-ols-modellen",
    "href": "errors.html#assumpties-over-de-fouten-residuals-in-ols-modellen",
    "title": "Bijlage D — Assumptieschendingen oplossen",
    "section": "",
    "text": "De variantie van de residuals is constant over het hele bereik van de voorspellingen van het model (homoskedasticiteit)\nDe residuals zijn onafhankelijk van elkaar\nDe residuals volgen een normaalverdeling met een gemiddelde van 0",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Assumptieschendingen oplossen</span>"
    ]
  },
  {
    "objectID": "errors.html#omgaan-met-heteroskedasticiteit",
    "href": "errors.html#omgaan-met-heteroskedasticiteit",
    "title": "Bijlage D — Assumptieschendingen oplossen",
    "section": "D.2 Omgaan met Heteroskedasticiteit",
    "text": "D.2 Omgaan met Heteroskedasticiteit\n\nD.2.1 Wat was het probleem ook al weer?\nOnderstaand voorbeeld komt uit Hoofdstuk 7 en voorspelt de mate van politieke stabiliteit in een land op basis van democratieniveaus. In het voorbeeld hebben we ook een kwadratische term voor democratiescore toegevoegd om non-lineaire verbanden te kunnen vatten. Hier is het model en de resultaten:\n\n#gekwadrateerde variabele maken\ndemdata &lt;- demdata |&gt; \n  mutate(v2x_polyarchy_sq = v2x_polyarchy^2)\n\n# Model schatten\nviolence_sqmodel &lt;- lm(pve ~ v2x_polyarchy + v2x_polyarchy_sq, \n                      data=demdata)\n\n# coëfficiënten bekijken\ntidy(violence_sqmodel, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term             estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        -0.589     0.243     -2.42 0.0165      -1.07    -0.109\n2 v2x_polyarchy      -1.73      1.10      -1.58 0.117       -3.90     0.438\n3 v2x_polyarchy_sq    3.83      1.05       3.64 0.000361     1.75     5.90 \n\n\nWe kunnen kijken of de assumptie van homoskedasticiteit geschonden is via resid_panel() zoals besproken in Hoofdstuk 7.\n\n# assumptie bekijken\nresid_panel(violence_sqmodel, plots = c(\"resid\"))\n\n\n\n\n\n\n\n\nAan de assumptie is voldaan als de fouten een even grote spreiding kennen op lage, gemiddelde, en hoge waarden van de voorspelde waarden. Ze moeten zich ongeveer in een evenwijdige band bevinden. Hier zien we dat de assumptie geschonden is aan de trechtervorm: we vinden een grote spreiding van residuals bij lage voorspele waarden (de schatting is hier onnauwkeurig) en weinig spreiding bij hoge voorspelde waarden (de schatting is hier veel nauwkeuriger).\n\n\nD.2.2 Mogelijke oplossing: robuste standaardfouten\n\n\n\n\n\n\nOpmerking\n\n\n\nDe vcov functie die we hieronder gebruiken is afkomstig uit hetsandwichpackage en helpt bij de berekening van robuuste standaardfouten. Je zult dit package misschien eerst moeten installeren.\n\n\nHeteroskedasticiteit heeft verschillende mogelijke oorzaken. Zo kan het onstaan door het ontbrekenen van belangrijke predictoren in het model. Het is een goed idee om na te denken over waarom de residuals zo verschillen en welke bijkomende onafhankelijke variabele deze spreiding kan verklaren. We kunnen dit echter niet altijd weten en als we al een idee hebben, kan het zijn dat de relevante onafhankelijke variabele niet in de dataset voorkomt.\nEen andere mogelijke oorzaak is dat we een lineaire relatie schatten waar eigenlijk een niet-lineaire relatie geschat moet worden. Dit is hier echter niet het geval.\nWat kunnen we dan nog doen?\nEen gangbare manier is om de berekenmethode voor de standaardfouten van de coëfficiënten in het model aan te passen. De standaardfouten die normaal door R worden berekend gaan uit van homoskedasticiteit, maar we kunnen ‘heteroskedasticiteit-robuuste’ standaardfouten berekenen als alternatief. Belangrijk is om te onthouden dat deze oplossing een mathematisch ‘truukje’ is, ons model past nog altijd slecht en het is belangrijk theoretisch hierover na te denken. De eerste stap blijft altijd om na te denken over mogelijk ontbrekende predictoren.\nDe eenvoudigste manier om robuuste standaardfouten te verkrijgen is via het modelsummary package. We bekijken eerst nog even de ‘normale’ regressie-output voor het model:\n\nmodelsummary(violence_sqmodel, \n             stars = T, \n             coef_rename = c(\n               \"(Intercept)\" = \"Intercept\", \n               \"v2x_polyarchy\" = \"Democratiescore\", \n               \"v2x_polyarchy_sq\" = \"Democratiescore gekwadrateerd\"), \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n        \n                \n                  Intercept\n                  -0.589*\n                \n                \n                  \n                  (0.243)\n                \n                \n                  Democratiescore\n                  -1.731\n                \n                \n                  \n                  (1.098)\n                \n                \n                  Democratiescore gekwadrateerd\n                  3.829***\n                \n                \n                  \n                  (1.051)\n                \n                \n                  Num.Obs.\n                  164\n                \n                \n                  R2\n                  0.401\n                \n                \n                  R2 Adj.\n                  0.394\n                \n        \n      \n    \n\n\n\nDe tabel hierboven maakt gebruik van de normale standaardfouten. We kunnen de robuuste opvragen via de vcov optie:\n\nmodelsummary(violence_sqmodel, \n             stars = T, \n             vcov = \"HC3\",\n             coef_rename = c(\n               \"(Intercept)\" = \"Intercept\", \n               \"v2x_polyarchy\" = \"Democratiescore\", \n               \"v2x_polyarchy_sq\" = \"Democratiescore gekwadrateerd\"), \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n        \n                \n                  Intercept\n                  -0.589+\n                \n                \n                  \n                  (0.303)\n                \n                \n                  Democratiescore\n                  -1.731\n                \n                \n                  \n                  (1.249)\n                \n                \n                  Democratiescore gekwadrateerd\n                  3.829***\n                \n                \n                  \n                  (1.107)\n                \n                \n                  Num.Obs.\n                  164\n                \n                \n                  R2\n                  0.401\n                \n                \n                  R2 Adj.\n                  0.394\n                \n        \n      \n    \n\n\n\n\nvcov = \"HC3\"\n\nDe vcov = optie vraagt om robuuste standaardfouten te berekenen en te gebruiken in de tabel. “HC3” staat voor ‘heteroskedasticiteit-robuuste standardfouten’. Er zijn verschillende heteroskedasticiteit-robuuste standaardfouten (bv., “HC0”, “HC1”, etc.). We raden “HC3” aan als standaard, ook omdat deze goed werkt bij kleine steekproefgroottes.\n\n\nLaten we de ‘normale’ en ‘robuuste’ standaardfouten vergelijken:\n\nmodelsummary(violence_sqmodel, \n             stars = T, \n             vcov = c(\"classical\", \"HC3\"), \n             coef_rename = c(\n               \"(Intercept)\" = \"Intercept\", \n               \"v2x_polyarchy\" = \"Democratiescore\", \n               \"v2x_polyarchy_sq\" = \"Democratiescore gekwadrateerd\"),\n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n                (2)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n        \n                \n                  Intercept\n                  -0.589*\n                  -0.589+\n                \n                \n                  \n                  (0.243)\n                  (0.303)\n                \n                \n                  Democratiescore\n                  -1.731\n                  -1.731\n                \n                \n                  \n                  (1.098)\n                  (1.249)\n                \n                \n                  Democratiescore gekwadrateerd\n                  3.829***\n                  3.829***\n                \n                \n                  \n                  (1.051)\n                  (1.107)\n                \n                \n                  Num.Obs.\n                  164\n                  164\n                \n                \n                  R2\n                  0.401\n                  0.401\n                \n                \n                  R2 Adj.\n                  0.394\n                  0.394\n                \n        \n      \n    \n\n\n\nDe eerste kolom toont de resultaten voor de ‘normale’ standaardfouten, de tweede kolom deze voor de ‘robuuste’ fouten. We kunnen het volgende opmerken:\n\nDe coëfficiënten veranderen niet, enkel de standaardfouten.\nDe robuuste standaardfouten zijn typisch groter. Heteroskedasticiteit zorgt immers doorgaans voor een neerwaarste bias: standaarfouten worden te klein geschat als we de normale methode zouden gebruiken.\nDe interpretatie van de resultaten verandert hier niet. De significantietoetsen voor de predictoren komen uit op dezelfde conclusies. Di is echter lang niet altijd het geval!\n\nHet voorbeeld hierboven maakt gebruik van modelsummary() en geeft de resultaten weer in een tabel. Ook voor voorspelde waarden en coëfficiëntenplots kunnen we robuuste standaardfouten gebruiken zodanig dat betrouwbaarheidsintervallen aangepast worden.\nWe blijven de bovenstaande vcov optie gebruiken, maar binnen de predictions() functie uit het marginaleffects package (bv., predictions(model, ..., vcov = \"HC3\")) voor voorspelde waarden.\nVoor coëfficiëntenplots kunnen we de syntax echter niet netjes combineren met tidy() zoals we deden in Hoofdstuk 8. In de plaats daarvan gebruiken we de avg_slopes() functie uit het marginaleffects package. avg_slopes() schat de marginale effecten van elke predictor in het model. Bij OLS is dit gelijk aan de coëfficiënten.\n\n# Resultaten via tidy\ntidy(violence_sqmodel)\n\n# A tibble: 3 × 5\n  term             estimate std.error statistic  p.value\n  &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)        -0.589     0.243     -2.42 0.0165  \n2 v2x_polyarchy      -1.73      1.10      -1.58 0.117   \n3 v2x_polyarchy_sq    3.83      1.05       3.64 0.000361\n\n# Resultaten  via avg_slopes\navg_slopes(violence_sqmodel)\n\n\n             Term Estimate Std. Error     z Pr(&gt;|z|)    S 2.5 % 97.5 %\n v2x_polyarchy       -1.73       1.10 -1.58    0.115  3.1 -3.88  0.421\n v2x_polyarchy_sq     3.83       1.05  3.64   &lt;0.001 11.9  1.77  5.888\n\nType:  response \nComparison: dY/dX\n\n\nWe voegen de vcov = optie toe aan de avg_slopes() functie en plotten de resultaten:\n\n# robuuste SEs en plot\n1avg_slopes(violence_sqmodel, vcov = \"HC3\") |&gt;\n  ggplot(aes(x = estimate, y = term)) + \n  geom_pointrange(aes(xmin = conf.low, xmax = conf.high)) + \n  geom_text(aes(label = round(estimate, 2)), vjust = -0.5) + \n  geom_vline(xintercept = 0, linetype = 'dashed', color = 'red') + \n  theme_bw() + \n  labs(x = \"Coëfficiënt\", \n       y = \"Onafhankelijke variabele\", \n       title = \"Coëfficiënten met Heteroskedasticiteit-robuuste betrouwbaarheidsintervallen\")\n\n\n1\n\nOpvragen van marginale effecten van de predictoren samen met de robuuste standaardfouten.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Assumptieschendingen oplossen</span>"
    ]
  },
  {
    "objectID": "errors.html#omgaan-met-afhankelijke-fouten",
    "href": "errors.html#omgaan-met-afhankelijke-fouten",
    "title": "Bijlage D — Assumptieschendingen oplossen",
    "section": "D.3 Omgaan met afhankelijke fouten",
    "text": "D.3 Omgaan met afhankelijke fouten\nEen tweede belangrijke assumptie in OLS (en logistische) modellen is deze van onafhankelijkheid. We gaan ervan uit dat de fouten in de populatie en in ons model niet gecorreleerd zijn met elkaar. Deze assumptie kan geschonden zijn wanneer data ‘geclusterd’ is.\n\nD.3.1 Probleem 1: geclusterde data\n\nD.3.1.1 Voorbeeld van het probleem\nStel dat we meten in welke mate burgers tevreden zijn met democratie in verschillende Europese landen (bv. met links-rechtspositie als predictor). We kunnen de European Social Survey (ESS) gebruike, waarbij respondenten uit verschillende landen werden ondervraagd. Wanneer de analyse meerdere landen beschouwt, zijn respondenten geclustert in hun land.\nWe bekijken de resultaten van een dergelijk model. De afhankelijke variabele meet tevredenheid met democratie op een schaal van 0 (“zeer ontevreden”) tot 10 (“zeer tevreden”). De onafhankelijke variabele meet links-rechtspositie met een schaal van 0 (“links”) tot 10 (“rechts”).\n\n# Model \ndemsatis_model &lt;- lm(stfdem ~ lrscale, data = ess_demsatis)\n\n# Coefficients\ntidy(demsatis_model, conf.int = TRUE)\n\n# A tibble: 2 × 7\n  term        estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    4.53    0.0308      147.  0            4.47      4.59 \n2 lrscale        0.128   0.00556      23.1 7.97e-117    0.117     0.139\n\n\nDe coëfficiënt voor links-rechtspositie (lrscale) is positief: mensen die zich meer aan de rechterkant van het politieke spectrum plaatsen zijn meer tevreden met democratie. De coëfficiënt is ook statistisch significant met wel een heel kleine p-waarde (7.97e-117). Laten we echter kijken hoe clustering hier bij komt kijken.\n\n\nShow the code\n# Extra package for plotting\n1library(patchwork)\n\n# Distribution plot\ndistribution_plot &lt;- ess_demsatis |&gt; \n2  group_by(country_name, stfdem) |&gt;\n  tally() |&gt; \n  ungroup() |&gt; \n3  group_by(country_name) |&gt;\n  mutate(prop = n / sum(n)) |&gt;\n  ggplot(aes(x = stfdem, y = prop)) + \n  geom_col() +\n  facet_wrap(~ country_name) + \n  theme_bw() + \n  labs(title = \"Variatie volgens Land\", \n       y = \"Proportie\", \n       x = \"Tevredenheidsscore\") + \n  scale_x_continuous(breaks = c(0,5,10))\n\n# Plot of means\nmean_plot &lt;- ess_demsatis |&gt; \n  group_by(country_name) |&gt; \n  summarize(dem_satis = mean(stfdem, na.rm = T)) |&gt; \n4  ggplot(aes(x = dem_satis, y = reorder(country_name, dem_satis))) +\n  geom_col() + \n  theme_bw() + \n  labs(title = \"Gemiddelde per land\", \n       y = \"Naam land\", \n       x = \"Gemiddelde tevredenheid met democratie\")\n\n# Combine together using patchwork\ndistribution_plot + mean_plot\n\n\n\n1\n\nDe patchwork library wordt hier gebruikt om meerdere grafieken te combineren met elkaar.\n\n2\n\nDeze regels berekenen het aantal antwoorden per antwoordcategorie per land.\n\n3\n\nWe berekenen hier de proportie van observaties met een specifieke respons per land.\n\n4\n\nDe reorder() optie herordent de y-as zodat die loopt van hogere tot lagere gemiddelde scores.\n\n\n\n\n\n\n\n\n\n\n\nHet linkse plot in de figuur hierboven toont de proportie observaties per antwoordcategorie (x-as) per land (aparte ‘facets’). De plot toont variatie tussen individuen binnen een land: sommige zijn tevreden, andere niet. De verdeling van observaties is echter niet dezelfde per land. Sommige landen zien meer tevreden respondenten (bv., Finland, Norwegen, en Zwitserland) terwijl in andere landen mensen zich meer onderaan de schaal bevinden (bv., Bulgarije, Servië, en Griekenland).\nEr is dus niet alleen variatie tussen individuen, maar ook variatie tussen landen. Dit zien we ook op het rechtse plot, dat de gemiddelde tevedenheidsscore per land weergeeft.2\nDemocratische tevredenheid is hoger in sommige landen dan andere. Daar kunnen verschillende redenen voor bestaan: andere politieke instituties, economische welvaart, corruptieniveaus enz. Mensen binnen een land leven in een context waarin die factoren gelijk zijn, maar mensen buiten een bepaald land leven in andere omstandigheden. We kunne dan ook verwachten dat errors van mensen binnen een bepaald land gecorreleerd zijn met elkaar in een studie waarbij meerdere landen zijn opgenomen.De standaardfouten in het model zijn dan wellicht ook niet correct.3\nWe kunnen 2 methoden gebruiken om dit te corrigeren:4\nWe kunnen gebruik maken van “geclusterde standaardfouten” en “fixed effects”. Net zoals bij heteroskedasticiteit herberekenen we de standaardfouten (Let op: de berekening is wel anders). Deze corrigeren voor het feit dat de errors van observaties binnen een cluster (hier: land) gecorreleerd zijn. Fixed effects toevoegen houdt in dat we een dummy-variabele toevoegen per cluster (hier:land) om te controleren op variaties in de afhankelijke variabele afkomstig uit kenmerken van de cluster.\nSommige onderzoekers maken ook gebruik van “multilevel modellen”. Met deze modellen kunnen predictoren op het niveau van individuele respondenten alsook predictoren op het cluster-niveau worden toegevoegd (bv. BBP) Deze methode is te gevorderd voor dit handboek en wordt verder niet besproken.\n\n\n\nD.3.2 Mogelijke oplossing: Clustered standard errors & fixed effects\nWe schatten ons model met geclusterde standaardfouten met de code uitgelegd hieronder. Om “fixed effects” toe te voegen transformeren we gewoon de clustervariabele in een factor-variabele. Wanneer we deze factor toevoegen aan het model neemt R dummies op voor elke cluster, behoudens de referentiecategorie. 5\n\n# factor maken\ness_demsatis &lt;- ess_demsatis |&gt; \n  mutate(\n    country_name_F = factor(country_name))\n\n# Controleren of alles juist is gegaan: Austria is hier de referentiecategorie\nlevels(ess_demsatis$country_name_F)\n\n [1] \"Austria\"        \"Belgium\"        \"Bulgaria\"       \"Croatia\"       \n [5] \"Cyprus\"         \"Finland\"        \"France\"         \"Germany\"       \n [9] \"Greece\"         \"Hungary\"        \"Iceland\"        \"Ireland\"       \n[13] \"Israel\"         \"Italy\"          \"Latvia\"         \"Lithuania\"     \n[17] \"Montenegro\"     \"Netherlands\"    \"Norway\"         \"Poland\"        \n[21] \"Portugal\"       \"Serbia\"         \"Slovakia\"       \"Slovenia\"      \n[25] \"Spain\"          \"Sweden\"         \"Switzerland\"    \"United Kingdom\"\n\n# Factor toevoegen aan model\ndemsatis_model2 &lt;- lm(stfdem ~ lrscale + country_name_F, data = ess_demsatis)\n\n# Coëfficiënten opvragen\ntidy(demsatis_model2, conf.int = TRUE)\n\n# A tibble: 29 × 7\n   term                estimate std.error statistic   p.value conf.low conf.high\n   &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)           5.15     0.0568     90.7   0            5.03     5.26  \n 2 lrscale               0.136    0.00521    26.2   4.59e-150    0.126    0.147 \n 3 country_name_FBelg…  -0.550    0.0790     -6.96  3.45e- 12   -0.704   -0.395 \n 4 country_name_FBulg…  -2.42     0.0751    -32.1   7.25e-224   -2.56    -2.27  \n 5 country_name_FCroa…  -1.35     0.0819    -16.5   8.89e- 61   -1.51    -1.19  \n 6 country_name_FCypr…  -1.27     0.108     -11.7   8.62e- 32   -1.49    -1.06  \n 7 country_name_FFinl…   0.885    0.0791     11.2   4.70e- 29    0.730    1.04  \n 8 country_name_FFran…  -1.53     0.0782    -19.6   4.41e- 85   -1.68    -1.38  \n 9 country_name_FGerm…  -0.0598   0.0705     -0.848 3.96e-  1   -0.198    0.0784\n10 country_name_FGree…  -1.62     0.0703    -23.0   1.57e-116   -1.76    -1.48  \n# ℹ 19 more rows\n\n\nHet model bevat nu een coëfficiënt voor links-rechtspositie (lrscale) en een reeks dummy-variabelen voor elk land (country_name_FBelgium, country_name_FBulgaria, etc.). Schrik niet van deze output, dit is effectief de bedoeling!\nDe coëfficient voor lrscale toont de associatie tussen links-rechtspositie en tevredenheid met democratie, gecontroleerd voor het land waar de respondent zich bevindt. De dummy-coëfficiënten tonen het verschil tussen elk land en de referentiecategorie (Oostenrijk), gecontroleerd voor lrscale. We vinden bijvoorbeeld dat als we Bulgaarse en Oostenrijkse burgers met dezelfde ideologiescore zouden vergelijken, dan zouden we verwachten dat tevredenheid van Bulgaarse burgers gemiddeld genomen 2.42 eenheden lager is dan die van Oostenrijkse burgers.\nDe resultaten hieboven maken nog gebruik van de ‘normale’ standaardfouten. We kunnen de geclusterde standaardfouten toevoegen via modelsummary() met de vcov = optie, zoals hieronder (coef_rename hebben we hier even weggelaten).\n\nmodelsummary(\n  demsatis_model2, \n  stars = T, \n  vcov = ~country_name_F, \n  gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n        \n                \n                  (Intercept)\n                  5.146***\n                \n                \n                  \n                  (0.230)\n                \n                \n                  lrscale\n                  0.136**\n                \n                \n                  \n                  (0.048)\n                \n                \n                  country_name_FBelgium\n                  -0.550***\n                \n                \n                  \n                  (0.012)\n                \n                \n                  country_name_FBulgaria\n                  -2.415***\n                \n                \n                  \n                  (0.022)\n                \n                \n                  country_name_FCroatia\n                  -1.349***\n                \n                \n                  \n                  (0.018)\n                \n                \n                  country_name_FCyprus\n                  -1.273***\n                \n                \n                  \n                  (0.021)\n                \n                \n                  country_name_FFinland\n                  0.885***\n                \n                \n                  \n                  (0.035)\n                \n                \n                  country_name_FFrance\n                  -1.531***\n                \n                \n                  \n                  (0.010)\n                \n                \n                  country_name_FGermany\n                  -0.060***\n                \n                \n                  \n                  (0.013)\n                \n                \n                  country_name_FGreece\n                  -1.620***\n                \n                \n                  \n                  (0.023)\n                \n                \n                  country_name_FHungary\n                  -1.353***\n                \n                \n                  \n                  (0.040)\n                \n                \n                  country_name_FIceland\n                  0.121***\n                \n                \n                  \n                  (0.001)\n                \n                \n                  country_name_FIreland\n                  0.098***\n                \n                \n                  \n                  (0.005)\n                \n                \n                  country_name_FIsrael\n                  -1.733***\n                \n                \n                  \n                  (0.055)\n                \n                \n                  country_name_FItaly\n                  -0.736***\n                \n                \n                  \n                  (0.016)\n                \n                \n                  country_name_FLatvia\n                  -1.313***\n                \n                \n                  \n                  (0.052)\n                \n                \n                  country_name_FLithuania\n                  -1.003***\n                \n                \n                  \n                  (0.019)\n                \n                \n                  country_name_FMontenegro\n                  -1.307***\n                \n                \n                  \n                  (0.029)\n                \n                \n                  country_name_FNetherlands\n                  0.172***\n                \n                \n                  \n                  (0.010)\n                \n                \n                  country_name_FNorway\n                  1.343***\n                \n                \n                  \n                  (0.015)\n                \n                \n                  country_name_FPoland\n                  -0.672***\n                \n                \n                  \n                  (0.034)\n                \n                \n                  country_name_FPortugal\n                  -0.946***\n                \n                \n                  \n                  (0.005)\n                \n                \n                  country_name_FSerbia\n                  -1.741***\n                \n                \n                  \n                  (0.008)\n                \n                \n                  country_name_FSlovakia\n                  -1.230***\n                \n                \n                  \n                  (0.014)\n                \n                \n                  country_name_FSlovenia\n                  -0.811***\n                \n                \n                  \n                  (0.003)\n                \n                \n                  country_name_FSpain\n                  -1.019***\n                \n                \n                  \n                  (0.008)\n                \n                \n                  country_name_FSweden\n                  0.799***\n                \n                \n                  \n                  (0.002)\n                \n                \n                  country_name_FSwitzerland\n                  1.710***\n                \n                \n                  \n                  (0.011)\n                \n                \n                  country_name_FUnited Kingdom\n                  -1.327***\n                \n                \n                  \n                  (0.008)\n                \n                \n                  Num.Obs.\n                  39522\n                \n                \n                  R2\n                  0.160\n                \n                \n                  R2 Adj.\n                  0.160\n                \n        \n      \n    \n\n\n\n\nvcov = \\~country_name_F\n\nMet deze optie vragen we om geclusterde standaardfouten te berekenen voor ons model. De clustervariabele moet aangeduid worden in de syntax.\n\n\nWe kunnen de vcov optie ook gebruiken voor voorspellingen en marginal effects binnen de avg_slopes en predictions functies:\n\npredictions(demsatis_model2, \n            newdata = datagrid(lrscale = c(0:10)), \n            vcov = ~country_name_F) |&gt; \n  ggplot(aes(x = lrscale, y = estimate)) + \n  geom_line() + \n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2) + \n  theme_bw() + \n  labs(title = \"Voorspelde waarden met geclusterde standaardfouten\", \n       x = \"Links-rechtspositionering\", \n       y = \"Voorspelde tevredenheid met democratie\") + \n  scale_x_continuous(breaks = c(0:10)) + \n  scale_y_continuous(limits = c(0,10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPresentatie\n\n\n\nMet de modelsummary functie hierboven creëerden we een regressietabel met de coëfficiënten voor alle `country_name_F’- categorieën. Als er echter heel veel dummies zijn (en die dummies zijn ook minder relevant voor de interpetatie), dan worden ze vaak weggelaten in de output. Wel moet je in de notitie aan de lezer verduidelijken dat ‘fixed effects’ en geclusterde standaardfouten werden gebruikt.\nWe gebruiken coef_map om bepaalde coëfficiënten weg te kunnen laten in de output (zie Paragraaf 15.2).\n\nmodelsummary(\n  demsatis_model2, \n  stars = T, \n  vcov = ~country_name_F, \n  coef_map = c(\"(Intercept)\" = \"Constante\", \n               \"lrscale\" = \"Links-Rechtspositie\"),\n  gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"),\n  title = \"Democratische tevredenheid en links-rechtspositie\", \n  notes = \"Lineaire regressiecoëfficiënten met geclusterde standaardfouten tussen haakjes. Model geschat met country fixed effects.\")\n\n\n\n    \n\n    \n    \n      \n        \n        Democratische tevredenheid en links-rechtspositie\n              \n                 \n                (1)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\nLineaire regressiecoëfficiënten met geclusterde standaardfouten tussen haakjes. Model geschat met country fixed effects.\n        \n                \n                  Constante\n                  5.146***\n                \n                \n                  \n                  (0.230)\n                \n                \n                  Links-Rechtspositie\n                  0.136**\n                \n                \n                  \n                  (0.048)\n                \n                \n                  Num.Obs.\n                  39522\n                \n                \n                  R2\n                  0.160\n                \n                \n                  R2 Adj.\n                  0.160\n                \n        \n      \n    \n\n\n\n\n\n\n\nD.3.3 Probleem 2: Data over de tijd heen en seriële autocorrelatie\nDe assumptie van onafhankelijke fouten kan ook geschonden worden als we dezelfde eenheid (bv. een persoon, land, bedrijf) observeren over meerder punten in de tijd. Dit wordt ‘time-series’ data genoemd.\nStel bijvoorbeeld dat we geïnteresseerd zijn in de relatie tussen welvaart en democratie in een land. We maken hier gebruik van V-Dem data en kijken naar de relatie tussen welvaart van een land (e_gdp) en democratiescore (v2x_polyarchy). We richten ons eerst op Nederland. Hieronder tonen we hoe de data eruit ziet.\n\n#Filteren op Nederland\nnetherlands &lt;- serial_data |&gt; \n  filter(country_name == \"Netherlands\")\n\n#eerste 15 rijen in de dataset bekijken\nhead(netherlands, n = 15L)\n\n   country_name year v2x_polyarchy    e_gdp\n1   Netherlands 1789         0.076 2309.141\n2   Netherlands 1790         0.076 2362.091\n3   Netherlands 1791         0.076 2411.786\n4   Netherlands 1792         0.076 2454.337\n5   Netherlands 1793         0.076 2481.157\n6   Netherlands 1794         0.076 2485.290\n7   Netherlands 1795         0.097 2463.161\n8   Netherlands 1796         0.133 2486.460\n9   Netherlands 1797         0.181 2491.454\n10  Netherlands 1798         0.179 2447.313\n11  Netherlands 1799         0.127 2358.512\n12  Netherlands 1800         0.127 2249.312\n13  Netherlands 1801         0.127 2283.304\n14  Netherlands 1802         0.127 2304.492\n15  Netherlands 1803         0.127 2283.129\n\n\nDe dataset meet de variabelen vanaf 1789. Maar vinden we een relatie tussen de twee variabelen? Gaat hogere welvaart gepaard met meer democratie? We kunnen een lineaire regressie schatten om dit te proberen nagaan. We beperken ons hier tot een bivariate analyse. In de praktijk zou je ook op zoek willen gaan naar controlevariabelen.6\n\n# Het model\nneth_model1 &lt;- lm(v2x_polyarchy ~ e_gdp, data = netherlands)\n\n# Coëfficiënt bekijken\ntidy(neth_model1, conf.int = TRUE)\n\n# A tibble: 2 × 7\n  term          estimate   std.error statistic  p.value   conf.low  conf.high\n  &lt;chr&gt;            &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 (Intercept) 0.355      0.0166           21.4 2.14e-56 0.323      0.388     \n2 e_gdp       0.00000384 0.000000255      15.0 5.82e-36 0.00000334 0.00000434\n\n\nDe coëfficiënt voor e_gdp is positief. Het getal is erg klein, maar dit betekent niet noodzakelijk een klein effect gezien de predictor hier een sterke spreiding heeft. De coëfficiënt is ook statistisch significant.\nEchter moeten we opletten: onze observaties zijn allemaal gelinkt aan hetzelfde land en zijn dus niet onafhankelijk. Dit betekent vaak dat we de standaardfouten onderschatten en we kunnen zo onterecht significate effecten vinden.\nDit probleem is gekend als seriële autocorrelatie: de errors van het model zijn gecorreleerd met elkaar over de tijd heen. Een error op tijdstip t is systematisch gerelateerd aan de error van het jaar voordien, t-1. Dit is logisch gezien de welvaart en het democratisch gehalte van een land vrij stabiel zijn en afhangen van onderliggende condities zoals economische instituties, natuurlijke rijkdommen enz. Deze factoren fluctueren niet zo sterk over de tijd heen waardoor opeenvolgende errors vaak lijken op elkaar.\nWe kunnen formeel nagaan of er seriële autocorrelatie aanwezig is met behulp van de Durbin-Watson statistiek zoals besproken in Hoofdstuk 7.\n\n1car::durbinWatsonTest(neth_model1)\n\n\n1\n\nHet car:: prefix staat ons hier toe om het carpackage te gebruiken zonder het te moeten laden. Dit heeft voordelen gezien carook funties heeft die conflicteren met andere functies die we gebruiken, in het bijzonder de recode functie uit het dplyr/tidyverse package.\n\n\n\n\n lag Autocorrelation D-W Statistic p-value\n   1       0.9667039    0.05304265       0\n Alternative hypothesis: rho != 0\n\n\nDe Autocorrelation kolom geeft de correlatie weer tussen errors van het ene jaar op het andere. De correlatie is 0.97. Dit is hoog, gezien het maximum +1 is. De D-W Statistic test formeel of de autocorrelatie te hoog is. Dit is het geval als D-W hoger is dan 3 of kleiner dan 1. Hier is het duidelijk lager dan 1 (0.053). De p-waarde is extreem klein en dus verwerpen we de nulhypothese dat er geen autocorrelatie is. De standaardfouten zijn niet correct.\nWe kunnen dit probleem oplossen door een ‘vertraagde afhankelijke variabele’ (‘lagged dependent variable’) toe te voegen als predictor in ons model. Deze vertraagde afhankelijke variabele bevat voor elke observatie de score voor de afhankelijke variabele in het onmiddellijk voorgaande tijdspunt. Door deze variabele op te nemen wordt het probleem van stabiliteit/inertie in de afhankelijke variabele (en gecorreleerde errors) verholpen.7\n\nD.3.3.1 Lagged Dependent Variables maken\nWe kunnen de lag() functie gebruiken om onze afhankelijke variabele te ‘vertragen’ voor een nieuw aangemaakte variabele.8\n\nnetherlands &lt;- netherlands |&gt; \n  mutate(dem_lag = lag(v2x_polyarchy, 1))\n\n\nlag(v2x_polyarchy, 1)\n\nWe gebruiken de functie lag op de relevante afhankelijke variabele (hier, v2x_polyarchy). Het nummer aan het einde van de functie geeft weer hoeveel eenheden vertraging we willen. Met het cijfer 1 zeggen we 1 tijdseenheid (hier: 1 jaar). Dit is het meest gebruikelijk. Indien we de v2x_polyarchy score van 2 jaar terug zouden willen, dan schrijven we ‘2’ enzovoort.\n\n\nLaten we even kijken wat dat doet:\n\nhead(netherlands, n = 15L)\n\n   country_name year v2x_polyarchy    e_gdp dem_lag\n1   Netherlands 1789         0.076 2309.141      NA\n2   Netherlands 1790         0.076 2362.091   0.076\n3   Netherlands 1791         0.076 2411.786   0.076\n4   Netherlands 1792         0.076 2454.337   0.076\n5   Netherlands 1793         0.076 2481.157   0.076\n6   Netherlands 1794         0.076 2485.290   0.076\n7   Netherlands 1795         0.097 2463.161   0.076\n8   Netherlands 1796         0.133 2486.460   0.097\n9   Netherlands 1797         0.181 2491.454   0.133\n10  Netherlands 1798         0.179 2447.313   0.181\n11  Netherlands 1799         0.127 2358.512   0.179\n12  Netherlands 1800         0.127 2249.312   0.127\n13  Netherlands 1801         0.127 2283.304   0.127\n14  Netherlands 1802         0.127 2304.492   0.127\n15  Netherlands 1803         0.127 2283.129   0.127\n\n\nElke rij in de dataset bevat waarden per uniek jaar (1789, 1790, …). v2x_polyarchy geeft de democratiescore van het land in het betreffende jaar. De nieuwe kolom (dem_lag) geeft de score in het voorgaande jaar. De waarde voor dem_lag in rij 9 (year = 1797) is 0.133; dis was de waarde voor democratie in 1796 (rij 8).We zien NA in de eerste rij gezien we geen voorgaande data hebben.\n\n\n\n\n\n\nWaarschuwing!\n\n\n\nHet spreekt voor zich dat de dataset eerst netjes geordend moet zijn op jaar vooraleer we functies zoals car::durbinWatsonTesten lag kunnen gebruiken. Hoe je een dataset kan ordenen (indien nodig) wordt besproken in Hoofdstuk 7.\n\n\nWe voegen nu de lagged dependent variabele toe als predictor aan ons origineel model\n\n# Het nieuwe model\nneth_model2 &lt;- lm(v2x_polyarchy ~ e_gdp + dem_lag, data = netherlands)\n\n# Coëfficiënten opvragen\ntidy(neth_model2, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term            estimate    std.error statistic   p.value   conf.low conf.high\n  &lt;chr&gt;              &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept) 0.0121       0.00667          1.81  7.20e-  2   -1.09e-3   2.52e-2\n2 e_gdp       0.0000000561 0.0000000838     0.669 5.04e-  1   -1.09e-7   2.21e-7\n3 dem_lag     0.978        0.0155          63.3   2.53e-145    9.48e-1   1.01e+0\n\n#Opvragen model fit statistieken via broom::glance()\nglance(neth_model2)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared  sigma statistic   p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.973         0.973 0.0486     4110. 7.47e-178     2   367. -727. -713.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\nDe coëfficiënt voor dem_lag is 0.978. Dit is hoog, onze afhankelijke variabele heeft een bereik van 0 tot 1. De coëfficiënt toont dus dat er sterke stabiliteit is tussen democratiescores in opeenvolgende jaren. 9 We vinden dan ook dat de R2 statistieken dichtbij hun maxima van 1 zitten: toevoeging van de lagged dependent variable verklaart bijna alle variatie in democratiescore.\nDe coëfficiënt voor e_gdp toont de associate tussen BBP en democratiescores gecontroleerd voor democratiescore in het voorgaande jaar. Dit vertelt ons eigenlijk of BBP gerelataard is aan verandering in democratiescore van jaar tot jaar. De coëfficiënt is positief, maar niet langer significant.\nHebben we daarmee het probleem van autocorrelatie opgelost? We gaan het na:\n\ncar::durbinWatsonTest(neth_model2) \n\n lag Autocorrelation D-W Statistic p-value\n   1       0.2865016      1.425975   0.006\n Alternative hypothesis: rho != 0\n\n\nAutocorrelatie bedraagt nu slechts 0.29, wat veel lager is dan de 0.97 in het voorgaande model. De D-W statistiek bevindt zich nu tussen 1 en 3. Er is nog autocorrelatie (zie de ook de p-waarde), maar we hebben al veel in rekening gebracht.\nVoorgaand voorbeeld was gericht op 1 land, namelijk Nederland. In het geval we meerdere landen hebben kunnen we ook de lag functie gebruiken, maar er zal wel een probleem optreden waar we ons van bewust moeten zijn. We tonen eerst wat het probleem is en bieden dan een oplossing:\n\nserial_data |&gt; \n  mutate(dem_lag = lag(v2x_polyarchy)) |&gt; \n1  slice(225:235)\n\n\n1\n\nDeze syntax vraagt R om de data te ‘snijden’ en data te tonen voor rij 225 tot en met 235.\n\n\n\n\n   country_name year v2x_polyarchy      e_gdp dem_lag\n1        Mexico 2013         0.623 423815.579   0.649\n2        Mexico 2014         0.620 429987.309   0.623\n3        Mexico 2015         0.639 432220.100   0.620\n4        Mexico 2016         0.640 440041.959   0.639\n5        Mexico 2017         0.635 449152.118   0.640\n6        Mexico 2018         0.675 455569.106   0.635\n7        Mexico 2019         0.685 456743.982   0.675\n8      Suriname 1960         0.526    237.768   0.685\n9      Suriname 1961         0.526    244.437   0.526\n10     Suriname 1962         0.526    255.809   0.526\n11     Suriname 1963         0.527    272.408   0.526\n\n\nWe tonen hier de transitie in de dataset van Mexico naar Suriname. In rij 7 bevind zich de data voor Mexico voor het laats beschikbare jaar 2019. Dan springt de dataset naar het eerste jaar voor Suriname, namelijk 1960. Als we kijken naar de dem_lag variabele zien we dat Suriname in 1960 de democratiescore van Mexico in 2019 heeft meegekregen. Dat mag natuurlijk niet. Zonder correctie doet R dit voor alle punten in de dataset waar we van 1 land naar een ander land gaan.\nWe vermijden dit door de group_by() functie te gebruiken:\n\nserial_data &lt;- serial_data |&gt; \n  group_by(country_name) |&gt; \n  mutate(dem_lag = lag(v2x_polyarchy)) |&gt; \n  ungroup() \n\n\ngroup_by(country_name)\n\nDe group_by() functie vraagt R om de dataset eerst te groeperen volgens de variabele tussen haakjes (hier: country_name). Daarna pas wordt de lagfunctie, via mutate(), toegepast. Wat er precies gebeurt kun je zien met deze gif van Andrew Heiss (2024):\n\nHeiss, Andrew. 2024. ‘Visualizing {Dplyr}’s Mutate(), Summarize(), Group_by(), and Ungroup() with Animations’. 4 april 2024. https://doi.org/10.59350/d2sz4-w4e25.\n\n\n\n\nungroup()\n\nDeze functie is nodig om mutate te vertellen dat we niet langer willen groeperen voor toekomstige toepassingen van de functie. Anders blijft mutate verdere bewerkingen per groep uitvoeren.\n\n\nLaten we bekijken wat er gebeurt is\n\nserial_data |&gt; \n  slice(225:235)\n\n# A tibble: 11 × 5\n   country_name  year v2x_polyarchy   e_gdp dem_lag\n   &lt;chr&gt;        &lt;dbl&gt;         &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 Mexico        2013         0.623 423816.   0.649\n 2 Mexico        2014         0.62  429987.   0.623\n 3 Mexico        2015         0.639 432220.   0.62 \n 4 Mexico        2016         0.64  440042.   0.639\n 5 Mexico        2017         0.635 449152.   0.64 \n 6 Mexico        2018         0.675 455569.   0.635\n 7 Mexico        2019         0.685 456744.   0.675\n 8 Suriname      1960         0.526    238.  NA    \n 9 Suriname      1961         0.526    244.   0.526\n10 Suriname      1962         0.526    256.   0.526\n11 Suriname      1963         0.527    272.   0.526\n\n\nWe zien nu een NA waarde in rij 8, het eerste beschikbare jaar voor Suriname. Dit is wat we willen.\nWe zouden nu de regressie opnieuw kunnen uitvoeren. Onze dataset heeft nu echter niet alleen een time series element, maar bevat ook geclusterde data want meerdere landen zijn opgenomen. We zullen de lagged dependent variable-techniek dus moeten combineren met bovenstaande technieken voor clustering (fixed effects en geclusterde standaardfouten).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Assumptieschendingen oplossen</span>"
    ]
  },
  {
    "objectID": "errors.html#omgaan-met-niet-normaal-verdeelde-residuals",
    "href": "errors.html#omgaan-met-niet-normaal-verdeelde-residuals",
    "title": "Bijlage D — Assumptieschendingen oplossen",
    "section": "D.4 Omgaan met niet-normaal verdeelde residuals",
    "text": "D.4 Omgaan met niet-normaal verdeelde residuals\n\nD.4.1 Wat was het probleem ook al weer?\nDe laatste assumptie die we hier bekijken stelt dat de errors/residuals/fouten in een OLS model normaal verdeeld zijn. Of aan deze assumptie voldaan is kunnen we nagaan met plots gemaakt via resid_panel(): een histogram van de residuals en een Q-Q plot van de residuals.\n\n# Model schatten\nnorm_model &lt;- lm(v2x_polyarchy ~ gini_disp + pr_fct + region1, data = normal_residual_data)\n\n# Coëfficiënten opvragen\ntidy(norm_model, conf.int = TRUE)\n\n# A tibble: 6 × 7\n  term            estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)      0.641     0.195       3.29  0.00154   0.253    1.03   \n2 gini_disp       -0.00492   0.00531    -0.928 0.357    -0.0155   0.00566\n3 pr_fctPR System  0.0831    0.0619      1.34  0.184    -0.0404   0.207  \n4 region1Africa   -0.0940    0.114      -0.824 0.413    -0.321    0.133  \n5 region1Europe    0.176     0.0665      2.65  0.00997   0.0435   0.309  \n6 region1Americas  0.168     0.0710      2.37  0.0207    0.0265   0.310  \n\n# Assumptie checken\nresid_panel(norm_model, plots = c(\"hist\", \"qq\"))\n\n\n\n\n\n\n\n\nBeide grafieken leiden tot dezelfde vaststelling: de assumptie is geschonden (zie Hoofdstuk 7). Met een relatief grote steekproef is een schending van deze assumptie doorgaans geen probleem. In kleine steekproeven kan dit wel problematisch zijn. Hier zien we met de glance() functie uit het broom package dat we met een kleine steekproef te maken hebben:\n\nglance(norm_model)$nobs\n\n[1] 77\n\n\nWe hebben 77 observaties in het model. Is dit klein of groot genoeg? Jammergenoeg bestaat hier geen eenduidig antwoord voor. Een vuistregel is dat we met een kleine steekproef te maken hebben bij minder dan 15 observaties per onafhankelijke variabele. Hier hebben we 5 predictors. We vinden dan dat we met 77 observaties net 2 meer hebben dan de vuistregel voorschrijft (5 * 15 = 75). Dit is echter dicht bij de grens, dus misschien is het toch veiliger om rekening te houden met een assumptieschending.\n\n\nD.4.2 Mogelijke oplossing: bootstrapping\nOok voor een schending van deze assumptie (met een kleine steekproef) moeten we de standaardfouten herberekenen. We gebruiken in dit geval weer een andere herberekening dan hierboven, namelijk ‘gebootstrapte’ standaardfouten. Met bootstrapping worden standaardfouten herschat met de volgende procedure:\nWe nemen een steekproef van de oorspronkelijke steekproef met dezelfde grootte. Dit gebeurt met teruglegging van de observaties, dat wil zeggen 1 observatie kan meerdere malen opgenomen worden in de nieuwe steekproef. Dat moet natuurlijk, anders kom je gewoon telkens dezelfde steekproef uit. Op basis van de nieuwe steekproef schatten we coëfficiënt en standaardfout opnieuw en slagen de resultaten op. Dit doen we een aantal keren. Ten slotte kijken we naar alle verschillende coëfficiënten die we uitgekomen zijn en in het bijzonder naar de standaardafwijking van de verzameling coëfficiënten. Deze standaardafwijking wordt de ’gebootstrapte’standaardfout.\nOok deze standaardfout kunnen we bekomen met de vcov= optie in de modelsummary() syntax. Wat nieuw is hier is dat we een element van toeval toevoegen in de berekening: R gaat ‘random’ nieuwe steekproeven trekken. Op zich is dit goed -moeten wij het niet doen!- maar juist door dit toevalselement kan de uitkomst telkens licht anders zijn. Om resultaten reproduceerbaar te houden zetten we hier dan ook een ‘seed’: een seed is een zelfgekozen startgeval (je kan 1 gebruiken maar ook je verjaardag enz.). Met de seed houdt R bij welke steekproeven precies getrokken werden en worden telkens dezelfde resultaten bereikt. Voor je je seed vastlegt wil je wel eerst nagaan of je met hetzelfde aantal steekproeven sterk verschillende resultaten uitkomt, want in dat geval vraag je R best meer steekproeven te trekken voor betere schattingen, zie onder).\n\n# seed vastleggen\nset.seed(1)\n\n# Model schatten \nmodelsummary(norm_model, \n             stars = T, \n             vcov = \"bootstrap\", \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n        \n                \n                  (Intercept)\n                  0.641**\n                \n                \n                  \n                  (0.230)\n                \n                \n                  gini_disp\n                  -0.005\n                \n                \n                  \n                  (0.006)\n                \n                \n                  pr_fctPR System\n                  0.083\n                \n                \n                  \n                  (0.082)\n                \n                \n                  region1Africa\n                  -0.094\n                \n                \n                  \n                  (0.100)\n                \n                \n                  region1Europe\n                  0.176*\n                \n                \n                  \n                  (0.079)\n                \n                \n                  region1Americas\n                  0.168*\n                \n                \n                  \n                  (0.080)\n                \n                \n                  Num.Obs.\n                  77\n                \n                \n                  R2\n                  0.305\n                \n                \n                  R2 Adj.\n                  0.256\n                \n        \n      \n    \n\n\n\n\nset.seed(1)\n\nWe zetten het toevallig trekken van steekproeven hier vast met een zelfgekozen getal zodat resultaten dezelfde blijven.\n\nvcov = \"boostrap\"\n\nDeze optie vraagt om de ‘gebootstrapte’ standaarfouten.\n\n\nWe kunnen de standaardfouten vergelijken:\n\n# Seed: zelfde als hierboven want dan krijgen we zelfde resultaten\nset.seed(1)\n\n# Modellen vergelijken\nmodelsummary(norm_model, \n             stars = T, \n             vcov = c(\"classical\", \"bootstrap\"),\n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n                (2)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n        \n                \n                  (Intercept)\n                  0.641**\n                  0.641**\n                \n                \n                  \n                  (0.195)\n                  (0.230)\n                \n                \n                  gini_disp\n                  -0.005\n                  -0.005\n                \n                \n                  \n                  (0.005)\n                  (0.006)\n                \n                \n                  pr_fctPR System\n                  0.083\n                  0.083\n                \n                \n                  \n                  (0.062)\n                  (0.082)\n                \n                \n                  region1Africa\n                  -0.094\n                  -0.094\n                \n                \n                  \n                  (0.114)\n                  (0.100)\n                \n                \n                  region1Europe\n                  0.176**\n                  0.176*\n                \n                \n                  \n                  (0.067)\n                  (0.079)\n                \n                \n                  region1Americas\n                  0.168*\n                  0.168*\n                \n                \n                  \n                  (0.071)\n                  (0.080)\n                \n                \n                  Num.Obs.\n                  77\n                  77\n                \n                \n                  R2\n                  0.305\n                  0.305\n                \n                \n                  R2 Adj.\n                  0.256\n                  0.256\n                \n        \n      \n    \n\n\n\nWat merken we op:\n\nDe coëfficiënten veranderen niet, enkel de standaardfouten. Dat zagen we ook bij heteroskedasticiteit-robuuste standaardfouten en geclusterde standaardfouten\nDe standaardfouten zijn verschillend. Doorgaans, maar niet altijd, zijn gebootstrapte standaardfouten groter.\nConclusies over de significantie van resultaten blijven hier dezelfde, hoewel we zien dat het significantieniveau voor de coëfficiënt van region1Europe veranderd is van p &lt; 0.01 naar p &lt; 0.05. De gevolgen kunnen veel groter zijn in andere analyses.\n\nZoals gezegd neemt R zelf nieuwe toevalssteekproeven. Standaard worden 250 steekproeven genomen. Zoals eerder gezegd zet je een ‘seed’ om resultaten gelijk te houden, maar natuurlijk is het niet echt betrouwbaar als resultaten bij elke trekking sterk veranderen. Vooraleer te beslissen om je seed vast te leggen, wil je nagaan of resultaten sterk verschillen zonder seed. Als dit het geval is, wil je R vragen meer steekproeven te trekken om betere schattingen te maken van de standaardfouten. Dit doen we in onderstaande syntax door R om 1000 steekproeven te vragen. We zetten een seed in de syntax, maar ga ervanuit dat we eerst goed gekeken hebben naar verschillende uitkomsten vooraleer een seed te zetten.\n\nset.seed(1) \n\nmodelsummary(norm_model, \n             stars = T, \n             vcov = \"bootstrap\", \n             R = 1000, \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n        \n                \n                  (Intercept)\n                  0.641**\n                \n                \n                  \n                  (0.216)\n                \n                \n                  gini_disp\n                  -0.005\n                \n                \n                  \n                  (0.006)\n                \n                \n                  pr_fctPR System\n                  0.083\n                \n                \n                  \n                  (0.079)\n                \n                \n                  region1Africa\n                  -0.094\n                \n                \n                  \n                  (0.101)\n                \n                \n                  region1Europe\n                  0.176*\n                \n                \n                  \n                  (0.076)\n                \n                \n                  region1Americas\n                  0.168*\n                \n                \n                  \n                  (0.081)\n                \n                \n                  Num.Obs.\n                  77\n                \n                \n                  R2\n                  0.305\n                \n                \n                  R2 Adj.\n                  0.256\n                \n        \n      \n    \n\n\n\n\nR = 1000\n\nDeze optie laat toe het aantal steekproeven dat R trekt aan te passen. Hier vragen we er 1000.\n\n\nOnze resultaten hier zijn gelijkaardig, maar niet identiek aan deze gevonden bij 250 steekproeven. Het heeft echter geen gevolgen voor de algemene conclusies over significantie.\nBootstrapping kan ook gebruikt worden binnen het marginaleffects package, bv. wanneer we voorspelde waarden en betrouwbaarheidsintervallen nodig hebben. De functie om bootstrapping te gebruiken (inferences()) is echter nog steeds in ontwikkeling en je moet er ook bijkomende packages voor installeren. Indien je dit nodig zou hebben, bekijk dan het “Bootstrap” hoofdstuk op de marginaleffects website.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Assumptieschendingen oplossen</span>"
    ]
  },
  {
    "objectID": "errors.html#footnotes",
    "href": "errors.html#footnotes",
    "title": "Bijlage D — Assumptieschendingen oplossen",
    "section": "",
    "text": "Slechts een van deze assumpties is ook van toepassing op logistische modellen: de assumptie van onafhankelijke fouten. De oplossingen hiervoor zijn dezelfde bij logistische modellen, vandaar dat we ons in deze voorbeelden richten op OLS modellen.↩︎\nWel zien we dat er meer variatie is tussen individuen dan tussen landen. dat is wel vaker zo in dergelijke cross-nationale surveydatasets.↩︎\nWe moeten er ook op letten dat er geen ‘ommitted variable bias’ optreedt. Hier gebruiken we bijvoorbeeld slechts 1 predictor en belangrijke controlevariabelen worden wellicht over het hoofd gezien.↩︎\nEr bestaan eigenlijk ook twee andere strategieën. Het probleem hier wordt veroorzaakt door het samenbrengen (“poolen”) van gegevens uit verschillende landen (“clusters”). Het kan echter zijn dat we ons zorgen maken over één cluster in het bijzonder, bijvoorbeeld het doel van ons artikel kan zijn om de relatie tussen ideologie en democratische tevredenheid specifiek in Duitsland of in Nederland te onderzoeken, enz. Een “oplossing” is dan om waarnemingen uit de andere landen weg te filteren en enkel een model voor 1 land te schatten. Het kan ook zijn dat we niet echt geïnteresseerd zijn in het lagere niveau van de dataset (bijv. de individuen in dit voorbeeld) en eigenlijk meer geven om het verklaren van de variatie tussen clusters (bijv. waarom landen als Zwitserland een hogere democratische tevredenheid hebben dan landen als Bulgarije). Een optie hier is om het clustergemiddelde te gebruiken als onze afhankelijke variabele in een regressiemodel en dit te voorspellen met predictoren op landniveau (bv. BBP). Zoals altijd is de eerste stap in elke data-analyse uitzoeken wat onze vraag is, omdat dit een grote invloed heeft op het type analyse dat geschikt is om te leren wat we willen leren.↩︎\nDeze strategie werkt ongeacht de hoeveelheid clusters die je hebt. De berekening kan wel langer duren bij een groter aantal clsuters. Stel dat we met longitudinale, panel-data werken van 500 respondenten die elke maand van het jaar bevraagd worden. Voor een ‘fixed effects’analyse betekent dit dat je 499 dummies toevoegd. Dit is best veel. In dit geval kun je ook specifieke packages gebruiken die speciaal ontworpen ziin voor ’fixed effects’ en vlugger werken, bijvoorbeeld het fixest package met bijhorende feols functie. Deze functie gebruikt ook automatisch geclusterde standaardfouten.↩︎\nAls we ons richten op controlevariabelen in het geval van 1 land dan moeten deze variëren over de tijd in Nederland (time-variant) en niet vaststaan (time-invariant).↩︎\nEr zijn nog andere manieren om dergelijke time series te modelleren, maar deze zijn te gevorderd voor dit handboek.↩︎\nHier maken we een vertraagde afhankelijke variable maar hetzelfde proces kan gebruikt worden voor onafhankelijke variabelen, bijvoorbeeld als er zorgen zijn over omgekeerde causale verbanden (‘reverse causality’).↩︎\nDe bivariate pearson correlatie tussen de twee variabelen is 0.99. Democratiescores in Nederland blijven erg stabiel van jaar tot jaar.↩︎",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Assumptieschendingen oplossen</span>"
    ]
  },
  {
    "objectID": "scales.html",
    "href": "scales.html",
    "title": "Bijlage E — Indexen en schalen",
    "section": "",
    "text": "E.1 Algemene principes\nDe R code die we in de volgende secties tonen kan gebruikt worden om verschillende soorten indexen/schalen te maken op basis van bestaande variabelen. Het spreekt echter voor zich dat het niet de bedoeling is lukraak wat variabelen bij elkaar te gooien. De beslissing welke variabelen samen te voegen en met welk doel moet gemotiveerd zijn. welke principes daarbij in gedachten moeten worden gehouden bespreken we hier. 2\nConceptualisatie vormt een natuurlijk beginpunt voor het nadenken over schalen. We willen vaak concepten zoals ‘democratie’, ‘populisme’, of ‘ideologie’ empirisch bestuderen, maar deze concepten kennen verschillende facetten of sub-componenten die je niet altijd met 1 vraag kunt meten. Soms gebeurt dit wel, denk bijvoorbeeld aan de gekende vraag over links-rechtspositie, maar ook hier kunnen we ons kritisch de vraag stellen of we hiermee echt een complex concept als ‘ideologie’ meten. Moeten we niet zowel economisch als sociaal-cultureel links-rechts meten bijvoorbeeld?\nDe vraag die we ons dan stellen is hoe we deze concepten best kunnen meten en of we dat met 1 of meerdere variabelen moeten doen. Bestaande studies helpen hierbij. Het V-Dem project meet bijvoorbeeld democratie (v2x_polyarchy) niet met 1 vraag gesteld aan experten (‘hoe democratisch is…?’) maar met verschillende vragen over bijvoorbeeld hoe vrij en eerlijk verkiezingen zijn, hoe transparant de overheid is enz. Antwoorden op verschillende vragen worden gecombineerd tot 1 getal voor democratie. In een survey vragen we doorgaans niet aan mensen hoe ‘populistisch’ ze zijn. Dit woord wordt meer gebruikt door wetenschappers dan gewone burgers. We kunnen wel vragen of ze akkoord of niet akkoord gaan met stellingen zoals ‘politici zijn geschikter om beleid te vormen dan gewone burgers’ en ‘politici zijn uit op eigenbelang’ en dan een schaal maken op basis van de antwoorden op deze stellingen.\nEen valide meting is een meting waarbij de vraag, of de combinatie van vragen in dit geval, gebruikt om het concept te meten alle belangrijke aspecten van het concept bevat. Een meting van democratie zonder een element over vrije en eerlijke verkiezingen zou best vreemd zijn bijvoorbeeld. We willen geen belangrijke dingen vergeten. Aan de andere kant willen we niet te veel elementen opnemen en ons concept niet uitrekken. Een meting van democratie bevat dan meestal ook geen indicatoren over welvaart in de samenleving. Voor validiteit moeten we goed nadenken over wat er nu bij ons concept hoort en wat eigenlijk iets anders is.\nEen meting moet ook betrouwbaar zijn: als we de meting opnieuw zouden doen, willen we gelijke of sterk gelijke resultaten. Je wil ook geen weegschaal die je telkens een ander cijfer geeft als je er 3 keer na elkaar gaat opstaan. Voor betrouwbare schalen kunnen we ons vaak beroepen op eerder onderzoek: wat hebben andere onderzoekers gebruikt en met welke resultaten? We kunnen ook echter kijken naar de correlatie tussen verschillende variabelen waarvan we denken dat ze een schaal kunnen vormen om 1 concept te meten. Als de sub-variabelen sterk gecorreleerd zijn, hebben we reden om aan te nemen dat ze verschillende aspecten van eenzelfde concept meten.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Indexen en schalen</span>"
    ]
  },
  {
    "objectID": "scales.html#voorbeeld-1-emoties-en-campagne-voeren",
    "href": "scales.html#voorbeeld-1-emoties-en-campagne-voeren",
    "title": "Bijlage E — Indexen en schalen",
    "section": "E.2 Voorbeeld 1: Emoties en campagne voeren",
    "text": "E.2 Voorbeeld 1: Emoties en campagne voeren\n\nE.2.1 Data\nWaarom doen burgers mee aan verkiezingscampagnes (bv. door de straat op te gaan om mensen aan te spreken of door geld te doneren)? Sommige onderzoekers leggen dit vooral uit door te verwijzen naar mensen hun vaardigheden en welvaart: hebben ze tijd voor vrijwilligerswerk, geld om te doneren, de politieke kennis om mensen te mobiliseren enz.? Maar mensen moeten ook overtuigd zijn dat campagne voeren nuttig en juist is om te doen. Ze moeten met andere woorden gemotiveerd zijn. recent onderzoek wijst uit dat emoties een belangrijke rol kunnen spelen om mensen tot actie aan te zetten. 3 We onderzoeken dit idee op basis van een subset van de 2024 American National Election Studies (ANES) en tonen aan hoe we schalen maken in R.\nANES is gebaseerd op een toevalssteekproef van volwassen Amerikaanse burgers, die ondervraagd worden zowel voor (pre-election) als na (post-election) de nationale verkiezingen. In 2024 werd respondenten gevraagd of zij verschillende soorten campagneactiviteiten hadden ondernomen:\n\n“Heb je mensen gesproken om hen te overtuigen te stemmen voor of tegen bepaalde kandidaten of partijen?” (persuade)\n“Heb je online deelgenomen aan politieke bijeenkomsten, speeches, geldinzamelingsacties of gelijkaardige zaken om een bepaalde kandidaat te steunen?” (online_meetings)\n“Heb je fysiek deelgenomen aan politieke bijeenkomsten, speeches, geldinzamelingsacties of gelijkaardige zaken om een bepaalde kandidaat te steunen?” (rallies)\n“Toonde je een politiek symbool tijdens de campagne zoals een button, kledingstuk, sticker op de wagen, affiche aan huis?” (campaign_button)\n“Deed je ander werk voor een kandidaat of partij?” (other_work)\n“Heb je geld gedoneerd aan een partij dit verkiezingsjaar?” (contribute_money_party)\n“Heb je geld gedoneerd aan een groep voor of tegen bepaalde kandidaten?” (contribute_money_group)\n\nRespondenten konden met ‘ja (code = 1)’ of ‘nee (code =0)’ antwoorden.\nWe bekijken eerst de descriptieve statistieken voor we meer ingewikkelde dingen proberen. We maken gebruik van de psych::describe() functie. De “mean” kolom geeft de proportie weer van respondenten die een bepaalde activiteit hebben ondernomen.\n\nscale_data |&gt; \n1  select(persuade:contribute_money_group) |&gt;\n2  psych::describe()  |&gt;\n3  select(vars:mean, min, max)\n\n\n1\n\nWe selecteren de variabelen waarvoor we statistieken willen. De campagnevariabelen bevinden zich naast elkaar in de data. We schrijven de eerste en de laatste met een dubbelpunt ertussen om ze allemaal te selecteren.\n\n2\n\nDoor psych:: als prefix te gebruiken hoeven we het package hier niet eerst te laden. Sommige functies van dit package conflicteren namelijk met die van tidyverse.\n\n3\n\nWe gebruiken de select() functie om slechts relevante kolommen weer te geven. Voor binaire variabelen zijn zaken zoals skew en kurtosis niet veelzeggend.\n\n\n\n\n                       vars    n mean min max\npersuade                  1 4957 0.40   0   1\nonline_meetings           2 4761 0.10   0   1\nrallies                   3 4959 0.05   0   1\ncampaign_button           4 4962 0.14   0   1\nother_work                5 4962 0.03   0   1\ncontribute_money_party    6 4760 0.10   0   1\ncontribute_money_group    7 4760 0.03   0   1\n\n\nOngeveer 40% van de respondenten heeft anderen proberen overtuigen. Andere activiteiten zijn minder frequent gebruikt. De verschillende vragen of ‘items’ (sub-componenten van een schaal) zullen we gebruiken voor de afhankelijke variabele.\nANES vroeg respondenten ook naar hun emoties voorgaand aan de verkiezingen met de vraag: Hoe [specifieke emotie] voel je je over hoe de zaken momenteel gaan in het land? De volgende emoties werden bevraagd:\n\nhoopvol (hopeful)\nangstig (afraid)\nwoedend (outraged)\nboos (angry)\ngelukkig (happy)\nbezorgd (worried)\ntrots (proud)\ngeïrriteerd (irritated)\nnerveus (nervous)\n\nRespondenten konden antwoorden op een 5-punten schaal: not at all (=1), a little (=2), somewhat (=3), very (=4), en extremely (=5). Ook hier bekijken we de beschrijvende statistieken eerst:\n\nscale_data |&gt; \n  select(hopeful:nervous) |&gt; \n  psych::describe() |&gt; \n  select(vars, n, mean, sd, median, min, max, skew, kurtosis)\n\n          vars    n mean   sd median min max  skew kurtosis\nhopeful      1 4756 2.49 1.11      3   1   5  0.24    -0.69\nafraid       2 4757 3.35 1.21      3   1   5 -0.25    -0.84\noutraged     3 4752 3.21 1.31      3   1   5 -0.20    -1.03\nangry        4 4754 3.23 1.24      3   1   5 -0.17    -0.91\nhappy        5 4756 2.01 1.01      2   1   5  0.62    -0.46\nworried      6 4755 3.58 1.15      4   1   5 -0.41    -0.70\nproud        7 4750 2.04 1.06      2   1   5  0.67    -0.44\nirritated    8 4753 3.57 1.16      4   1   5 -0.44    -0.68\nnervous      9 4758 3.47 1.18      4   1   5 -0.36    -0.73\n\n\nWe zien dat respondenten over het algemeen niet zo positief zijn: gemiddelden voor negatieve gevoelens liggen hoger dan die voor positieve gevoelens. Maar er is sterke variatie in de variabelen.\nWe willen nu de relatie nagaan tussen emoties en campagne voeren. Voor zowel de ‘onafhankelijke’ (emoties) als de ‘afhankelijke’ (campagne) variabelen hebben we meerdere aparte variabelen in de dataset. Hoe gaan we te werk?\nWe zouden verschillende (logistische) modellen kunnen schatten per campagne-item en telkens alle emotievariabelen toevoegen als predictors. Dit kan een goede aanpak zijn als we willen weten of welbepaalde emoties een andere invloed hebben op welbepaalde activiteiten ten opzichte van andere. Als we geïnteresseerd zijn in de algemene relatie tussen emoties en campagne voeren, maken we indexen of schalen.\nOnze emoties verschillen, maar toch kunnen we ook hier een schaal maken als we ervanuit gaan dat positieve en negatieve emoties samen voorkomen (i.e. correleren). We gaan dit eerst na:\n\nscale_data |&gt; \n1  select(hopeful:nervous) |&gt;\n2  rename_with(str_to_title) |&gt;\n3  datasummary_correlation()\n\n\n1\n\nWe selecteren de variabelen waarvoor we correlaties willen berekenen.\n\n2\n\nDe str_to_title() functie komt uit het stringr package (deel van tidyverse). we gebruiken het om de kolomnamen te laten beginnen met een hoofdletter in plaats van een kleine letter, dan moeten we niet individueel de variabelen hernoemen (Zie deze StackOverflow thread.\n\n3\n\nDeze functie uit het modelsummary package maakt een correlatietabel. Zie Hoofdstuk 8 voor verdere informatie.\n\n\n\n\n\n\nTabel E.1: Correlaties tussen emoties\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Hopeful\n                Afraid\n                Outraged\n                Angry\n                Happy\n                Worried\n                Proud\n                Irritated\n                Nervous\n              \n        \n        \n        \n                \n                  Hopeful\n                  1\n                  .\n                  .\n                  .\n                  .\n                  .\n                  .\n                  .\n                  .\n                \n                \n                  Afraid\n                  -.33\n                  1\n                  .\n                  .\n                  .\n                  .\n                  .\n                  .\n                  .\n                \n                \n                  Outraged\n                  -.33\n                  .64\n                  1\n                  .\n                  .\n                  .\n                  .\n                  .\n                  .\n                \n                \n                  Angry\n                  -.34\n                  .66\n                  .77\n                  1\n                  .\n                  .\n                  .\n                  .\n                  .\n                \n                \n                  Happy\n                  .61\n                  -.39\n                  -.41\n                  -.40\n                  1\n                  .\n                  .\n                  .\n                  .\n                \n                \n                  Worried\n                  -.35\n                  .75\n                  .66\n                  .66\n                  -.42\n                  1\n                  .\n                  .\n                  .\n                \n                \n                  Proud\n                  .60\n                  -.36\n                  -.39\n                  -.39\n                  .72\n                  -.41\n                  1\n                  .\n                  .\n                \n                \n                  Irritated\n                  -.36\n                  .64\n                  .72\n                  .73\n                  -.44\n                  .68\n                  -.42\n                  1\n                  .\n                \n                \n                  Nervous\n                  -.31\n                  .75\n                  .62\n                  .64\n                  -.36\n                  .75\n                  -.35\n                  .64\n                  1\n                \n        \n      \n    \n\n\n\n\n\n\nTabel E.1 toont dat positieve emoties positief correleren, dat negatieve emoties positief correleren en dat positieve en negative emoties negatief correleren. Dit lijkt erop te wijzen dat we indexen voor ‘positieve’ en ‘negatieve’ emoties zouden kunnen maken, ook om multicollineariteit tegen te gaan.\n\n\nE.2.2 Betrouwbaarheid van schalen\nDe concepten van ‘emoties’ en ‘campagne voeren’ lijken valide en de belangrijkste componenten te bevatten van deze zaken in het echte leven (we kunnen hier natuurlijk verder over reflecteren in de conclusie van onze paper). De positieve en negatieve indexen van emoties hierboven gesuggereerd worden ook ondersteund in de literatuur. Eerder onderzoek over “affective intelligence theory” stelt immers dat menselijk gedrag aangestuurd wordt door twee emotionele systemen. De items staan eigenlijk ook in ANES om dit te testen 4\nMaar we moeten ook naar betrouwbaarheid kijken: zou een index van positieve emoties intern betrouwbaar zijn? Meten onze verschillende emoties voldoende hetzelfde ‘positieve’ aspect. De correlaties hierboven (zie Tabel E.1) lijken te zeggen van ja, maar er bestaan ook betere statistische methoden die helpen de vraag te beantwoorden of de correlatie sterk genoeg is.\nWe gebruiken de Cronbach’s alpha (\\(\\alpha\\)), gebaseerd op de gemiddelde covariantie van de onderliggende variabelen in de schaal.5 De \\(\\alpha\\) maatstaf heeft een bereik van 0 tot 1. Hogere waarden duiden op hogere betrouwbaarheid. De volgende vuistregels gelden:\n\n\\(\\geq\\) 0.90: Excellente betrouwbaarheid\n0.80-0.89: Goede betrouwbaarheid\n0.70-0.79: Aanvaardbare betrouwbaarheid\n0.60-0.69: Twijfelachtige betrouwbaarheid\n&lt; 0.60: Slechte betrouwbaarheid\n\nDoorgaans gebruiken we geen index met een \\(\\alpha\\) onder 0.6. Bij binaire variabelen kan de betrouwbaarheid echter onderschat worden omdat de \\(\\alpha\\) test eigenlijk continue variabelen verwacht. Er bestaan andere methoden voor binaire data maar deze vallen buiten het materiaal van dit handboek.\nWe kunnen de \\(\\alpha\\) berekenen met de cronbachs_alpha() functie uit het performance package.\n\n# Campagne index\nscale_data |&gt; \n  select(persuade:contribute_money_group) |&gt; \n  cronbachs_alpha() \n\n[1] 0.6306181\n\n# Positieve emoties\nscale_data |&gt; \n  select(hopeful, happy, proud) |&gt; \n  cronbachs_alpha()\n\n[1] 0.8418678\n\n# Negatieve Emoties\nscale_data |&gt; \n  select(afraid, outraged, angry, worried, irritated, nervous) |&gt; \n  cronbachs_alpha()\n\n[1] 0.9287744\n\n\nDe \\(\\alpha\\) scores voor de emotieschalen zijn 0.84 en 0.93 respectievelijk en dus sterk betrouwbaar. De betrouwbaarheid voor negatieve emoties is vooral hoger omdat er meerdere items gebruikt zijn. De \\(\\alpha\\) score voor campagne voeren is lager: 0.63. Gezien de scores doorgaans lager zijn bij binaire variabelen maken we de beslissing om toch met de index door te gaan.\n\n\nE.2.3 Som of gemiddelde?\nWe zullen 3 indexen maken: 1 voor campagne en 2 voor emoties. We moeten een keuze maken tussen variabelen optellen of het gemiddelde nemen. De keuze ligt aan de onderzoeker, maar er zijn wel wat richtlijnen. Bij campagne kijken we naar verschillende activiteiten. Hier houdt het steek om te meten hoeveel verschillende activiteiten iemand heeft gedaan eerder dan of die persoon gemiddeld een activiteit heeft gedaan. Optellen dus. Bij emoties lijkt de originele schaal van 1 tot 5 nuttig: voelt iemand zich helemaal niet of juist sterk zo? Een nieuwe somschaal op 30 (bv. voor negatieve emoties hier) heeft weinig intuïtieve betekenis. Hier nemen we dus het gemiddelde.\nWe moeten ook rekening houden met ontbrekende waarden. Als we R vragen om een som of gemiddelde te berekenen moeten we zeggen hoe met missing data om te gaan via na.rm = TRUE of na.rm = FALSE. Bij na.rm =TRUE worden missing waarden (NA) weggelaten bij de berekening. Dit is de correcte manier, anders krijgen we ‘NA’ voor de som/het gemiddelde. Zie het verschil hieronder.\n\n# voorbeelddata\nx &lt;- c(5, 1, 2, NA, 5)\n\n# gemiddelde berekenen\nmean(x, na.rm = TRUE)\n\n[1] 3.25\n\nmean(x, na.rm = FALSE)\n\n[1] NA\n\n\nAls we een index van gemiddelden maken voor 5 items, en 1 (of meerdere) zijn missing, dan wordt het gemiddelde berekend voor de overige 4 (of minder) waarden. Dit is doorgaans prima.\nWat als we een som nemen? We moeten opnieuw na.rm = TRUE gebruiken. Nu geeft de functie een score van 0 voor alle NA waarden bij de optelling. Dit kan soms vreemde gevolgen hebben. Een observatie met enkel missing waarden voor de items zal opeens een 0 krijgen als eindscore en geen NA. Zie onderstaand voorbeeld:\n\n# voorbeelddata\ndata &lt;- tibble(\n  x = c(NA, NA, NA, NA, NA), \n  y = c(0, 1, 0, 0, NA)\n)\n\n# Inspectie\ndata\n\n# A tibble: 5 × 2\n  x         y\n  &lt;lgl&gt; &lt;dbl&gt;\n1 NA        0\n2 NA        1\n3 NA        0\n4 NA        0\n5 NA       NA\n\n# Som maken\ndata |&gt; \n  mutate(sum_x = sum(x, na.rm = T), \n         sum_y = sum(y, na.rm = T))\n\n# A tibble: 5 × 4\n  x         y sum_x sum_y\n  &lt;lgl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;\n1 NA        0     0     1\n2 NA        1     0     1\n3 NA        0     0     1\n4 NA        0     0     1\n5 NA       NA     0     1\n\n\nIn zekere zin gaan we voor X hier data ‘verzinnen’, wat problematisch kan zijn. We weten immers niet wat echt waar is voor deze observatie. In de ANES survey nam niet iedereen mee aan het gedeelte van de survey dat na de verkiezingen werd afgenomen en waarin de campagnevragen stonden. Voor al deze mensen zouden we dus 0 ingeven, hoewel ze geen respons hebben gegeven. we kunnen deze mensen wel uit de data filteren maar dan blijven er nog respondenten voor wie we geen waarden hebben en eigenlijk niet kunnen zeggen wat ze gedaan hebben.6 Hieronder tonen we hoe dit aan te pakken.\nWe will show how to find these types of observations and how to deal with them below.\n\n\nE.2.4 Schalen maken\nEigenlijk hebben we vooral nood aan 2 basisfuncties binnen R: mean() en sum().7 Voorgaand hebben we deze functies op 1 variabele tegelijk toegepast. Nu combineren we meerder variabelen (kolommen in de dataset) tot een gecombineerde variabele (kolom). Dit doen we met behulp van functies uit tidyverse: rowwise() en c_across(). Je kunt meer over deze functies leren via deze vignette.\n\nE.2.4.1 Een index gebaseerd op een gemiddelde\nWe maken 2 indexen op basis van gemiddelden: eentje voor de positieve emoties en eentje voor de negatieve emoties.\n\nscale_data &lt;- scale_data |&gt; \n  rowwise() |&gt; \n  mutate(\n    positive_emotions = mean(c(hopeful, happy, proud), na.rm = T), \n    negative_emotions = mean(c(afraid, outraged, angry, worried, \n                               irritated, nervous), na.rm =T)) |&gt; \n  ungroup()\n\nZo lees je de syntax:\n\nscale_data |&gt; rowwise() |&gt;\n\nde nieuwe functie hier is rowwise(). Zonder deze functie zou mutate() gewoon gemiddelden berekenen op basis van alle rijen in de dataset en deze gemiddelden toevoegen aan de dataset (iedereen zou dus dezelfde algemene waarden krijgen voor de variabelen). Met rowwise() vragen we R om gemiddelden per rij te berekenen zodat elke observatie zijn eigen gemiddelde score toegevoegd krijgt.\n\nmutate(positive_emotions = mean(c(hopeful, happy, proud), na.rm = T), ...))\n\nWe vragen R om met mutate() nieuwe variabelen (kolommen) te maken. De eerste variabele noemen we positive_emotions, de tweede negative_emotions. Dit is de gemiddelde score voor de waarden van de variabelen aangegeven met c(...). Het gedeelte na.rm = T vraagt R missing waarden te negeren bij de berekening.\n\nungroup()\n\nWe vragen R om de groepen (gemaakt met rowwise()) te vergeten zodat dit groeperen per rij niet gebruikt wordt in verdere syntax die gebruikmaakt van mutate().\n\n\nWe kunnen de data bekijken:\n\nscale_data |&gt; \n  select(hopeful:negative_emotions) |&gt; \n1  head() |&gt;\n2  kable(digits = 2)\n\n\n1\n\nAutomatisch selecteren van de eerste rijen van de data voor presentatie.\n\n2\n\nkable() wordt gebruikt voor het maken van tabellen in html files. Hier gebruiken we het om ervoor te zorgen dat alle kolommen zichtbaar zijn voor de lezer.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhopeful\nafraid\noutraged\nangry\nhappy\nworried\nproud\nirritated\nnervous\npositive_emotions\nnegative_emotions\n\n\n\n\n1\n5\n5\n5\n1\n5\n1\n5\n5\n1.00\n5.00\n\n\n2\n4\n3\n3\n2\n3\n1\n3\n3\n1.67\n3.17\n\n\n3\n5\n4\n4\n2\n5\n3\n4\n5\n2.67\n4.50\n\n\n3\n4\n2\n3\n3\n4\n4\n4\n4\n3.33\n3.50\n\n\n2\n5\n5\n4\n1\n5\n2\n5\n5\n1.67\n4.83\n\n\n5\n1\n1\n1\n4\n1\n5\n1\n1\n4.67\n1.00\n\n\n\n\n\nDe eerste respondent was duidelijk ongelukkig met de toestand in de VS. Voor alle positieve emoties wordt de laagste score van 1 gegeven (het gemiddelde voor positieve emoties is dan ook 1). Voor de negatieve emoties werd telkens de maximale score van 5 gegeven (en 5 is dus ook het gemiddelde). Respondent 6 is zowat de tegenpool van respondent 1 terwijl andere respondenten zich meer in het midden bevinden.\nMet een Pearson correlatie kunnen we nagaan hoe de twee schalen zich tot elkaar verhouden:\n\ncor.test(scale_data$positive_emotions, \n         scale_data$negative_emotions, \n         method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  scale_data$positive_emotions and scale_data$negative_emotions\nt = -39.523, df = 4758, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.5182429 -0.4754587\nsample estimates:\n      cor \n-0.497153 \n\n\nDe schalen zijn negatief gecorreleerd met een gemiddeld sterke samenhang. Dit betekent dat respondenten ook ambivalent kunnen zijn en zowel positieve als negatieve gevoelens ervaren.\n\n\nE.2.4.2 Een index gebaseerd op een som\nHet proces voor een index gebaseerd op een som is gelijkaardig, behalve dat we moeten opletten met observaties die ontbrekende waarden hebben voor de variabelen die de schaal/index gaan vormen, zoals hierboven uitgelegd. Deze observaties mogen we niet meenemen in de berekening. We bekijken eerst of er missing waarden zijn over de cases heen:\n\nscale_data &lt;- scale_data |&gt; \n  rowwise() |&gt; \n  mutate(engage_missing = sum(is.na(c(persuade, online_meetings, rallies, \n                                      campaign_button, other_work, \n                                      contribute_money_party, contribute_money_group)))) |&gt; \n  ungroup()\n\n\nsum(is.na(c(persuade, ..., contribute_money_group))))\n\nWe gebruiken hier rowwise() gevolgd door mutate() zoals we hierboven al deden. Nu gebruiken we echter sum() om totalen te berekenen. We willen hier berekenen hoeveel van de observaties ontbrekende waarden hebben en voor hoeveel van de onderliggende variabelen. We maken dus ook gebruik van de is.na() functie. Deze functie transformeert achter de schermen de kolommen (variabelen) aangeduid met c() tot binaire variabelen waarbij 0 staat voor valide waarden en 1 voor ontbrekende waarden. Zo berekenen we hoeveel ontbrekende waarden een observatie heeft.\n\n\nLaten we eens kijken of er observaties zijn met ontbrekende waarden via de table() functie:\n\ntable(scale_data$engage_missing)\n\n\n   0    1    3    4    6    7 \n4752    9  199    2    1    1 \n\n\nDe meeste observaties (4752) hebben geen enkele (0) ontbrekende waarde. Sommige respondenten (9) hebben er 1. Er is ook een respondent die voor alle 7 de variabelen een ontbrekende waarde geeft. Deze zouden we eruit kunnen filteren op de volgende manier:8\n\nscale_data &lt;- scale_data |&gt; \n  filter(engage_missing &lt; 7)  \n\nNu kunnen we dan onze index maken. We gebruiken hiervoor de functie c_across():\n\nscale_data &lt;- scale_data |&gt; \n  rowwise() |&gt; \n  mutate(campaign_engagement = sum(c_across(persuade:contribute_money_group))) |&gt; \n  ungroup()\n\n\ncampaign_engagement = sum(c_across(persuade:contribute_money_group)))\n\nToen we het gemiddelde over een aantal variabelen heen wilden berekenen gebruikten we gewoon de functie c(). Dat werkt prima, maar kan omslachtig zijn als er veel variabelen zijn om uit te schrijven. Met c_across kunnen we de eerste variabele en de laatste schrijven met daartussen een dubbelpunt (persuade:contribute_money_group). Zo selecteert R ook alle tussenliggende variabelen. Deze functie is natuurlijk enkel nuttig als de relevante variabelen netjes bij elkaar staan in de dataset.\n\n\nLaten we een kijkje nemen naar de uiteindelijke index:\n\ntable(scale_data$campaign_engagement)\n\n\n   0    1    2    3    4    5    6    7 \n2436 1345  504  257  120   60   19   11 \n\n\nHet merendeel van de respondenten is niet betrokken bij campagneactiviteiten. Zij scoren 0 op de index. Een groot aantal respondenten doet 1 activiteit (1345). Hoe meer activiteiten, hoe minder respondenten. Slechts 11 respondenten hebben deelgenomen aan alle 7 de activiteiten.\n\n\n\nE.2.5 Model schatten\nNu we al onze schalen gecreëerd hebben kunnen we een regressiemodel schatten. Hier gebruiken we een lineair model met positieve en negatieve emoties als onafhankelijke variabelen en campagne engagement als afhankelijke variabele:9\n\n# Model \nengagement_model &lt;- lm(campaign_engagement ~ positive_emotions + negative_emotions, \n                       data = scale_data)\n\n# Coefficients\ntidy(engagement_model)\n\n# A tibble: 3 × 5\n  term              estimate std.error statistic  p.value\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)         -0.648    0.0971     -6.68 2.68e-11\n2 positive_emotions    0.320    0.0211     15.2  1.00e-50\n3 negative_emotions    0.239    0.0188     12.7  1.73e-36\n\n\nEr bestaat voor beide predictoren een positieve, significante relatie met de afhankelijke variabele. Zowel positieve als negatieve emoties zijn geassocieerd met politieke participatie.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Indexen en schalen</span>"
    ]
  },
  {
    "objectID": "scales.html#voorbeeld-2-verschillende-meeteenheden",
    "href": "scales.html#voorbeeld-2-verschillende-meeteenheden",
    "title": "Bijlage E — Indexen en schalen",
    "section": "E.3 Voorbeeld 2: verschillende meeteenheden",
    "text": "E.3 Voorbeeld 2: verschillende meeteenheden\nDe schalen die we hierboven hebben gemaakt waren gebaseerd op variabelen die zelf op dezelfde schaal waren gemeten (binaire 0/1 variabelen voor campagneactiviteiten en emotiebelevenis op een schaal van 1 tot 5 voor de emotievariabelen). Het kan echter voorkomen dat we een index willen maken van variabelen die op verschillende schalen gemeten zijn. Dat vergt een enigszins andere aanpak.\n\nE.3.1 Twee benaderingen: normaliseren en standaardiseren\nHet tweede voorbeeld richt zich op de Human Development Index (HDI). De HDI is “a summary measure of average achievement in key dimensions of human development: a long and healthy life, being knowledgeable and having a decent standard of living”.\nDe HDI van landen wordt gemeten op basis van de volgende variabelen: levensverwachting in jaren, scholingsgraad (verwacht en gemiddeld aantal jaren onderwijs genoten), en de welvaart van een land gemeten met het natuurlijk logaritme van het BNI per capita. Deze figuur legt het berekeningsproces uit:\n\nIn dit voorbeeld gaan we zelf de HDI scores van landen berekenen op basis van onderliggende data afkomstig van de Verenigde Naties. We richten ons op het jaar 2023.\nDe volgende variabelen worden gebruikt: levensverwachting bij geboorte in jaren (life_expectancy), het verwachte aantal jaren onderwijs genoten (expected_schooling), het gemiddelde aantal jaren onderwijs genoten (mean_schooling), en het gelogde BNI per capita (gni_percap_logged):10\n\ndatasummary(life_expectancy + expected_schooling + mean_schooling + gni_percap_logged ~ \n              Mean + SD + Min + Max + N, data = hdi_data)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Mean\n                SD\n                Min\n                Max\n                N\n              \n        \n        \n        \n                \n                  life_expectancy\n                  73.11\n                  7.16\n                  54.46\n                  85.00\n                  193\n                \n                \n                  expected_schooling\n                  13.49\n                  2.91\n                  5.63\n                  18.00\n                  193\n                \n                \n                  mean_schooling\n                  9.17\n                  3.19\n                  1.41\n                  14.30\n                  193\n                \n                \n                  gni_percap_logged\n                  9.51\n                  1.17\n                  6.53\n                  11.23\n                  193\n                \n        \n      \n    \n\n\n\nDe variabelen zijn duidelijk op verschillende schalen gemeten. Het bereik van levensverwachting loopt van 54 tot 85, terwijl dat van gemiddelde scholing loopt van 1.41 tot 14.30.\nEen index met een gemiddelde score over alle variabelen heen zou ons weinig leren. Eerst moeten de variabelen op eenzelfde schaal worden gezet. Hier bestaan twee manieren voor: normaliseren of standaardiseren.\nBij normaliseren herschalen we de variabelen zodat ze allemaal dezelfde minimum- en maximum waarden hebben. De onderstaande formule herschaalt de variabelen zodat ze een bereik van 0 tot 1 hebben. De score van 0 wordt geven aan observaties die de minimumwaarde hadden op de originele variabele. De score van 1 wordt gegeven voor de maximumwaarde op de originele variabele. Moesten we de variabele op een schaal van 0 tot 10 willen brengen, zouden we een vermenigvuldiging met 10 aan de formule kunnen toevoegen.\n\\[\\text{(0-1) Normalized Variable} = \\frac{X_{i} - min(X)}{max(X) - min(X)}\\]\nDe HDI maakt grotendeels gebruik van dergelijk normaliseringsproces. Echter worden voor de variabelen niet de minimum- en maximumwaarden in de data gebruikt om het bereik te bepalen, maar zelfgekozen waarden. Voor levensverwachting worden 20 en 85 als minimum en maximum aangeduid. Dit doen ze omdat het aansluit bij de realiteit: “no country in the 20th century had a life expectancy at birth of less than 20 years” and “85 [is] a realistic aspirational target for many countries over the last 30 years.” Voor BNI per capita wordt het minimum gezet op log($100) en het maximum op log($75000). Voor de onderwijsvariabelen is het iets makkelijker. De maxima worden vastgezet op 18 (expected schooling) en 15 (mean schooling) en dan worden de variabelen gedeeld door 18 en 15 respectievelijk om ze te normaliseren.\nWe blijven in dit voorbeeld trouw aan de VN aanpak en gebruiken manueel deze vastgezette waarden om te normaliseren. We tonen echter ook hoe je met de rescale() functie uit het scales package automatisch kunt normaliseren op basis van de minimum en maximumwaarden die je vindt in de data.\nNormalisatie zorgt ervoor dat alle variabelen hetzelfde bereik hebben en kan gebruikt worden voor interval/ratio, ordinale, en binaire variabelen. Normaliseren heeft echter geen impact op de variantie van variabelen. Gezien sommige variabelen een grotere variantie hebben dan anderen kan het zijn dat sommigen meer bijdragen tot de eindscore dan anderen. Een alternatief is om eerst de variabelen te standaardiseren:\n\\[\\text{Standardized Variable} = \\frac{X_{i} - \\bar{X}}{\\text{Std. Dev}(X)}\\]\nVoor elke observatie trekken we de gemiddelde score over de data heen af van de waarde voor de observatie. Dan delen we de uitkomst door de standaarddeviatie van de variabele. De nieuwe variabele heeft altijd een gemiddelde van 0, waarbij 0 staat voor de gemiddelde score op de oorspronkelijke variabele. Afwijkingen van 0 worden uitgedrukt in standaarddeviaties. De variatie van variabelen wordt hierbij gelijkgezet en zo dragen ze gelijk bij aan de uiteindelijke index. De interpretatie van de gestandaardiseerde variabele is wel anders. Een eenheid hoger op deze variabele betekent 1 standaarddeviatie hoger op de oorspronkelijke schaal. Een gestandaardiseerde variabele met een waarde hoger dan 0 betekent dat de waarde hoger ligt dan het gemiddelde op de oorspronkelijke schaal. Dit betekent echter niet noodzakelijk een ‘hoge’ waarde op de oorspronkelijke schaal gezien het gemiddelde zich niet noodzakelijk in het midden bevindt (cfr. verschil gemiddelde en mediaan). Standaardiseren is vooral nuttig bij interval/ratio variabelen.\n\n\nE.3.2 Schalen maken\nWe maken in onderstaande secties de HDI door gebruik te maken van zowel normalisering als standaardisering. We bestuderen ook de verschillen.\n\nE.3.2.1 Normalisering\nVoor de HDI wordt gebruik gemaakt van 3 genormaliseerde variabelen: levensverwachting, het gemiddelde van verwachte en gemiddelde scholing in een land, en het natuurlijk logaritme van het BNI per capita (zie bovenstaande uitleg). We zullen eerste manueel normaliseren en dan gebruik maken van de rescale() functie uit het scales package.\nOnze eerste stap is het berekenen van het gemiddelde van de onderwijsvariabelen. Eerst normaliseren we beide variabelen. De VN deelt verwachte scholing door 18 en gemiddelde scholing door 15 om een 0-1 schaal te maken (zie uitleg boven). Dan nemen ze het gemiddelde van de twee variabelen. Dit doen we met de volgende syntax, waarbij we de rowwise() functie gebruiken.\n\n# Onderwijsvariabele voor gebruik in HDI\nhdi_data &lt;- hdi_data |&gt; \n  mutate(\n    expected_yrs_rescale1 = expected_schooling / 18, \n    mean_yrs_rescale1 = mean_schooling / 15) |&gt; \n  rowwise() |&gt; \n  mutate(\n    education_index_1 = mean(c(expected_yrs_rescale1, mean_yrs_rescale1), na.rm = T)\n  ) |&gt; \n  ungroup()\n\n# Statistieken bekijken\nsummary(hdi_data$education_index_1)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.2491  0.5567  0.7130  0.6806  0.8280  0.9636 \n\n# Blik op de dataset\nhdi_data |&gt; \n  select(expected_schooling, mean_schooling, expected_yrs_rescale1, mean_yrs_rescale1, education_index_1) |&gt;\n  head()\n\n# A tibble: 6 × 5\n  expected_schooling mean_schooling expected_yrs_rescale1 mean_yrs_rescale1\n               &lt;dbl&gt;          &lt;dbl&gt;                 &lt;dbl&gt;             &lt;dbl&gt;\n1               18             13.9                 1                 0.927\n2               18             13.1                 1                 0.875\n3               16.7           13.9                 0.926             0.930\n4               18             13.0                 1                 0.868\n5               17.3           14.3                 0.962             0.953\n6               18             12.7                 1                 0.849\n# ℹ 1 more variable: education_index_1 &lt;dbl&gt;\n\n\nDe uiteindelijke indexvariabele heeft een bereik tussen 0 en 1 met een minimum van 0.25 en een maximum van 0.96. Door te kijken naar de relevante variabelen in de dataset kunnen we de berekening volgen. Voor de eerste observatie vinden we het maximum van 18 jaar verwachte scholing. Als we dit delen door 18 vinden we voor expected_yrs_rescale1 het maximum van 1. Voor gemiddelde scholing heeft deze observatie echter niet het maximum maar 13.91.Als we dit getal delen door 15 vinden we voor mean_yrs_rescale1 een getal dichtbij het maximum: 0.93. Het gemiddelde van 1 en 0.93 vinden we bij education_index_1.\nWe normaliseren nu ook levensverwachting met het VN minimum van 20 en maximum van 85. Voor (log) BNI per capita gebruiken we het VN minimum van log(100) en maximum van log(75000). Hier kunnen we meer de standaardformule voor normaliseren toepassen.\n\n# Normaliseren van variabelen\nhdi_data &lt;- hdi_data |&gt; \n  mutate(\n    life_rescale1 = (life_expectancy - 20) / (85 - 20), \n    gni_rescale1 = (gni_percap_logged - log(100)) / (log(75000) - log(100)))\n\n# Statsitieken bekijken\nsummary(hdi_data$life_rescale1)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.5302  0.7290  0.8229  0.8170  0.8976  1.0000 \n\nsummary(hdi_data$gni_rescale1)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.2914  0.6120  0.7654  0.7407  0.8924  1.0000 \n\n\nWe kunnen zien dat het nieuwe maximum van de variabelen 1 is, de minima zijn hierbij wel niet precies 0 (dat zijn ze wel met de scales methode hieronder besproken).\nTen slotte kunnen we onze index samenstellen door het gemiddelde te nemen van onze 3 variabelen met de rowwise() en mean(c(), na.rm =T)) syntax.11\n\n# Uiteindelijke schaal\nhdi_data &lt;- hdi_data |&gt; \n  rowwise() |&gt; \n  mutate(hdi_normalize_un = mean(c(life_rescale1, gni_rescale1, \n                                   education_index_1), na.rm = T)) |&gt; \n  ungroup()\n\n# Statistieken bekijken\nsummary(hdi_data$hdi_normalize_un)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.4059  0.6298  0.7646  0.7461  0.8620  0.9719 \n\n\nDe schaal loopt van 0.41 tot 0.97. Hogere waarden staan voor hogere scholingsgraad, levensverwachting en welvaart.\nIn bovenstaande syntax maakten we gebruik van de minimum- en maximumwaarden bepaald door de VN. Maar we kunnen deze ook uit de data halen. Dit is vaak eenvoudiger, zeker als je geen theoretische basis hebt voor je keuzes zoals de VN. We kunnen de scales::rescale() functie gebruiken om dit automatisch te doen:\n\nhdi_data &lt;- hdi_data |&gt; \n  mutate(\n1    expected_yrs_rescale2 = scales::rescale(expected_schooling, to = c(0,1)),\n    mean_yrs_rescale2 = scales::rescale(mean_schooling, to = c(0,1)), \n    life_rescale2 = scales::rescale(life_expectancy, to = c(0,1)), \n    gni_rescale2 = scales::rescale(gni_percap_logged, to = c(0,1)))\n\n\n1\n\nWe noemen het package hier in de syntax (scales::) zodat we het niet hoeven te laden. Het scales package heeft namelijk ook een aantal functies die conflicteren met andere packages die we gebruiken.\n\n\n\n\nZo lees je de syntax:\n\nscales::rescale(\n\nWe gebruiken de functie rescale() uit het scales package. We noemen het package in de syntax (scales::) om het niet te hoeven laden.\n\nexpected_schooling, to = c(0,1))\n\nWe noemen de variabele die we willen normaliseren. Met de to = c(0,1)vertellen we R dat we de variabele willen herschalen zodat ze een bereik van 0 tot 1 heeft. We zouden deze waarden kunnen veranderen, bv. naar c(0,10) voor een bereik van 0 tot 10.\n\n\nLaten we kijken naar het verschil tussen de VN-methode en rescale:\n\n# Originele variabele en VN normalisering\np1 &lt;- ggplot(hdi_data, aes(x = life_expectancy, y = life_rescale1)) + geom_point() + \n  scale_y_continuous(limits = c(0,1)) + \n  labs(title = \"Normalisering met VN min(x) en max(x)\") \n\n# Originele variabele en scales::rescale() normalisering\np2 &lt;- ggplot(hdi_data, aes(x = life_expectancy, y = life_rescale2)) + geom_point() + \n  labs(title = \"Normalisering met scales::rescale()\")\n\n# Plots combineren met patchwork library\np1 + p2 \n\n\n\n\n\n\n\n\nBeide genormaliseerde variabelen hebben een theoretisch bereik van 0 tot 1. Maar met rescale wordt er altijd een echt minimum en maximum gevonden in de data en zul je altijd de waarden 0 en 1 terugvinden. De VN heeft echter door het zelf bepalen van minima en maxima in plaats van ze door de data te laten bepalen, het minimum voor de data in de praktijk hoger gelegd (bij 0.53). In 2023 had geen enkel land een levensverwachting van 20, het theoretische minimum van de VN, dus vinden we 0 niet terug. Het theoretische maximum van 85 werd dan wel weer bereikt.\nWe berekenen nu de index met de scales::rescale() genormaliseerde variabelen:\n\n# Index berekenen\nhdi_data &lt;- hdi_data |&gt; \n  rowwise() |&gt; \n  mutate(\n    education_index_2 = mean(c(expected_yrs_rescale2, mean_yrs_rescale2), na.rm = T),\n    hdi_normalize_scales = mean(c(education_index_2, life_rescale2, gni_rescale2), na.rm = T)\n    ) |&gt; \n  ungroup()\n\nLaten we de twee versies vergelijken:\n\n# Statistieken vergelijken\nsummary(hdi_data$hdi_normalize_scales) # scales::rescale() \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.09029 0.44718 0.65276 0.62116 0.80117 0.96629 \n\nsummary(hdi_data$hdi_normalize_un) # VN waarden\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.4059  0.6298  0.7646  0.7461  0.8620  0.9719 \n\n# Correlatie\ncor.test(x = hdi_data$hdi_normalize_un, \n         y = hdi_data$hdi_normalize_scales, \n         method = 'pearson')\n\n\n    Pearson's product-moment correlation\n\ndata:  hdi_data$hdi_normalize_un and hdi_data$hdi_normalize_scales\nt = 240.73, df = 191, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9978160 0.9987628\nsample estimates:\n      cor \n0.9983561 \n\n\nDe schalen lopen van 0 tot 1 maar zijn niet volledig identiek. In lijn met wat we hierboven al zagen ligt het minimum hoger bij de VN versie. Toch correleren de twee versies zeer sterk en positief met een pearson correlatie van 0.998. Verschillen zullen dan ook weinig uitmaken in regressieanalyses.\n\n\nE.3.2.2 Standaardisering\nOm te standaardiseren trekken we van een variabele de gemiddelde waarde af en delen we door de standaardafwijking. Hier kunnen we de ingebouwde R-functie scale() voor gebruiken. je hoeft geen package te laden.\n\n# Standaardiseren\nhdi_data &lt;- hdi_data |&gt; \n  mutate(\n    life_std = scale(life_expectancy, center = TRUE, scale = TRUE), \n    expected_yrs_std = scale(expected_schooling, center = TRUE, scale = TRUE), \n    mean_yrs_std = scale(mean_schooling, center = TRUE, scale = TRUE), \n    gni_std = scale(gni_percap_logged, center = TRUE, scale = TRUE)\n  )\n\nZo lees je de syntax:\n\nscale(\n\nWe gebruiken de functie scale() op de variabele tussen haakjes.\n\nlife_expectancy, center = TRUE, scale = TRUE)\n\nWe benoemen de variabele en vragen R eerst het gemiddelde van de variabele van elke waarde af te trekken met center = TRUE en dan te standaardiseren door te delen door de standaardafwijking met scale = TRUE.\n\n\nLaten we de statistieken van de variabelen bekijken:\n\n# Descriptieve statistieken opvragen\nhdi_data |&gt;\n  select(life_std, expected_yrs_std, mean_yrs_std, gni_std) |&gt;\n  psych::describe() \n\n                 vars   n mean sd median trimmed  mad   min  max range  skew\nlife_std            1 193    0  1   0.05    0.04 1.17 -2.61 1.66  4.27 -0.29\nexpected_yrs_std    2 193    0  1  -0.05    0.05 1.10 -2.70 1.55  4.25 -0.34\nmean_yrs_std        3 193    0  1   0.24    0.07 1.13 -2.44 1.61  4.04 -0.52\ngni_std             4 193    0  1   0.14    0.05 1.20 -2.54 1.47  4.01 -0.37\n                 kurtosis   se\nlife_std            -0.71 0.07\nexpected_yrs_std    -0.51 0.07\nmean_yrs_std        -0.72 0.07\ngni_std             -0.80 0.07\n\n\nAlle variabelen hebben een gemiddelde van 0 en een standaardafwijking van 1. De minima en maxima zijn niet dezelfde maar de waarden hebben dezelfde betekenis: hoeveel verschilt de observatie van de gemiddelde waarde van de originele variabele.\nWe maken nu de index door het gemiddelde van de variabelen te nemen:\n\n# Schaal maken\nhdi_data &lt;- hdi_data |&gt; \n  rowwise() |&gt; \n  mutate(\n    hdi_standardized = mean(c(life_std, expected_yrs_std, \n                              mean_yrs_std, gni_std), \n                            na.rm = T))\n\n# Statistieken bekijken\nsummary(hdi_data$hdi_standardized)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-2.12111 -0.73406  0.09892  0.00000  0.75342  1.44253 \n\n\nde schaal loopt van -2.12 tot 1.44 met een gemiddelde waarde van 0. Observaties dichter bij het maximum hebben scores hoger dan het gemiddelde voor (bijna) alle onderliggende variabelen.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Indexen en schalen</span>"
    ]
  },
  {
    "objectID": "scales.html#referenties",
    "href": "scales.html#referenties",
    "title": "Bijlage E — Indexen en schalen",
    "section": "E.4 Referenties",
    "text": "E.4 Referenties\n\n\n\n\nAdcock, Robert, en David Collier. 2001. ‘Measurement Validity: A Shared Standard for Qualitative and Quantitative Research’. American political science review 95 (3): 529–46.\n\n\nBrady, Henry E, Sidney Verba, en Kay Lehman Schlozman. 1995. ‘Beyond SES: A Resource Model of Political Participation’. American Political Science Review 89 (2): 271–94. https://doi.org/10.2307/2082425.\n\n\nCastanho Silva, Bruno, Sebastian Jungkunz, Marc Helbling, en Levente Littvay. 2020. ‘An Empirical Comparison of Seven Populist Attitudes Scales’. Political Research Quarterly 73 (2): 409–24. https://doi.org/10.1177/1065912919833176.\n\n\nMarcus, George E, en Michael B Mackuen. 1993. ‘Anxiety, Enthusiasm, and the Vote: The Emotional Underpinnings of Learning and Involvement During Presidential Campaigns’. The American Political Science Review 87 (3): 672–85. https://www.jstor.org/stable/2938743.\n\n\nValentino, Nicholas A, Ted Brader, Eric W Groenendyk, Kysha Gregorowicz, en Vincent L Hutchings. 2011. ‘Election Night’s Alright for Fighting: The Role of Emotions in Political Participation’. The Journal of Politics 73 (1): 156–70.\n\n\nVasiopoulos, Pavlos, George E. Marcus, Nicholas A. Valentino, en Martial Foucault. 2019. ‘Fear, Anger, and Voting for the Far Right: Evidence from the November 13, 2015 Paris Terror Attacks’. Political Psychology 40 (4): 679–704.\n\n\nYoung, Lauren E. 2019. ‘The Psychology of State Repression: Fear and Dissent Decisions in Zimbabwe’. American Political Science Review 113 (1): 140–55.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Indexen en schalen</span>"
    ]
  },
  {
    "objectID": "scales.html#footnotes",
    "href": "scales.html#footnotes",
    "title": "Bijlage E — Indexen en schalen",
    "section": "",
    "text": "Zie Castanho Silva e.a. (2020) voor een bespreking van verschillende populismeschalen.↩︎\nZie bijvoorbeeld Adcock en Collier (2001) voor een meer uitgebreide discussie van de principes uitgelegd hier.↩︎\nZie Brady, Verba, en Schlozman (1995) over de rol van vaardigheden en welvaart in politieke participatie en Valentino e.a. (2011) over de rol van emoties. Hier richten we ons op de positieve rol van emoties op participatie, maar deze kunnen ook negatieve effecten hebben, zie bijvoorbeeld de studie van Young (2019) in Zimbabwe.↩︎\nZie Marcus en Mackuen (1993) voor een baanbrekende studie hierover en meer recent werk van Valentino e.a. (2011) en Vasiopoulos e.a. (2019).↩︎\nDe formule is: \\(\\alpha = \\frac{k\\bar{c}}{\\bar{v} + (k - 1)\\bar{c}}\\). \\(k\\) = aantal items. \\(\\bar{v}\\) = gemiddelde variantie van de items. \\(\\bar{c}\\) = gemiddelde covariantie van de items.↩︎\nRespondenten kunnen weigeren of ‘Don’t know’ antwoorden geven bijvoorbeeld. Deze antwoorden worden doorgaans op missing gezet.↩︎\nProbeer een index niet manueel te maken (bv., newvar = var1 + var2 + var3). Dit werkt als er geen missing data is, maar dit is in de praktijk vaak niet het geval.↩︎\nWe zouden hier ook de complete.cases() functie kunnen gebruiken zoals we dat doen om model fit statistieken over modellen heen te kunnen analyseren (zie Paragraaf 6.2). Daarmee zouden we ook observaties wegdoen die maar voor een of enkele variabelen een ontbrekende waarde hebben. Wat we nu doen is ervan uitgaan dat een ontbrekende waarde een probleem vormt als alles ontbreekt, maar dat we in een situatie met zowel valide als ontbrekende waarden mogen uitgaan van een ‘0’ score voor de variabele waar een ontbrekende waarde wordt genoteerd. Dit kunnen we natuurlijk ter discussie stellen. Vaak moeten we een afweging maken over hoe we zoveel data als mogelijk kunnen gebruiken en hoe we zo accuraat mogelijk met de data kunnen omgaan. we zouden ook kunnen beslissen om observaties weg te doen die ontbrekende waarden hebben voor meer dan de helft van de variabelen enz.↩︎\nOLS modellen zijn niet altijd geschikt voor variabelen waarbij een telling wordt gemaakt (‘count data’). Meer toepasselijke modellen (poisson regressie en negative binomial modellen) vallen echter buiten dit handboek.↩︎\nDe VN nemen enkele datamanagement stappen vooraleer de HDI te berekenen. Deze hebben wij hier ook genomen. Voor landen met een levensverwachting groter dan 85 wordt de waarde vastgezet op een maximum van 85. Voor landen met een BNI onder 100 wordt de waarde vastgezet op 100 (vooraleer het natuurlijk logaritme wordt genomen). De redenen hiervoor staan uitgelegd hier.↩︎\nWe berekenen hier gewoon het gemiddelde, maar de VN gebruikt het geometrisch gemiddelde. Hierdoor wijkt onze berekening wat af. Het psych package bevat een functie om het geometrisch gemiddelde te berekenen.↩︎",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Indexen en schalen</span>"
    ]
  },
  {
    "objectID": "part_linear.html",
    "href": "part_linear.html",
    "title": "Lineaire Statistische Modellen",
    "section": "",
    "text": "Dit onderdeel richt zich op het uitvoeren van lineaire statistische analyses. Je leert…\n\nde correlatiecoëfficiënt tussen 2 continue variabelen te berekenen en interpreteren.\neen lineair regressiemodel uit te voeren met zowel continue als categorische onafhankelijke variabelen.\nschendingen van assumpties van lineaire modellen na te gaan.",
    "crumbs": [
      "Lineaire Statistische Modellen"
    ]
  },
  {
    "objectID": "part_logistic.html",
    "href": "part_logistic.html",
    "title": "Logistische Regressiemodellen",
    "section": "",
    "text": "In dit onderdeel richten we ons op logistische regressies voor binaire afhankelijke variabelen. We leren hoe…\n\nEen logistisch model te schatten\nHoe het model te interpreteren op basis van de coëfficiënten, de odds ratios, marginale effecten en voorspelde waarden.\nDe assumpties van deze modellen te testen",
    "crumbs": [
      "Logistische Regressiemodellen"
    ]
  },
  {
    "objectID": "part_interactions.html",
    "href": "part_interactions.html",
    "title": "Interacties in Lineaire en Logistische Regressiemodellen",
    "section": "",
    "text": "In dit onderdeel ligt de focus op de inclusie van interactie-effecten in regressieanalyses en hun interpretatie. Je leert hoe je…\n\nInteractievariabelen toevoegt aan regressiemodellen\ngemiddelde marginale effecten en voorspelde waarden/kansen gebruikt om interactie te interpreteren.",
    "crumbs": [
      "Interacties in Lineaire en Logistische Regressiemodellen"
    ]
  }
]