---
title: "Overview of R functions - Complex survey data"
author: "Leila Demarest"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: yes
    number_sections: true
    toc_depth: 3
    toc_float:
      collapsed: yes
  word_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

In this overview document, we demonstrate how to account for stratification, clustering, and weighting in regression analyses. We first load relevant packages and import the dataset to work with. We use the France Round 9 dataset of the [European Social Survey](https://www.europeansocialsurvey.org) (ESS). This dataset is available in SPSS format (.sav) from the ESS website. Missings are already indicated as 'NA' in this dataset.

```{r, message=FALSE}
library(survey)          #complex survey data
library(sandwich)        #robust standard errors
library(lmtest)          #use in combo with sandwich
library(rio)             #loading data
library(modelsummary)    #for creating regression tables
library(margins)         #calculating AMEs
library(marginaleffects) #calculating AMEs
library(tidyverse)       #data manipulation and plotting
library(broom)           #tidying
```

```{r}
ESS9FR <- import("Data/ESS9e03, France.sav")
```

We will use a linear model in which we predict trust in the country's parliament (*trstprl*) with gender (*gndr*), age (*agea*), trust in people (*ppltrst*), use of internet (*netusoft*). We factorize gender first and then run the OLS regression model for a simple random sample by way of example.

```{r}
ESS9FR <- ESS9FR |>
  mutate(gndr_f = factorize(gndr))
ESS9FR <- ESS9FR |>
  mutate(gndr_f = droplevels(gndr_f))

Model <- lm(trstprl ~ gndr_f + agea + ppltrst + netusoft, data=ESS9FR)
summary(Model)
```

# Survey Design

The package [survey](https://cran.r-project.org/web/packages/survey/index.html) can be used to indicate complex survey sample designs and take the design into account for analyses. The first step is indicating the stratification variable, the cluster (PSU) variable, and the weight variable via the `svydesign` function. Note that each of the variables is preceded by a tilde (\~).

It is not possible to leave out the cluster variable in the function. If no clustering occurred, you can default to a unique number per observation (e.g. respondent number, *idno*). In the following section, we indicate stratification, clustering, and weights first separately in the design. The final code and model can be found in the ´Combined´ section, which also includes a logistic regression example.

The survey package model results can be combined with the `modelsummary` package. You specify design elements in the notes section (e.g. standard errors clustered at...).

# Stratification

While stratification is often not accounted for in analyses, we first demonstrate how to adjust standard errors for this design feature. The `svydesign`function below does not indicate a real cluster variable yet but the response number *idno* (see above). For strata, we indicate the variable *stratum* which is the name given to the stratification variable in this specific dataset. The `summary` function can be used to obtain information on the data structure. We do not include it here given the volume of data printed.

```{r}
ESS9FRsvy <- svydesign(id= ~idno, strata= ~stratum, data=ESS9FR)
```

To estimate the linear regression, we now have to rely on generalized linear modelling (`glm`) given the complex survey design. Instead of indicating the dataset, we indicate the design object created with `svydesign`in the formula. The results of the model can be compared with the simple regression model above.

```{r}
Modelstrat <- svyglm(trstprl ~ gndr_f + agea + ppltrst + netusoft, design = ESS9FRsvy)
summary(Modelstrat)
```

# Clustering

We now account for clustering with the `svydesign`function (removing the stratification element of the design). The cluster variable in the dataset is *psu*.

```{r}
ESS9FRsvy <- svydesign(id= ~psu, data=ESS9FR)
```

Again, we estimate the model and can inspect the difference between our clustered standard errors and the ones from the simple model estimated above.

```{r}
Modelclust <- svyglm(trstprl ~ gndr_f + agea + ppltrst + netusoft, design = ESS9FRsvy)
summary(Modelclust)
```

## Clustering non-survey data

Note that clustering of standard errors does not only apply when using complex survey data, but is also used in case of other nested structures (e.g. lawmakers belonging to the same political party) or repeated observations (e.g. country-year dataset). To account for clustering in these cases, we can use the `vcovCL` function from the [sandwich](https://cran.r-project.org/web/packages/sandwich/index.html) package (in combination with [lmtest](https://cran.r-project.org/web/packages/lmtest/index.html) which has the function `coeftest`). This package is also used to estimate heteroskedasticity robust errors (with the function `vcovHC`). Note that estimation results are not entirely identical to the svy ones.

Here we use these packages to estimate clustered standard errors for the same model. Note that slight calculation differences between methods are typical.

```{r}
coeftest(Model, vcov = vcovCL(Model, cluster = ~psu))
```

# Weights

Now we include weights in the analysis with the `svydesign`function (removing the stratification and cluster elements of the design). The weight variable in the dataset is *pspwght*.

```{r}
ESS9FRsvy <- svydesign(id= ~idno, weights = ~pspwght, data=ESS9FR)
```

The model is estimated as follows:

```{r}
Modelw <- svyglm(trstprl ~ gndr_f + agea + ppltrst + netusoft, design = ESS9FRsvy)
summary(Modelw)
```

# Combined

All design features can be easily combined as follows:

```{r}
ESS9FRsvy <- svydesign(id= ~psu, weights = ~pspwght, strata= ~stratum, data=ESS9FR)
```

And model results inspected:

```{r}
Modelall <- svyglm(trstprl ~ gndr_f + agea + ppltrst + netusoft, design = ESS9FRsvy)
summary(Modelall)
```

## Logistic regression example

The complex survey design functions used for linear regression can easily be used for logistic regression. Here we estimate a model with the same predictors, using *vote* (yes/no) as the dependent.

```{r}
ESS9FR <- ESS9FR |>
  mutate(vote = factorize(vote)) 
ESS9FR <- ESS9FR |> 
  mutate(vote = relevel(vote, "No"))
ESS9FR <- ESS9FR |>
  mutate(vote = na_if(vote, 
                      "Not eligible to vote"))
```

Note that we have to define the sample design again, otherwise the vote recoding into a binary is not copied to the design dataset:

```{r}
ESS9FRsvy <- svydesign(id= ~psu, weights = ~pspwght, strata= ~stratum, data=ESS9FR)

```

```{r}
Modellog <- svyglm(vote ~ gndr_f + agea + ppltrst + netusoft, family= binomial, design = ESS9FRsvy)
summary(Modellog)
```

The warning on non-integer successes is due to the addition of weights and can be ignored.

## AMEs

The `marginaleffects`package is not compatible with the svy features. The [margins](https://cran.r-project.org/web/packages/margins/index.html) package is, however. To use it, we have to take care to:

-drop unused levels from predictor factor variables (done for gender above)

-use a complete cases dataset

-redefine the survey design with the complete cases dataset.

Here we use one more addition:

`options(survey.lonely.psu="adjust")`. This option prevents a warning if there is only 1 observation in a (lonely) cluster.

```{r}
ESS9FR_complete <- ESS9FR |>
  filter(complete.cases(vote, gndr_f, agea, ppltrst, netusoft))

ESS9FRsvy <- svydesign(id= ~psu, weights = ~pspwght, strata= ~stratum, data=ESS9FR_complete)

options(survey.lonely.psu="adjust")
```

```{r}
Modellog <- svyglm(vote ~ gndr_f + agea + ppltrst + netusoft, family= binomial, design = ESS9FRsvy)
summary(Modellog)
```

We specify the design in the margins command to estimate the AMEs:

```{r}
margins(Modellog, design = ESS9FRsvy)
```

We could make use of the `marginaleffects`package with some tweaks. We cannot include stratification, but can account for clustering and weights as follows. Estimation results can differ from svy.

```{r}
#weights can be added to the lm or glm functions
Modellog2 <- glm(vote ~ gndr_f + agea + ppltrst + netusoft, family= binomial,
                 data = ESS9FR_complete,
                 weights = pspwght)

#clustered SEs can be added in the AME syntax, weigths need to be specified again
AME <- avg_slopes(Modellog2,
                  conf_level = 0.95, 
                  vcov = ~psu,
                  wts = "pspwght",
                  newdata = ESS9FR_complete)
tibble(AME)
```
