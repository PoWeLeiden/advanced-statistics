{"title":"OLS Assumpties","markdown":{"yaml":{"code-annotations":"hover"},"headingText":"OLS Assumpties","headingAttr":{"id":"sec-ols-assumptions","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n\n\nIn dit hoofdstuk ligt de focus op het testen van de assumpties van OLS regressie. Deze 6 assumpties worden getest:\n\n-   Onafhankelijke fouten (autocorrelatie)\n-   Beperkte multicollineariteit\n-   Lineariteit en additiviteit\n-   Homoskedasticiteit\n-   Normaal verdeelde errors (residuals)\n-   Beperkte impact 'outliers' en 'influential cases'\n\nWe beginnen met het laden van relevante R packages. Deze packages zijn reeds geïnstalleerd op de universitaire computers, maar moeten eerst geladen worden.\n\n```{r}\n#| message: false\n#| warning: false\n\n#specifieke packages voor testen assumpties\nlibrary(car)             #meerdere assumptie testen\nlibrary(ggResidpanel)    #assumpties testen met grafieken\nlibrary(expss)           #frequentietabellen maken\n\n#algemene packages\nlibrary(rio)             #laden van data\nlibrary(tidyverse)       #datamanipulatie en grafieken\nlibrary(broom)           #data voor residuals en influential cases\nlibrary(marginaleffects) #voorspellingen\n```\n\n::: callout-important\n#### Waarschuwing!\n\nHet is belangrijk te vermelden dat 2 packages die we hier gebruiken voor het testen van assumpties niet altijd compatibel zijn met het `dplyr` package (uit `tidyverse`): `car` en `expss`. Deze 2 packages hebben namelijk ook een `recode` functie die een verschillende syntax gebruikt dan dezelfde functie in `dplyr`. Als je de `recode` syntax van `dplyr` gebruikt (onze standaard) na het laden van `car` of `expss` kun je een foutmelding krijgen. Er zijn 3 manieren om hier mee om te gaan:\n\n-   We laden `car` en `expss` vooraleer we `tidyverse` laden om ervoor te zorgen dat de `recode` functie van `dplyr` geïnstalleerd wordt als de finale versie. Dit is wat we doen in de R code hierboven;\n\n-   Wanneer je gebruik maakt van `recode`, kun je het specifieke package voor de functie ook aanduiden in de syntax. In plaats van gewoon `recode` te schrijven, schrijf je dan `dplyr::recode`.\n\n-   Je kunt `car` en `expss` ook ontkoppelen nadat je ze gebruikt hebt om specifieke assumpties te testen met de `detach` functie. De R code hieronder toont hoe je dit kan doen. Hier wordt er een hashtag voor de syntax geplaatst zodat de code niet echt wordt gebruikt, gezien we de packages verder nog gebruiken in dit overzicht.\n\n```{r}\n# detach(\"package:car\")\n# detach(\"package:expss\")\n```\n:::\n\n## Onafhankelijke fouten en de Durbin-Watson test {#sec-linear-autocorr-DW}\n\nDe assumptie van onafhankelijke fouten is gerelateerd aan de voorwaarde dat observaties onafhankelijk van elkaar geselecteerd moeten zijn. Aan deze voorwaarde is niet voldaan als er een tijdsrelatie is tussen de observaties of als er sprake is van geografische clustering (bv. gebruik van multistage sampling voor een survey).\n\nDe Durbin-Watson test kan gebruikt worden om na te gaan of een tijdsrelatie leidt tot een te sterke correlatie tussen de fouten (errors/residuals). De test kan niet gebruikt worden als er geen tijdsrelatie is (bv. een cross-sectionele survey). Bovendien moet de dataset geordend zijn volgens tijd: van oud naar nieuw of van nieuw naar oud.\n\nDe voorbeelddataset \"gdp-dem, time order.csv\" voldoet aan deze voorwaarden. Het bevat het BBP (\"gdp\") en de democratiescore (\"democracy\") voor een enkel land over de jaren heen. De dataset is fictief. Er is geen missing data, maar de syntax kan ook gebruikt worden indien er ontbrekende waarden zijn ('NA').\n\n```{r}\n#| eval: false\ndta <- import(\"gdp-dem, time order.csv\")\nhead(dta, n = 10L) #Zodat we enkel 10 eerste rijen zien\n```\n\n```{r}\n#| echo: false\ndta <- import(\"data/gdp-dem, time order.csv\")\nhead(dta, n = 10L)\n```\n\nIndien de dataset niet gesorteerd is, kun je dit zelf doen met behulp van de `arrange` functie uit het `dplyr` package (onderdeel van `tidyverse`).\n\n```{r}\n#sorteer oud-nieuw\ndta <- dta |>\n  arrange(year)\n\n#sort nieuw-oud\ndta <- dta |>\n  arrange(desc(year))\n```\n\n`dta <- dta`\n\n:   Met deze code verduidelijken we dat we willen dat de nieuwe, gesorteerde dataset, de oude overschrijft. We zouden ook een nieuwe dataset kunnen creëren zonder de oude te vervangen, maar dat is meestal niet nodig.\n\n`arrange(year)`\n\n:   Met deze functie sorteren ('arrange') we de dataset volgens de waarden van de variabele tussen haakjes. Op deze manier wordt gesorteerd van lage (oud) naar hogere waarden (nieuw). We kunnen op meerdere variabelen sorteren door deze tussen haakjes toe te voegen, gescheiden van elkaar door een komma.\n\n`arrange(desc(year))`\n\n:   Met deze syntax laten we de dataset sorteren van hoge (nieuw) naar lage (oud) waarden (\"descending\").\n\nWe voeren een bivariate regressieanalyse uit met gdp als onafhankelijke variabele en democratie als afhankelijke variabele:\n\n```{r}\ntime_model <- lm(democracy ~ gdp, data = dta)\ntidy(time_model)\n```\n\nDan gebruiken we de Durbin-Watson uit het [car](https://CRAN.R-project.org/package=car) package.\n\n```{r}\ndurbinWatsonTest(time_model) \n```\n\n`durbinWatsonTest(modelname)`\n\n:   We voeren de Durbin-Watson test uit op het model tussen haakjes.\n\n::: callout-note\n#### Output uitleg\n\n-   Autocorrelation: Mate van correlatie tussen de fouten (errors of residuals)\n-   D-W Statistic: De Durbin-Watson statistiek. Waarden lager dan 1 en hoger dan 3 wijzen op te hoge autocorrelatie\n-   p-waarde: p-waarde voor de nulhypothese dat de autocorrelatie niet significant van 0 verschilt, de alternatieve hypothese is dat die wel verschilt.\n:::\n\nDe D-W statistiek voor dit model is `r round(durbinWatsonTest(time_model)$dw, 2)`. Dit wijst op een probleem met autocorrelatie.\n\n## Beperkte multicollineariteit {#sec-linear-no-excessive-multicollinearity}\n\nVoor de andere assumptietests maken we gebruik van data zonder autocorrelatie. We gebruiken onze landendataset (`demadata.rds`) en schatten een meervoudig regressiemodel waarbij V-Dem polyarchy scores (`v2x_polyarchy`) voorspeld worden op basis van economische ongelijkheid (`gini_2019`), regime in het verleden (`TYPEDEMO1984`: democratie of autocratie in 1984, naar een factor variabele getransformeerd) en BBP in 2006 (`GDP2006`).\n\n```{r}\n#| eval: false\n#data laden\ndemdata <- import(\"demdata.rds\") |> \n  as_tibble()\n\n#Factor maken van binaire variabele\ndemdata <- demdata |> \n  mutate(TYPEDEMO1984_factor = factorize(TYPEDEMO1984))\n\n#Meervoudig model schatten en resultaten bekijken\nmodel_multiple <- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984_factor + GDP2006, data = demdata)\n\nsummary(model_multiple)\n```\n\n```{r}\n#| echo: false\n#Load Data\ndemdata <- import(\"data/demdata.rds\") |> \n  as_tibble()\n\n#Factorize our binary variable\ndemdata <- demdata |> \n  mutate(TYPEDEMO1984_factor = factorize(TYPEDEMO1984))\n\n#Run and store a model and then look at the output\nmodel_multiple <- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984_factor + GDP2006, data = demdata)\n\ntidy(model_multiple, conf.int = TRUE)\n```\n\nDe coëfficienten voor `gini_2019` (p = 0.322) en `TYPEDEMO1984_factor` (p = 0.246) zijn niet significant. Om te kijken of er sprake is van te hoge multicollineariteit gebruiken we opnieuw het `car` package, nu voor de `vif()` functie.\n\n```{r}\nvif(model_multiple)\n```\n\n`vif(multiple)`\n\n:   We gebruiken de vif functie op het model tussen haakjes\n\nDe output geeft de VIF statistieken voor elke onafhankelijke variabele. Geen van de waarden is hoger dan 5 dus is er geen sprake van te hoge multicollineariteit.\n\n::: callout-important\n#### Waarschuwing!\n\nIndien je een factor variabele opneemt met 3 of meer oorspronkelijke categorieën (bv. meerdere regio's, onderwijsniveaus) dan krijg je licht andere output:\n\n```{r}\ndemdata <- demdata |> \n  mutate(Typeregime2006_factor = factorize(Typeregime2006))\n\nvif_example <- lm(v2x_polyarchy ~ gini_2019 + GDP2006 + Typeregime2006_factor, data = demdata) \n\nvif(vif_example)\n```\n\n`vif()` geeft nu een `GVIF` en `GVIF^(1/(2*DF))`. Dit zijn aanpassingen gezien categorische variabelen meerdere coëfficiënten hebben en dus vrijheidsgraden. We evalueren multicollineariteit door `GVIF^(1/(2*DF))` te kwadrateren en we gebruiken dezelfde vuistregels als bij de gewone VIF. In principe kunnen we ook kijken of `GVIF^(1/(2*DF))` op zich hoger is dan 2.23 (gezien 2.23²= 5).\n:::\n\n## Lineariteit en additiviteit\n\nEen lineair regressiemodel berust op de assumptie dat er een lineaire relatie is tussen de predictoren en de afhankelijke variabele. Om te onderzoeken of de assumptie niet geschonden is maken we gebruik van plots, aangemaakt via het [ggResidpanel](https://CRAN.R-project.org/package=ggResidpanel) package.\n\nWe gaan hier eerst de assumptie na voor een simpel model waarbij electorale democratie (`v2x_polyarchy`) voorspeld wordt door ongelijkheid (`gini_2019`).\n\n```{r}\nbivar_model <- lm(v2x_polyarchy ~ gini_2019, data=demdata)\n\nresid_panel(bivar_model, plots = c(\"resid\"))\n```\n\n`resid_panel(bivar_model,`\n\n:   We voeren de functie resid_panel uit op het model tussen haakjes.\n\n`plots = c(\"resid\"))`\n\n:   De functie kan gebruikt worden voor meerdere soorten plots. Hier verduidelijken we dat we het plot van residuals tegen voorspelde waarden willen (\"resid\").\n\nOp het plot zien we geen duidelijk patroon in de data, over het algemeen gewoon een puntenwolk. Het ontbreken van een patroon duidt erop dat de relatie tussen ongelijkheid en democratiescores als lineair kan beschouwd worden.\n\nWanneer je een ordinale variabele gebruikt als predictor in plaats van een echt continue variabele, dan ziet het plot er anders uit (i.e. neerwaarts gaande lijnen van residuals).\n\n### Logaritmische functies\n\nWe krijgen niet altijd gewoon een puntenwolk zonder patroon te zien. Laten we het plot bekijken voor ons complexer model voor democratiescores (`model_multiple`).\n\n```{r}\nresid_panel(model_multiple, plots = c(\"resid\"))\n```\n\nIn het plot zien we een lijnpatroon bij hogere waarden op de x-as. We kunnen onderzoeken welke onafhankelijke variabele dit patroon veroorzaakt door te kijken naar de partiële regressieplots via de `avPlots()` functie uit het `car` package.\n\n```{r}\navPlots(model_multiple)\n```\n\n`avPlots(model_multiple)`\n\n:   We vragen R om de partiële regressieplots voor het model tussen haakjes.\n\nDeze partiële regressieplots (\"added-variable plot\") tonen de relatie tussen de predictor en de afhankelijke variabele gecontroleerd voor de andere predictoren in het model.\n\nVoor de onafhankelijke variabele `gini_2019`, vinden we een relatief vlakke lijn (de coëfficiënt was ook niet significant). De residuals zijn vrij gelijk verspreid onder en boven de lijn dus er lijkt geen afwijking van lineariteit te zijn.\n\nVoor de `TYPEDEMO1984_factor` variabele bekijken we het plot niet gezien we slechts twee waarden voor deze variabele hebben.\n\nAls we de onafhankelijke variabele `GDP2006` bekijken vinden we een positief hellende regressielijn (de coëfficiënt was ook significant), maar de punten zijn niet gelijk verspreid rond de lijn. Het lijkt hier eerder dat de relatie een degressieve curve volgt dan een rechte lijn.\n\nOm hiervoor te compenseren voeren we een logaritmische transformatie uit op `GDP2006`. We kunnen dit doen via `mutate`.\n\n```{r}\n#nieuwe gelogde variabele die we kunnen toevoegen aan de regressie\ndemdata <- demdata |>\n  mutate(LNGDP2006 = log(GDP2006))\n#gevolgd door regressie\nmultiple_ln <- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984_factor + LNGDP2006, \n               data=demdata)\n```\n\nWe kunnen nu het residual plot en de partiële regressieplots opnieuw inspecteren.\n\n```{r}\n#Residual Plot\nresid_panel(multiple_ln, plots = c(\"resid\"))\n\n#Partiële regressieplots\navPlots(multiple_ln)\n```\n\n::: callout-important\n#### Waarschuwing!\n\nMet de logaritimische transformatie van een predictor verandert ook de interpretatie van de coëfficiënt. De volgende regels zijn van toepassing:\n\n-   **1**% toename in X (op originele schaal) leidt tot een verandering van coëfficiënt \\* log(1.**01**) eenheden in Y\n\n-   **10**% toename in X (op originele schaal) leidt tot een verandering van coëfficiënt \\* log(1.**10**) eenheden in Y\n\nBij een gelogde predictor is het echter vaak aan te raden een figuur met voorspelde waarden te maken om het effect te duiden.\n\nEerst kijken we naar de verdeling van de waarden van de gelogde predictor over alle observaties gebruikt in het model. We bekijken dus enkel data zonder ontbrekende waarden ('NA') voor een of meerdere van de variabelen gebruikt in het model.\n\n```{r}\n# Eerst de waarden van GDP2006 nagaan voor de gebruikte observaties\ndemdata_sub <- demdata |>\n  filter(complete.cases(v2x_polyarchy, gini_2019, TYPEDEMO1984_factor, LNGDP2006))\n\nsummary(demdata_sub$LNGDP2006)\n```\n\nDan berekenen we voorspelde waarden over het bereik van de gelogde predictor. Hier willen we best veel voorspelde waarden berekenen want dan krijgen we een mooiere gecurvde lijn in onze figuur.\n\n```{r}\n# voorspellingen\nbbp_preds <- predictions(multiple_ln, \n                         newdata = datagrid(LNGDP2006= seq(from=5.5,\n                                                           to=11,\n                                                           by=0.5)))  # <1>\n\n```\n\n1.  `seq()` staat voor 'sequence'. We vragen hier om voorspelde waarden te berekenen vanaf 5.5 tot 11 met tussenstappen van 0.5 eenheden.\n\nDan maken we een nieuwe variabele aan in de dataset om op de x-as van onze figuur te gaan plaatsen. Eigenlijk gaan we gewoon de gelogde predictor in de dataset terug transformeren naar de originele schaal door de waarden te exponentiëren via de `exp()` functie.\n\n```{r}\n#exponentiëren van gelogde predictor\nbbp_preds <- bbp_preds |> \n  mutate(GDP2006 = exp(LNGDP2006)) # <1>\n```\n\n1.  `exp()` is het omgekeerde van log, zoals - het omgekeerde is van + etc.\n\nTen slotte maken we onze figuur:\n\n```{r}\n#figuur maken van voorspelde waarden\nggplot(bbp_preds, aes(x=GDP2006, y=estimate)) + \n  geom_line() +\n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), \n              alpha = 0.1) +\n  labs(title = \"Voorspelde electorale democratiescore op basis van BBP 2006\",\n       x = \"BBP 2006\",   \n       y = \"Voorspelde waarde\") +  \n  scale_y_continuous(limits=c(0,1))\n```\n\nInterpretaties veranderen ook als je de afhankelijke variabele log-transformeert. Voor verdere mogelijkheden met logaritmische transformaties, verwijzen we ja naar [deze](https://kenbenoit.net/assets/courses/ME104/logmodels2.pdf) en [deze](https://library.virginia.edu/data/articles/interpreting-log-transformations-in-a-linear-model) pagina.\n:::\n\n### Kwadratische functies {#sec-quadratic-relationships}\n\nEen andere niet-lineaire relatie die we kunnen tegenkomen is de kwadratische of curvilineaire relatie. Bij wijze van voorbeeld hier inspireren we ons op de 'meer geweld in het midden'-these, namelijk het idee dat landen met hybride regimes (gemiddelde democratiescores) meer geweld en instabiliteit ervaren dan zowel autoritaire systemen (lage democratiescores) als democratische systemen (hoge democratiescores).\n\nDe variabele voor politiek geweld en instabiliteit is hier `pve` en is gebaseerd of de 2021 World Governance Indicators. Hogere waarden staan voor minder geweld en instabiliteit. Hier gebruiken we electorale democratie (`v2x_polyarchy`) als onafhankelijke variabele.\n\nWe inspecteren hier eerst de empirische, bivariate relatie met behulp van een scatterplot.\n\n```{r}\n#| warning: false\n#| message: false\n\nggplot(demdata, aes(x = v2x_polyarchy, y = pve)) + \n  geom_point() + \n  geom_smooth(method = \"loess\") +\n  labs(title = \"Politiek geweld en democratie\", \n       x = \"Electorale democratie (2020)\", \n       y = \"Afwezigheid van politiek geweld en instabiliteit (2021)\")\n```\n\nDe syntax lijkt sterk op wat we eerder gezien hebben (@sec-visualizing-bivariate-relationships-with-a-scatterplot), met 1 belangrijk verschil:\n\n`geom_smooth(method = \"loess\")`\n\n:   Hier vragen we R om een lijn te tekenen om de relatie tussen de 2 variabelen te vatten. We vragen hier niet om een rechte lijn (method=\"lm\"), maar een 'locally estimated scatterplot smoothing' (loess) lijn (method = \"loess\"). Deze lijn volgt de data zo nauwgezet mogelijk om de relatie tussen de variabelen weer te geven. De loess methode is de standaard (default) methode om de lijn te tekenen. We zouden dus ook gewoon `geom_smooth()` kunnen schrijven om dezelfde uitkomst te verkrijgen.\n\nZoals we kunnen zien als we naar het scatterplot kijken is er enige steun voor een curvilineaire relatie. We schatten nu eerst een lineair regressiemodel:\n\n```{r}\n#schat het model\nViolence_linmodel <- lm(pve ~ v2x_polyarchy, data = demdata)\n\n#bekijk resultaten\ntidy(Violence_linmodel, conf.int = TRUE)\n```\n\nDe niet-lineaire relatie kun je soms zien uit het residuals plot, in de vorm van een gebogen patroon, maar dit is visueel minder zichtbaar hier:\n\n```{r}\nresid_panel(Violence_linmodel, plots = c(\"resid\"))\n```\n\nOm te onderzoeken of de relatie beter als kwadratisch wordt gevat voegen we een kwadratische term toe aan het model. We kunnen deze variabele eerst maken en dan toevoegen aan het model, samen met de originele variabele. We kunnen de transformatie ook in de regressielijn zelf toevoegen via de `I()` functie. Dit is iets eenvoudiger gezien we de variabele niet moeten maken. Bovendien werkt deze methode beter met functies van het `marginaleffects` package die we gebruiken om modellen te interpreteren (bv. de `predictions()` functie).\n\n```{r}\n#gewadrateerde variabele maken\ndemdata <- demdata |> \n  mutate(v2x_polyarchy_sq = v2x_polyarchy^2)\n\n#nieuw model schatten\nViolence_sqmodel <- lm(pve ~ v2x_polyarchy + v2x_polyarchy_sq, \n               data=demdata)\n\n#transformatie toepassen in regressie\nViolencesqmodel <- lm(pve ~ v2x_polyarchy + I(v2x_polyarchy^2), \n                      data=demdata)\n\nsummary(Violencesqmodel)\n\ntidy(Violence_sqmodel, conf.int = TRUE)\n```\n\nWe vinden hier dat de kwadratische variabele significant is (p \\< 0.001) en dus dat de relatie tussen `v2x_polyarchy` en `pve` beter als curvilineair dan lineair te beschrijven is.\n\nWe kunnen dan het residuals plot opnieuw inspecteren (zie onder).\n\n::: callout-important\n#### Waarschuwing!\n\nBij een kwadratische predictor is de interpretatie van de coëfficiënten (want de originele en gekwadrateerde variabelen horen samen) best moeilijk. De volgende regels zijn van toepassing:\n\n-   Als de coëfficiënt voor X positief is en die voor X^2^ negatief, dan is de relatie tussen X en Y **concaaf** (omgekeerde U)\n-   Als de coëfficiënt voor X negatief is en die voor X^2^ positief, dan is de relatie tussen X en Y **convex** (U-vorm)\n-   Als beide coëfficiënten dezelfde richting hebben (beiden positief of beiden negatief), dan wordt het effect van X op Y sterker als X hogere waarden aanneemt.\n\nWederom is het vaak beter om de relatie visueel te verduidelijken. Om dit te doen kijken we eerste naar de waarden die de predictor aanneemt voor de observaties gebruikt bij de schatting van het model:\n\n```{r}\n#waarden van X nagaan voor de gebruikte observaties\ndemdata_sub2 <- demdata |>\n  filter(complete.cases(v2x_polyarchy , pve))\nsummary(demdata_sub2$v2x_polyarchy)\n```\n\nWe berekenen vervolgens voorspelde waarden via `predictions()`. Hier willen we best veel voorspelde waarden berekenen want dan krijgen we een mooiere gecurvde lijn in onze figuur.\n\n```{r}\n# voorspellingen maken op basis van de waarden\npve_preds <- predictions(Violencesqmodel, \n                         newdata = datagrid(v2x_polyarchy= seq(from=0, to=0.9, by=0.05)))\n```\n\nTen slotte maken we onze figuur:\n\n```{r}\n#figuur maken van voorspelde waarden\nggplot(pve_preds, aes(x=v2x_polyarchy, y=estimate)) + \n  geom_line() +\n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), \n              alpha = 0.1) + \n  labs(title = \"Voorspelde afwezigheid van geweld en instabiliteit\",\n       x = \"Electorale democratie\",   \n       y = \"Voorspelde waarde\") \n```\n:::\n\n## Homoskedasticiteit\n\nOm te onderzoeken of de assumptie van homoskedasticiteit geschonden is maken we opnieuw gebruik van het residuals plot (scatterplot van voorspelde waarden en residuals). Hier vinden we bijvoorbeeld heteroskedasticiteit voor het kwadratische model (`Violence_sqmodel`):\n\n```{r}\n\nresid_panel(Violence_sqmodel, plots = c(\"resid\"))\n```\n\nOpnieuw zien we liever een wolk van toevallig verspreide punten (homoskedasticiteit) eerder daan een trechter-vorm (heteroskedasticiteit). De trechter-vorm in het plot wijst erop dat de assumptie geschonden is.\n\n## Normaal verdeelde errors\n\nWe onderzoeken of de assumptie van normaal verdeelde errors is geschonden met behulp van 2 mogelijke plots uit het `ggResidpanel` package: een histogram van de fouten en een kwartielplot (qq-plot) van de fouten.\n\nHier gaan we na of de assumptie geschonden is voor ons meervoudig regressiemodel met gelogde GDP predictor (multiple_ln):\n\n```{r}\nresid_panel(multiple_ln, plots = c(\"hist\", \"qq\"))\n```\n\n`plots = c(\"hist\", \"qq\"))`\n\n:   Hier vragen we om het histogram (\"hist\") samen met het qq-plot (\"qq\").\n\nWe zouden ook het residuals plot (\"resid\") kunnen toevoegen indien we meerdere assumpties vlug samen willen testen:\n\n```{r}\nresid_panel(multiple_ln, plots = c(\"resid\", \"hist\", \"qq\"))\n\n```\n\n## Beperkte impact outliers en influential cases\n\nWe gebruiken de `augment()` functie uit het `broom` package op de meervoudig regressie met gelogde GDP predictor (`multiple_ln`). De statistieken worden in een nieuwe dataset opgeslagen in onderstaande code.\n\n```{r}\n#augment gebruiken en resultaten opslaan in nieuw object\ndemdata_multln <- augment(multiple_ln)\n```\n\n`demdata_multln <-augment(multiple_ln)`\n\n:   We gebruiken de augment functie op het model tussen haakjes en slaan de resultaten op in een nieuw data object (`demdata_multln`).\n\nDe gegevens in het dataobject zien er als volgt uit:\n\n```{r}\ndemdata_multln\n```\n\n::: callout-note\n#### Output uitleg\n\n`augment()` creëert een dataframe met alle observaties die gebruikt zijn om het model te schatten. Je vindt de volgende kolommen terug:\n\n-   `.rownames`: Di is het rijnummer van de observatie zoals je die vindt in de originele dataset (zonder eventuele missing waarden)\n-   `v2x_polyarchy` tot en met `LNGDP2006`: Dit zijn de variabelen gebruikt in het model met de waarden die elke observatie ervoor heeft.\n-   `.fitted`: De voorspelde ('fitted') waarden op basis van de schattingen in het model.\n-   `resid`: De residuals (fouten/errors) voor elke observatie, waarbij Residual = Observed - Fitted/Predicted. Hier: Residual = `v2x_polyarchy` - `.fitted`\n-   `.hat`: Diagonaal van de hat matrix (te negeren).\n-   `.sigma:` Geschatte standaardafwijking van de fouten als de observatie uit het model zou worden verwijderd (te negeren)\n-   `.cooksd`: De Cook's D waarde voor de observatie. Zie onder.\n-   `.std.resid`: Niet getoond in de output hierboven maar aanwezig in de dataset. Deze kolom bevat de *gestandaardiseerde* residuals van het model. Zie onder.\n:::\n\nWe gebruiken de gestandaardiseerde residuals (`.std.resid`) om eerst outliers te onderzoeken. Vervolgens gebruiken we de Cook's D waarden (`.cooksd`) om influential cases te onderzoeken.\n\n### Outliers analyseren {#sec-linear-investigating-outliers}\n\nOm te beginnen bekijken we de descriptieve statistieken voor de gestandaardiseerde residuals (opgeslagen in het data object `demdata_multln`) . We kijken specifiek naar de minimum- en maximum waarden als eerste check voor outliers. We bekijken in het bijzonder of gestandaardiseerde residuals hoger zijn dan de drempelwaarden van (\\|1.96\\|, \\|2.58\\|, en zeker \\|3.29\\|).\n\n```{r}\nsummary(demdata_multln$.std.resid)\n```\n\nWe vinden waarden die zorgwekkend kunnen zijn. Zo is er al zeker 1 observatie waarvan de gestandaardiseerde residual een absolute waarde hoger dan 2.58 heeft (aangezien het minimum -3.128 is). Maar we moeten nog nagaan hoeveel observaties precies de drempelwaarden overschrijden.\n\nWe doen dit door 3 dummy variabelen aan te maken in onze dataset: SRE1.96, SRE2.58, SRE3.29. Deze dummy variabelen nemen de waarde '1' aan als de gestandaardiseerde residual van een observatie hoger is dan de drempelwaarde in de naam van de variabele. Als de waarde van de gestandaardiseerde residual lager is, neemt de dummy de waarde '0' aan. We gebruiken hier de `case when` functie (uit `dplyr`) voor de hercodering. Zie [Statistiek I, 5.1](https://poweleiden.github.io/statistiek1/data_05_advanced_recoding.html#recoding-variables-using-case_when){target=\"_blank\"}\n\nOnderstaande code kun je grotendeels onaangepast laten in je eigen voorbeelden, enkel de naam van de dataset (hier: `demdata_multln`) moet aangepast worden voor eigen toepassingen.\n\n```{r}\ndemdata_multln <- demdata_multln |>\n  mutate(SRE1.96 = case_when(\n    .std.resid > 1.96 | .std.resid < -1.96  ~ 1,\n    .std.resid > -1.96 & .std.resid < 1.96 ~ 0),\n         SRE2.58 = case_when(\n    .std.resid > 2.58 | .std.resid < -2.58  ~ 1,\n    .std.resid > -2.58 & .std.resid < 2.58 ~ 0),\n        SRE3.29 = case_when(\n    .std.resid > 3.29 | .std.resid < -3.29  ~ 1,\n    .std.resid > -3.29 & .std.resid < 3.29 ~ 0\n  ))\n```\n\n`demdata_multln <- demdata_multln |>`\n\n:   De nieuwe variabelen maken gebruik van de demdata_multln dataset (voor de .std.resid variabele), en worden ook zelf opgeslagen in deze dataset.\n\n`mutate(SRE1.96 = case_when(`\n\n:   We creëren hier de nieuwe variabele SRE1.96. De waarden worden bepaald door de `case_when` functie.\n\n`.std.resid > 1.96 | .std.resid < -1.96 ~ 1,`\n\n:   Hier duiden we aan dat wanneer gestandaardiseerde residuals groter dan 1.96 of (de streep '\\|' staat symbool voor 'of' ) lager dan -1.96 zijn, de SRE1.96 variabele de waarde 1 aanneemt (\\~). Let erop dat de variabele .std.resid twee keer geschreven moet worden.\n\n`.std.resid > -1.96 & .std.resid < 1.96 ~ 0),`\n\n:   Hier duiden we aan dat wanneer gestandaardiseerde residuals groter dan -1.96 en (de '&' staat hier voor 'en') lager dan 1.96 zijn, de SRE1.96 variabele de waarde 0 aanneemt (\\~).\n\nNu we de dummies aangemaakt hebben kunnen we frequentietabellen voor elk van hen bekijken. We maken gebruik van de `fre()` functie uit het `expss` package.\n\nDe code hieronder kun je wederom grotendeels gebruiken voor eigen voorbeelden; enkel de naam van de dataset (hier: `demdata_multln`) dient veranderd te worden voor eigen toepassingen.\n\n```{r}\nfre(demdata_multln$SRE1.96)\nfre(demdata_multln$SRE2.58)\nfre(demdata_multln$SRE3.29)\n```\n\nWe vinden hier dat meer dan 5% van de observaties een gestandaardiseerde residual heeft met een absolute waarde hoger dan 1.96, meer dan 1% heeft een gestandaardiseerde residual met een absolute waarde hoger dan 2.58. Er is geen enkele observatie met een absolute waarde hoger dan 3.29 (dit konden we reeds aflezen uit de descriptieve statistieken).\n\nOm te onderzoeken of de outliers ook een invloed hebben op de resultaten van het model vergelijken we de resultaten van ons model met die van een nieuw model zonder outliers. Hier doen we dit voor outliers met gestandaardiseerde residuals met absolute waarde hoger dan 1.96. De SRE1.96 variabele kan vervangen worden met de SRE2.58 en SRE3.29 variabelen om alternatieve manieren om outliers uit te sluiten te onderzoeken.\n\n```{r}\nmultiple_ln1.96 <- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984_factor + LNGDP2006,\n               data = subset(demdata_multln, SRE1.96 == 0))\n```\n\n`data = subset(demdata_multln, SRE1.96 == 0))`\n\n:   Met deze code gebruiken we de demdata_multln dataset gecreëerd met augment, maar we behouden enkel observaties die voor de variabele SRE1.96 de waarde 0 hebben.\n\nAls we de modellen met en zonder outliers vergelijken gaan we na of de coëfficiënten en hun significantie substantieel veranderd zijn. Let wel, outliers kunnen niet zomaar verwijderd worden om om de model fit te verbeteren. Er moet een gemotiveerde, theoretische reden zijn voor uitsluiting van observaties.\n\n### Influential cases analyseren {#sec-linear-investigating-influential-cases}\n\nOm influential cases te onderzoeken gaan we na of er observaties zijn in de dataset met hoge Cook's D waarden:\n\n-   waarden hoger dan 1 zijn over het algemeen zorgwekkend;\n\n-   waarden hoger dan 0.5 moeten nader bestudeerd worden en kunnen een risico vormen;\n\n-   waarden die veel hoger zijn dan de andere Cook's D waarden behoeven ook verdere aandacht.\n\nWe bekijken eerst de overzichtsstatistieken voor de Cook's D waarden.\n\n```{r}\nsummary(demdata_multln$.cooksd)\n```\n\nHet overzicht toont dat er minstens 1 observatie is met een hoge Cook's D waarde. De maximum waarde is 0.66 en deze waarde is substantieel hoger dan de andere waarden. De waarde voor het 3de kwartiel is slechts 0.016, wat betekent dat 75% van de observaties een waarde lager hebben dan 0.016.\n\nWe kunnen ook een visualisatie maken van de Cook's D waarden met het `ggResidpanel` package:\n\n```{r}\nresid_panel(multiple_ln, plots = c(\"cookd\"))\n```\n\n`plots = c(\"cookd\"))`\n\n:   We vragen hier om een plot met Cook's D waarden op de y-as. Het rijnummer van de observatie in de dataset komt op de x-as.\n\nDe grafiek toont dat er slechts 1 case is om ons zorgen over te maken. Dit is de case met de maximumwaarde van 0.66.\n\nWe kunnen deze case verwijderen uit het model om na te gaan of de resultaten beïnvloed worden:\n\n```{r}\nmultiple_lncook <- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984_factor + LNGDP2006,\n               data = subset(demdata_multln, .cooksd < 0.65))\n```\n\n`data = subset(demdata_multln, .cooksd < 0.65))`\n\n:   We gebruiken de demdata_multln dataset maar vragen om een subset van de data met enkel die observaties met een waarde lager dan 0.65 voor .cooksd. We kiezen deze waarde hier omdat de case die we willen uitsluiten een waarde van 0.66 heeft. In principe hadden we ook 0.66 zelf, 0.64 enz. kunnen kiezen, zolang het een grenswaarde is die de mogelijk invloedrijke casus uitsluit.\n\nWe kunnen ook outliers en influential cases tegelijk uitsluiten als we in de syntax gebruik maken van het '&' teken:\n\n```{r}\nmultiple_ln_excl <- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984_factor + LNGDP2006,\n               data = subset(demdata_multln,\n                             SRE1.96==0 & .cooksd < 0.65))\n```\n\n### Specifieke probleemgevallen analyseren\n\nWat we in vorige analyses niet bekeken hebben is welke specifieke observaties outliers of influential cases waren. Om dit te kunnen doen moeten we de gestandaardiseerde residuals en Cook's D waarden toevoegen aan onze originele dataset, waar we de country name variabele hebben.\n\nIndien er missende waarden zijn, zoals hier het geval is, kunnen we deze statistieken niet zomaar met augment toevoegen aan de originele dataset. Een oplossing is om eerst een dataset te creëren met niet-missende waarden voor de variabelen gebruikt in het model en dan met augment de statistieken aan deze 'complete cases' dataset toe te voegen:\n\n```{r}\n# subset van de dataset zonder 'NA' waarden\ndemdata_complete <- demdata |>\n  filter(complete.cases(v2x_polyarchy, gini_2019, TYPEDEMO1984_factor, LNGDP2006))\n\n# model opnieuw geschat met nieuwe dataset\nmultiple_ln <- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984_factor + LNGDP2006, \n               data=demdata_complete)\n\n# augment gebruiken om statistieken toe te voegen\ndemdata_complete <-augment(multiple_ln, data=demdata_complete)\n```\n\nNu kunnen we specifieke outliers onderzoeken met de volgende code:\n\n```{r}\ndemdata_complete |> \n  filter(.std.resid > 1.96 | .std.resid < -1.96) |>\n  select(country_name, .std.resid)\n```\n\n`filter(.std.resid > 1.96 | .std.resid < -1.96)`\n\n:   Hier willen we outliers vinden, dus we filteren voor observaties met gestandaardiseerde residual hoger dan 1.96 of lager dan -1.96.\n\n`select(country_name.std.resid)`\n\n:   Hier vragen we R om de namen van de landen en hun specifieke gestandaardiseerde residual.\n\nDe influential case vinden we op een gelijkaardige manier:\n\n```{r}\ndemdata_complete |> \n  filter(.cooksd > 0.65) |>\n  select(country_name, .cooksd)\n```\n","srcMarkdownNoYaml":"\n\n# OLS Assumpties {#sec-ols-assumptions}\n\nIn dit hoofdstuk ligt de focus op het testen van de assumpties van OLS regressie. Deze 6 assumpties worden getest:\n\n-   Onafhankelijke fouten (autocorrelatie)\n-   Beperkte multicollineariteit\n-   Lineariteit en additiviteit\n-   Homoskedasticiteit\n-   Normaal verdeelde errors (residuals)\n-   Beperkte impact 'outliers' en 'influential cases'\n\nWe beginnen met het laden van relevante R packages. Deze packages zijn reeds geïnstalleerd op de universitaire computers, maar moeten eerst geladen worden.\n\n```{r}\n#| message: false\n#| warning: false\n\n#specifieke packages voor testen assumpties\nlibrary(car)             #meerdere assumptie testen\nlibrary(ggResidpanel)    #assumpties testen met grafieken\nlibrary(expss)           #frequentietabellen maken\n\n#algemene packages\nlibrary(rio)             #laden van data\nlibrary(tidyverse)       #datamanipulatie en grafieken\nlibrary(broom)           #data voor residuals en influential cases\nlibrary(marginaleffects) #voorspellingen\n```\n\n::: callout-important\n#### Waarschuwing!\n\nHet is belangrijk te vermelden dat 2 packages die we hier gebruiken voor het testen van assumpties niet altijd compatibel zijn met het `dplyr` package (uit `tidyverse`): `car` en `expss`. Deze 2 packages hebben namelijk ook een `recode` functie die een verschillende syntax gebruikt dan dezelfde functie in `dplyr`. Als je de `recode` syntax van `dplyr` gebruikt (onze standaard) na het laden van `car` of `expss` kun je een foutmelding krijgen. Er zijn 3 manieren om hier mee om te gaan:\n\n-   We laden `car` en `expss` vooraleer we `tidyverse` laden om ervoor te zorgen dat de `recode` functie van `dplyr` geïnstalleerd wordt als de finale versie. Dit is wat we doen in de R code hierboven;\n\n-   Wanneer je gebruik maakt van `recode`, kun je het specifieke package voor de functie ook aanduiden in de syntax. In plaats van gewoon `recode` te schrijven, schrijf je dan `dplyr::recode`.\n\n-   Je kunt `car` en `expss` ook ontkoppelen nadat je ze gebruikt hebt om specifieke assumpties te testen met de `detach` functie. De R code hieronder toont hoe je dit kan doen. Hier wordt er een hashtag voor de syntax geplaatst zodat de code niet echt wordt gebruikt, gezien we de packages verder nog gebruiken in dit overzicht.\n\n```{r}\n# detach(\"package:car\")\n# detach(\"package:expss\")\n```\n:::\n\n## Onafhankelijke fouten en de Durbin-Watson test {#sec-linear-autocorr-DW}\n\nDe assumptie van onafhankelijke fouten is gerelateerd aan de voorwaarde dat observaties onafhankelijk van elkaar geselecteerd moeten zijn. Aan deze voorwaarde is niet voldaan als er een tijdsrelatie is tussen de observaties of als er sprake is van geografische clustering (bv. gebruik van multistage sampling voor een survey).\n\nDe Durbin-Watson test kan gebruikt worden om na te gaan of een tijdsrelatie leidt tot een te sterke correlatie tussen de fouten (errors/residuals). De test kan niet gebruikt worden als er geen tijdsrelatie is (bv. een cross-sectionele survey). Bovendien moet de dataset geordend zijn volgens tijd: van oud naar nieuw of van nieuw naar oud.\n\nDe voorbeelddataset \"gdp-dem, time order.csv\" voldoet aan deze voorwaarden. Het bevat het BBP (\"gdp\") en de democratiescore (\"democracy\") voor een enkel land over de jaren heen. De dataset is fictief. Er is geen missing data, maar de syntax kan ook gebruikt worden indien er ontbrekende waarden zijn ('NA').\n\n```{r}\n#| eval: false\ndta <- import(\"gdp-dem, time order.csv\")\nhead(dta, n = 10L) #Zodat we enkel 10 eerste rijen zien\n```\n\n```{r}\n#| echo: false\ndta <- import(\"data/gdp-dem, time order.csv\")\nhead(dta, n = 10L)\n```\n\nIndien de dataset niet gesorteerd is, kun je dit zelf doen met behulp van de `arrange` functie uit het `dplyr` package (onderdeel van `tidyverse`).\n\n```{r}\n#sorteer oud-nieuw\ndta <- dta |>\n  arrange(year)\n\n#sort nieuw-oud\ndta <- dta |>\n  arrange(desc(year))\n```\n\n`dta <- dta`\n\n:   Met deze code verduidelijken we dat we willen dat de nieuwe, gesorteerde dataset, de oude overschrijft. We zouden ook een nieuwe dataset kunnen creëren zonder de oude te vervangen, maar dat is meestal niet nodig.\n\n`arrange(year)`\n\n:   Met deze functie sorteren ('arrange') we de dataset volgens de waarden van de variabele tussen haakjes. Op deze manier wordt gesorteerd van lage (oud) naar hogere waarden (nieuw). We kunnen op meerdere variabelen sorteren door deze tussen haakjes toe te voegen, gescheiden van elkaar door een komma.\n\n`arrange(desc(year))`\n\n:   Met deze syntax laten we de dataset sorteren van hoge (nieuw) naar lage (oud) waarden (\"descending\").\n\nWe voeren een bivariate regressieanalyse uit met gdp als onafhankelijke variabele en democratie als afhankelijke variabele:\n\n```{r}\ntime_model <- lm(democracy ~ gdp, data = dta)\ntidy(time_model)\n```\n\nDan gebruiken we de Durbin-Watson uit het [car](https://CRAN.R-project.org/package=car) package.\n\n```{r}\ndurbinWatsonTest(time_model) \n```\n\n`durbinWatsonTest(modelname)`\n\n:   We voeren de Durbin-Watson test uit op het model tussen haakjes.\n\n::: callout-note\n#### Output uitleg\n\n-   Autocorrelation: Mate van correlatie tussen de fouten (errors of residuals)\n-   D-W Statistic: De Durbin-Watson statistiek. Waarden lager dan 1 en hoger dan 3 wijzen op te hoge autocorrelatie\n-   p-waarde: p-waarde voor de nulhypothese dat de autocorrelatie niet significant van 0 verschilt, de alternatieve hypothese is dat die wel verschilt.\n:::\n\nDe D-W statistiek voor dit model is `r round(durbinWatsonTest(time_model)$dw, 2)`. Dit wijst op een probleem met autocorrelatie.\n\n## Beperkte multicollineariteit {#sec-linear-no-excessive-multicollinearity}\n\nVoor de andere assumptietests maken we gebruik van data zonder autocorrelatie. We gebruiken onze landendataset (`demadata.rds`) en schatten een meervoudig regressiemodel waarbij V-Dem polyarchy scores (`v2x_polyarchy`) voorspeld worden op basis van economische ongelijkheid (`gini_2019`), regime in het verleden (`TYPEDEMO1984`: democratie of autocratie in 1984, naar een factor variabele getransformeerd) en BBP in 2006 (`GDP2006`).\n\n```{r}\n#| eval: false\n#data laden\ndemdata <- import(\"demdata.rds\") |> \n  as_tibble()\n\n#Factor maken van binaire variabele\ndemdata <- demdata |> \n  mutate(TYPEDEMO1984_factor = factorize(TYPEDEMO1984))\n\n#Meervoudig model schatten en resultaten bekijken\nmodel_multiple <- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984_factor + GDP2006, data = demdata)\n\nsummary(model_multiple)\n```\n\n```{r}\n#| echo: false\n#Load Data\ndemdata <- import(\"data/demdata.rds\") |> \n  as_tibble()\n\n#Factorize our binary variable\ndemdata <- demdata |> \n  mutate(TYPEDEMO1984_factor = factorize(TYPEDEMO1984))\n\n#Run and store a model and then look at the output\nmodel_multiple <- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984_factor + GDP2006, data = demdata)\n\ntidy(model_multiple, conf.int = TRUE)\n```\n\nDe coëfficienten voor `gini_2019` (p = 0.322) en `TYPEDEMO1984_factor` (p = 0.246) zijn niet significant. Om te kijken of er sprake is van te hoge multicollineariteit gebruiken we opnieuw het `car` package, nu voor de `vif()` functie.\n\n```{r}\nvif(model_multiple)\n```\n\n`vif(multiple)`\n\n:   We gebruiken de vif functie op het model tussen haakjes\n\nDe output geeft de VIF statistieken voor elke onafhankelijke variabele. Geen van de waarden is hoger dan 5 dus is er geen sprake van te hoge multicollineariteit.\n\n::: callout-important\n#### Waarschuwing!\n\nIndien je een factor variabele opneemt met 3 of meer oorspronkelijke categorieën (bv. meerdere regio's, onderwijsniveaus) dan krijg je licht andere output:\n\n```{r}\ndemdata <- demdata |> \n  mutate(Typeregime2006_factor = factorize(Typeregime2006))\n\nvif_example <- lm(v2x_polyarchy ~ gini_2019 + GDP2006 + Typeregime2006_factor, data = demdata) \n\nvif(vif_example)\n```\n\n`vif()` geeft nu een `GVIF` en `GVIF^(1/(2*DF))`. Dit zijn aanpassingen gezien categorische variabelen meerdere coëfficiënten hebben en dus vrijheidsgraden. We evalueren multicollineariteit door `GVIF^(1/(2*DF))` te kwadrateren en we gebruiken dezelfde vuistregels als bij de gewone VIF. In principe kunnen we ook kijken of `GVIF^(1/(2*DF))` op zich hoger is dan 2.23 (gezien 2.23²= 5).\n:::\n\n## Lineariteit en additiviteit\n\nEen lineair regressiemodel berust op de assumptie dat er een lineaire relatie is tussen de predictoren en de afhankelijke variabele. Om te onderzoeken of de assumptie niet geschonden is maken we gebruik van plots, aangemaakt via het [ggResidpanel](https://CRAN.R-project.org/package=ggResidpanel) package.\n\nWe gaan hier eerst de assumptie na voor een simpel model waarbij electorale democratie (`v2x_polyarchy`) voorspeld wordt door ongelijkheid (`gini_2019`).\n\n```{r}\nbivar_model <- lm(v2x_polyarchy ~ gini_2019, data=demdata)\n\nresid_panel(bivar_model, plots = c(\"resid\"))\n```\n\n`resid_panel(bivar_model,`\n\n:   We voeren de functie resid_panel uit op het model tussen haakjes.\n\n`plots = c(\"resid\"))`\n\n:   De functie kan gebruikt worden voor meerdere soorten plots. Hier verduidelijken we dat we het plot van residuals tegen voorspelde waarden willen (\"resid\").\n\nOp het plot zien we geen duidelijk patroon in de data, over het algemeen gewoon een puntenwolk. Het ontbreken van een patroon duidt erop dat de relatie tussen ongelijkheid en democratiescores als lineair kan beschouwd worden.\n\nWanneer je een ordinale variabele gebruikt als predictor in plaats van een echt continue variabele, dan ziet het plot er anders uit (i.e. neerwaarts gaande lijnen van residuals).\n\n### Logaritmische functies\n\nWe krijgen niet altijd gewoon een puntenwolk zonder patroon te zien. Laten we het plot bekijken voor ons complexer model voor democratiescores (`model_multiple`).\n\n```{r}\nresid_panel(model_multiple, plots = c(\"resid\"))\n```\n\nIn het plot zien we een lijnpatroon bij hogere waarden op de x-as. We kunnen onderzoeken welke onafhankelijke variabele dit patroon veroorzaakt door te kijken naar de partiële regressieplots via de `avPlots()` functie uit het `car` package.\n\n```{r}\navPlots(model_multiple)\n```\n\n`avPlots(model_multiple)`\n\n:   We vragen R om de partiële regressieplots voor het model tussen haakjes.\n\nDeze partiële regressieplots (\"added-variable plot\") tonen de relatie tussen de predictor en de afhankelijke variabele gecontroleerd voor de andere predictoren in het model.\n\nVoor de onafhankelijke variabele `gini_2019`, vinden we een relatief vlakke lijn (de coëfficiënt was ook niet significant). De residuals zijn vrij gelijk verspreid onder en boven de lijn dus er lijkt geen afwijking van lineariteit te zijn.\n\nVoor de `TYPEDEMO1984_factor` variabele bekijken we het plot niet gezien we slechts twee waarden voor deze variabele hebben.\n\nAls we de onafhankelijke variabele `GDP2006` bekijken vinden we een positief hellende regressielijn (de coëfficiënt was ook significant), maar de punten zijn niet gelijk verspreid rond de lijn. Het lijkt hier eerder dat de relatie een degressieve curve volgt dan een rechte lijn.\n\nOm hiervoor te compenseren voeren we een logaritmische transformatie uit op `GDP2006`. We kunnen dit doen via `mutate`.\n\n```{r}\n#nieuwe gelogde variabele die we kunnen toevoegen aan de regressie\ndemdata <- demdata |>\n  mutate(LNGDP2006 = log(GDP2006))\n#gevolgd door regressie\nmultiple_ln <- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984_factor + LNGDP2006, \n               data=demdata)\n```\n\nWe kunnen nu het residual plot en de partiële regressieplots opnieuw inspecteren.\n\n```{r}\n#Residual Plot\nresid_panel(multiple_ln, plots = c(\"resid\"))\n\n#Partiële regressieplots\navPlots(multiple_ln)\n```\n\n::: callout-important\n#### Waarschuwing!\n\nMet de logaritimische transformatie van een predictor verandert ook de interpretatie van de coëfficiënt. De volgende regels zijn van toepassing:\n\n-   **1**% toename in X (op originele schaal) leidt tot een verandering van coëfficiënt \\* log(1.**01**) eenheden in Y\n\n-   **10**% toename in X (op originele schaal) leidt tot een verandering van coëfficiënt \\* log(1.**10**) eenheden in Y\n\nBij een gelogde predictor is het echter vaak aan te raden een figuur met voorspelde waarden te maken om het effect te duiden.\n\nEerst kijken we naar de verdeling van de waarden van de gelogde predictor over alle observaties gebruikt in het model. We bekijken dus enkel data zonder ontbrekende waarden ('NA') voor een of meerdere van de variabelen gebruikt in het model.\n\n```{r}\n# Eerst de waarden van GDP2006 nagaan voor de gebruikte observaties\ndemdata_sub <- demdata |>\n  filter(complete.cases(v2x_polyarchy, gini_2019, TYPEDEMO1984_factor, LNGDP2006))\n\nsummary(demdata_sub$LNGDP2006)\n```\n\nDan berekenen we voorspelde waarden over het bereik van de gelogde predictor. Hier willen we best veel voorspelde waarden berekenen want dan krijgen we een mooiere gecurvde lijn in onze figuur.\n\n```{r}\n# voorspellingen\nbbp_preds <- predictions(multiple_ln, \n                         newdata = datagrid(LNGDP2006= seq(from=5.5,\n                                                           to=11,\n                                                           by=0.5)))  # <1>\n\n```\n\n1.  `seq()` staat voor 'sequence'. We vragen hier om voorspelde waarden te berekenen vanaf 5.5 tot 11 met tussenstappen van 0.5 eenheden.\n\nDan maken we een nieuwe variabele aan in de dataset om op de x-as van onze figuur te gaan plaatsen. Eigenlijk gaan we gewoon de gelogde predictor in de dataset terug transformeren naar de originele schaal door de waarden te exponentiëren via de `exp()` functie.\n\n```{r}\n#exponentiëren van gelogde predictor\nbbp_preds <- bbp_preds |> \n  mutate(GDP2006 = exp(LNGDP2006)) # <1>\n```\n\n1.  `exp()` is het omgekeerde van log, zoals - het omgekeerde is van + etc.\n\nTen slotte maken we onze figuur:\n\n```{r}\n#figuur maken van voorspelde waarden\nggplot(bbp_preds, aes(x=GDP2006, y=estimate)) + \n  geom_line() +\n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), \n              alpha = 0.1) +\n  labs(title = \"Voorspelde electorale democratiescore op basis van BBP 2006\",\n       x = \"BBP 2006\",   \n       y = \"Voorspelde waarde\") +  \n  scale_y_continuous(limits=c(0,1))\n```\n\nInterpretaties veranderen ook als je de afhankelijke variabele log-transformeert. Voor verdere mogelijkheden met logaritmische transformaties, verwijzen we ja naar [deze](https://kenbenoit.net/assets/courses/ME104/logmodels2.pdf) en [deze](https://library.virginia.edu/data/articles/interpreting-log-transformations-in-a-linear-model) pagina.\n:::\n\n### Kwadratische functies {#sec-quadratic-relationships}\n\nEen andere niet-lineaire relatie die we kunnen tegenkomen is de kwadratische of curvilineaire relatie. Bij wijze van voorbeeld hier inspireren we ons op de 'meer geweld in het midden'-these, namelijk het idee dat landen met hybride regimes (gemiddelde democratiescores) meer geweld en instabiliteit ervaren dan zowel autoritaire systemen (lage democratiescores) als democratische systemen (hoge democratiescores).\n\nDe variabele voor politiek geweld en instabiliteit is hier `pve` en is gebaseerd of de 2021 World Governance Indicators. Hogere waarden staan voor minder geweld en instabiliteit. Hier gebruiken we electorale democratie (`v2x_polyarchy`) als onafhankelijke variabele.\n\nWe inspecteren hier eerst de empirische, bivariate relatie met behulp van een scatterplot.\n\n```{r}\n#| warning: false\n#| message: false\n\nggplot(demdata, aes(x = v2x_polyarchy, y = pve)) + \n  geom_point() + \n  geom_smooth(method = \"loess\") +\n  labs(title = \"Politiek geweld en democratie\", \n       x = \"Electorale democratie (2020)\", \n       y = \"Afwezigheid van politiek geweld en instabiliteit (2021)\")\n```\n\nDe syntax lijkt sterk op wat we eerder gezien hebben (@sec-visualizing-bivariate-relationships-with-a-scatterplot), met 1 belangrijk verschil:\n\n`geom_smooth(method = \"loess\")`\n\n:   Hier vragen we R om een lijn te tekenen om de relatie tussen de 2 variabelen te vatten. We vragen hier niet om een rechte lijn (method=\"lm\"), maar een 'locally estimated scatterplot smoothing' (loess) lijn (method = \"loess\"). Deze lijn volgt de data zo nauwgezet mogelijk om de relatie tussen de variabelen weer te geven. De loess methode is de standaard (default) methode om de lijn te tekenen. We zouden dus ook gewoon `geom_smooth()` kunnen schrijven om dezelfde uitkomst te verkrijgen.\n\nZoals we kunnen zien als we naar het scatterplot kijken is er enige steun voor een curvilineaire relatie. We schatten nu eerst een lineair regressiemodel:\n\n```{r}\n#schat het model\nViolence_linmodel <- lm(pve ~ v2x_polyarchy, data = demdata)\n\n#bekijk resultaten\ntidy(Violence_linmodel, conf.int = TRUE)\n```\n\nDe niet-lineaire relatie kun je soms zien uit het residuals plot, in de vorm van een gebogen patroon, maar dit is visueel minder zichtbaar hier:\n\n```{r}\nresid_panel(Violence_linmodel, plots = c(\"resid\"))\n```\n\nOm te onderzoeken of de relatie beter als kwadratisch wordt gevat voegen we een kwadratische term toe aan het model. We kunnen deze variabele eerst maken en dan toevoegen aan het model, samen met de originele variabele. We kunnen de transformatie ook in de regressielijn zelf toevoegen via de `I()` functie. Dit is iets eenvoudiger gezien we de variabele niet moeten maken. Bovendien werkt deze methode beter met functies van het `marginaleffects` package die we gebruiken om modellen te interpreteren (bv. de `predictions()` functie).\n\n```{r}\n#gewadrateerde variabele maken\ndemdata <- demdata |> \n  mutate(v2x_polyarchy_sq = v2x_polyarchy^2)\n\n#nieuw model schatten\nViolence_sqmodel <- lm(pve ~ v2x_polyarchy + v2x_polyarchy_sq, \n               data=demdata)\n\n#transformatie toepassen in regressie\nViolencesqmodel <- lm(pve ~ v2x_polyarchy + I(v2x_polyarchy^2), \n                      data=demdata)\n\nsummary(Violencesqmodel)\n\ntidy(Violence_sqmodel, conf.int = TRUE)\n```\n\nWe vinden hier dat de kwadratische variabele significant is (p \\< 0.001) en dus dat de relatie tussen `v2x_polyarchy` en `pve` beter als curvilineair dan lineair te beschrijven is.\n\nWe kunnen dan het residuals plot opnieuw inspecteren (zie onder).\n\n::: callout-important\n#### Waarschuwing!\n\nBij een kwadratische predictor is de interpretatie van de coëfficiënten (want de originele en gekwadrateerde variabelen horen samen) best moeilijk. De volgende regels zijn van toepassing:\n\n-   Als de coëfficiënt voor X positief is en die voor X^2^ negatief, dan is de relatie tussen X en Y **concaaf** (omgekeerde U)\n-   Als de coëfficiënt voor X negatief is en die voor X^2^ positief, dan is de relatie tussen X en Y **convex** (U-vorm)\n-   Als beide coëfficiënten dezelfde richting hebben (beiden positief of beiden negatief), dan wordt het effect van X op Y sterker als X hogere waarden aanneemt.\n\nWederom is het vaak beter om de relatie visueel te verduidelijken. Om dit te doen kijken we eerste naar de waarden die de predictor aanneemt voor de observaties gebruikt bij de schatting van het model:\n\n```{r}\n#waarden van X nagaan voor de gebruikte observaties\ndemdata_sub2 <- demdata |>\n  filter(complete.cases(v2x_polyarchy , pve))\nsummary(demdata_sub2$v2x_polyarchy)\n```\n\nWe berekenen vervolgens voorspelde waarden via `predictions()`. Hier willen we best veel voorspelde waarden berekenen want dan krijgen we een mooiere gecurvde lijn in onze figuur.\n\n```{r}\n# voorspellingen maken op basis van de waarden\npve_preds <- predictions(Violencesqmodel, \n                         newdata = datagrid(v2x_polyarchy= seq(from=0, to=0.9, by=0.05)))\n```\n\nTen slotte maken we onze figuur:\n\n```{r}\n#figuur maken van voorspelde waarden\nggplot(pve_preds, aes(x=v2x_polyarchy, y=estimate)) + \n  geom_line() +\n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), \n              alpha = 0.1) + \n  labs(title = \"Voorspelde afwezigheid van geweld en instabiliteit\",\n       x = \"Electorale democratie\",   \n       y = \"Voorspelde waarde\") \n```\n:::\n\n## Homoskedasticiteit\n\nOm te onderzoeken of de assumptie van homoskedasticiteit geschonden is maken we opnieuw gebruik van het residuals plot (scatterplot van voorspelde waarden en residuals). Hier vinden we bijvoorbeeld heteroskedasticiteit voor het kwadratische model (`Violence_sqmodel`):\n\n```{r}\n\nresid_panel(Violence_sqmodel, plots = c(\"resid\"))\n```\n\nOpnieuw zien we liever een wolk van toevallig verspreide punten (homoskedasticiteit) eerder daan een trechter-vorm (heteroskedasticiteit). De trechter-vorm in het plot wijst erop dat de assumptie geschonden is.\n\n## Normaal verdeelde errors\n\nWe onderzoeken of de assumptie van normaal verdeelde errors is geschonden met behulp van 2 mogelijke plots uit het `ggResidpanel` package: een histogram van de fouten en een kwartielplot (qq-plot) van de fouten.\n\nHier gaan we na of de assumptie geschonden is voor ons meervoudig regressiemodel met gelogde GDP predictor (multiple_ln):\n\n```{r}\nresid_panel(multiple_ln, plots = c(\"hist\", \"qq\"))\n```\n\n`plots = c(\"hist\", \"qq\"))`\n\n:   Hier vragen we om het histogram (\"hist\") samen met het qq-plot (\"qq\").\n\nWe zouden ook het residuals plot (\"resid\") kunnen toevoegen indien we meerdere assumpties vlug samen willen testen:\n\n```{r}\nresid_panel(multiple_ln, plots = c(\"resid\", \"hist\", \"qq\"))\n\n```\n\n## Beperkte impact outliers en influential cases\n\nWe gebruiken de `augment()` functie uit het `broom` package op de meervoudig regressie met gelogde GDP predictor (`multiple_ln`). De statistieken worden in een nieuwe dataset opgeslagen in onderstaande code.\n\n```{r}\n#augment gebruiken en resultaten opslaan in nieuw object\ndemdata_multln <- augment(multiple_ln)\n```\n\n`demdata_multln <-augment(multiple_ln)`\n\n:   We gebruiken de augment functie op het model tussen haakjes en slaan de resultaten op in een nieuw data object (`demdata_multln`).\n\nDe gegevens in het dataobject zien er als volgt uit:\n\n```{r}\ndemdata_multln\n```\n\n::: callout-note\n#### Output uitleg\n\n`augment()` creëert een dataframe met alle observaties die gebruikt zijn om het model te schatten. Je vindt de volgende kolommen terug:\n\n-   `.rownames`: Di is het rijnummer van de observatie zoals je die vindt in de originele dataset (zonder eventuele missing waarden)\n-   `v2x_polyarchy` tot en met `LNGDP2006`: Dit zijn de variabelen gebruikt in het model met de waarden die elke observatie ervoor heeft.\n-   `.fitted`: De voorspelde ('fitted') waarden op basis van de schattingen in het model.\n-   `resid`: De residuals (fouten/errors) voor elke observatie, waarbij Residual = Observed - Fitted/Predicted. Hier: Residual = `v2x_polyarchy` - `.fitted`\n-   `.hat`: Diagonaal van de hat matrix (te negeren).\n-   `.sigma:` Geschatte standaardafwijking van de fouten als de observatie uit het model zou worden verwijderd (te negeren)\n-   `.cooksd`: De Cook's D waarde voor de observatie. Zie onder.\n-   `.std.resid`: Niet getoond in de output hierboven maar aanwezig in de dataset. Deze kolom bevat de *gestandaardiseerde* residuals van het model. Zie onder.\n:::\n\nWe gebruiken de gestandaardiseerde residuals (`.std.resid`) om eerst outliers te onderzoeken. Vervolgens gebruiken we de Cook's D waarden (`.cooksd`) om influential cases te onderzoeken.\n\n### Outliers analyseren {#sec-linear-investigating-outliers}\n\nOm te beginnen bekijken we de descriptieve statistieken voor de gestandaardiseerde residuals (opgeslagen in het data object `demdata_multln`) . We kijken specifiek naar de minimum- en maximum waarden als eerste check voor outliers. We bekijken in het bijzonder of gestandaardiseerde residuals hoger zijn dan de drempelwaarden van (\\|1.96\\|, \\|2.58\\|, en zeker \\|3.29\\|).\n\n```{r}\nsummary(demdata_multln$.std.resid)\n```\n\nWe vinden waarden die zorgwekkend kunnen zijn. Zo is er al zeker 1 observatie waarvan de gestandaardiseerde residual een absolute waarde hoger dan 2.58 heeft (aangezien het minimum -3.128 is). Maar we moeten nog nagaan hoeveel observaties precies de drempelwaarden overschrijden.\n\nWe doen dit door 3 dummy variabelen aan te maken in onze dataset: SRE1.96, SRE2.58, SRE3.29. Deze dummy variabelen nemen de waarde '1' aan als de gestandaardiseerde residual van een observatie hoger is dan de drempelwaarde in de naam van de variabele. Als de waarde van de gestandaardiseerde residual lager is, neemt de dummy de waarde '0' aan. We gebruiken hier de `case when` functie (uit `dplyr`) voor de hercodering. Zie [Statistiek I, 5.1](https://poweleiden.github.io/statistiek1/data_05_advanced_recoding.html#recoding-variables-using-case_when){target=\"_blank\"}\n\nOnderstaande code kun je grotendeels onaangepast laten in je eigen voorbeelden, enkel de naam van de dataset (hier: `demdata_multln`) moet aangepast worden voor eigen toepassingen.\n\n```{r}\ndemdata_multln <- demdata_multln |>\n  mutate(SRE1.96 = case_when(\n    .std.resid > 1.96 | .std.resid < -1.96  ~ 1,\n    .std.resid > -1.96 & .std.resid < 1.96 ~ 0),\n         SRE2.58 = case_when(\n    .std.resid > 2.58 | .std.resid < -2.58  ~ 1,\n    .std.resid > -2.58 & .std.resid < 2.58 ~ 0),\n        SRE3.29 = case_when(\n    .std.resid > 3.29 | .std.resid < -3.29  ~ 1,\n    .std.resid > -3.29 & .std.resid < 3.29 ~ 0\n  ))\n```\n\n`demdata_multln <- demdata_multln |>`\n\n:   De nieuwe variabelen maken gebruik van de demdata_multln dataset (voor de .std.resid variabele), en worden ook zelf opgeslagen in deze dataset.\n\n`mutate(SRE1.96 = case_when(`\n\n:   We creëren hier de nieuwe variabele SRE1.96. De waarden worden bepaald door de `case_when` functie.\n\n`.std.resid > 1.96 | .std.resid < -1.96 ~ 1,`\n\n:   Hier duiden we aan dat wanneer gestandaardiseerde residuals groter dan 1.96 of (de streep '\\|' staat symbool voor 'of' ) lager dan -1.96 zijn, de SRE1.96 variabele de waarde 1 aanneemt (\\~). Let erop dat de variabele .std.resid twee keer geschreven moet worden.\n\n`.std.resid > -1.96 & .std.resid < 1.96 ~ 0),`\n\n:   Hier duiden we aan dat wanneer gestandaardiseerde residuals groter dan -1.96 en (de '&' staat hier voor 'en') lager dan 1.96 zijn, de SRE1.96 variabele de waarde 0 aanneemt (\\~).\n\nNu we de dummies aangemaakt hebben kunnen we frequentietabellen voor elk van hen bekijken. We maken gebruik van de `fre()` functie uit het `expss` package.\n\nDe code hieronder kun je wederom grotendeels gebruiken voor eigen voorbeelden; enkel de naam van de dataset (hier: `demdata_multln`) dient veranderd te worden voor eigen toepassingen.\n\n```{r}\nfre(demdata_multln$SRE1.96)\nfre(demdata_multln$SRE2.58)\nfre(demdata_multln$SRE3.29)\n```\n\nWe vinden hier dat meer dan 5% van de observaties een gestandaardiseerde residual heeft met een absolute waarde hoger dan 1.96, meer dan 1% heeft een gestandaardiseerde residual met een absolute waarde hoger dan 2.58. Er is geen enkele observatie met een absolute waarde hoger dan 3.29 (dit konden we reeds aflezen uit de descriptieve statistieken).\n\nOm te onderzoeken of de outliers ook een invloed hebben op de resultaten van het model vergelijken we de resultaten van ons model met die van een nieuw model zonder outliers. Hier doen we dit voor outliers met gestandaardiseerde residuals met absolute waarde hoger dan 1.96. De SRE1.96 variabele kan vervangen worden met de SRE2.58 en SRE3.29 variabelen om alternatieve manieren om outliers uit te sluiten te onderzoeken.\n\n```{r}\nmultiple_ln1.96 <- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984_factor + LNGDP2006,\n               data = subset(demdata_multln, SRE1.96 == 0))\n```\n\n`data = subset(demdata_multln, SRE1.96 == 0))`\n\n:   Met deze code gebruiken we de demdata_multln dataset gecreëerd met augment, maar we behouden enkel observaties die voor de variabele SRE1.96 de waarde 0 hebben.\n\nAls we de modellen met en zonder outliers vergelijken gaan we na of de coëfficiënten en hun significantie substantieel veranderd zijn. Let wel, outliers kunnen niet zomaar verwijderd worden om om de model fit te verbeteren. Er moet een gemotiveerde, theoretische reden zijn voor uitsluiting van observaties.\n\n### Influential cases analyseren {#sec-linear-investigating-influential-cases}\n\nOm influential cases te onderzoeken gaan we na of er observaties zijn in de dataset met hoge Cook's D waarden:\n\n-   waarden hoger dan 1 zijn over het algemeen zorgwekkend;\n\n-   waarden hoger dan 0.5 moeten nader bestudeerd worden en kunnen een risico vormen;\n\n-   waarden die veel hoger zijn dan de andere Cook's D waarden behoeven ook verdere aandacht.\n\nWe bekijken eerst de overzichtsstatistieken voor de Cook's D waarden.\n\n```{r}\nsummary(demdata_multln$.cooksd)\n```\n\nHet overzicht toont dat er minstens 1 observatie is met een hoge Cook's D waarde. De maximum waarde is 0.66 en deze waarde is substantieel hoger dan de andere waarden. De waarde voor het 3de kwartiel is slechts 0.016, wat betekent dat 75% van de observaties een waarde lager hebben dan 0.016.\n\nWe kunnen ook een visualisatie maken van de Cook's D waarden met het `ggResidpanel` package:\n\n```{r}\nresid_panel(multiple_ln, plots = c(\"cookd\"))\n```\n\n`plots = c(\"cookd\"))`\n\n:   We vragen hier om een plot met Cook's D waarden op de y-as. Het rijnummer van de observatie in de dataset komt op de x-as.\n\nDe grafiek toont dat er slechts 1 case is om ons zorgen over te maken. Dit is de case met de maximumwaarde van 0.66.\n\nWe kunnen deze case verwijderen uit het model om na te gaan of de resultaten beïnvloed worden:\n\n```{r}\nmultiple_lncook <- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984_factor + LNGDP2006,\n               data = subset(demdata_multln, .cooksd < 0.65))\n```\n\n`data = subset(demdata_multln, .cooksd < 0.65))`\n\n:   We gebruiken de demdata_multln dataset maar vragen om een subset van de data met enkel die observaties met een waarde lager dan 0.65 voor .cooksd. We kiezen deze waarde hier omdat de case die we willen uitsluiten een waarde van 0.66 heeft. In principe hadden we ook 0.66 zelf, 0.64 enz. kunnen kiezen, zolang het een grenswaarde is die de mogelijk invloedrijke casus uitsluit.\n\nWe kunnen ook outliers en influential cases tegelijk uitsluiten als we in de syntax gebruik maken van het '&' teken:\n\n```{r}\nmultiple_ln_excl <- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984_factor + LNGDP2006,\n               data = subset(demdata_multln,\n                             SRE1.96==0 & .cooksd < 0.65))\n```\n\n### Specifieke probleemgevallen analyseren\n\nWat we in vorige analyses niet bekeken hebben is welke specifieke observaties outliers of influential cases waren. Om dit te kunnen doen moeten we de gestandaardiseerde residuals en Cook's D waarden toevoegen aan onze originele dataset, waar we de country name variabele hebben.\n\nIndien er missende waarden zijn, zoals hier het geval is, kunnen we deze statistieken niet zomaar met augment toevoegen aan de originele dataset. Een oplossing is om eerst een dataset te creëren met niet-missende waarden voor de variabelen gebruikt in het model en dan met augment de statistieken aan deze 'complete cases' dataset toe te voegen:\n\n```{r}\n# subset van de dataset zonder 'NA' waarden\ndemdata_complete <- demdata |>\n  filter(complete.cases(v2x_polyarchy, gini_2019, TYPEDEMO1984_factor, LNGDP2006))\n\n# model opnieuw geschat met nieuwe dataset\nmultiple_ln <- lm(v2x_polyarchy ~ gini_2019 + TYPEDEMO1984_factor + LNGDP2006, \n               data=demdata_complete)\n\n# augment gebruiken om statistieken toe te voegen\ndemdata_complete <-augment(multiple_ln, data=demdata_complete)\n```\n\nNu kunnen we specifieke outliers onderzoeken met de volgende code:\n\n```{r}\ndemdata_complete |> \n  filter(.std.resid > 1.96 | .std.resid < -1.96) |>\n  select(country_name, .std.resid)\n```\n\n`filter(.std.resid > 1.96 | .std.resid < -1.96)`\n\n:   Hier willen we outliers vinden, dus we filteren voor observaties met gestandaardiseerde residual hoger dan 1.96 of lager dan -1.96.\n\n`select(country_name.std.resid)`\n\n:   Hier vragen we R om de namen van de landen en hun specifieke gestandaardiseerde residual.\n\nDe influential case vinden we op een gelijkaardige manier:\n\n```{r}\ndemdata_complete |> \n  filter(.cooksd > 0.65) |>\n  select(country_name, .cooksd)\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"linear_07.html"},"language":{"toc-title-document":"Inhoudsopgave","toc-title-website":"Op deze pagina","related-formats-title":"Andere formaten","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Bron","other-links-title":"Andere Links","code-links-title":"Code Links","launch-dev-container-title":"Dev Container starten","launch-binder-title":"Binder starten","article-notebook-label":"Artikel Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Broncode downloaden","notebook-preview-back":"Terug naar Artikel","manuscript-meca-bundle":"MECA Archief","section-title-abstract":"Samenvatting","section-title-appendices":"Bijlagen","section-title-footnotes":"Voetnoten","section-title-references":"Referenties","section-title-reuse":"Hergebruik","section-title-copyright":"Auteursrechten","section-title-citation":"Citaat","appendix-attribution-cite-as":"Citeer dit werk als:","appendix-attribution-bibtex":"BibTeX citaat:","appendix-view-license":"Licentie Bekijken","title-block-author-single":"Auteur","title-block-author-plural":"Auteurs","title-block-affiliation-single":"Affiliatie","title-block-affiliation-plural":"Affiliaties","title-block-published":"Publicatiedatum","title-block-modified":"Gewijzigd","title-block-keywords":"Trefwoorden","callout-tip-title":"Tip","callout-note-title":"Opmerking","callout-warning-title":"Waarschuwing","callout-important-title":"Belangrijk","callout-caution-title":"Opgelet","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Alle code tonen","code-tools-hide-all-code":"Alle code verbergen","code-tools-view-source":"Broncode bekijken","code-tools-source-code":"Broncode","tools-share":"Share","tools-download":"Download","code-line":"Regel","code-lines":"Regels","copy-button-tooltip":"Kopieer naar klembord","copy-button-tooltip-success":"Gekopieerd!","repo-action-links-edit":"Pagina bewerken","repo-action-links-source":"Broncode bekijken","repo-action-links-issue":"Een probleem melden","back-to-top":"Terug naar boven","search-no-results-text":"Geen resultaten","search-matching-documents-text":"Gevonden documenten","search-copy-link-title":"Kopieer link om te zoeken","search-hide-matches-text":"Extra overeenkomsten verbergen","search-more-match-text":"meer overeenkomst in dit document","search-more-matches-text":"meer overeenkomsten in dit document","search-clear-button-title":"Wissen","search-text-placeholder":"","search-detached-cancel-button-title":"Annuleren","search-submit-button-title":"Verzenden","search-label":"Zoeken","toggle-section":"Schakel sectie","toggle-sidebar":"Schakel zijbalknavigatie","toggle-dark-mode":"Schakel donkere modus","toggle-reader-mode":"Schakel leesmodus","toggle-navigation":"Schakel navigatie","crossref-fig-title":"Figuur","crossref-tbl-title":"Tabel","crossref-lst-title":"Listing","crossref-thm-title":"Stelling","crossref-lem-title":"Lemma","crossref-cor-title":"Conclusie","crossref-prp-title":"Voorstel","crossref-cnj-title":"Aanname","crossref-def-title":"Definitie","crossref-exm-title":"Voorbeeld","crossref-exr-title":"Oefening","crossref-ch-prefix":"Hoofdstuk","crossref-apx-prefix":"Bijlage","crossref-sec-prefix":"Paragraaf","crossref-eq-prefix":"Vergelijking","crossref-lof-title":"Lijst van figuren","crossref-lot-title":"Lijst van tabellen","crossref-lol-title":"Lijst van listings","environment-proof-title":"Bewijs","environment-remark-title":"Opmerking","environment-solution-title":"Oplossing","listing-page-order-by":"Sorteer op","listing-page-order-by-default":"Standaard","listing-page-order-by-date-asc":"Oudste","listing-page-order-by-date-desc":"Nieuwste","listing-page-order-by-number-desc":"Aflopend","listing-page-order-by-number-asc":"Oplopend","listing-page-field-date":"Datum","listing-page-field-title":"Titel","listing-page-field-description":"Beschrijving","listing-page-field-author":"Auteur","listing-page-field-filename":"Bestandsnaam","listing-page-field-filemodified":"Gewijzigd","listing-page-field-subtitle":"Subtitel","listing-page-field-readingtime":"Leestijd","listing-page-field-wordcount":"Woordentelling","listing-page-field-categories":"Categorieën","listing-page-minutes-compact":"{0} min","listing-page-category-all":"Alle","listing-page-no-matches":"Geen overeenkomsten","listing-page-words":"{0} woorden","listing-page-filter":"Filter","draft":"Ontwerp"},"metadata":{"lang":"nl","fig-responsive":true,"quarto-version":"1.5.57","bibliography":["references.bib"],"editor":"visual","theme":{"light":"cosmo","dark":"darkly"},"code-annotations":"hover"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}