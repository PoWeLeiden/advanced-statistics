{"title":"Assumptieschendingen oplossen","markdown":{"yaml":{"code-annotations":"hover","citation-location":"margin"},"headingText":"Assumptieschendingen oplossen","containsRefs":false,"markdown":"\n\n\n```{r}\n#| message: false\n#| warning: false\n#| echo: false\n\n#Packages\nlibrary(ggResidpanel)   #<1> \nlibrary(rio)            #<2>\nlibrary(tidyverse)      #<3>\nlibrary(modelsummary)   #<4>\nlibrary(marginaleffects) #<5>\nlibrary(broom) #<6>\n\n# Gebruikte datasets\ndemdata <- import(\"./data/demdata.rds\")\ness_demsatis <- import(\"./data/ess_demsatis.dta\")\nnormal_residual_data <- import(\"./data/normal_residual_data.rda\")\nserial_data <- import(\"./data/serial_autocorrelation.rda\")\n```\n\n```{r}\n#| message: false\n#| warning: false\n#| eval: false\n\n#Packages\nlibrary(ggResidpanel)   #<1> \nlibrary(rio)            #<2>\nlibrary(tidyverse)      #<3>\nlibrary(modelsummary)   #<4>\nlibrary(marginaleffects) #<5>\nlibrary(broom) #<6>\n\n# Gebruikte datasets\ndemdata <- import(\"demdata.rds\")\ness_demsatis <- import(\"ess_demsatis.dta\")\nnormal_residual_data <- import(\"normal_residual_data.rda\")\nserial_data <- import(\"./data/serial_autocorrelation.rda\")\n```\n\n1.  Assumpties testen met plots\n2.  Data importeren\n3.  Datamanipulatie/plots\n4.  Regressietabellen maken\n5.  Voorspelde waarden en marginale effecten\n6.  Gegevens samenvatten\n\n::: {.callout-note title=\"Voor wie is deze Appendix?\"}\nJe hoeft niet te weten hoe je deze analyses moet uitvoeren voor de opdrachten in Statistiek II. Deze gids is bedoeld voor studenten die hun eindpaper schrijven voor Academische Vaardigheden: Kwantitatieve Data-Analyse of een BAP-scriptieproject en graag assumptieschendingen willen vermijden.\n:::\n\nRegressiemodellen zijn gebaseerd op een aantal assumpties of aannames. Een belangrijk onderdeel van de analyse is nagaan of aan die assumpties voldaan is. Zoniet, dan moeten assumptieschendingen op een passende manier behandeld worden. Statistiek II richt zich meer op het eerste deel van het proces: wanneer is niet voldaan aan een assumptie? In deze Appendix geven we een kort overzicht van enkele mogelijke oplossingen voor assumptieschendingen waar je mee geconfronteerd kan worden.\n\n## Assumpties over de fouten (residuals) in OLS modellen\n\n$$\ny_{i} = b_{0} + b_{1} * x_{1} + b_{2} * x_{2} ... b_{k} * x_{k} + e_{i}\n$$\n\nDe $e_{i}$ term in bovenstaande vergelijking staat voor de 'error', fout, of residual in een linear regressiemodel. Er zijn drie assumpties over deze fouten:[^errors-1]\n\n[^errors-1]: Slechts een van deze assumpties is ook van toepassing op logistische modellen: de assumptie van onafhankelijke fouten. De oplossingen hiervoor zijn dezelfde bij logistische modellen, vandaar dat we ons in deze voorbeelden richten op OLS modellen.\n\n-   De variantie van de residuals is *constant* over het hele bereik van de voorspellingen van het model (homoskedasticiteit)\n-   De residuals zijn *onafhankelijk* van elkaar\n-   De residuals volgen een *normaalverdeling* met een gemiddelde van 0\n\nSchendingen van deze assumpties hebben belangrijke gevolgen voor statistische significantietests. Ernstige schendingen leiden tot onbetrouwbare schattingen van de standaardfout van een coëfficiënt en, als gevolg daarvan, tot onjuiste oordelen over statistische significantie.\n\n## Omgaan met Heteroskedasticiteit\n\n### Wat was het probleem ook al weer?\n\nOnderstaand voorbeeld komt uit @sec-ols-assumptions en voorspelt de mate van politieke stabiliteit in een land op basis van democratieniveaus. In het voorbeeld hebben we ook een kwadratische term voor democratiescore toegevoegd om non-lineaire verbanden te kunnen vatten. Hier is het model en de resultaten:\n\n```{r}\n#gekwadrateerde variabele maken\ndemdata <- demdata |> \n  mutate(v2x_polyarchy_sq = v2x_polyarchy^2)\n\n# Model schatten\nviolence_sqmodel <- lm(pve ~ v2x_polyarchy + v2x_polyarchy_sq, \n                      data=demdata)\n\n# coëfficiënten bekijken\ntidy(violence_sqmodel, conf.int = TRUE)\n```\n\nWe kunnen kijken of de assumptie van homoskedasticiteit geschonden is via `resid_panel()` zoals besproken in @sec-ols-assumptions.\n\n```{r}\n# assumptie bekijken\nresid_panel(violence_sqmodel, plots = c(\"resid\"))\n```\n\nAan de assumptie is voldaan als de fouten een even grote spreiding kennen op lage, gemiddelde, en hoge waarden van de voorspelde waarden. Ze moeten zich ongeveer in een evenwijdige band bevinden. Hier zien we dat de assumptie geschonden is aan de trechtervorm: we vinden een grote spreiding van residuals bij lage voorspele waarden (de schatting is hier onnauwkeurig) en weinig spreiding bij hoge voorspelde waarden (de schatting is hier veel nauwkeuriger).\n\n### Mogelijke oplossing: robuste standaardfouten\n\n::: callout-note\nDe `vcov` functie die we hieronder gebruiken is afkomstig uit het`sandwich`package en helpt bij de berekening van robuuste standaardfouten. Je zult dit package misschien eerst moeten installeren.\n:::\n\nHeteroskedasticiteit heeft verschillende mogelijke oorzaken. Zo kan het onstaan door het ontbrekenen van belangrijke predictoren in het model. Het is een goed idee om na te denken over waarom de residuals zo verschillen en welke bijkomende onafhankelijke variabele deze spreiding kan verklaren. We kunnen dit echter niet altijd weten en als we al een idee hebben, kan het zijn dat de relevante onafhankelijke variabele niet in de dataset voorkomt.\n\nEen andere mogelijke oorzaak is dat we een lineaire relatie schatten waar eigenlijk een niet-lineaire relatie geschat moet worden. Dit is hier echter niet het geval.\n\nWat kunnen we dan nog doen?\n\nEen gangbare manier is om de berekenmethode voor de standaardfouten van de coëfficiënten in het model aan te passen. De standaardfouten die normaal door R worden berekend gaan uit van homoskedasticiteit, maar we kunnen 'heteroskedasticiteit-robuuste' standaardfouten berekenen als alternatief. Belangrijk is om te onthouden dat deze oplossing een mathematisch 'truukje' is, ons model past nog altijd slecht en het is belangrijk theoretisch hierover na te denken. De eerste stap blijft altijd om na te denken over mogelijk ontbrekende predictoren.\n\nDe eenvoudigste manier om robuuste standaardfouten te verkrijgen is via het `modelsummary` package. We bekijken eerst nog even de 'normale' regressie-output voor het model:\n\n```{r}\nmodelsummary(violence_sqmodel, \n             stars = T, \n             coef_rename = c(\n               \"(Intercept)\" = \"Intercept\", \n               \"v2x_polyarchy\" = \"Democratiescore\", \n               \"v2x_polyarchy_sq\" = \"Democratiescore gekwadrateerd\"), \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n```\n\nDe tabel hierboven maakt gebruik van de normale standaardfouten. We kunnen de robuuste opvragen via de `vcov` optie:\n\n```{r}\nmodelsummary(violence_sqmodel, \n             stars = T, \n             vcov = \"HC3\",\n             coef_rename = c(\n               \"(Intercept)\" = \"Intercept\", \n               \"v2x_polyarchy\" = \"Democratiescore\", \n               \"v2x_polyarchy_sq\" = \"Democratiescore gekwadrateerd\"), \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n```\n\n`vcov = \"HC3\"`\n\n:   De `vcov =` optie vraagt om robuuste standaardfouten te berekenen en te gebruiken in de tabel. \"HC3\" staat voor 'heteroskedasticiteit-robuuste standardfouten'. Er zijn verschillende heteroskedasticiteit-robuuste standaardfouten (bv., \"HC0\", \"HC1\", etc.). We raden \"HC3\" aan als standaard, ook omdat deze goed werkt bij kleine steekproefgroottes.\n\nLaten we de 'normale' en 'robuuste' standaardfouten vergelijken:\n\n```{r}\n\nmodelsummary(violence_sqmodel, \n             stars = T, \n             vcov = c(\"classical\", \"HC3\"), \n             coef_rename = c(\n               \"(Intercept)\" = \"Intercept\", \n               \"v2x_polyarchy\" = \"Democratiescore\", \n               \"v2x_polyarchy_sq\" = \"Democratiescore gekwadrateerd\"),\n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n```\n\nDe eerste kolom toont de resultaten voor de 'normale' standaardfouten, de tweede kolom deze voor de 'robuuste' fouten. We kunnen het volgende opmerken:\n\n-   De coëfficiënten veranderen niet, enkel de standaardfouten.\n-   De robuuste standaardfouten zijn typisch groter. Heteroskedasticiteit zorgt immers doorgaans voor een neerwaarste bias: standaarfouten worden te klein geschat als we de normale methode zouden gebruiken.\n-   De interpretatie van de resultaten verandert hier niet. De significantietoetsen voor de predictoren komen uit op dezelfde conclusies. Di is echter lang niet altijd het geval!\n\nHet voorbeeld hierboven maakt gebruik van `modelsummary()` en geeft de resultaten weer in een tabel. Ook voor voorspelde waarden en coëfficiëntenplots kunnen we robuuste standaardfouten gebruiken zodanig dat betrouwbaarheidsintervallen aangepast worden.\n\nWe blijven de bovenstaande `vcov` optie gebruiken, maar binnen de `predictions()` functie uit het `marginaleffects` package (bv., `predictions(model, ..., vcov = \"HC3\")`) voor voorspelde waarden.\n\nVoor coëfficiëntenplots kunnen we de syntax echter niet netjes combineren met `tidy()` zoals we deden in @sec-reporting-and-presenting-results. In de plaats daarvan gebruiken we de `avg_slopes()` functie uit het `marginaleffects` package. `avg_slopes()` schat de marginale effecten van elke predictor in het model. Bij OLS is dit gelijk aan de coëfficiënten.\n\n```{r}\n# Resultaten via tidy\ntidy(violence_sqmodel)\n\n# Resultaten  via avg_slopes\navg_slopes(violence_sqmodel)\n```\n\nWe voegen de `vcov =` optie toe aan de `avg_slopes()` functie en plotten de resultaten:\n\n```{r}\n# robuuste SEs en plot\navg_slopes(violence_sqmodel, vcov = \"HC3\") |> # <1>\n  ggplot(aes(x = estimate, y = term)) + \n  geom_pointrange(aes(xmin = conf.low, xmax = conf.high)) + \n  geom_text(aes(label = round(estimate, 2)), vjust = -0.5) + \n  geom_vline(xintercept = 0, linetype = 'dashed', color = 'red') + \n  theme_bw() + \n  labs(x = \"Coëfficiënt\", \n       y = \"Onafhankelijke variabele\", \n       title = \"Coëfficiënten met Heteroskedasticiteit-robuuste betrouwbaarheidsintervallen\")\n```\n\n1.  Opvragen van marginale effecten van de predictoren samen met de robuuste standaardfouten.\n\n## Omgaan met afhankelijke fouten\n\nEen tweede belangrijke assumptie in OLS (en logistische) modellen is deze van *onafhankelijkheid*. We gaan ervan uit dat de fouten in de populatie en in ons model niet gecorreleerd zijn met elkaar. Deze assumptie kan geschonden zijn wanneer data 'geclusterd' is.\n\n### Probleem 1: geclusterde data\n\n#### Voorbeeld van het probleem\n\nStel dat we meten in welke mate burgers tevreden zijn met democratie in verschillende Europese landen (bv. met links-rechtspositie als predictor). We kunnen de European Social Survey (ESS) gebruike, waarbij respondenten uit verschillende landen werden ondervraagd. Wanneer de analyse meerdere landen beschouwt, zijn respondenten geclustert in hun land.\n\nWe bekijken de resultaten van een dergelijk model. De afhankelijke variabele meet tevredenheid met democratie op een schaal van 0 (\"zeer ontevreden\") tot 10 (\"zeer tevreden\"). De onafhankelijke variabele meet links-rechtspositie met een schaal van 0 (\"links\") tot 10 (\"rechts\").\n\n```{r}\n\n# Model \ndemsatis_model <- lm(stfdem ~ lrscale, data = ess_demsatis)\n\n# Coefficients\ntidy(demsatis_model, conf.int = TRUE)\n\n```\n\nDe coëfficiënt voor links-rechtspositie (`lrscale`) is positief: mensen die zich meer aan de rechterkant van het politieke spectrum plaatsen zijn meer tevreden met democratie. De coëfficiënt is ook statistisch significant met wel een heel kleine p-waarde (7.97e-117). Laten we echter kijken hoe clustering hier bij komt kijken.\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\n#| fig-width: 12\n#| fig-height: 8\n\n# Extra package for plotting\nlibrary(patchwork) # <1>\n\n# Distribution plot\ndistribution_plot <- ess_demsatis |> \n  group_by(country_name, stfdem) |> # <2>\n  tally() |> \n  ungroup() |> \n  group_by(country_name) |> # <3>\n  mutate(prop = n / sum(n)) |>\n  ggplot(aes(x = stfdem, y = prop)) + \n  geom_col() +\n  facet_wrap(~ country_name) + \n  theme_bw() + \n  labs(title = \"Variatie volgens Land\", \n       y = \"Proportie\", \n       x = \"Tevredenheidsscore\") + \n  scale_x_continuous(breaks = c(0,5,10))\n\n# Plot of means\nmean_plot <- ess_demsatis |> \n  group_by(country_name) |> \n  summarize(dem_satis = mean(stfdem, na.rm = T)) |> \n  ggplot(aes(x = dem_satis, y = reorder(country_name, dem_satis))) + # <4>\n  geom_col() + \n  theme_bw() + \n  labs(title = \"Gemiddelde per land\", \n       y = \"Naam land\", \n       x = \"Gemiddelde tevredenheid met democratie\")\n\n# Combine together using patchwork\ndistribution_plot + mean_plot\n\n\n```\n\n1.  De `patchwork` library wordt hier gebruikt om meerdere grafieken te combineren met elkaar.\n2.  Deze regels berekenen het aantal antwoorden per antwoordcategorie per land.\n3.  We berekenen hier de proportie van observaties met een specifieke respons per land.\n4.  De `reorder()` optie herordent de y-as zodat die loopt van hogere tot lagere gemiddelde scores.\n\nHet linkse plot in de figuur hierboven toont de proportie observaties per antwoordcategorie (x-as) per land (aparte 'facets'). De plot toont variatie tussen individuen binnen een land: sommige zijn tevreden, andere niet. De verdeling van observaties is echter niet dezelfde per land. Sommige landen zien meer tevreden respondenten (bv., Finland, Norwegen, en Zwitserland) terwijl in andere landen mensen zich meer onderaan de schaal bevinden (bv., Bulgarije, Servië, en Griekenland).\n\nEr is dus niet alleen variatie tussen individuen, maar ook variatie *tussen landen*. Dit zien we ook op het rechtse plot, dat de gemiddelde tevedenheidsscore per land weergeeft.[^errors-2]\n\n[^errors-2]: Wel zien we dat er meer variatie is tussen individuen dan tussen landen. dat is wel vaker zo in dergelijke cross-nationale surveydatasets.\n\nDemocratische tevredenheid is hoger in sommige landen dan andere. Daar kunnen verschillende redenen voor bestaan: andere politieke instituties, economische welvaart, corruptieniveaus enz. Mensen binnen een land leven in een context waarin die factoren gelijk zijn, maar mensen buiten een bepaald land leven in andere omstandigheden. We kunne dan ook verwachten dat errors van mensen binnen een bepaald land gecorreleerd zijn met elkaar in een studie waarbij meerdere landen zijn opgenomen.De standaardfouten in het model zijn dan wellicht ook niet correct.[^errors-3]\n\n[^errors-3]: We moeten er ook op letten dat er geen 'ommitted variable bias' optreedt. Hier gebruiken we bijvoorbeeld slechts 1 predictor en belangrijke controlevariabelen worden wellicht over het hoofd gezien.\n\nWe kunnen 2 methoden gebruiken om dit te corrigeren:[^errors-4]\n\n[^errors-4]: Er bestaan eigenlijk ook twee andere strategieën. Het probleem hier wordt veroorzaakt door het samenbrengen (\"poolen\") van gegevens uit verschillende landen (\"clusters\"). Het kan echter zijn dat we ons zorgen maken over één cluster in het bijzonder, bijvoorbeeld het doel van ons artikel kan zijn om de relatie tussen ideologie en democratische tevredenheid specifiek in Duitsland of in Nederland te onderzoeken, enz. Een \"oplossing\" is dan om waarnemingen uit de andere landen weg te filteren en enkel een model voor 1 land te schatten. Het kan ook zijn dat we niet echt geïnteresseerd zijn in het lagere niveau van de dataset (bijv. de individuen in dit voorbeeld) en eigenlijk meer geven om het verklaren van de variatie tussen clusters (bijv. waarom landen als Zwitserland een hogere democratische tevredenheid hebben dan landen als Bulgarije). Een optie hier is om het clustergemiddelde te gebruiken als onze afhankelijke variabele in een regressiemodel en dit te voorspellen met predictoren op landniveau (bv. BBP). Zoals altijd is de eerste stap in elke data-analyse uitzoeken *wat onze vraag is*, omdat dit een grote invloed heeft op het type analyse dat geschikt is om te leren wat we willen leren.\n\nWe kunnen gebruik maken van \"geclusterde standaardfouten\" en \"fixed effects\". Net zoals bij heteroskedasticiteit herberekenen we de standaardfouten (Let op: de berekening is wel anders). Deze corrigeren voor het feit dat de errors van observaties binnen een cluster (hier: land) gecorreleerd zijn. Fixed effects toevoegen houdt in dat we een dummy-variabele toevoegen per cluster (hier:land) om te controleren op variaties in de afhankelijke variabele afkomstig uit kenmerken van de cluster.\n\nSommige onderzoekers maken ook gebruik van \"multilevel modellen\". Met deze modellen kunnen predictoren op het niveau van individuele respondenten alsook predictoren op het cluster-niveau worden toegevoegd (bv. BBP) Deze methode is te gevorderd voor dit handboek en wordt verder niet besproken.\n\n### Mogelijke oplossing: Clustered standard errors & fixed effects\n\nWe schatten ons model met geclusterde standaardfouten met de code uitgelegd hieronder. Om \"fixed effects\" toe te voegen transformeren we gewoon de clustervariabele in een factor-variabele. Wanneer we deze factor toevoegen aan het model neemt R dummies op voor elke cluster, behoudens de referentiecategorie. [^errors-5]\n\n[^errors-5]: Deze strategie werkt ongeacht de hoeveelheid clusters die je hebt. De berekening kan wel langer duren bij een groter aantal clsuters. Stel dat we met longitudinale, panel-data werken van 500 respondenten die elke maand van het jaar bevraagd worden. Voor een 'fixed effects'analyse betekent dit dat je 499 dummies toevoegd. Dit is best veel. In dit geval kun je ook specifieke packages gebruiken die speciaal ontworpen ziin voor 'fixed effects' en vlugger werken, bijvoorbeeld het [fixest](https://lrberge.github.io/fixest/) package met bijhorende `feols` functie. Deze functie gebruikt ook automatisch geclusterde standaardfouten.\n\n```{r}\n\n# factor maken\ness_demsatis <- ess_demsatis |> \n  mutate(\n    country_name_F = factor(country_name))\n\n# Controleren of alles juist is gegaan: Austria is hier de referentiecategorie\nlevels(ess_demsatis$country_name_F)\n\n# Factor toevoegen aan model\ndemsatis_model2 <- lm(stfdem ~ lrscale + country_name_F, data = ess_demsatis)\n\n# Coëfficiënten opvragen\ntidy(demsatis_model2, conf.int = TRUE)\n\n```\n\nHet model bevat nu een coëfficiënt voor links-rechtspositie (`lrscale`) en een reeks dummy-variabelen voor elk land (`country_name_FBelgium`, `country_name_FBulgaria`, etc.). Schrik niet van deze output, dit is effectief de bedoeling!\n\nDe coëfficient voor `lrscale` toont de associatie tussen links-rechtspositie en tevredenheid met democratie, gecontroleerd voor het land waar de respondent zich bevindt. De dummy-coëfficiënten tonen het verschil tussen elk land en de referentiecategorie (Oostenrijk), gecontroleerd voor `lrscale`. We vinden bijvoorbeeld dat als we Bulgaarse en Oostenrijkse burgers met dezelfde ideologiescore zouden vergelijken, dan zouden we verwachten dat tevredenheid van Bulgaarse burgers gemiddeld genomen 2.42 eenheden lager is dan die van Oostenrijkse burgers.\n\nDe resultaten hieboven maken nog gebruik van de 'normale' standaardfouten. We kunnen de geclusterde standaardfouten toevoegen via `modelsummary()` met de `vcov =` optie, zoals hieronder (`coef_rename` hebben we hier even weggelaten).\n\n```{r}\nmodelsummary(\n  demsatis_model2, \n  stars = T, \n  vcov = ~country_name_F, \n  gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n```\n\n`vcov = \\~country_name_F`\n\n:   Met deze optie vragen we om geclusterde standaardfouten te berekenen voor ons model. De clustervariabele moet aangeduid worden in de syntax.\n\nWe kunnen de `vcov` optie ook gebruiken voor voorspellingen en marginal effects binnen de `avg_slopes` en `predictions` functies:\n\n```{r}\npredictions(demsatis_model2, \n            newdata = datagrid(lrscale = c(0:10)), \n            vcov = ~country_name_F) |> \n  ggplot(aes(x = lrscale, y = estimate)) + \n  geom_line() + \n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2) + \n  theme_bw() + \n  labs(title = \"Voorspelde waarden met geclusterde standaardfouten\", \n       x = \"Links-rechtspositionering\", \n       y = \"Voorspelde tevredenheid met democratie\") + \n  scale_x_continuous(breaks = c(0:10)) + \n  scale_y_continuous(limits = c(0,10))\n```\n\n::: callout-important\n#### Presentatie\n\nMet de `modelsummary` functie hierboven creëerden we een regressietabel met de coëfficiënten voor alle \\`country_name_F'- categorieën. Als er echter heel veel dummies zijn (en die dummies zijn ook minder relevant voor de interpetatie), dan worden ze vaak weggelaten in de output. Wel moet je in de notitie aan de lezer verduidelijken dat 'fixed effects' en geclusterde standaardfouten werden gebruikt.\n\nWe gebruiken `coef_map` om bepaalde coëfficiënten weg te kunnen laten in de output (zie @sec-interaction-term-in-a-regression-table).\n\n```{r}\nmodelsummary(\n  demsatis_model2, \n  stars = T, \n  vcov = ~country_name_F, \n  coef_map = c(\"(Intercept)\" = \"Constante\", \n               \"lrscale\" = \"Links-Rechtspositie\"),\n  gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"),\n  title = \"Democratische tevredenheid en links-rechtspositie\", \n  notes = \"Lineaire regressiecoëfficiënten met geclusterde standaardfouten tussen haakjes. Model geschat met country fixed effects.\")\n\n```\n:::\n\n### Probleem 2: Data over de tijd heen en seriële autocorrelatie\n\nDe assumptie van onafhankelijke fouten kan ook geschonden worden als we dezelfde eenheid (bv. een persoon, land, bedrijf) observeren over meerder punten in de tijd. Dit wordt 'time-series' data genoemd.\n\nStel bijvoorbeeld dat we geïnteresseerd zijn in de relatie tussen welvaart en democratie in een land. We maken hier gebruik van V-Dem data en kijken naar de relatie tussen welvaart van een land (`e_gdp`) en democratiescore (`v2x_polyarchy`). We richten ons eerst op Nederland. Hieronder tonen we hoe de data eruit ziet.\n\n```{r}\n#Filteren op Nederland\nnetherlands <- serial_data |> \n  filter(country_name == \"Netherlands\")\n\n#eerste 15 rijen in de dataset bekijken\nhead(netherlands, n = 15L)\n```\n\nDe dataset meet de variabelen vanaf 1789. Maar vinden we een relatie tussen de twee variabelen? Gaat hogere welvaart gepaard met meer democratie? We kunnen een lineaire regressie schatten om dit te proberen nagaan. We beperken ons hier tot een bivariate analyse. In de praktijk zou je ook op zoek willen gaan naar controlevariabelen.[^errors-6]\n\n[^errors-6]: Als we ons richten op controlevariabelen in het geval van 1 land dan moeten deze variëren over de tijd in Nederland (time-variant) en niet vaststaan (time-invariant).\n\n```{r}\n# Het model\nneth_model1 <- lm(v2x_polyarchy ~ e_gdp, data = netherlands)\n\n# Coëfficiënt bekijken\ntidy(neth_model1, conf.int = TRUE)\n\n```\n\nDe coëfficiënt voor `e_gdp` is positief. Het getal is erg klein, maar dit betekent niet noodzakelijk een klein effect gezien de predictor hier een sterke spreiding heeft. De coëfficiënt is ook statistisch significant.\n\nEchter moeten we opletten: onze observaties zijn allemaal gelinkt aan hetzelfde land en zijn dus niet onafhankelijk. Dit betekent vaak dat we de standaardfouten onderschatten en we kunnen zo onterecht significate effecten vinden.\n\nDit probleem is gekend als seriële autocorrelatie: de errors van het model zijn gecorreleerd met elkaar over de tijd heen. Een error op tijdstip *t* is systematisch gerelateerd aan de error van het jaar voordien, *t-1*. Dit is logisch gezien de welvaart en het democratisch gehalte van een land vrij stabiel zijn en afhangen van onderliggende condities zoals economische instituties, natuurlijke rijkdommen enz. Deze factoren fluctueren niet zo sterk over de tijd heen waardoor opeenvolgende errors vaak lijken op elkaar.\n\nWe kunnen formeel nagaan of er seriële autocorrelatie aanwezig is met behulp van de Durbin-Watson statistiek zoals besproken in @sec-ols-assumptions.\n\n```{r}\ncar::durbinWatsonTest(neth_model1) #<1>\n\n```\n\n1.  Het `car::` prefix staat ons hier toe om het `car`package te gebruiken zonder het te moeten laden. Dit heeft voordelen gezien `car`ook funties heeft die conflicteren met andere functies die we gebruiken, in het bijzonder de `recode` functie uit het `dplyr`/`tidyverse` package.\n\nDe Autocorrelation kolom geeft de correlatie weer tussen errors van het ene jaar op het andere. De correlatie is 0.97. Dit is hoog, gezien het maximum +1 is. De D-W Statistic test formeel of de autocorrelatie te hoog is. Dit is het geval als D-W hoger is dan 3 of kleiner dan 1. Hier is het duidelijk lager dan 1 (0.053). De p-waarde is extreem klein en dus verwerpen we de nulhypothese dat er geen autocorrelatie is. De standaardfouten zijn niet correct.\n\nWe kunnen dit probleem oplossen door een 'vertraagde afhankelijke variabele' ('lagged dependent variable') toe te voegen als predictor in ons model. Deze vertraagde afhankelijke variabele bevat voor elke observatie de score voor de afhankelijke variabele in het onmiddellijk voorgaande tijdspunt. Door deze variabele op te nemen wordt het probleem van stabiliteit/inertie in de afhankelijke variabele (en gecorreleerde errors) verholpen.[^errors-7]\n\n[^errors-7]: Er zijn nog andere manieren om dergelijke time series te modelleren, maar deze zijn te gevorderd voor dit handboek.\n\n#### Lagged Dependent Variables maken\n\nWe kunnen de `lag()` functie gebruiken om onze afhankelijke variabele te 'vertragen' voor een nieuw aangemaakte variabele.[^errors-8]\n\n[^errors-8]: Hier maken we een vertraagde afhankelijke variable maar hetzelfde proces kan gebruikt worden voor *onafhankelijke* variabelen, bijvoorbeeld als er zorgen zijn over omgekeerde causale verbanden ('reverse causality').\n\n```{r}\nnetherlands <- netherlands |> \n  mutate(dem_lag = lag(v2x_polyarchy, 1))\n```\n\n`lag(v2x_polyarchy, 1)`\n\n:   We gebruiken de functie `lag` op de relevante afhankelijke variabele (hier, `v2x_polyarchy`). Het nummer aan het einde van de functie geeft weer hoeveel eenheden vertraging we willen. Met het cijfer 1 zeggen we 1 tijdseenheid (hier: 1 jaar). Dit is het meest gebruikelijk. Indien we de `v2x_polyarchy` score van 2 jaar terug zouden willen, dan schrijven we '2' enzovoort.\n\nLaten we even kijken wat dat doet:\n\n```{r}\nhead(netherlands, n = 15L)\n```\n\nElke rij in de dataset bevat waarden per uniek jaar (1789, 1790, ...). `v2x_polyarchy` geeft de democratiescore van het land in het betreffende jaar. De nieuwe kolom (`dem_lag`) geeft de score in het *voorgaande jaar*. De waarde voor `dem_lag` in rij 9 (year = 1797) is 0.133; dis was de waarde voor democratie in 1796 (rij 8).We zien NA in de eerste rij gezien we geen voorgaande data hebben.\n\n::: callout-important\n#### Waarschuwing!\n\nHet spreekt voor zich dat de dataset eerst netjes geordend moet zijn op jaar vooraleer we functies zoals `car::durbinWatsonTest`en `lag` kunnen gebruiken. Hoe je een dataset kan ordenen (indien nodig) wordt besproken in @sec-ols-assumptions.\n:::\n\nWe voegen nu de lagged dependent variabele toe als predictor aan ons origineel model\n\n```{r}\n# Het nieuwe model\nneth_model2 <- lm(v2x_polyarchy ~ e_gdp + dem_lag, data = netherlands)\n\n# Coëfficiënten opvragen\ntidy(neth_model2, conf.int = TRUE)\n\n#Opvragen model fit statistieken via broom::glance()\nglance(neth_model2)\n\n```\n\nDe coëfficiënt voor `dem_lag` is 0.978. Dit is hoog, onze afhankelijke variabele heeft een bereik van 0 tot 1. De coëfficiënt toont dus dat er sterke stabiliteit is tussen democratiescores in opeenvolgende jaren. [^errors-9] We vinden dan ook dat de R^2^ statistieken dichtbij hun maxima van 1 zitten: toevoeging van de lagged dependent variable verklaart bijna alle variatie in democratiescore.\n\n[^errors-9]: De bivariate pearson correlatie tussen de twee variabelen is 0.99. Democratiescores in Nederland blijven erg stabiel van jaar tot jaar.\n\nDe coëfficiënt voor `e_gdp` toont de associate tussen BBP en democratiescores gecontroleerd voor democratiescore in het voorgaande jaar. Dit vertelt ons eigenlijk of BBP gerelataard is aan *verandering in democratiescore* van jaar tot jaar. De coëfficiënt is positief, maar niet langer significant.\n\nHebben we daarmee het probleem van autocorrelatie opgelost? We gaan het na:\n\n```{r}\ncar::durbinWatsonTest(neth_model2) \n```\n\nAutocorrelatie bedraagt nu slechts 0.29, wat veel lager is dan de 0.97 in het voorgaande model. De D-W statistiek bevindt zich nu tussen 1 en 3. Er is nog autocorrelatie (zie de ook de p-waarde), maar we hebben al veel in rekening gebracht.\n\nVoorgaand voorbeeld was gericht op 1 land, namelijk Nederland. In het geval we meerdere landen hebben kunnen we ook de `lag` functie gebruiken, maar er zal wel een probleem optreden waar we ons van bewust moeten zijn. We tonen eerst wat het probleem is en bieden dan een oplossing:\n\n```{r}\nserial_data |> \n  mutate(dem_lag = lag(v2x_polyarchy)) |> \n  slice(225:235) # <1>\n```\n\n1.  Deze syntax vraagt R om de data te 'snijden' en data te tonen voor rij 225 tot en met 235.\n\nWe tonen hier de transitie in de dataset van Mexico naar Suriname. In rij 7 bevind zich de data voor Mexico voor het laats beschikbare jaar 2019. Dan springt de dataset naar het eerste jaar voor Suriname, namelijk 1960. Als we kijken naar de `dem_lag` variabele zien we dat Suriname in 1960 de democratiescore van Mexico in 2019 heeft meegekregen. Dat mag natuurlijk niet. Zonder correctie doet R dit voor alle punten in de dataset waar we van 1 land naar een ander land gaan.\n\nWe vermijden dit door de `group_by()` functie te gebruiken:\n\n```{r}\nserial_data <- serial_data |> \n  group_by(country_name) |> \n  mutate(dem_lag = lag(v2x_polyarchy)) |> \n  ungroup() \n```\n\n`group_by(country_name)`\n\n:   De `group_by()` functie vraagt R om de dataset eerst te groeperen volgens de variabele tussen haakjes (hier: country_name). Daarna pas wordt de `lag`functie, via `mutate()`, toegepast. Wat er precies gebeurt kun je zien met deze gif van [Andrew Heiss](https://www.andrewheiss.com/blog/2024/04/04/group_by-summarize-ungroup-animations/){target=\"_blank\"} [-@heiss2024]:\n\n{{< video figures/grp-mutate.mp4 >}}\n\n`ungroup()`\n\n:   Deze functie is nodig om `mutate` te vertellen dat we niet langer willen groeperen voor toekomstige toepassingen van de functie. Anders blijft `mutate` verdere bewerkingen per groep uitvoeren.\n\nLaten we bekijken wat er gebeurt is\n\n```{r}\nserial_data |> \n  slice(225:235)\n\n```\n\nWe zien nu een NA waarde in rij 8, het eerste beschikbare jaar voor Suriname. Dit is wat we willen.\n\nWe zouden nu de regressie opnieuw kunnen uitvoeren. Onze dataset heeft nu echter niet alleen een time series element, maar bevat ook geclusterde data want meerdere landen zijn opgenomen. We zullen de lagged dependent variable-techniek dus moeten combineren met bovenstaande technieken voor clustering (fixed effects en geclusterde standaardfouten).\n\n## Omgaan met niet-normaal verdeelde residuals\n\n### Wat was het probleem ook al weer?\n\nDe laatste assumptie die we hier bekijken stelt dat de errors/residuals/fouten in een OLS model normaal verdeeld zijn. Of aan deze assumptie voldaan is kunnen we nagaan met plots gemaakt via `resid_panel()`: een histogram van de residuals en een Q-Q plot van de residuals.\n\n```{r}\n# Model schatten\nnorm_model <- lm(v2x_polyarchy ~ gini_disp + pr_fct + region1, data = normal_residual_data)\n\n# Coëfficiënten opvragen\ntidy(norm_model, conf.int = TRUE)\n\n# Assumptie checken\nresid_panel(norm_model, plots = c(\"hist\", \"qq\"))\n```\n\nBeide grafieken leiden tot dezelfde vaststelling: de assumptie is geschonden (zie @sec-ols-assumptions). Met een relatief grote steekproef is een schending van deze assumptie doorgaans geen probleem. In kleine steekproeven kan dit wel problematisch zijn. Hier zien we met de `glance()` functie uit het `broom` package dat we met een kleine steekproef te maken hebben:\n\n```{r}\nglance(norm_model)$nobs\n```\n\nWe hebben 77 observaties in het model. Is dit klein of groot genoeg? Jammergenoeg bestaat hier geen eenduidig antwoord voor. Een vuistregel is dat we met een kleine steekproef te maken hebben bij minder dan 15 observaties per onafhankelijke variabele. Hier hebben we 5 predictors. We vinden dan dat we met 77 observaties net 2 meer hebben dan de vuistregel voorschrijft (5 \\* 15 = 75). Dit is echter dicht bij de grens, dus misschien is het toch veiliger om rekening te houden met een assumptieschending.\n\n### Mogelijke oplossing: bootstrapping\n\nOok voor een schending van deze assumptie (met een kleine steekproef) moeten we de standaardfouten herberekenen. We gebruiken in dit geval weer een andere herberekening dan hierboven, namelijk 'gebootstrapte' standaardfouten. Met bootstrapping worden standaardfouten herschat met de volgende procedure:\n\nWe nemen een steekproef van de oorspronkelijke steekproef met dezelfde grootte. Dit gebeurt met teruglegging van de observaties, dat wil zeggen 1 observatie kan meerdere malen opgenomen worden in de nieuwe steekproef. Dat moet natuurlijk, anders kom je gewoon telkens dezelfde steekproef uit. Op basis van de nieuwe steekproef schatten we coëfficiënt en standaardfout opnieuw en slagen de resultaten op. Dit doen we een aantal keren. Ten slotte kijken we naar alle verschillende coëfficiënten die we uitgekomen zijn en in het bijzonder naar de standaardafwijking van de verzameling coëfficiënten. Deze standaardafwijking wordt de 'gebootstrapte'standaardfout.\n\nOok deze standaardfout kunnen we bekomen met de `vcov=` optie in de `modelsummary()` syntax. Wat nieuw is hier is dat we een element van toeval toevoegen in de berekening: R gaat 'random' nieuwe steekproeven trekken. Op zich is dit goed -moeten wij het niet doen!- maar juist door dit toevalselement kan de uitkomst telkens licht anders zijn. Om resultaten reproduceerbaar te houden zetten we hier dan ook een 'seed': een seed is een zelfgekozen startgeval (je kan 1 gebruiken maar ook je verjaardag enz.). Met de seed houdt R bij welke steekproeven precies getrokken werden en worden telkens dezelfde resultaten bereikt. Voor je je seed vastlegt wil je wel eerst nagaan of je met hetzelfde aantal steekproeven sterk verschillende resultaten uitkomt, want in dat geval vraag je R best meer steekproeven te trekken voor betere schattingen, zie onder).\n\n```{r}\n# seed vastleggen\nset.seed(1)\n\n# Model schatten \nmodelsummary(norm_model, \n             stars = T, \n             vcov = \"bootstrap\", \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n```\n\n`set.seed(1)`\n\n:   We zetten het toevallig trekken van steekproeven hier vast met een zelfgekozen getal zodat resultaten dezelfde blijven.\n\n`vcov = \"boostrap\"`\n\n:   Deze optie vraagt om de 'gebootstrapte' standaarfouten.\n\nWe kunnen de standaardfouten vergelijken:\n\n```{r}\n# Seed: zelfde als hierboven want dan krijgen we zelfde resultaten\nset.seed(1)\n\n# Modellen vergelijken\nmodelsummary(norm_model, \n             stars = T, \n             vcov = c(\"classical\", \"bootstrap\"),\n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n```\n\nWat merken we op:\n\n-   De coëfficiënten veranderen niet, enkel de standaardfouten. Dat zagen we ook bij heteroskedasticiteit-robuuste standaardfouten en geclusterde standaardfouten\n-   De standaardfouten zijn verschillend. Doorgaans, maar niet altijd, zijn gebootstrapte standaardfouten groter.\n-   Conclusies over de significantie van resultaten blijven hier dezelfde, hoewel we zien dat het significantieniveau voor de coëfficiënt van `region1Europe` veranderd is van p \\< 0.01 naar p \\< 0.05. De gevolgen kunnen veel groter zijn in andere analyses.\n\nZoals gezegd neemt R zelf nieuwe toevalssteekproeven. Standaard worden 250 steekproeven genomen. Zoals eerder gezegd zet je een 'seed' om resultaten gelijk te houden, maar natuurlijk is het niet echt betrouwbaar als resultaten bij elke trekking sterk veranderen. Vooraleer te beslissen om je seed vast te leggen, wil je nagaan of resultaten sterk verschillen zonder seed. Als dit het geval is, wil je R vragen meer steekproeven te trekken om betere schattingen te maken van de standaardfouten. Dit doen we in onderstaande syntax door R om 1000 steekproeven te vragen. We zetten een seed in de syntax, maar ga ervanuit dat we eerst goed gekeken hebben naar verschillende uitkomsten vooraleer een seed te zetten.\n\n```{r}\nset.seed(1) \n\nmodelsummary(norm_model, \n             stars = T, \n             vcov = \"bootstrap\", \n             R = 1000, \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n```\n\n`R = 1000`\n\n:   Deze optie laat toe het aantal steekproeven dat R trekt aan te passen. Hier vragen we er 1000.\n\nOnze resultaten hier zijn gelijkaardig, maar niet identiek aan deze gevonden bij 250 steekproeven. Het heeft echter geen gevolgen voor de algemene conclusies over significantie.\n\nBootstrapping kan ook gebruikt worden binnen het `marginaleffects` package, bv. wanneer we voorspelde waarden en betrouwbaarheidsintervallen nodig hebben. De functie om bootstrapping te gebruiken (`inferences()`) is echter nog steeds in ontwikkeling en je moet er ook bijkomende packages voor installeren. Indien je dit nodig zou hebben, bekijk dan het [\"Bootstrap\"](https://marginaleffects.com/bonus/bootstrap.html) hoofdstuk op de `marginaleffects` website.\n","srcMarkdownNoYaml":"\n\n# Assumptieschendingen oplossen\n\n```{r}\n#| message: false\n#| warning: false\n#| echo: false\n\n#Packages\nlibrary(ggResidpanel)   #<1> \nlibrary(rio)            #<2>\nlibrary(tidyverse)      #<3>\nlibrary(modelsummary)   #<4>\nlibrary(marginaleffects) #<5>\nlibrary(broom) #<6>\n\n# Gebruikte datasets\ndemdata <- import(\"./data/demdata.rds\")\ness_demsatis <- import(\"./data/ess_demsatis.dta\")\nnormal_residual_data <- import(\"./data/normal_residual_data.rda\")\nserial_data <- import(\"./data/serial_autocorrelation.rda\")\n```\n\n```{r}\n#| message: false\n#| warning: false\n#| eval: false\n\n#Packages\nlibrary(ggResidpanel)   #<1> \nlibrary(rio)            #<2>\nlibrary(tidyverse)      #<3>\nlibrary(modelsummary)   #<4>\nlibrary(marginaleffects) #<5>\nlibrary(broom) #<6>\n\n# Gebruikte datasets\ndemdata <- import(\"demdata.rds\")\ness_demsatis <- import(\"ess_demsatis.dta\")\nnormal_residual_data <- import(\"normal_residual_data.rda\")\nserial_data <- import(\"./data/serial_autocorrelation.rda\")\n```\n\n1.  Assumpties testen met plots\n2.  Data importeren\n3.  Datamanipulatie/plots\n4.  Regressietabellen maken\n5.  Voorspelde waarden en marginale effecten\n6.  Gegevens samenvatten\n\n::: {.callout-note title=\"Voor wie is deze Appendix?\"}\nJe hoeft niet te weten hoe je deze analyses moet uitvoeren voor de opdrachten in Statistiek II. Deze gids is bedoeld voor studenten die hun eindpaper schrijven voor Academische Vaardigheden: Kwantitatieve Data-Analyse of een BAP-scriptieproject en graag assumptieschendingen willen vermijden.\n:::\n\nRegressiemodellen zijn gebaseerd op een aantal assumpties of aannames. Een belangrijk onderdeel van de analyse is nagaan of aan die assumpties voldaan is. Zoniet, dan moeten assumptieschendingen op een passende manier behandeld worden. Statistiek II richt zich meer op het eerste deel van het proces: wanneer is niet voldaan aan een assumptie? In deze Appendix geven we een kort overzicht van enkele mogelijke oplossingen voor assumptieschendingen waar je mee geconfronteerd kan worden.\n\n## Assumpties over de fouten (residuals) in OLS modellen\n\n$$\ny_{i} = b_{0} + b_{1} * x_{1} + b_{2} * x_{2} ... b_{k} * x_{k} + e_{i}\n$$\n\nDe $e_{i}$ term in bovenstaande vergelijking staat voor de 'error', fout, of residual in een linear regressiemodel. Er zijn drie assumpties over deze fouten:[^errors-1]\n\n[^errors-1]: Slechts een van deze assumpties is ook van toepassing op logistische modellen: de assumptie van onafhankelijke fouten. De oplossingen hiervoor zijn dezelfde bij logistische modellen, vandaar dat we ons in deze voorbeelden richten op OLS modellen.\n\n-   De variantie van de residuals is *constant* over het hele bereik van de voorspellingen van het model (homoskedasticiteit)\n-   De residuals zijn *onafhankelijk* van elkaar\n-   De residuals volgen een *normaalverdeling* met een gemiddelde van 0\n\nSchendingen van deze assumpties hebben belangrijke gevolgen voor statistische significantietests. Ernstige schendingen leiden tot onbetrouwbare schattingen van de standaardfout van een coëfficiënt en, als gevolg daarvan, tot onjuiste oordelen over statistische significantie.\n\n## Omgaan met Heteroskedasticiteit\n\n### Wat was het probleem ook al weer?\n\nOnderstaand voorbeeld komt uit @sec-ols-assumptions en voorspelt de mate van politieke stabiliteit in een land op basis van democratieniveaus. In het voorbeeld hebben we ook een kwadratische term voor democratiescore toegevoegd om non-lineaire verbanden te kunnen vatten. Hier is het model en de resultaten:\n\n```{r}\n#gekwadrateerde variabele maken\ndemdata <- demdata |> \n  mutate(v2x_polyarchy_sq = v2x_polyarchy^2)\n\n# Model schatten\nviolence_sqmodel <- lm(pve ~ v2x_polyarchy + v2x_polyarchy_sq, \n                      data=demdata)\n\n# coëfficiënten bekijken\ntidy(violence_sqmodel, conf.int = TRUE)\n```\n\nWe kunnen kijken of de assumptie van homoskedasticiteit geschonden is via `resid_panel()` zoals besproken in @sec-ols-assumptions.\n\n```{r}\n# assumptie bekijken\nresid_panel(violence_sqmodel, plots = c(\"resid\"))\n```\n\nAan de assumptie is voldaan als de fouten een even grote spreiding kennen op lage, gemiddelde, en hoge waarden van de voorspelde waarden. Ze moeten zich ongeveer in een evenwijdige band bevinden. Hier zien we dat de assumptie geschonden is aan de trechtervorm: we vinden een grote spreiding van residuals bij lage voorspele waarden (de schatting is hier onnauwkeurig) en weinig spreiding bij hoge voorspelde waarden (de schatting is hier veel nauwkeuriger).\n\n### Mogelijke oplossing: robuste standaardfouten\n\n::: callout-note\nDe `vcov` functie die we hieronder gebruiken is afkomstig uit het`sandwich`package en helpt bij de berekening van robuuste standaardfouten. Je zult dit package misschien eerst moeten installeren.\n:::\n\nHeteroskedasticiteit heeft verschillende mogelijke oorzaken. Zo kan het onstaan door het ontbrekenen van belangrijke predictoren in het model. Het is een goed idee om na te denken over waarom de residuals zo verschillen en welke bijkomende onafhankelijke variabele deze spreiding kan verklaren. We kunnen dit echter niet altijd weten en als we al een idee hebben, kan het zijn dat de relevante onafhankelijke variabele niet in de dataset voorkomt.\n\nEen andere mogelijke oorzaak is dat we een lineaire relatie schatten waar eigenlijk een niet-lineaire relatie geschat moet worden. Dit is hier echter niet het geval.\n\nWat kunnen we dan nog doen?\n\nEen gangbare manier is om de berekenmethode voor de standaardfouten van de coëfficiënten in het model aan te passen. De standaardfouten die normaal door R worden berekend gaan uit van homoskedasticiteit, maar we kunnen 'heteroskedasticiteit-robuuste' standaardfouten berekenen als alternatief. Belangrijk is om te onthouden dat deze oplossing een mathematisch 'truukje' is, ons model past nog altijd slecht en het is belangrijk theoretisch hierover na te denken. De eerste stap blijft altijd om na te denken over mogelijk ontbrekende predictoren.\n\nDe eenvoudigste manier om robuuste standaardfouten te verkrijgen is via het `modelsummary` package. We bekijken eerst nog even de 'normale' regressie-output voor het model:\n\n```{r}\nmodelsummary(violence_sqmodel, \n             stars = T, \n             coef_rename = c(\n               \"(Intercept)\" = \"Intercept\", \n               \"v2x_polyarchy\" = \"Democratiescore\", \n               \"v2x_polyarchy_sq\" = \"Democratiescore gekwadrateerd\"), \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n```\n\nDe tabel hierboven maakt gebruik van de normale standaardfouten. We kunnen de robuuste opvragen via de `vcov` optie:\n\n```{r}\nmodelsummary(violence_sqmodel, \n             stars = T, \n             vcov = \"HC3\",\n             coef_rename = c(\n               \"(Intercept)\" = \"Intercept\", \n               \"v2x_polyarchy\" = \"Democratiescore\", \n               \"v2x_polyarchy_sq\" = \"Democratiescore gekwadrateerd\"), \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n```\n\n`vcov = \"HC3\"`\n\n:   De `vcov =` optie vraagt om robuuste standaardfouten te berekenen en te gebruiken in de tabel. \"HC3\" staat voor 'heteroskedasticiteit-robuuste standardfouten'. Er zijn verschillende heteroskedasticiteit-robuuste standaardfouten (bv., \"HC0\", \"HC1\", etc.). We raden \"HC3\" aan als standaard, ook omdat deze goed werkt bij kleine steekproefgroottes.\n\nLaten we de 'normale' en 'robuuste' standaardfouten vergelijken:\n\n```{r}\n\nmodelsummary(violence_sqmodel, \n             stars = T, \n             vcov = c(\"classical\", \"HC3\"), \n             coef_rename = c(\n               \"(Intercept)\" = \"Intercept\", \n               \"v2x_polyarchy\" = \"Democratiescore\", \n               \"v2x_polyarchy_sq\" = \"Democratiescore gekwadrateerd\"),\n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n```\n\nDe eerste kolom toont de resultaten voor de 'normale' standaardfouten, de tweede kolom deze voor de 'robuuste' fouten. We kunnen het volgende opmerken:\n\n-   De coëfficiënten veranderen niet, enkel de standaardfouten.\n-   De robuuste standaardfouten zijn typisch groter. Heteroskedasticiteit zorgt immers doorgaans voor een neerwaarste bias: standaarfouten worden te klein geschat als we de normale methode zouden gebruiken.\n-   De interpretatie van de resultaten verandert hier niet. De significantietoetsen voor de predictoren komen uit op dezelfde conclusies. Di is echter lang niet altijd het geval!\n\nHet voorbeeld hierboven maakt gebruik van `modelsummary()` en geeft de resultaten weer in een tabel. Ook voor voorspelde waarden en coëfficiëntenplots kunnen we robuuste standaardfouten gebruiken zodanig dat betrouwbaarheidsintervallen aangepast worden.\n\nWe blijven de bovenstaande `vcov` optie gebruiken, maar binnen de `predictions()` functie uit het `marginaleffects` package (bv., `predictions(model, ..., vcov = \"HC3\")`) voor voorspelde waarden.\n\nVoor coëfficiëntenplots kunnen we de syntax echter niet netjes combineren met `tidy()` zoals we deden in @sec-reporting-and-presenting-results. In de plaats daarvan gebruiken we de `avg_slopes()` functie uit het `marginaleffects` package. `avg_slopes()` schat de marginale effecten van elke predictor in het model. Bij OLS is dit gelijk aan de coëfficiënten.\n\n```{r}\n# Resultaten via tidy\ntidy(violence_sqmodel)\n\n# Resultaten  via avg_slopes\navg_slopes(violence_sqmodel)\n```\n\nWe voegen de `vcov =` optie toe aan de `avg_slopes()` functie en plotten de resultaten:\n\n```{r}\n# robuuste SEs en plot\navg_slopes(violence_sqmodel, vcov = \"HC3\") |> # <1>\n  ggplot(aes(x = estimate, y = term)) + \n  geom_pointrange(aes(xmin = conf.low, xmax = conf.high)) + \n  geom_text(aes(label = round(estimate, 2)), vjust = -0.5) + \n  geom_vline(xintercept = 0, linetype = 'dashed', color = 'red') + \n  theme_bw() + \n  labs(x = \"Coëfficiënt\", \n       y = \"Onafhankelijke variabele\", \n       title = \"Coëfficiënten met Heteroskedasticiteit-robuuste betrouwbaarheidsintervallen\")\n```\n\n1.  Opvragen van marginale effecten van de predictoren samen met de robuuste standaardfouten.\n\n## Omgaan met afhankelijke fouten\n\nEen tweede belangrijke assumptie in OLS (en logistische) modellen is deze van *onafhankelijkheid*. We gaan ervan uit dat de fouten in de populatie en in ons model niet gecorreleerd zijn met elkaar. Deze assumptie kan geschonden zijn wanneer data 'geclusterd' is.\n\n### Probleem 1: geclusterde data\n\n#### Voorbeeld van het probleem\n\nStel dat we meten in welke mate burgers tevreden zijn met democratie in verschillende Europese landen (bv. met links-rechtspositie als predictor). We kunnen de European Social Survey (ESS) gebruike, waarbij respondenten uit verschillende landen werden ondervraagd. Wanneer de analyse meerdere landen beschouwt, zijn respondenten geclustert in hun land.\n\nWe bekijken de resultaten van een dergelijk model. De afhankelijke variabele meet tevredenheid met democratie op een schaal van 0 (\"zeer ontevreden\") tot 10 (\"zeer tevreden\"). De onafhankelijke variabele meet links-rechtspositie met een schaal van 0 (\"links\") tot 10 (\"rechts\").\n\n```{r}\n\n# Model \ndemsatis_model <- lm(stfdem ~ lrscale, data = ess_demsatis)\n\n# Coefficients\ntidy(demsatis_model, conf.int = TRUE)\n\n```\n\nDe coëfficiënt voor links-rechtspositie (`lrscale`) is positief: mensen die zich meer aan de rechterkant van het politieke spectrum plaatsen zijn meer tevreden met democratie. De coëfficiënt is ook statistisch significant met wel een heel kleine p-waarde (7.97e-117). Laten we echter kijken hoe clustering hier bij komt kijken.\n\n```{r}\n#| code-fold: true\n#| code-summary: \"Show the code\"\n#| fig-width: 12\n#| fig-height: 8\n\n# Extra package for plotting\nlibrary(patchwork) # <1>\n\n# Distribution plot\ndistribution_plot <- ess_demsatis |> \n  group_by(country_name, stfdem) |> # <2>\n  tally() |> \n  ungroup() |> \n  group_by(country_name) |> # <3>\n  mutate(prop = n / sum(n)) |>\n  ggplot(aes(x = stfdem, y = prop)) + \n  geom_col() +\n  facet_wrap(~ country_name) + \n  theme_bw() + \n  labs(title = \"Variatie volgens Land\", \n       y = \"Proportie\", \n       x = \"Tevredenheidsscore\") + \n  scale_x_continuous(breaks = c(0,5,10))\n\n# Plot of means\nmean_plot <- ess_demsatis |> \n  group_by(country_name) |> \n  summarize(dem_satis = mean(stfdem, na.rm = T)) |> \n  ggplot(aes(x = dem_satis, y = reorder(country_name, dem_satis))) + # <4>\n  geom_col() + \n  theme_bw() + \n  labs(title = \"Gemiddelde per land\", \n       y = \"Naam land\", \n       x = \"Gemiddelde tevredenheid met democratie\")\n\n# Combine together using patchwork\ndistribution_plot + mean_plot\n\n\n```\n\n1.  De `patchwork` library wordt hier gebruikt om meerdere grafieken te combineren met elkaar.\n2.  Deze regels berekenen het aantal antwoorden per antwoordcategorie per land.\n3.  We berekenen hier de proportie van observaties met een specifieke respons per land.\n4.  De `reorder()` optie herordent de y-as zodat die loopt van hogere tot lagere gemiddelde scores.\n\nHet linkse plot in de figuur hierboven toont de proportie observaties per antwoordcategorie (x-as) per land (aparte 'facets'). De plot toont variatie tussen individuen binnen een land: sommige zijn tevreden, andere niet. De verdeling van observaties is echter niet dezelfde per land. Sommige landen zien meer tevreden respondenten (bv., Finland, Norwegen, en Zwitserland) terwijl in andere landen mensen zich meer onderaan de schaal bevinden (bv., Bulgarije, Servië, en Griekenland).\n\nEr is dus niet alleen variatie tussen individuen, maar ook variatie *tussen landen*. Dit zien we ook op het rechtse plot, dat de gemiddelde tevedenheidsscore per land weergeeft.[^errors-2]\n\n[^errors-2]: Wel zien we dat er meer variatie is tussen individuen dan tussen landen. dat is wel vaker zo in dergelijke cross-nationale surveydatasets.\n\nDemocratische tevredenheid is hoger in sommige landen dan andere. Daar kunnen verschillende redenen voor bestaan: andere politieke instituties, economische welvaart, corruptieniveaus enz. Mensen binnen een land leven in een context waarin die factoren gelijk zijn, maar mensen buiten een bepaald land leven in andere omstandigheden. We kunne dan ook verwachten dat errors van mensen binnen een bepaald land gecorreleerd zijn met elkaar in een studie waarbij meerdere landen zijn opgenomen.De standaardfouten in het model zijn dan wellicht ook niet correct.[^errors-3]\n\n[^errors-3]: We moeten er ook op letten dat er geen 'ommitted variable bias' optreedt. Hier gebruiken we bijvoorbeeld slechts 1 predictor en belangrijke controlevariabelen worden wellicht over het hoofd gezien.\n\nWe kunnen 2 methoden gebruiken om dit te corrigeren:[^errors-4]\n\n[^errors-4]: Er bestaan eigenlijk ook twee andere strategieën. Het probleem hier wordt veroorzaakt door het samenbrengen (\"poolen\") van gegevens uit verschillende landen (\"clusters\"). Het kan echter zijn dat we ons zorgen maken over één cluster in het bijzonder, bijvoorbeeld het doel van ons artikel kan zijn om de relatie tussen ideologie en democratische tevredenheid specifiek in Duitsland of in Nederland te onderzoeken, enz. Een \"oplossing\" is dan om waarnemingen uit de andere landen weg te filteren en enkel een model voor 1 land te schatten. Het kan ook zijn dat we niet echt geïnteresseerd zijn in het lagere niveau van de dataset (bijv. de individuen in dit voorbeeld) en eigenlijk meer geven om het verklaren van de variatie tussen clusters (bijv. waarom landen als Zwitserland een hogere democratische tevredenheid hebben dan landen als Bulgarije). Een optie hier is om het clustergemiddelde te gebruiken als onze afhankelijke variabele in een regressiemodel en dit te voorspellen met predictoren op landniveau (bv. BBP). Zoals altijd is de eerste stap in elke data-analyse uitzoeken *wat onze vraag is*, omdat dit een grote invloed heeft op het type analyse dat geschikt is om te leren wat we willen leren.\n\nWe kunnen gebruik maken van \"geclusterde standaardfouten\" en \"fixed effects\". Net zoals bij heteroskedasticiteit herberekenen we de standaardfouten (Let op: de berekening is wel anders). Deze corrigeren voor het feit dat de errors van observaties binnen een cluster (hier: land) gecorreleerd zijn. Fixed effects toevoegen houdt in dat we een dummy-variabele toevoegen per cluster (hier:land) om te controleren op variaties in de afhankelijke variabele afkomstig uit kenmerken van de cluster.\n\nSommige onderzoekers maken ook gebruik van \"multilevel modellen\". Met deze modellen kunnen predictoren op het niveau van individuele respondenten alsook predictoren op het cluster-niveau worden toegevoegd (bv. BBP) Deze methode is te gevorderd voor dit handboek en wordt verder niet besproken.\n\n### Mogelijke oplossing: Clustered standard errors & fixed effects\n\nWe schatten ons model met geclusterde standaardfouten met de code uitgelegd hieronder. Om \"fixed effects\" toe te voegen transformeren we gewoon de clustervariabele in een factor-variabele. Wanneer we deze factor toevoegen aan het model neemt R dummies op voor elke cluster, behoudens de referentiecategorie. [^errors-5]\n\n[^errors-5]: Deze strategie werkt ongeacht de hoeveelheid clusters die je hebt. De berekening kan wel langer duren bij een groter aantal clsuters. Stel dat we met longitudinale, panel-data werken van 500 respondenten die elke maand van het jaar bevraagd worden. Voor een 'fixed effects'analyse betekent dit dat je 499 dummies toevoegd. Dit is best veel. In dit geval kun je ook specifieke packages gebruiken die speciaal ontworpen ziin voor 'fixed effects' en vlugger werken, bijvoorbeeld het [fixest](https://lrberge.github.io/fixest/) package met bijhorende `feols` functie. Deze functie gebruikt ook automatisch geclusterde standaardfouten.\n\n```{r}\n\n# factor maken\ness_demsatis <- ess_demsatis |> \n  mutate(\n    country_name_F = factor(country_name))\n\n# Controleren of alles juist is gegaan: Austria is hier de referentiecategorie\nlevels(ess_demsatis$country_name_F)\n\n# Factor toevoegen aan model\ndemsatis_model2 <- lm(stfdem ~ lrscale + country_name_F, data = ess_demsatis)\n\n# Coëfficiënten opvragen\ntidy(demsatis_model2, conf.int = TRUE)\n\n```\n\nHet model bevat nu een coëfficiënt voor links-rechtspositie (`lrscale`) en een reeks dummy-variabelen voor elk land (`country_name_FBelgium`, `country_name_FBulgaria`, etc.). Schrik niet van deze output, dit is effectief de bedoeling!\n\nDe coëfficient voor `lrscale` toont de associatie tussen links-rechtspositie en tevredenheid met democratie, gecontroleerd voor het land waar de respondent zich bevindt. De dummy-coëfficiënten tonen het verschil tussen elk land en de referentiecategorie (Oostenrijk), gecontroleerd voor `lrscale`. We vinden bijvoorbeeld dat als we Bulgaarse en Oostenrijkse burgers met dezelfde ideologiescore zouden vergelijken, dan zouden we verwachten dat tevredenheid van Bulgaarse burgers gemiddeld genomen 2.42 eenheden lager is dan die van Oostenrijkse burgers.\n\nDe resultaten hieboven maken nog gebruik van de 'normale' standaardfouten. We kunnen de geclusterde standaardfouten toevoegen via `modelsummary()` met de `vcov =` optie, zoals hieronder (`coef_rename` hebben we hier even weggelaten).\n\n```{r}\nmodelsummary(\n  demsatis_model2, \n  stars = T, \n  vcov = ~country_name_F, \n  gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n```\n\n`vcov = \\~country_name_F`\n\n:   Met deze optie vragen we om geclusterde standaardfouten te berekenen voor ons model. De clustervariabele moet aangeduid worden in de syntax.\n\nWe kunnen de `vcov` optie ook gebruiken voor voorspellingen en marginal effects binnen de `avg_slopes` en `predictions` functies:\n\n```{r}\npredictions(demsatis_model2, \n            newdata = datagrid(lrscale = c(0:10)), \n            vcov = ~country_name_F) |> \n  ggplot(aes(x = lrscale, y = estimate)) + \n  geom_line() + \n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2) + \n  theme_bw() + \n  labs(title = \"Voorspelde waarden met geclusterde standaardfouten\", \n       x = \"Links-rechtspositionering\", \n       y = \"Voorspelde tevredenheid met democratie\") + \n  scale_x_continuous(breaks = c(0:10)) + \n  scale_y_continuous(limits = c(0,10))\n```\n\n::: callout-important\n#### Presentatie\n\nMet de `modelsummary` functie hierboven creëerden we een regressietabel met de coëfficiënten voor alle \\`country_name_F'- categorieën. Als er echter heel veel dummies zijn (en die dummies zijn ook minder relevant voor de interpetatie), dan worden ze vaak weggelaten in de output. Wel moet je in de notitie aan de lezer verduidelijken dat 'fixed effects' en geclusterde standaardfouten werden gebruikt.\n\nWe gebruiken `coef_map` om bepaalde coëfficiënten weg te kunnen laten in de output (zie @sec-interaction-term-in-a-regression-table).\n\n```{r}\nmodelsummary(\n  demsatis_model2, \n  stars = T, \n  vcov = ~country_name_F, \n  coef_map = c(\"(Intercept)\" = \"Constante\", \n               \"lrscale\" = \"Links-Rechtspositie\"),\n  gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"),\n  title = \"Democratische tevredenheid en links-rechtspositie\", \n  notes = \"Lineaire regressiecoëfficiënten met geclusterde standaardfouten tussen haakjes. Model geschat met country fixed effects.\")\n\n```\n:::\n\n### Probleem 2: Data over de tijd heen en seriële autocorrelatie\n\nDe assumptie van onafhankelijke fouten kan ook geschonden worden als we dezelfde eenheid (bv. een persoon, land, bedrijf) observeren over meerder punten in de tijd. Dit wordt 'time-series' data genoemd.\n\nStel bijvoorbeeld dat we geïnteresseerd zijn in de relatie tussen welvaart en democratie in een land. We maken hier gebruik van V-Dem data en kijken naar de relatie tussen welvaart van een land (`e_gdp`) en democratiescore (`v2x_polyarchy`). We richten ons eerst op Nederland. Hieronder tonen we hoe de data eruit ziet.\n\n```{r}\n#Filteren op Nederland\nnetherlands <- serial_data |> \n  filter(country_name == \"Netherlands\")\n\n#eerste 15 rijen in de dataset bekijken\nhead(netherlands, n = 15L)\n```\n\nDe dataset meet de variabelen vanaf 1789. Maar vinden we een relatie tussen de twee variabelen? Gaat hogere welvaart gepaard met meer democratie? We kunnen een lineaire regressie schatten om dit te proberen nagaan. We beperken ons hier tot een bivariate analyse. In de praktijk zou je ook op zoek willen gaan naar controlevariabelen.[^errors-6]\n\n[^errors-6]: Als we ons richten op controlevariabelen in het geval van 1 land dan moeten deze variëren over de tijd in Nederland (time-variant) en niet vaststaan (time-invariant).\n\n```{r}\n# Het model\nneth_model1 <- lm(v2x_polyarchy ~ e_gdp, data = netherlands)\n\n# Coëfficiënt bekijken\ntidy(neth_model1, conf.int = TRUE)\n\n```\n\nDe coëfficiënt voor `e_gdp` is positief. Het getal is erg klein, maar dit betekent niet noodzakelijk een klein effect gezien de predictor hier een sterke spreiding heeft. De coëfficiënt is ook statistisch significant.\n\nEchter moeten we opletten: onze observaties zijn allemaal gelinkt aan hetzelfde land en zijn dus niet onafhankelijk. Dit betekent vaak dat we de standaardfouten onderschatten en we kunnen zo onterecht significate effecten vinden.\n\nDit probleem is gekend als seriële autocorrelatie: de errors van het model zijn gecorreleerd met elkaar over de tijd heen. Een error op tijdstip *t* is systematisch gerelateerd aan de error van het jaar voordien, *t-1*. Dit is logisch gezien de welvaart en het democratisch gehalte van een land vrij stabiel zijn en afhangen van onderliggende condities zoals economische instituties, natuurlijke rijkdommen enz. Deze factoren fluctueren niet zo sterk over de tijd heen waardoor opeenvolgende errors vaak lijken op elkaar.\n\nWe kunnen formeel nagaan of er seriële autocorrelatie aanwezig is met behulp van de Durbin-Watson statistiek zoals besproken in @sec-ols-assumptions.\n\n```{r}\ncar::durbinWatsonTest(neth_model1) #<1>\n\n```\n\n1.  Het `car::` prefix staat ons hier toe om het `car`package te gebruiken zonder het te moeten laden. Dit heeft voordelen gezien `car`ook funties heeft die conflicteren met andere functies die we gebruiken, in het bijzonder de `recode` functie uit het `dplyr`/`tidyverse` package.\n\nDe Autocorrelation kolom geeft de correlatie weer tussen errors van het ene jaar op het andere. De correlatie is 0.97. Dit is hoog, gezien het maximum +1 is. De D-W Statistic test formeel of de autocorrelatie te hoog is. Dit is het geval als D-W hoger is dan 3 of kleiner dan 1. Hier is het duidelijk lager dan 1 (0.053). De p-waarde is extreem klein en dus verwerpen we de nulhypothese dat er geen autocorrelatie is. De standaardfouten zijn niet correct.\n\nWe kunnen dit probleem oplossen door een 'vertraagde afhankelijke variabele' ('lagged dependent variable') toe te voegen als predictor in ons model. Deze vertraagde afhankelijke variabele bevat voor elke observatie de score voor de afhankelijke variabele in het onmiddellijk voorgaande tijdspunt. Door deze variabele op te nemen wordt het probleem van stabiliteit/inertie in de afhankelijke variabele (en gecorreleerde errors) verholpen.[^errors-7]\n\n[^errors-7]: Er zijn nog andere manieren om dergelijke time series te modelleren, maar deze zijn te gevorderd voor dit handboek.\n\n#### Lagged Dependent Variables maken\n\nWe kunnen de `lag()` functie gebruiken om onze afhankelijke variabele te 'vertragen' voor een nieuw aangemaakte variabele.[^errors-8]\n\n[^errors-8]: Hier maken we een vertraagde afhankelijke variable maar hetzelfde proces kan gebruikt worden voor *onafhankelijke* variabelen, bijvoorbeeld als er zorgen zijn over omgekeerde causale verbanden ('reverse causality').\n\n```{r}\nnetherlands <- netherlands |> \n  mutate(dem_lag = lag(v2x_polyarchy, 1))\n```\n\n`lag(v2x_polyarchy, 1)`\n\n:   We gebruiken de functie `lag` op de relevante afhankelijke variabele (hier, `v2x_polyarchy`). Het nummer aan het einde van de functie geeft weer hoeveel eenheden vertraging we willen. Met het cijfer 1 zeggen we 1 tijdseenheid (hier: 1 jaar). Dit is het meest gebruikelijk. Indien we de `v2x_polyarchy` score van 2 jaar terug zouden willen, dan schrijven we '2' enzovoort.\n\nLaten we even kijken wat dat doet:\n\n```{r}\nhead(netherlands, n = 15L)\n```\n\nElke rij in de dataset bevat waarden per uniek jaar (1789, 1790, ...). `v2x_polyarchy` geeft de democratiescore van het land in het betreffende jaar. De nieuwe kolom (`dem_lag`) geeft de score in het *voorgaande jaar*. De waarde voor `dem_lag` in rij 9 (year = 1797) is 0.133; dis was de waarde voor democratie in 1796 (rij 8).We zien NA in de eerste rij gezien we geen voorgaande data hebben.\n\n::: callout-important\n#### Waarschuwing!\n\nHet spreekt voor zich dat de dataset eerst netjes geordend moet zijn op jaar vooraleer we functies zoals `car::durbinWatsonTest`en `lag` kunnen gebruiken. Hoe je een dataset kan ordenen (indien nodig) wordt besproken in @sec-ols-assumptions.\n:::\n\nWe voegen nu de lagged dependent variabele toe als predictor aan ons origineel model\n\n```{r}\n# Het nieuwe model\nneth_model2 <- lm(v2x_polyarchy ~ e_gdp + dem_lag, data = netherlands)\n\n# Coëfficiënten opvragen\ntidy(neth_model2, conf.int = TRUE)\n\n#Opvragen model fit statistieken via broom::glance()\nglance(neth_model2)\n\n```\n\nDe coëfficiënt voor `dem_lag` is 0.978. Dit is hoog, onze afhankelijke variabele heeft een bereik van 0 tot 1. De coëfficiënt toont dus dat er sterke stabiliteit is tussen democratiescores in opeenvolgende jaren. [^errors-9] We vinden dan ook dat de R^2^ statistieken dichtbij hun maxima van 1 zitten: toevoeging van de lagged dependent variable verklaart bijna alle variatie in democratiescore.\n\n[^errors-9]: De bivariate pearson correlatie tussen de twee variabelen is 0.99. Democratiescores in Nederland blijven erg stabiel van jaar tot jaar.\n\nDe coëfficiënt voor `e_gdp` toont de associate tussen BBP en democratiescores gecontroleerd voor democratiescore in het voorgaande jaar. Dit vertelt ons eigenlijk of BBP gerelataard is aan *verandering in democratiescore* van jaar tot jaar. De coëfficiënt is positief, maar niet langer significant.\n\nHebben we daarmee het probleem van autocorrelatie opgelost? We gaan het na:\n\n```{r}\ncar::durbinWatsonTest(neth_model2) \n```\n\nAutocorrelatie bedraagt nu slechts 0.29, wat veel lager is dan de 0.97 in het voorgaande model. De D-W statistiek bevindt zich nu tussen 1 en 3. Er is nog autocorrelatie (zie de ook de p-waarde), maar we hebben al veel in rekening gebracht.\n\nVoorgaand voorbeeld was gericht op 1 land, namelijk Nederland. In het geval we meerdere landen hebben kunnen we ook de `lag` functie gebruiken, maar er zal wel een probleem optreden waar we ons van bewust moeten zijn. We tonen eerst wat het probleem is en bieden dan een oplossing:\n\n```{r}\nserial_data |> \n  mutate(dem_lag = lag(v2x_polyarchy)) |> \n  slice(225:235) # <1>\n```\n\n1.  Deze syntax vraagt R om de data te 'snijden' en data te tonen voor rij 225 tot en met 235.\n\nWe tonen hier de transitie in de dataset van Mexico naar Suriname. In rij 7 bevind zich de data voor Mexico voor het laats beschikbare jaar 2019. Dan springt de dataset naar het eerste jaar voor Suriname, namelijk 1960. Als we kijken naar de `dem_lag` variabele zien we dat Suriname in 1960 de democratiescore van Mexico in 2019 heeft meegekregen. Dat mag natuurlijk niet. Zonder correctie doet R dit voor alle punten in de dataset waar we van 1 land naar een ander land gaan.\n\nWe vermijden dit door de `group_by()` functie te gebruiken:\n\n```{r}\nserial_data <- serial_data |> \n  group_by(country_name) |> \n  mutate(dem_lag = lag(v2x_polyarchy)) |> \n  ungroup() \n```\n\n`group_by(country_name)`\n\n:   De `group_by()` functie vraagt R om de dataset eerst te groeperen volgens de variabele tussen haakjes (hier: country_name). Daarna pas wordt de `lag`functie, via `mutate()`, toegepast. Wat er precies gebeurt kun je zien met deze gif van [Andrew Heiss](https://www.andrewheiss.com/blog/2024/04/04/group_by-summarize-ungroup-animations/){target=\"_blank\"} [-@heiss2024]:\n\n{{< video figures/grp-mutate.mp4 >}}\n\n`ungroup()`\n\n:   Deze functie is nodig om `mutate` te vertellen dat we niet langer willen groeperen voor toekomstige toepassingen van de functie. Anders blijft `mutate` verdere bewerkingen per groep uitvoeren.\n\nLaten we bekijken wat er gebeurt is\n\n```{r}\nserial_data |> \n  slice(225:235)\n\n```\n\nWe zien nu een NA waarde in rij 8, het eerste beschikbare jaar voor Suriname. Dit is wat we willen.\n\nWe zouden nu de regressie opnieuw kunnen uitvoeren. Onze dataset heeft nu echter niet alleen een time series element, maar bevat ook geclusterde data want meerdere landen zijn opgenomen. We zullen de lagged dependent variable-techniek dus moeten combineren met bovenstaande technieken voor clustering (fixed effects en geclusterde standaardfouten).\n\n## Omgaan met niet-normaal verdeelde residuals\n\n### Wat was het probleem ook al weer?\n\nDe laatste assumptie die we hier bekijken stelt dat de errors/residuals/fouten in een OLS model normaal verdeeld zijn. Of aan deze assumptie voldaan is kunnen we nagaan met plots gemaakt via `resid_panel()`: een histogram van de residuals en een Q-Q plot van de residuals.\n\n```{r}\n# Model schatten\nnorm_model <- lm(v2x_polyarchy ~ gini_disp + pr_fct + region1, data = normal_residual_data)\n\n# Coëfficiënten opvragen\ntidy(norm_model, conf.int = TRUE)\n\n# Assumptie checken\nresid_panel(norm_model, plots = c(\"hist\", \"qq\"))\n```\n\nBeide grafieken leiden tot dezelfde vaststelling: de assumptie is geschonden (zie @sec-ols-assumptions). Met een relatief grote steekproef is een schending van deze assumptie doorgaans geen probleem. In kleine steekproeven kan dit wel problematisch zijn. Hier zien we met de `glance()` functie uit het `broom` package dat we met een kleine steekproef te maken hebben:\n\n```{r}\nglance(norm_model)$nobs\n```\n\nWe hebben 77 observaties in het model. Is dit klein of groot genoeg? Jammergenoeg bestaat hier geen eenduidig antwoord voor. Een vuistregel is dat we met een kleine steekproef te maken hebben bij minder dan 15 observaties per onafhankelijke variabele. Hier hebben we 5 predictors. We vinden dan dat we met 77 observaties net 2 meer hebben dan de vuistregel voorschrijft (5 \\* 15 = 75). Dit is echter dicht bij de grens, dus misschien is het toch veiliger om rekening te houden met een assumptieschending.\n\n### Mogelijke oplossing: bootstrapping\n\nOok voor een schending van deze assumptie (met een kleine steekproef) moeten we de standaardfouten herberekenen. We gebruiken in dit geval weer een andere herberekening dan hierboven, namelijk 'gebootstrapte' standaardfouten. Met bootstrapping worden standaardfouten herschat met de volgende procedure:\n\nWe nemen een steekproef van de oorspronkelijke steekproef met dezelfde grootte. Dit gebeurt met teruglegging van de observaties, dat wil zeggen 1 observatie kan meerdere malen opgenomen worden in de nieuwe steekproef. Dat moet natuurlijk, anders kom je gewoon telkens dezelfde steekproef uit. Op basis van de nieuwe steekproef schatten we coëfficiënt en standaardfout opnieuw en slagen de resultaten op. Dit doen we een aantal keren. Ten slotte kijken we naar alle verschillende coëfficiënten die we uitgekomen zijn en in het bijzonder naar de standaardafwijking van de verzameling coëfficiënten. Deze standaardafwijking wordt de 'gebootstrapte'standaardfout.\n\nOok deze standaardfout kunnen we bekomen met de `vcov=` optie in de `modelsummary()` syntax. Wat nieuw is hier is dat we een element van toeval toevoegen in de berekening: R gaat 'random' nieuwe steekproeven trekken. Op zich is dit goed -moeten wij het niet doen!- maar juist door dit toevalselement kan de uitkomst telkens licht anders zijn. Om resultaten reproduceerbaar te houden zetten we hier dan ook een 'seed': een seed is een zelfgekozen startgeval (je kan 1 gebruiken maar ook je verjaardag enz.). Met de seed houdt R bij welke steekproeven precies getrokken werden en worden telkens dezelfde resultaten bereikt. Voor je je seed vastlegt wil je wel eerst nagaan of je met hetzelfde aantal steekproeven sterk verschillende resultaten uitkomt, want in dat geval vraag je R best meer steekproeven te trekken voor betere schattingen, zie onder).\n\n```{r}\n# seed vastleggen\nset.seed(1)\n\n# Model schatten \nmodelsummary(norm_model, \n             stars = T, \n             vcov = \"bootstrap\", \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n```\n\n`set.seed(1)`\n\n:   We zetten het toevallig trekken van steekproeven hier vast met een zelfgekozen getal zodat resultaten dezelfde blijven.\n\n`vcov = \"boostrap\"`\n\n:   Deze optie vraagt om de 'gebootstrapte' standaarfouten.\n\nWe kunnen de standaardfouten vergelijken:\n\n```{r}\n# Seed: zelfde als hierboven want dan krijgen we zelfde resultaten\nset.seed(1)\n\n# Modellen vergelijken\nmodelsummary(norm_model, \n             stars = T, \n             vcov = c(\"classical\", \"bootstrap\"),\n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n```\n\nWat merken we op:\n\n-   De coëfficiënten veranderen niet, enkel de standaardfouten. Dat zagen we ook bij heteroskedasticiteit-robuuste standaardfouten en geclusterde standaardfouten\n-   De standaardfouten zijn verschillend. Doorgaans, maar niet altijd, zijn gebootstrapte standaardfouten groter.\n-   Conclusies over de significantie van resultaten blijven hier dezelfde, hoewel we zien dat het significantieniveau voor de coëfficiënt van `region1Europe` veranderd is van p \\< 0.01 naar p \\< 0.05. De gevolgen kunnen veel groter zijn in andere analyses.\n\nZoals gezegd neemt R zelf nieuwe toevalssteekproeven. Standaard worden 250 steekproeven genomen. Zoals eerder gezegd zet je een 'seed' om resultaten gelijk te houden, maar natuurlijk is het niet echt betrouwbaar als resultaten bij elke trekking sterk veranderen. Vooraleer te beslissen om je seed vast te leggen, wil je nagaan of resultaten sterk verschillen zonder seed. Als dit het geval is, wil je R vragen meer steekproeven te trekken om betere schattingen te maken van de standaardfouten. Dit doen we in onderstaande syntax door R om 1000 steekproeven te vragen. We zetten een seed in de syntax, maar ga ervanuit dat we eerst goed gekeken hebben naar verschillende uitkomsten vooraleer een seed te zetten.\n\n```{r}\nset.seed(1) \n\nmodelsummary(norm_model, \n             stars = T, \n             vcov = \"bootstrap\", \n             R = 1000, \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n```\n\n`R = 1000`\n\n:   Deze optie laat toe het aantal steekproeven dat R trekt aan te passen. Hier vragen we er 1000.\n\nOnze resultaten hier zijn gelijkaardig, maar niet identiek aan deze gevonden bij 250 steekproeven. Het heeft echter geen gevolgen voor de algemene conclusies over significantie.\n\nBootstrapping kan ook gebruikt worden binnen het `marginaleffects` package, bv. wanneer we voorspelde waarden en betrouwbaarheidsintervallen nodig hebben. De functie om bootstrapping te gebruiken (`inferences()`) is echter nog steeds in ontwikkeling en je moet er ook bijkomende packages voor installeren. Indien je dit nodig zou hebben, bekijk dan het [\"Bootstrap\"](https://marginaleffects.com/bonus/bootstrap.html) hoofdstuk op de `marginaleffects` website.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"errors.html"},"language":{"toc-title-document":"Inhoudsopgave","toc-title-website":"Op deze pagina","related-formats-title":"Andere formaten","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Bron","other-links-title":"Andere Links","code-links-title":"Code Links","launch-dev-container-title":"Dev Container starten","launch-binder-title":"Binder starten","article-notebook-label":"Artikel Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Broncode downloaden","notebook-preview-back":"Terug naar Artikel","manuscript-meca-bundle":"MECA Archief","section-title-abstract":"Samenvatting","section-title-appendices":"Bijlagen","section-title-footnotes":"Voetnoten","section-title-references":"Referenties","section-title-reuse":"Hergebruik","section-title-copyright":"Auteursrechten","section-title-citation":"Citaat","appendix-attribution-cite-as":"Citeer dit werk als:","appendix-attribution-bibtex":"BibTeX citaat:","appendix-view-license":"Licentie Bekijken","title-block-author-single":"Auteur","title-block-author-plural":"Auteurs","title-block-affiliation-single":"Affiliatie","title-block-affiliation-plural":"Affiliaties","title-block-published":"Publicatiedatum","title-block-modified":"Gewijzigd","title-block-keywords":"Trefwoorden","callout-tip-title":"Tip","callout-note-title":"Opmerking","callout-warning-title":"Waarschuwing","callout-important-title":"Belangrijk","callout-caution-title":"Opgelet","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Alle code tonen","code-tools-hide-all-code":"Alle code verbergen","code-tools-view-source":"Broncode bekijken","code-tools-source-code":"Broncode","tools-share":"Share","tools-download":"Download","code-line":"Regel","code-lines":"Regels","copy-button-tooltip":"Kopieer naar klembord","copy-button-tooltip-success":"Gekopieerd!","repo-action-links-edit":"Pagina bewerken","repo-action-links-source":"Broncode bekijken","repo-action-links-issue":"Een probleem melden","back-to-top":"Terug naar boven","search-no-results-text":"Geen resultaten","search-matching-documents-text":"Gevonden documenten","search-copy-link-title":"Kopieer link om te zoeken","search-hide-matches-text":"Extra overeenkomsten verbergen","search-more-match-text":"meer overeenkomst in dit document","search-more-matches-text":"meer overeenkomsten in dit document","search-clear-button-title":"Wissen","search-text-placeholder":"","search-detached-cancel-button-title":"Annuleren","search-submit-button-title":"Verzenden","search-label":"Zoeken","toggle-section":"Schakel sectie","toggle-sidebar":"Schakel zijbalknavigatie","toggle-dark-mode":"Schakel donkere modus","toggle-reader-mode":"Schakel leesmodus","toggle-navigation":"Schakel navigatie","crossref-fig-title":"Figuur","crossref-tbl-title":"Tabel","crossref-lst-title":"Listing","crossref-thm-title":"Stelling","crossref-lem-title":"Lemma","crossref-cor-title":"Conclusie","crossref-prp-title":"Voorstel","crossref-cnj-title":"Aanname","crossref-def-title":"Definitie","crossref-exm-title":"Voorbeeld","crossref-exr-title":"Oefening","crossref-ch-prefix":"Hoofdstuk","crossref-apx-prefix":"Bijlage","crossref-sec-prefix":"Paragraaf","crossref-eq-prefix":"Vergelijking","crossref-lof-title":"Lijst van figuren","crossref-lot-title":"Lijst van tabellen","crossref-lol-title":"Lijst van listings","environment-proof-title":"Bewijs","environment-remark-title":"Opmerking","environment-solution-title":"Oplossing","listing-page-order-by":"Sorteer op","listing-page-order-by-default":"Standaard","listing-page-order-by-date-asc":"Oudste","listing-page-order-by-date-desc":"Nieuwste","listing-page-order-by-number-desc":"Aflopend","listing-page-order-by-number-asc":"Oplopend","listing-page-field-date":"Datum","listing-page-field-title":"Titel","listing-page-field-description":"Beschrijving","listing-page-field-author":"Auteur","listing-page-field-filename":"Bestandsnaam","listing-page-field-filemodified":"Gewijzigd","listing-page-field-subtitle":"Subtitel","listing-page-field-readingtime":"Leestijd","listing-page-field-wordcount":"Woordentelling","listing-page-field-categories":"Categorieën","listing-page-minutes-compact":"{0} min","listing-page-category-all":"Alle","listing-page-no-matches":"Geen overeenkomsten","listing-page-words":"{0} woorden","listing-page-filter":"Filter","draft":"Ontwerp"},"metadata":{"lang":"nl","fig-responsive":true,"quarto-version":"1.5.57","bibliography":["references.bib"],"editor":"visual","theme":{"light":"cosmo","dark":"darkly"},"code-annotations":"hover","citation-location":"margin"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}