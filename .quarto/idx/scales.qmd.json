{"title":"Indexen en schalen","markdown":{"yaml":{"code-annotations":"hover","bibliography":"references.bib","execution":{"error":true}},"headingText":"Indexen en schalen","headingAttr":{"id":"sec-scales","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n\n\n```{r}\n#| message: false\n#| warning: false\n#| echo: false\n\n#Packages\nlibrary(patchwork)\nlibrary(kableExtra) \nlibrary(rio)            \nlibrary(tidyverse)      \nlibrary(broom) \nlibrary(performance)\nlibrary(modelsummary)\n\n# Datasets used in examples below\nscale_data <- import(\"./data/scale_data.rda\")\nhdi_data <- import(\"./data/hdi_data.csv\")\n```\n\n```{r}\n#| eval: false\n\n#Packages\nlibrary(patchwork)    # Grafieken combineren\nlibrary(kableExtra)   # html tabel maken\nlibrary(rio)          # data import\nlibrary(tidyverse)    # Datamanagement enplotten    \nlibrary(broom)        # coëfficiënten\nlibrary(performance)  # Model en schaal statistieken\nlibrary(modelsummary) # Descriptieve statistiektabellen\n\n# Gebruikte datasets\nscale_data <- import(\"scale_data.rda\")\nhdi_data <- import(\"hdi_data.csv\")\n```\n\n::: {.callout-note title=\"Voor wie is deze appendix?\"}\nJe hoeft niet te weten hoe je deze analyses moet uitvoeren voor de opdrachten in Statistiek II. Deze gids is bedoeld voor studenten die hun eindpaper schrijven voor Academische Vaardigheden: Kwantitatieve Data-Analyse of een BAP-scriptieproject.\n:::\n\nSoms kan het nuttig zijn om variabelen te combineren tot een enkele variabele of schaal, zowel voor afhankelijke als onafhankelijke variabelen. Stel dat we 'populistische attitudes' willen meten, dan kunnen we denken aan een combinatie van anti-elitaire attitudes, het geloof dat de publieke wil het beleid moet sturen en het hebben van een manicheïsch wereldbeeld (i.e. de wereld in termen van goed en kwaad zien).[^scales-1]\n\n[^scales-1]: Zie @castanhosilva2020 voor een bespreking van verschillende populismeschalen.\n\nEen onderzoeksvraag vergt soms dat we meerdere elementen (variabelen) combineren tot 1 variabele of schaal. Het is vaak ook betrouwbaarder om met meerdere vragen eenzelfde concept te meten dan slechts met 1 vraag. Op het statistiektentamen stellen we ook niet 1 maar meerdere vragen om een betrouwbare test te hebben van hoe goed studenten de leerstof kennen. Ten slotte kunnen we door het combineren van meerdere variabelen tot slechts 1 variabele statistische modellen vereenvoudigen (bv. door niet 10 maar 5 onafhankelijke variabelen toe te voegen: 4 + een index van de andere predictors). Dit samenvoegen is ook handig als predictors sterk gecorreleerd zijn en een model onderhevig zou zijn aan sterke multicollineariteit indien onafhankelijke variabelen samen worden toegevoegd.\n\nDeze appendix bekijkt hoe we op basis van meerdere variabelen slechts 1 variabele of index/schaal kunnen creëeren. Eerst bespreken we algemene principes die een leidraad vormen bij beslissingen over het maken van een schaal. Dan tonen we hoe de *betrouwbaarheid* van een schaal nagegaan kan worden en hoe we een nieuwe schaal kunnen maken op basis van de som of het gemiddelde van bestaande variabelen. In een tweede uitgewerkt voorbeeld bespreken we wat te doen als de variabelen waarmee je een schaal wil maken gemeten zijn op verschillende manieren.\n\n## Algemene principes\n\nDe R code die we in de volgende secties tonen kan gebruikt worden om verschillende soorten indexen/schalen te maken op basis van bestaande variabelen. Het spreekt echter voor zich dat het niet de bedoeling is lukraak wat variabelen bij elkaar te gooien. De beslissing welke variabelen samen te voegen en met welk doel moet gemotiveerd zijn. welke principes daarbij in gedachten moeten worden gehouden bespreken we hier. [^scales-2]\n\n[^scales-2]: Zie bijvoorbeeld @adcock2001 voor een meer uitgebreide discussie van de principes uitgelegd hier.\n\nConceptualisatie vormt een natuurlijk beginpunt voor het nadenken over schalen. We willen vaak concepten zoals 'democratie', 'populisme', of 'ideologie' empirisch bestuderen, maar deze concepten kennen verschillende facetten of sub-componenten die je niet altijd met 1 vraag kunt meten. Soms gebeurt dit wel, denk bijvoorbeeld aan de gekende vraag over links-rechtspositie, maar ook hier kunnen we ons kritisch de vraag stellen of we hiermee echt een complex concept als 'ideologie' meten. Moeten we niet zowel economisch als sociaal-cultureel links-rechts meten bijvoorbeeld?\n\nDe vraag die we ons dan stellen is hoe we deze concepten best kunnen meten en of we dat met 1 of meerdere variabelen moeten doen. Bestaande studies helpen hierbij. Het V-Dem project meet bijvoorbeeld democratie (`v2x_polyarchy`) niet met 1 vraag gesteld aan experten ('hoe democratisch is...?') maar met verschillende vragen over bijvoorbeeld hoe vrij en eerlijk verkiezingen zijn, hoe transparant de overheid is enz. Antwoorden op verschillende vragen worden gecombineerd tot 1 getal voor democratie. In een survey vragen we doorgaans niet aan mensen hoe 'populistisch' ze zijn. Dit woord wordt meer gebruikt door wetenschappers dan gewone burgers. We kunnen wel vragen of ze akkoord of niet akkoord gaan met stellingen zoals 'politici zijn geschikter om beleid te vormen dan gewone burgers' en 'politici zijn uit op eigenbelang' en dan een schaal maken op basis van de antwoorden op deze stellingen.\n\nEen *valide* meting is een meting waarbij de vraag, of de combinatie van vragen in dit geval, gebruikt om het concept te meten alle belangrijke aspecten van het concept bevat. Een meting van democratie zonder een element over vrije en eerlijke verkiezingen zou best vreemd zijn bijvoorbeeld. We willen geen belangrijke dingen vergeten. Aan de andere kant willen we niet te veel elementen opnemen en ons concept niet uitrekken. Een meting van democratie bevat dan meestal ook geen indicatoren over welvaart in de samenleving. Voor validiteit moeten we goed nadenken over wat er nu bij ons concept hoort en wat eigenlijk iets anders is.\n\nEen meting moet ook *betrouwbaar* zijn: als we de meting opnieuw zouden doen, willen we gelijke of sterk gelijke resultaten. Je wil ook geen weegschaal die je telkens een ander cijfer geeft als je er 3 keer na elkaar gaat opstaan. Voor betrouwbare schalen kunnen we ons vaak beroepen op eerder onderzoek: wat hebben andere onderzoekers gebruikt en met welke resultaten? We kunnen ook echter kijken naar de correlatie tussen verschillende variabelen waarvan we denken dat ze een schaal kunnen vormen om 1 concept te meten. Als de sub-variabelen sterk gecorreleerd zijn, hebben we reden om aan te nemen dat ze verschillende aspecten van eenzelfde concept meten.\n\n## Voorbeeld 1: Emoties en campagne voeren\n\n### Data\n\nWaarom doen burgers mee aan verkiezingscampagnes (bv. door de straat op te gaan om mensen aan te spreken of door geld te doneren)? Sommige onderzoekers leggen dit vooral uit door te verwijzen naar mensen hun vaardigheden en welvaart: hebben ze tijd voor vrijwilligerswerk, geld om te doneren, de politieke kennis om mensen te mobiliseren enz.? Maar mensen moeten ook overtuigd zijn dat campagne voeren nuttig en juist is om te doen. Ze moeten met andere woorden gemotiveerd zijn. recent onderzoek wijst uit dat *emoties* een belangrijke rol kunnen spelen om mensen tot actie aan te zetten. [^scales-3] We onderzoeken dit idee op basis van een subset van de 2024 American National Election Studies (ANES) en tonen aan hoe we schalen maken in R.\n\n[^scales-3]: Zie @Brady1995 over de rol van vaardigheden en welvaart in politieke participatie en @Valentino2011 over de rol van emoties. Hier richten we ons op de positieve rol van emoties op participatie, maar deze kunnen ook negatieve effecten hebben, zie bijvoorbeeld de studie van @Young2019 in Zimbabwe.\n\nANES is gebaseerd op een toevalssteekproef van volwassen Amerikaanse burgers, die ondervraagd worden zowel voor (pre-election) als na (post-election) de nationale verkiezingen. In 2024 werd respondenten gevraagd of zij verschillende soorten campagneactiviteiten hadden ondernomen:\n\n-   \"Heb je mensen gesproken om hen te overtuigen te stemmen voor of tegen bepaalde kandidaten of partijen?\" (`persuade`)\n-   \"Heb je online deelgenomen aan politieke bijeenkomsten, speeches, geldinzamelingsacties of gelijkaardige zaken om een bepaalde kandidaat te steunen?\" (`online_meetings`)\n-   \"Heb je fysiek deelgenomen aan politieke bijeenkomsten, speeches, geldinzamelingsacties of gelijkaardige zaken om een bepaalde kandidaat te steunen?\" (`rallies`)\n-   \"Toonde je een politiek symbool tijdens de campagne zoals een button, kledingstuk, sticker op de wagen, affiche aan huis?\" (`campaign_button`)\n-   \"Deed je ander werk voor een kandidaat of partij?\" (`other_work`)\n-   \"Heb je geld gedoneerd aan een partij dit verkiezingsjaar?\" (`contribute_money_party`)\n-   \"Heb je geld gedoneerd aan een groep voor of tegen bepaalde kandidaten?\" (`contribute_money_group`)\n\nRespondenten konden met 'ja (code = 1)' of 'nee (code =0)' antwoorden.\n\nWe bekijken eerst de descriptieve statistieken voor we meer ingewikkelde dingen proberen. We maken gebruik van de `psych::describe()` functie. De \"mean\" kolom geeft de proportie weer van respondenten die een bepaalde activiteit hebben ondernomen.\n\n```{r}\nscale_data |> \n  select(persuade:contribute_money_group) |> # <1>\n  psych::describe()  |> # <2>\n  select(vars:mean, min, max) # <3>\n```\n\n1.  We selecteren de variabelen waarvoor we statistieken willen. De campagnevariabelen bevinden zich naast elkaar in de data. We schrijven de eerste en de laatste met een dubbelpunt ertussen om ze allemaal te selecteren.\n2.  Door `psych::` als prefix te gebruiken hoeven we het package hier niet eerst te laden. Sommige functies van dit package conflicteren namelijk met die van `tidyverse`.\n3.  We gebruiken de `select()` functie om slechts relevante kolommen weer te geven. Voor binaire variabelen zijn zaken zoals skew en kurtosis niet veelzeggend.\n\nOngeveer 40% van de respondenten heeft anderen proberen overtuigen. Andere activiteiten zijn minder frequent gebruikt. De verschillende vragen of 'items' (sub-componenten van een schaal) zullen we gebruiken voor de afhankelijke variabele.\n\nANES vroeg respondenten ook naar hun emoties voorgaand aan de verkiezingen met de vraag: Hoe \\[specifieke emotie\\] voel je je over hoe de zaken momenteel gaan in het land? De volgende emoties werden bevraagd:\n\n-   hoopvol (`hopeful`)\n-   angstig (`afraid`)\n-   woedend (`outraged`)\n-   boos (`angry`)\n-   gelukkig (`happy`)\n-   bezorgd (`worried`)\n-   trots (`proud`)\n-   geïrriteerd (`irritated`)\n-   nerveus (`nervous`)\n\nRespondenten konden antwoorden op een 5-punten schaal: not at all (=1), a little (=2), somewhat (=3), very (=4), en extremely (=5). Ook hier bekijken we de beschrijvende statistieken eerst:\n\n```{r}\nscale_data |> \n  select(hopeful:nervous) |> \n  psych::describe() |> \n  select(vars, n, mean, sd, median, min, max, skew, kurtosis)\n```\n\nWe zien dat respondenten over het algemeen niet zo positief zijn: gemiddelden voor negatieve gevoelens liggen hoger dan die voor positieve gevoelens. Maar er is sterke variatie in de variabelen.\n\nWe willen nu de relatie nagaan tussen emoties en campagne voeren. Voor zowel de 'onafhankelijke' (emoties) als de 'afhankelijke' (campagne) variabelen hebben we meerdere aparte variabelen in de dataset. Hoe gaan we te werk?\n\nWe zouden verschillende (logistische) modellen kunnen schatten per campagne-item en telkens alle emotievariabelen toevoegen als predictors. Dit kan een goede aanpak zijn als we willen weten of welbepaalde emoties een andere invloed hebben op welbepaalde activiteiten ten opzichte van andere. Als we geïnteresseerd zijn in de algemene relatie tussen emoties en campagne voeren, maken we indexen of schalen.\n\nOnze emoties verschillen, maar toch kunnen we ook hier een schaal maken als we ervanuit gaan dat positieve en negatieve emoties samen voorkomen (i.e. correleren). We gaan dit eerst na:\n\n```{r}\n#| tbl-cap: \"Correlaties tussen emoties\"\n#| label: tbl-emotion-corr\n\nscale_data |> \n  select(hopeful:nervous) |>  # <1>\n  rename_with(str_to_title) |> # <2>\n  datasummary_correlation() # <3>\n\n```\n\n1.  We selecteren de variabelen waarvoor we correlaties willen berekenen.\n2.  De `str_to_title()` functie komt uit het `stringr` package (deel van `tidyverse`). we gebruiken het om de kolomnamen te laten beginnen met een hoofdletter in plaats van een kleine letter, dan moeten we niet individueel de variabelen hernoemen (Zie [deze](https://stackoverflow.com/questions/13258020/change-letter-case-of-column-names){target=\"_blank\"} StackOverflow thread.\n3.  Deze functie uit het `modelsummary` package maakt een correlatietabel. Zie @sec-reporting-and-presenting-results voor verdere informatie.\n\n@tbl-emotion-corr toont dat positieve emoties positief correleren, dat negatieve emoties positief correleren en dat positieve en negative emoties negatief correleren. Dit lijkt erop te wijzen dat we indexen voor 'positieve' en 'negatieve' emoties zouden kunnen maken, ook om multicollineariteit tegen te gaan.\n\n### Betrouwbaarheid van schalen\n\nDe concepten van 'emoties' en 'campagne voeren' lijken valide en de belangrijkste componenten te bevatten van deze zaken in het echte leven (we kunnen hier natuurlijk verder over reflecteren in de conclusie van onze paper). De positieve en negatieve indexen van emoties hierboven gesuggereerd worden ook ondersteund in de literatuur. Eerder onderzoek over \"affective intelligence theory\" stelt immers dat menselijk gedrag aangestuurd wordt door twee emotionele systemen. De items staan eigenlijk ook in ANES om dit te testen [^scales-4]\n\n[^scales-4]: Zie @Marcus1993 voor een baanbrekende studie hierover en meer recent werk van @Valentino2011 en @Vasiopoulos2019.\n\nMaar we moeten ook naar betrouwbaarheid kijken: zou een index van positieve emoties intern betrouwbaar zijn? Meten onze verschillende emoties voldoende hetzelfde 'positieve' aspect. De correlaties hierboven (zie @tbl-emotion-corr) lijken te zeggen van ja, maar er bestaan ook betere statistische methoden die helpen de vraag te beantwoorden of de correlatie sterk genoeg is.\n\nWe gebruiken de Cronbach's alpha ($\\alpha$), gebaseerd op de gemiddelde covariantie van de onderliggende variabelen in de schaal.[^scales-5] De $\\alpha$ maatstaf heeft een bereik van 0 tot 1. Hogere waarden duiden op hogere betrouwbaarheid. De volgende vuistregels gelden:\n\n[^scales-5]: De formule is: $\\alpha = \\frac{k\\bar{c}}{\\bar{v} + (k - 1)\\bar{c}}$. $k$ = aantal items. $\\bar{v}$ = gemiddelde variantie van de items. $\\bar{c}$ = gemiddelde covariantie van de items.\n\n-   $\\geq$ 0.90: Excellente betrouwbaarheid\n-   0.80-0.89: Goede betrouwbaarheid\n-   0.70-0.79: Aanvaardbare betrouwbaarheid\n-   0.60-0.69: Twijfelachtige betrouwbaarheid\n-   \\< 0.60: Slechte betrouwbaarheid\n\nDoorgaans gebruiken we geen index met een $\\alpha$ onder 0.6. Bij binaire variabelen kan de betrouwbaarheid echter onderschat worden omdat de $\\alpha$ test eigenlijk continue variabelen verwacht. Er bestaan andere methoden voor binaire data maar deze vallen buiten het materiaal van dit handboek.\n\nWe kunnen de $\\alpha$ berekenen met de `cronbachs_alpha()` functie uit het `performance` package.\n\n```{r}\n# Campagne index\nscale_data |> \n  select(persuade:contribute_money_group) |> \n  cronbachs_alpha() \n\n# Positieve emoties\nscale_data |> \n  select(hopeful, happy, proud) |> \n  cronbachs_alpha()\n  \n# Negatieve Emoties\nscale_data |> \n  select(afraid, outraged, angry, worried, irritated, nervous) |> \n  cronbachs_alpha()\n\n```\n\nDe $\\alpha$ scores voor de emotieschalen zijn 0.84 en 0.93 respectievelijk en dus sterk betrouwbaar. De betrouwbaarheid voor negatieve emoties is vooral hoger omdat er meerdere items gebruikt zijn. De $\\alpha$ score voor campagne voeren is lager: 0.63. Gezien de scores doorgaans lager zijn bij binaire variabelen maken we de beslissing om toch met de index door te gaan.\n\n### Som of gemiddelde?\n\nWe zullen 3 indexen maken: 1 voor campagne en 2 voor emoties. We moeten een keuze maken tussen variabelen optellen of het gemiddelde nemen. De keuze ligt aan de onderzoeker, maar er zijn wel wat richtlijnen. Bij campagne kijken we naar verschillende activiteiten. Hier houdt het steek om te meten hoeveel verschillende activiteiten iemand heeft gedaan eerder dan of die persoon gemiddeld een activiteit heeft gedaan. Optellen dus. Bij emoties lijkt de originele schaal van 1 tot 5 nuttig: voelt iemand zich helemaal niet of juist sterk zo? Een nieuwe somschaal op 30 (bv. voor negatieve emoties hier) heeft weinig intuïtieve betekenis. Hier nemen we dus het gemiddelde.\n\nWe moeten ook rekening houden met ontbrekende waarden. Als we R vragen om een som of gemiddelde te berekenen moeten we zeggen hoe met missing data om te gaan via `na.rm = TRUE` of `na.rm = FALSE`. Bij `na.rm =TRUE` worden missing waarden (NA) weggelaten bij de berekening. Dit is de correcte manier, anders krijgen we 'NA' voor de som/het gemiddelde. Zie het verschil hieronder.\n\n```{r}\n# voorbeelddata\nx <- c(5, 1, 2, NA, 5)\n\n# gemiddelde berekenen\nmean(x, na.rm = TRUE)\nmean(x, na.rm = FALSE)\n```\n\nAls we een index van gemiddelden maken voor 5 items, en 1 (of meerdere) zijn missing, dan wordt het gemiddelde berekend voor de overige 4 (of minder) waarden. Dit is doorgaans prima.\n\nWat als we een som nemen? We moeten opnieuw `na.rm = TRUE` gebruiken. Nu geeft de functie een score van 0 voor alle NA waarden bij de optelling. Dit kan soms vreemde gevolgen hebben. Een observatie met enkel missing waarden voor de items zal opeens een 0 krijgen als eindscore en geen NA. Zie onderstaand voorbeeld:\n\n```{r}\n# voorbeelddata\ndata <- tibble(\n  x = c(NA, NA, NA, NA, NA), \n  y = c(0, 1, 0, 0, NA)\n)\n\n# Inspectie\ndata\n\n# Som maken\ndata |> \n  mutate(sum_x = sum(x, na.rm = T), \n         sum_y = sum(y, na.rm = T))\n```\n\nIn zekere zin gaan we voor X hier data 'verzinnen', wat problematisch kan zijn. We weten immers niet wat echt waar is voor deze observatie. In de ANES survey nam niet iedereen mee aan het gedeelte van de survey dat na de verkiezingen werd afgenomen en waarin de campagnevragen stonden. Voor al deze mensen zouden we dus 0 ingeven, hoewel ze geen respons hebben gegeven. we kunnen deze mensen wel uit de data filteren maar dan blijven er nog respondenten voor wie we geen waarden hebben en eigenlijk niet kunnen zeggen wat ze gedaan hebben.[^scales-6] Hieronder tonen we hoe dit aan te pakken.\n\n[^scales-6]: Respondenten kunnen weigeren of 'Don't know' antwoorden geven bijvoorbeeld. Deze antwoorden worden doorgaans op missing gezet.\n\nWe will show how to find these types of observations and how to deal with them below.\n\n### Schalen maken\n\nEigenlijk hebben we vooral nood aan 2 basisfuncties binnen R: `mean()` en `sum()`.[^scales-7] Voorgaand hebben we deze functies op 1 variabele tegelijk toegepast. Nu combineren we meerder variabelen (kolommen in de dataset) tot een gecombineerde variabele (kolom). Dit doen we met behulp van functies uit `tidyverse`: `rowwise()` en `c_across()`. Je kunt meer over deze functies leren via deze [vignette](https://dplyr.tidyverse.org/articles/rowwise.html){target=\"_blank\"}.\n\n[^scales-7]: Probeer een index niet manueel te maken (bv., `newvar = var1 + var2 + var3`). Dit werkt als er geen missing data is, maar dit is in de praktijk vaak niet het geval.\n\n#### Een index gebaseerd op een gemiddelde\n\nWe maken 2 indexen op basis van gemiddelden: eentje voor de positieve emoties en eentje voor de negatieve emoties.\n\n```{r}\nscale_data <- scale_data |> \n  rowwise() |> \n  mutate(\n    positive_emotions = mean(c(hopeful, happy, proud), na.rm = T), \n    negative_emotions = mean(c(afraid, outraged, angry, worried, \n                               irritated, nervous), na.rm =T)) |> \n  ungroup()\n\n```\n\nZo lees je de syntax:\n\n`scale_data |> rowwise() |>`\n\n:   de nieuwe functie hier is `rowwise()`. Zonder deze functie zou `mutate()` gewoon gemiddelden berekenen op basis van alle rijen in de dataset en deze gemiddelden toevoegen aan de dataset (iedereen zou dus dezelfde algemene waarden krijgen voor de variabelen). Met `rowwise()` vragen we R om gemiddelden per rij te berekenen zodat elke observatie zijn eigen gemiddelde score toegevoegd krijgt.\n\n`mutate(positive_emotions = mean(c(hopeful, happy, proud), na.rm = T), ...))`\n\n:   We vragen R om met `mutate()` nieuwe variabelen (kolommen) te maken. De eerste variabele noemen we `positive_emotions`, de tweede `negative_emotions`. Dit is de gemiddelde score voor de waarden van de variabelen aangegeven met `c(...)`. Het gedeelte `na.rm = T` vraagt R missing waarden te negeren bij de berekening.\n\n`ungroup()`\n\n:   We vragen R om de groepen (gemaakt met `rowwise()`) te vergeten zodat dit groeperen per rij niet gebruikt wordt in verdere syntax die gebruikmaakt van `mutate()`.\n\nWe kunnen de data bekijken:\n\n```{r}\nscale_data |> \n  select(hopeful:negative_emotions) |> \n  head() |> # <1> \n  kable(digits = 2) # <2>\n```\n\n1.  Automatisch selecteren van de eerste rijen van de data voor presentatie.\n2.  `kable()` wordt gebruikt voor het maken van tabellen in html files. Hier gebruiken we het om ervoor te zorgen dat alle kolommen zichtbaar zijn voor de lezer.\n\nDe eerste respondent was duidelijk ongelukkig met de toestand in de VS. Voor alle positieve emoties wordt de laagste score van 1 gegeven (het gemiddelde voor positieve emoties is dan ook 1). Voor de negatieve emoties werd telkens de maximale score van 5 gegeven (en 5 is dus ook het gemiddelde). Respondent 6 is zowat de tegenpool van respondent 1 terwijl andere respondenten zich meer in het midden bevinden.\n\nMet een Pearson correlatie kunnen we nagaan hoe de twee schalen zich tot elkaar verhouden:\n\n```{r}\ncor.test(scale_data$positive_emotions, \n         scale_data$negative_emotions, \n         method = \"pearson\")\n\n```\n\nDe schalen zijn negatief gecorreleerd met een gemiddeld sterke samenhang. Dit betekent dat respondenten ook ambivalent kunnen zijn en zowel positieve als negatieve gevoelens ervaren.\n\n#### Een index gebaseerd op een som\n\nHet proces voor een index gebaseerd op een som is gelijkaardig, behalve dat we moeten opletten met observaties die ontbrekende waarden hebben voor de variabelen die de schaal/index gaan vormen, zoals hierboven uitgelegd. Deze observaties mogen we niet meenemen in de berekening. We bekijken eerst of er missing waarden zijn over de cases heen:\n\n```{r}\nscale_data <- scale_data |> \n  rowwise() |> \n  mutate(engage_missing = sum(is.na(c(persuade, online_meetings, rallies, \n                                      campaign_button, other_work, \n                                      contribute_money_party, contribute_money_group)))) |> \n  ungroup()\n```\n\n`sum(is.na(c(persuade, ..., contribute_money_group))))`\n\n:   We gebruiken hier `rowwise()` gevolgd door `mutate()` zoals we hierboven al deden. Nu gebruiken we echter `sum()` om totalen te berekenen. We willen hier berekenen hoeveel van de observaties ontbrekende waarden hebben en voor hoeveel van de onderliggende variabelen. We maken dus ook gebruik van de `is.na()` functie. Deze functie transformeert achter de schermen de kolommen (variabelen) aangeduid met `c()` tot binaire variabelen waarbij 0 staat voor valide waarden en 1 voor ontbrekende waarden. Zo berekenen we hoeveel ontbrekende waarden een observatie heeft.\n\nLaten we eens kijken of er observaties zijn met ontbrekende waarden via de `table()` functie:\n\n```{r}\ntable(scale_data$engage_missing)\n```\n\nDe meeste observaties (4752) hebben geen enkele (0) ontbrekende waarde. Sommige respondenten (9) hebben er 1. Er is ook een respondent die voor alle 7 de variabelen een ontbrekende waarde geeft. Deze zouden we eruit kunnen filteren op de volgende manier:[^scales-8]\n\n[^scales-8]: We zouden hier ook de `complete.cases()` functie kunnen gebruiken zoals we dat doen om model fit statistieken over modellen heen te kunnen analyseren (zie @sec-linear-comparing-models). Daarmee zouden we ook observaties wegdoen die maar voor een of enkele variabelen een ontbrekende waarde hebben. Wat we nu doen is ervan uitgaan dat een ontbrekende waarde een probleem vormt als alles ontbreekt, maar dat we in een situatie met zowel valide als ontbrekende waarden mogen uitgaan van een '0' score voor de variabele waar een ontbrekende waarde wordt genoteerd. Dit kunnen we natuurlijk ter discussie stellen. Vaak moeten we een afweging maken over hoe we zoveel data als mogelijk kunnen gebruiken en hoe we zo accuraat mogelijk met de data kunnen omgaan. we zouden ook kunnen beslissen om observaties weg te doen die ontbrekende waarden hebben voor meer dan de helft van de variabelen enz.\n\n```{r}\nscale_data <- scale_data |> \n  filter(engage_missing < 7)  \n```\n\nNu kunnen we dan onze index maken. We gebruiken hiervoor de functie `c_across()`:\n\n```{r}\nscale_data <- scale_data |> \n  rowwise() |> \n  mutate(campaign_engagement = sum(c_across(persuade:contribute_money_group))) |> \n  ungroup()\n```\n\n`campaign_engagement = sum(c_across(persuade:contribute_money_group)))`\n\n:   Toen we het gemiddelde over een aantal variabelen heen wilden berekenen gebruikten we gewoon de functie `c()`. Dat werkt prima, maar kan omslachtig zijn als er veel variabelen zijn om uit te schrijven. Met `c_across` kunnen we de eerste variabele en de laatste schrijven met daartussen een dubbelpunt (`persuade:contribute_money_group`). Zo selecteert R ook alle tussenliggende variabelen. Deze functie is natuurlijk enkel nuttig als de relevante variabelen netjes bij elkaar staan in de dataset.\n\nLaten we een kijkje nemen naar de uiteindelijke index:\n\n```{r}\ntable(scale_data$campaign_engagement)\n```\n\nHet merendeel van de respondenten is niet betrokken bij campagneactiviteiten. Zij scoren 0 op de index. Een groot aantal respondenten doet 1 activiteit (1345). Hoe meer activiteiten, hoe minder respondenten. Slechts 11 respondenten hebben deelgenomen aan alle 7 de activiteiten.\n\n### Model schatten\n\nNu we al onze schalen gecreëerd hebben kunnen we een regressiemodel schatten. Hier gebruiken we een lineair model met positieve en negatieve emoties als onafhankelijke variabelen en campagne engagement als afhankelijke variabele:[^scales-9]\n\n[^scales-9]: OLS modellen zijn niet altijd geschikt voor variabelen waarbij een telling wordt gemaakt ('count data'). Meer toepasselijke modellen (poisson regressie en negative binomial modellen) vallen echter buiten dit handboek.\n\n```{r}\n# Model \nengagement_model <- lm(campaign_engagement ~ positive_emotions + negative_emotions, \n                       data = scale_data)\n\n# Coefficients\ntidy(engagement_model)\n```\n\nEr bestaat voor beide predictoren een positieve, significante relatie met de afhankelijke variabele. Zowel positieve als negatieve emoties zijn geassocieerd met politieke participatie.\n\n## Voorbeeld 2: verschillende meeteenheden\n\nDe schalen die we hierboven hebben gemaakt waren gebaseerd op variabelen die zelf op dezelfde schaal waren gemeten (binaire 0/1 variabelen voor campagneactiviteiten en emotiebelevenis op een schaal van 1 tot 5 voor de emotievariabelen). Het kan echter voorkomen dat we een index willen maken van variabelen die op verschillende schalen gemeten zijn. Dat vergt een enigszins andere aanpak.\n\n### Twee benaderingen: normaliseren en standaardiseren\n\nHet tweede voorbeeld richt zich op de Human Development Index (HDI). De [HDI](https://hdr.undp.org/data-center/human-development-index#/indicies/HDI){target=\"_blank\"} is \"a summary measure of average achievement in key dimensions of human development: a long and healthy life, being knowledgeable and having a decent standard of living\".\n\nDe HDI van landen wordt gemeten op basis van de volgende variabelen: levensverwachting in jaren, scholingsgraad (verwacht en gemiddeld aantal jaren onderwijs genoten), en de welvaart van een land gemeten met het natuurlijk logaritme van het BNI per capita. Deze figuur legt het berekeningsproces uit:\n\n![](figures/hdi_measurement.png){fig-alt=\"An image showing the main components of HDI: life expectancy, educational attainment, and gross national income.\"}\n\nIn dit voorbeeld gaan we zelf de HDI scores van landen berekenen op basis van onderliggende data afkomstig van de [Verenigde Naties](https://hdr.undp.org/data-center/documentation-and-downloads){target=\"_blank\"}. We richten ons op het jaar 2023.\n\nDe volgende variabelen worden gebruikt: levensverwachting bij geboorte in jaren (`life_expectancy`), het verwachte aantal jaren onderwijs genoten (`expected_schooling`), het gemiddelde aantal jaren onderwijs genoten (`mean_schooling`), en het gelogde BNI per capita (`gni_percap_logged`):[^scales-10]\n\n[^scales-10]: De VN nemen enkele datamanagement stappen vooraleer de HDI te berekenen. Deze hebben wij hier ook genomen. Voor landen met een levensverwachting groter dan 85 wordt de waarde vastgezet op een maximum van 85. Voor landen met een BNI onder 100 wordt de waarde vastgezet op 100 (vooraleer het natuurlijk logaritme wordt genomen). De redenen hiervoor staan uitgelegd [hier](https://hdr.undp.org/data-center/documentation-and-downloads){target=\"_blank\"}.\n\n```{r}\ndatasummary(life_expectancy + expected_schooling + mean_schooling + gni_percap_logged ~ \n              Mean + SD + Min + Max + N, data = hdi_data)\n\n```\n\nDe variabelen zijn duidelijk op verschillende schalen gemeten. Het bereik van levensverwachting loopt van 54 tot 85, terwijl dat van gemiddelde scholing loopt van 1.41 tot 14.30.\n\nEen index met een gemiddelde score over alle variabelen heen zou ons weinig leren. Eerst moeten de variabelen op eenzelfde schaal worden gezet. Hier bestaan twee manieren voor: normaliseren of standaardiseren.\n\nBij normaliseren herschalen we de variabelen zodat ze allemaal dezelfde minimum- en maximum waarden hebben. De onderstaande formule herschaalt de variabelen zodat ze een bereik van 0 tot 1 hebben. De score van 0 wordt geven aan observaties die de minimumwaarde hadden op de originele variabele. De score van 1 wordt gegeven voor de maximumwaarde op de originele variabele. Moesten we de variabele op een schaal van 0 tot 10 willen brengen, zouden we een vermenigvuldiging met 10 aan de formule kunnen toevoegen.\n\n$$\\text{(0-1) Normalized Variable} = \\frac{X_{i} - min(X)}{max(X) - min(X)}$$\n\nDe HDI maakt grotendeels gebruik van dergelijk normaliseringsproces. Echter worden voor de variabelen niet de minimum- en maximumwaarden in de data gebruikt om het bereik te bepalen, maar zelfgekozen waarden. Voor levensverwachting worden 20 en 85 als minimum en maximum aangeduid. Dit doen ze omdat het aansluit bij de realiteit: \"no country in the 20th century had a life expectancy at birth of less than 20 years\" and \"85 \\[is\\] a realistic aspirational target for many countries over the last 30 years.\" Voor BNI per capita wordt het minimum gezet op log(\\$100) en het maximum op log(\\$75000). Voor de onderwijsvariabelen is het iets makkelijker. De maxima worden vastgezet op 18 (expected schooling) en 15 (mean schooling) en dan worden de variabelen gedeeld door 18 en 15 respectievelijk om ze te normaliseren.\n\nWe blijven in dit voorbeeld trouw aan de VN aanpak en gebruiken manueel deze vastgezette waarden om te normaliseren. We tonen echter ook hoe je met de `rescale()` functie uit het `scales` package automatisch kunt normaliseren op basis van de minimum en maximumwaarden die je vindt in de data.\n\nNormalisatie zorgt ervoor dat alle variabelen hetzelfde bereik hebben en kan gebruikt worden voor interval/ratio, ordinale, en binaire variabelen. Normaliseren heeft echter geen impact op de variantie van variabelen. Gezien sommige variabelen een grotere variantie hebben dan anderen kan het zijn dat sommigen meer bijdragen tot de eindscore dan anderen. Een alternatief is om eerst de variabelen te standaardiseren:\n\n$$\\text{Standardized Variable} = \\frac{X_{i} - \\bar{X}}{\\text{Std. Dev}(X)}$$\n\nVoor elke observatie trekken we de gemiddelde score over de data heen af van de waarde voor de observatie. Dan delen we de uitkomst door de standaarddeviatie van de variabele. De nieuwe variabele heeft altijd een gemiddelde van 0, waarbij 0 staat voor de gemiddelde score op de oorspronkelijke variabele. Afwijkingen van 0 worden uitgedrukt in standaarddeviaties. De variatie van variabelen wordt hierbij gelijkgezet en zo dragen ze gelijk bij aan de uiteindelijke index. De interpretatie van de gestandaardiseerde variabele is wel anders. Een eenheid hoger op deze variabele betekent 1 standaarddeviatie hoger op de oorspronkelijke schaal. Een gestandaardiseerde variabele met een waarde hoger dan 0 betekent dat de waarde hoger ligt dan het gemiddelde op de oorspronkelijke schaal. Dit betekent echter niet noodzakelijk een 'hoge' waarde op de oorspronkelijke schaal gezien het gemiddelde zich niet noodzakelijk in het midden bevindt (cfr. verschil gemiddelde en mediaan). Standaardiseren is vooral nuttig bij interval/ratio variabelen.\n\n### Schalen maken\n\nWe maken in onderstaande secties de HDI door gebruik te maken van zowel normalisering als standaardisering. We bestuderen ook de verschillen.\n\n#### Normalisering\n\nVoor de HDI wordt gebruik gemaakt van 3 genormaliseerde variabelen: levensverwachting, het gemiddelde van verwachte en gemiddelde scholing in een land, en het natuurlijk logaritme van het BNI per capita (zie bovenstaande uitleg). We zullen eerste manueel normaliseren en dan gebruik maken van de `rescale()` functie uit het `scales` package.\n\nOnze eerste stap is het berekenen van het gemiddelde van de onderwijsvariabelen. Eerst normaliseren we beide variabelen. De VN deelt verwachte scholing door 18 en gemiddelde scholing door 15 om een 0-1 schaal te maken (zie uitleg boven). Dan nemen ze het gemiddelde van de twee variabelen. Dit doen we met de volgende syntax, waarbij we de `rowwise()` functie gebruiken.\n\n```{r}\n# Onderwijsvariabele voor gebruik in HDI\nhdi_data <- hdi_data |> \n  mutate(\n    expected_yrs_rescale1 = expected_schooling / 18, \n    mean_yrs_rescale1 = mean_schooling / 15) |> \n  rowwise() |> \n  mutate(\n    education_index_1 = mean(c(expected_yrs_rescale1, mean_yrs_rescale1), na.rm = T)\n  ) |> \n  ungroup()\n\n# Statistieken bekijken\nsummary(hdi_data$education_index_1)\n\n# Blik op de dataset\nhdi_data |> \n  select(expected_schooling, mean_schooling, expected_yrs_rescale1, mean_yrs_rescale1, education_index_1) |>\n  head()\n\n```\n\nDe uiteindelijke indexvariabele heeft een bereik tussen 0 en 1 met een minimum van 0.25 en een maximum van 0.96. Door te kijken naar de relevante variabelen in de dataset kunnen we de berekening volgen. Voor de eerste observatie vinden we het maximum van 18 jaar verwachte scholing. Als we dit delen door 18 vinden we voor `expected_yrs_rescale1` het maximum van 1. Voor gemiddelde scholing heeft deze observatie echter niet het maximum maar 13.91.Als we dit getal delen door 15 vinden we voor `mean_yrs_rescale1` een getal dichtbij het maximum: 0.93. Het gemiddelde van 1 en 0.93 vinden we bij `education_index_1`.\n\nWe normaliseren nu ook levensverwachting met het VN minimum van 20 en maximum van 85. Voor (log) BNI per capita gebruiken we het VN minimum van log(100) en maximum van log(75000). Hier kunnen we meer de standaardformule voor normaliseren toepassen.\n\n```{r}\n# Normaliseren van variabelen\nhdi_data <- hdi_data |> \n  mutate(\n    life_rescale1 = (life_expectancy - 20) / (85 - 20), \n    gni_rescale1 = (gni_percap_logged - log(100)) / (log(75000) - log(100)))\n\n# Statsitieken bekijken\nsummary(hdi_data$life_rescale1)\nsummary(hdi_data$gni_rescale1)\n\n```\n\nWe kunnen zien dat het nieuwe maximum van de variabelen 1 is, de minima zijn hierbij wel niet precies 0 (dat zijn ze wel met de `scales` methode hieronder besproken).\n\nTen slotte kunnen we onze index samenstellen door het gemiddelde te nemen van onze 3 variabelen met de `rowwise()` en `mean(c(), na.rm =T)`) syntax.[^scales-11]\n\n[^scales-11]: We berekenen hier gewoon het gemiddelde, maar de VN gebruikt het geometrisch gemiddelde. Hierdoor wijkt onze berekening wat af. Het `psych` package bevat een functie om het geometrisch gemiddelde te berekenen.\n\n```{r}\n# Uiteindelijke schaal\nhdi_data <- hdi_data |> \n  rowwise() |> \n  mutate(hdi_normalize_un = mean(c(life_rescale1, gni_rescale1, \n                                   education_index_1), na.rm = T)) |> \n  ungroup()\n\n# Statistieken bekijken\nsummary(hdi_data$hdi_normalize_un)\n\n```\n\nDe schaal loopt van 0.41 tot 0.97. Hogere waarden staan voor hogere scholingsgraad, levensverwachting en welvaart.\n\nIn bovenstaande syntax maakten we gebruik van de minimum- en maximumwaarden bepaald door de VN. Maar we kunnen deze ook uit de data halen. Dit is vaak eenvoudiger, zeker als je geen theoretische basis hebt voor je keuzes zoals de VN. We kunnen de `scales::rescale()` functie gebruiken om dit automatisch te doen:\n\n```{r}\nhdi_data <- hdi_data |> \n  mutate(\n    expected_yrs_rescale2 = scales::rescale(expected_schooling, to = c(0,1)), # <1>\n    mean_yrs_rescale2 = scales::rescale(mean_schooling, to = c(0,1)), \n    life_rescale2 = scales::rescale(life_expectancy, to = c(0,1)), \n    gni_rescale2 = scales::rescale(gni_percap_logged, to = c(0,1)))\n\n```\n\n1.  We noemen het package hier in de syntax (`scales::`) zodat we het niet hoeven te laden. Het `scales` package heeft namelijk ook een aantal functies die conflicteren met andere packages die we gebruiken.\n\nZo lees je de syntax:\n\n`scales::rescale(`\n\n:   We gebruiken de functie `rescale()` uit het `scales` package. We noemen het package in de syntax (`scales::`) om het niet te hoeven laden.\n\n`expected_schooling, to = c(0,1))`\n\n:   We noemen de variabele die we willen normaliseren. Met de `to = c(0,1)`vertellen we R dat we de variabele willen herschalen zodat ze een bereik van 0 tot 1 heeft. We zouden deze waarden kunnen veranderen, bv. naar `c(0,10)` voor een bereik van 0 tot 10.\n\nLaten we kijken naar het verschil tussen de VN-methode en `rescale`:\n\n```{r}\n# Originele variabele en VN normalisering\np1 <- ggplot(hdi_data, aes(x = life_expectancy, y = life_rescale1)) + geom_point() + \n  scale_y_continuous(limits = c(0,1)) + \n  labs(title = \"Normalisering met VN min(x) en max(x)\") \n\n# Originele variabele en scales::rescale() normalisering\np2 <- ggplot(hdi_data, aes(x = life_expectancy, y = life_rescale2)) + geom_point() + \n  labs(title = \"Normalisering met scales::rescale()\")\n\n# Plots combineren met patchwork library\np1 + p2 \n\n```\n\nBeide genormaliseerde variabelen hebben een theoretisch bereik van 0 tot 1. Maar met `rescale` wordt er altijd een echt minimum en maximum gevonden in de data en zul je altijd de waarden 0 en 1 terugvinden. De VN heeft echter door het zelf bepalen van minima en maxima in plaats van ze door de data te laten bepalen, het minimum voor de data in de praktijk hoger gelegd (bij 0.53). In 2023 had geen enkel land een levensverwachting van 20, het theoretische minimum van de VN, dus vinden we 0 niet terug. Het theoretische maximum van 85 werd dan wel weer bereikt.\n\nWe berekenen nu de index met de `scales::rescale()` genormaliseerde variabelen:\n\n```{r}\n# Index berekenen\nhdi_data <- hdi_data |> \n  rowwise() |> \n  mutate(\n    education_index_2 = mean(c(expected_yrs_rescale2, mean_yrs_rescale2), na.rm = T),\n    hdi_normalize_scales = mean(c(education_index_2, life_rescale2, gni_rescale2), na.rm = T)\n    ) |> \n  ungroup()\n```\n\nLaten we de twee versies vergelijken:\n\n```{r}\n# Statistieken vergelijken\nsummary(hdi_data$hdi_normalize_scales) # scales::rescale() \nsummary(hdi_data$hdi_normalize_un) # VN waarden\n\n# Correlatie\ncor.test(x = hdi_data$hdi_normalize_un, \n         y = hdi_data$hdi_normalize_scales, \n         method = 'pearson')\n```\n\nDe schalen lopen van 0 tot 1 maar zijn niet volledig identiek. In lijn met wat we hierboven al zagen ligt het minimum hoger bij de VN versie. Toch correleren de twee versies zeer sterk en positief met een pearson correlatie van 0.998. Verschillen zullen dan ook weinig uitmaken in regressieanalyses.\n\n#### Standaardisering\n\nOm te standaardiseren trekken we van een variabele de gemiddelde waarde af en delen we door de standaardafwijking. Hier kunnen we de ingebouwde R-functie `scale()` voor gebruiken. je hoeft geen package te laden.\n\n```{r}\n# Standaardiseren\nhdi_data <- hdi_data |> \n  mutate(\n    life_std = scale(life_expectancy, center = TRUE, scale = TRUE), \n    expected_yrs_std = scale(expected_schooling, center = TRUE, scale = TRUE), \n    mean_yrs_std = scale(mean_schooling, center = TRUE, scale = TRUE), \n    gni_std = scale(gni_percap_logged, center = TRUE, scale = TRUE)\n  )\n```\n\nZo lees je de syntax:\n\n`scale(`\n\n:   We gebruiken de functie `scale()` op de variabele tussen haakjes.\n\n`life_expectancy, center = TRUE, scale = TRUE)`\n\n:   We benoemen de variabele en vragen R eerst het gemiddelde van de variabele van elke waarde af te trekken met `center = TRUE` en dan te standaardiseren door te delen door de standaardafwijking met `scale = TRUE`.\n\nLaten we de statistieken van de variabelen bekijken:\n\n```{r}\n# Descriptieve statistieken opvragen\nhdi_data |>\n  select(life_std, expected_yrs_std, mean_yrs_std, gni_std) |>\n  psych::describe() \n```\n\nAlle variabelen hebben een gemiddelde van 0 en een standaardafwijking van 1. De minima en maxima zijn niet dezelfde maar de waarden hebben dezelfde betekenis: hoeveel verschilt de observatie van de gemiddelde waarde van de originele variabele.\n\nWe maken nu de index door het gemiddelde van de variabelen te nemen:\n\n```{r}\n# Schaal maken\nhdi_data <- hdi_data |> \n  rowwise() |> \n  mutate(\n    hdi_standardized = mean(c(life_std, expected_yrs_std, \n                              mean_yrs_std, gni_std), \n                            na.rm = T))\n\n# Statistieken bekijken\nsummary(hdi_data$hdi_standardized)\n```\n\nde schaal loopt van -2.12 tot 1.44 met een gemiddelde waarde van 0. Observaties dichter bij het maximum hebben scores hoger dan het gemiddelde voor (bijna) alle onderliggende variabelen.\n\n## Referenties\n","srcMarkdownNoYaml":"\n\n# Indexen en schalen {#sec-scales}\n\n```{r}\n#| message: false\n#| warning: false\n#| echo: false\n\n#Packages\nlibrary(patchwork)\nlibrary(kableExtra) \nlibrary(rio)            \nlibrary(tidyverse)      \nlibrary(broom) \nlibrary(performance)\nlibrary(modelsummary)\n\n# Datasets used in examples below\nscale_data <- import(\"./data/scale_data.rda\")\nhdi_data <- import(\"./data/hdi_data.csv\")\n```\n\n```{r}\n#| eval: false\n\n#Packages\nlibrary(patchwork)    # Grafieken combineren\nlibrary(kableExtra)   # html tabel maken\nlibrary(rio)          # data import\nlibrary(tidyverse)    # Datamanagement enplotten    \nlibrary(broom)        # coëfficiënten\nlibrary(performance)  # Model en schaal statistieken\nlibrary(modelsummary) # Descriptieve statistiektabellen\n\n# Gebruikte datasets\nscale_data <- import(\"scale_data.rda\")\nhdi_data <- import(\"hdi_data.csv\")\n```\n\n::: {.callout-note title=\"Voor wie is deze appendix?\"}\nJe hoeft niet te weten hoe je deze analyses moet uitvoeren voor de opdrachten in Statistiek II. Deze gids is bedoeld voor studenten die hun eindpaper schrijven voor Academische Vaardigheden: Kwantitatieve Data-Analyse of een BAP-scriptieproject.\n:::\n\nSoms kan het nuttig zijn om variabelen te combineren tot een enkele variabele of schaal, zowel voor afhankelijke als onafhankelijke variabelen. Stel dat we 'populistische attitudes' willen meten, dan kunnen we denken aan een combinatie van anti-elitaire attitudes, het geloof dat de publieke wil het beleid moet sturen en het hebben van een manicheïsch wereldbeeld (i.e. de wereld in termen van goed en kwaad zien).[^scales-1]\n\n[^scales-1]: Zie @castanhosilva2020 voor een bespreking van verschillende populismeschalen.\n\nEen onderzoeksvraag vergt soms dat we meerdere elementen (variabelen) combineren tot 1 variabele of schaal. Het is vaak ook betrouwbaarder om met meerdere vragen eenzelfde concept te meten dan slechts met 1 vraag. Op het statistiektentamen stellen we ook niet 1 maar meerdere vragen om een betrouwbare test te hebben van hoe goed studenten de leerstof kennen. Ten slotte kunnen we door het combineren van meerdere variabelen tot slechts 1 variabele statistische modellen vereenvoudigen (bv. door niet 10 maar 5 onafhankelijke variabelen toe te voegen: 4 + een index van de andere predictors). Dit samenvoegen is ook handig als predictors sterk gecorreleerd zijn en een model onderhevig zou zijn aan sterke multicollineariteit indien onafhankelijke variabelen samen worden toegevoegd.\n\nDeze appendix bekijkt hoe we op basis van meerdere variabelen slechts 1 variabele of index/schaal kunnen creëeren. Eerst bespreken we algemene principes die een leidraad vormen bij beslissingen over het maken van een schaal. Dan tonen we hoe de *betrouwbaarheid* van een schaal nagegaan kan worden en hoe we een nieuwe schaal kunnen maken op basis van de som of het gemiddelde van bestaande variabelen. In een tweede uitgewerkt voorbeeld bespreken we wat te doen als de variabelen waarmee je een schaal wil maken gemeten zijn op verschillende manieren.\n\n## Algemene principes\n\nDe R code die we in de volgende secties tonen kan gebruikt worden om verschillende soorten indexen/schalen te maken op basis van bestaande variabelen. Het spreekt echter voor zich dat het niet de bedoeling is lukraak wat variabelen bij elkaar te gooien. De beslissing welke variabelen samen te voegen en met welk doel moet gemotiveerd zijn. welke principes daarbij in gedachten moeten worden gehouden bespreken we hier. [^scales-2]\n\n[^scales-2]: Zie bijvoorbeeld @adcock2001 voor een meer uitgebreide discussie van de principes uitgelegd hier.\n\nConceptualisatie vormt een natuurlijk beginpunt voor het nadenken over schalen. We willen vaak concepten zoals 'democratie', 'populisme', of 'ideologie' empirisch bestuderen, maar deze concepten kennen verschillende facetten of sub-componenten die je niet altijd met 1 vraag kunt meten. Soms gebeurt dit wel, denk bijvoorbeeld aan de gekende vraag over links-rechtspositie, maar ook hier kunnen we ons kritisch de vraag stellen of we hiermee echt een complex concept als 'ideologie' meten. Moeten we niet zowel economisch als sociaal-cultureel links-rechts meten bijvoorbeeld?\n\nDe vraag die we ons dan stellen is hoe we deze concepten best kunnen meten en of we dat met 1 of meerdere variabelen moeten doen. Bestaande studies helpen hierbij. Het V-Dem project meet bijvoorbeeld democratie (`v2x_polyarchy`) niet met 1 vraag gesteld aan experten ('hoe democratisch is...?') maar met verschillende vragen over bijvoorbeeld hoe vrij en eerlijk verkiezingen zijn, hoe transparant de overheid is enz. Antwoorden op verschillende vragen worden gecombineerd tot 1 getal voor democratie. In een survey vragen we doorgaans niet aan mensen hoe 'populistisch' ze zijn. Dit woord wordt meer gebruikt door wetenschappers dan gewone burgers. We kunnen wel vragen of ze akkoord of niet akkoord gaan met stellingen zoals 'politici zijn geschikter om beleid te vormen dan gewone burgers' en 'politici zijn uit op eigenbelang' en dan een schaal maken op basis van de antwoorden op deze stellingen.\n\nEen *valide* meting is een meting waarbij de vraag, of de combinatie van vragen in dit geval, gebruikt om het concept te meten alle belangrijke aspecten van het concept bevat. Een meting van democratie zonder een element over vrije en eerlijke verkiezingen zou best vreemd zijn bijvoorbeeld. We willen geen belangrijke dingen vergeten. Aan de andere kant willen we niet te veel elementen opnemen en ons concept niet uitrekken. Een meting van democratie bevat dan meestal ook geen indicatoren over welvaart in de samenleving. Voor validiteit moeten we goed nadenken over wat er nu bij ons concept hoort en wat eigenlijk iets anders is.\n\nEen meting moet ook *betrouwbaar* zijn: als we de meting opnieuw zouden doen, willen we gelijke of sterk gelijke resultaten. Je wil ook geen weegschaal die je telkens een ander cijfer geeft als je er 3 keer na elkaar gaat opstaan. Voor betrouwbare schalen kunnen we ons vaak beroepen op eerder onderzoek: wat hebben andere onderzoekers gebruikt en met welke resultaten? We kunnen ook echter kijken naar de correlatie tussen verschillende variabelen waarvan we denken dat ze een schaal kunnen vormen om 1 concept te meten. Als de sub-variabelen sterk gecorreleerd zijn, hebben we reden om aan te nemen dat ze verschillende aspecten van eenzelfde concept meten.\n\n## Voorbeeld 1: Emoties en campagne voeren\n\n### Data\n\nWaarom doen burgers mee aan verkiezingscampagnes (bv. door de straat op te gaan om mensen aan te spreken of door geld te doneren)? Sommige onderzoekers leggen dit vooral uit door te verwijzen naar mensen hun vaardigheden en welvaart: hebben ze tijd voor vrijwilligerswerk, geld om te doneren, de politieke kennis om mensen te mobiliseren enz.? Maar mensen moeten ook overtuigd zijn dat campagne voeren nuttig en juist is om te doen. Ze moeten met andere woorden gemotiveerd zijn. recent onderzoek wijst uit dat *emoties* een belangrijke rol kunnen spelen om mensen tot actie aan te zetten. [^scales-3] We onderzoeken dit idee op basis van een subset van de 2024 American National Election Studies (ANES) en tonen aan hoe we schalen maken in R.\n\n[^scales-3]: Zie @Brady1995 over de rol van vaardigheden en welvaart in politieke participatie en @Valentino2011 over de rol van emoties. Hier richten we ons op de positieve rol van emoties op participatie, maar deze kunnen ook negatieve effecten hebben, zie bijvoorbeeld de studie van @Young2019 in Zimbabwe.\n\nANES is gebaseerd op een toevalssteekproef van volwassen Amerikaanse burgers, die ondervraagd worden zowel voor (pre-election) als na (post-election) de nationale verkiezingen. In 2024 werd respondenten gevraagd of zij verschillende soorten campagneactiviteiten hadden ondernomen:\n\n-   \"Heb je mensen gesproken om hen te overtuigen te stemmen voor of tegen bepaalde kandidaten of partijen?\" (`persuade`)\n-   \"Heb je online deelgenomen aan politieke bijeenkomsten, speeches, geldinzamelingsacties of gelijkaardige zaken om een bepaalde kandidaat te steunen?\" (`online_meetings`)\n-   \"Heb je fysiek deelgenomen aan politieke bijeenkomsten, speeches, geldinzamelingsacties of gelijkaardige zaken om een bepaalde kandidaat te steunen?\" (`rallies`)\n-   \"Toonde je een politiek symbool tijdens de campagne zoals een button, kledingstuk, sticker op de wagen, affiche aan huis?\" (`campaign_button`)\n-   \"Deed je ander werk voor een kandidaat of partij?\" (`other_work`)\n-   \"Heb je geld gedoneerd aan een partij dit verkiezingsjaar?\" (`contribute_money_party`)\n-   \"Heb je geld gedoneerd aan een groep voor of tegen bepaalde kandidaten?\" (`contribute_money_group`)\n\nRespondenten konden met 'ja (code = 1)' of 'nee (code =0)' antwoorden.\n\nWe bekijken eerst de descriptieve statistieken voor we meer ingewikkelde dingen proberen. We maken gebruik van de `psych::describe()` functie. De \"mean\" kolom geeft de proportie weer van respondenten die een bepaalde activiteit hebben ondernomen.\n\n```{r}\nscale_data |> \n  select(persuade:contribute_money_group) |> # <1>\n  psych::describe()  |> # <2>\n  select(vars:mean, min, max) # <3>\n```\n\n1.  We selecteren de variabelen waarvoor we statistieken willen. De campagnevariabelen bevinden zich naast elkaar in de data. We schrijven de eerste en de laatste met een dubbelpunt ertussen om ze allemaal te selecteren.\n2.  Door `psych::` als prefix te gebruiken hoeven we het package hier niet eerst te laden. Sommige functies van dit package conflicteren namelijk met die van `tidyverse`.\n3.  We gebruiken de `select()` functie om slechts relevante kolommen weer te geven. Voor binaire variabelen zijn zaken zoals skew en kurtosis niet veelzeggend.\n\nOngeveer 40% van de respondenten heeft anderen proberen overtuigen. Andere activiteiten zijn minder frequent gebruikt. De verschillende vragen of 'items' (sub-componenten van een schaal) zullen we gebruiken voor de afhankelijke variabele.\n\nANES vroeg respondenten ook naar hun emoties voorgaand aan de verkiezingen met de vraag: Hoe \\[specifieke emotie\\] voel je je over hoe de zaken momenteel gaan in het land? De volgende emoties werden bevraagd:\n\n-   hoopvol (`hopeful`)\n-   angstig (`afraid`)\n-   woedend (`outraged`)\n-   boos (`angry`)\n-   gelukkig (`happy`)\n-   bezorgd (`worried`)\n-   trots (`proud`)\n-   geïrriteerd (`irritated`)\n-   nerveus (`nervous`)\n\nRespondenten konden antwoorden op een 5-punten schaal: not at all (=1), a little (=2), somewhat (=3), very (=4), en extremely (=5). Ook hier bekijken we de beschrijvende statistieken eerst:\n\n```{r}\nscale_data |> \n  select(hopeful:nervous) |> \n  psych::describe() |> \n  select(vars, n, mean, sd, median, min, max, skew, kurtosis)\n```\n\nWe zien dat respondenten over het algemeen niet zo positief zijn: gemiddelden voor negatieve gevoelens liggen hoger dan die voor positieve gevoelens. Maar er is sterke variatie in de variabelen.\n\nWe willen nu de relatie nagaan tussen emoties en campagne voeren. Voor zowel de 'onafhankelijke' (emoties) als de 'afhankelijke' (campagne) variabelen hebben we meerdere aparte variabelen in de dataset. Hoe gaan we te werk?\n\nWe zouden verschillende (logistische) modellen kunnen schatten per campagne-item en telkens alle emotievariabelen toevoegen als predictors. Dit kan een goede aanpak zijn als we willen weten of welbepaalde emoties een andere invloed hebben op welbepaalde activiteiten ten opzichte van andere. Als we geïnteresseerd zijn in de algemene relatie tussen emoties en campagne voeren, maken we indexen of schalen.\n\nOnze emoties verschillen, maar toch kunnen we ook hier een schaal maken als we ervanuit gaan dat positieve en negatieve emoties samen voorkomen (i.e. correleren). We gaan dit eerst na:\n\n```{r}\n#| tbl-cap: \"Correlaties tussen emoties\"\n#| label: tbl-emotion-corr\n\nscale_data |> \n  select(hopeful:nervous) |>  # <1>\n  rename_with(str_to_title) |> # <2>\n  datasummary_correlation() # <3>\n\n```\n\n1.  We selecteren de variabelen waarvoor we correlaties willen berekenen.\n2.  De `str_to_title()` functie komt uit het `stringr` package (deel van `tidyverse`). we gebruiken het om de kolomnamen te laten beginnen met een hoofdletter in plaats van een kleine letter, dan moeten we niet individueel de variabelen hernoemen (Zie [deze](https://stackoverflow.com/questions/13258020/change-letter-case-of-column-names){target=\"_blank\"} StackOverflow thread.\n3.  Deze functie uit het `modelsummary` package maakt een correlatietabel. Zie @sec-reporting-and-presenting-results voor verdere informatie.\n\n@tbl-emotion-corr toont dat positieve emoties positief correleren, dat negatieve emoties positief correleren en dat positieve en negative emoties negatief correleren. Dit lijkt erop te wijzen dat we indexen voor 'positieve' en 'negatieve' emoties zouden kunnen maken, ook om multicollineariteit tegen te gaan.\n\n### Betrouwbaarheid van schalen\n\nDe concepten van 'emoties' en 'campagne voeren' lijken valide en de belangrijkste componenten te bevatten van deze zaken in het echte leven (we kunnen hier natuurlijk verder over reflecteren in de conclusie van onze paper). De positieve en negatieve indexen van emoties hierboven gesuggereerd worden ook ondersteund in de literatuur. Eerder onderzoek over \"affective intelligence theory\" stelt immers dat menselijk gedrag aangestuurd wordt door twee emotionele systemen. De items staan eigenlijk ook in ANES om dit te testen [^scales-4]\n\n[^scales-4]: Zie @Marcus1993 voor een baanbrekende studie hierover en meer recent werk van @Valentino2011 en @Vasiopoulos2019.\n\nMaar we moeten ook naar betrouwbaarheid kijken: zou een index van positieve emoties intern betrouwbaar zijn? Meten onze verschillende emoties voldoende hetzelfde 'positieve' aspect. De correlaties hierboven (zie @tbl-emotion-corr) lijken te zeggen van ja, maar er bestaan ook betere statistische methoden die helpen de vraag te beantwoorden of de correlatie sterk genoeg is.\n\nWe gebruiken de Cronbach's alpha ($\\alpha$), gebaseerd op de gemiddelde covariantie van de onderliggende variabelen in de schaal.[^scales-5] De $\\alpha$ maatstaf heeft een bereik van 0 tot 1. Hogere waarden duiden op hogere betrouwbaarheid. De volgende vuistregels gelden:\n\n[^scales-5]: De formule is: $\\alpha = \\frac{k\\bar{c}}{\\bar{v} + (k - 1)\\bar{c}}$. $k$ = aantal items. $\\bar{v}$ = gemiddelde variantie van de items. $\\bar{c}$ = gemiddelde covariantie van de items.\n\n-   $\\geq$ 0.90: Excellente betrouwbaarheid\n-   0.80-0.89: Goede betrouwbaarheid\n-   0.70-0.79: Aanvaardbare betrouwbaarheid\n-   0.60-0.69: Twijfelachtige betrouwbaarheid\n-   \\< 0.60: Slechte betrouwbaarheid\n\nDoorgaans gebruiken we geen index met een $\\alpha$ onder 0.6. Bij binaire variabelen kan de betrouwbaarheid echter onderschat worden omdat de $\\alpha$ test eigenlijk continue variabelen verwacht. Er bestaan andere methoden voor binaire data maar deze vallen buiten het materiaal van dit handboek.\n\nWe kunnen de $\\alpha$ berekenen met de `cronbachs_alpha()` functie uit het `performance` package.\n\n```{r}\n# Campagne index\nscale_data |> \n  select(persuade:contribute_money_group) |> \n  cronbachs_alpha() \n\n# Positieve emoties\nscale_data |> \n  select(hopeful, happy, proud) |> \n  cronbachs_alpha()\n  \n# Negatieve Emoties\nscale_data |> \n  select(afraid, outraged, angry, worried, irritated, nervous) |> \n  cronbachs_alpha()\n\n```\n\nDe $\\alpha$ scores voor de emotieschalen zijn 0.84 en 0.93 respectievelijk en dus sterk betrouwbaar. De betrouwbaarheid voor negatieve emoties is vooral hoger omdat er meerdere items gebruikt zijn. De $\\alpha$ score voor campagne voeren is lager: 0.63. Gezien de scores doorgaans lager zijn bij binaire variabelen maken we de beslissing om toch met de index door te gaan.\n\n### Som of gemiddelde?\n\nWe zullen 3 indexen maken: 1 voor campagne en 2 voor emoties. We moeten een keuze maken tussen variabelen optellen of het gemiddelde nemen. De keuze ligt aan de onderzoeker, maar er zijn wel wat richtlijnen. Bij campagne kijken we naar verschillende activiteiten. Hier houdt het steek om te meten hoeveel verschillende activiteiten iemand heeft gedaan eerder dan of die persoon gemiddeld een activiteit heeft gedaan. Optellen dus. Bij emoties lijkt de originele schaal van 1 tot 5 nuttig: voelt iemand zich helemaal niet of juist sterk zo? Een nieuwe somschaal op 30 (bv. voor negatieve emoties hier) heeft weinig intuïtieve betekenis. Hier nemen we dus het gemiddelde.\n\nWe moeten ook rekening houden met ontbrekende waarden. Als we R vragen om een som of gemiddelde te berekenen moeten we zeggen hoe met missing data om te gaan via `na.rm = TRUE` of `na.rm = FALSE`. Bij `na.rm =TRUE` worden missing waarden (NA) weggelaten bij de berekening. Dit is de correcte manier, anders krijgen we 'NA' voor de som/het gemiddelde. Zie het verschil hieronder.\n\n```{r}\n# voorbeelddata\nx <- c(5, 1, 2, NA, 5)\n\n# gemiddelde berekenen\nmean(x, na.rm = TRUE)\nmean(x, na.rm = FALSE)\n```\n\nAls we een index van gemiddelden maken voor 5 items, en 1 (of meerdere) zijn missing, dan wordt het gemiddelde berekend voor de overige 4 (of minder) waarden. Dit is doorgaans prima.\n\nWat als we een som nemen? We moeten opnieuw `na.rm = TRUE` gebruiken. Nu geeft de functie een score van 0 voor alle NA waarden bij de optelling. Dit kan soms vreemde gevolgen hebben. Een observatie met enkel missing waarden voor de items zal opeens een 0 krijgen als eindscore en geen NA. Zie onderstaand voorbeeld:\n\n```{r}\n# voorbeelddata\ndata <- tibble(\n  x = c(NA, NA, NA, NA, NA), \n  y = c(0, 1, 0, 0, NA)\n)\n\n# Inspectie\ndata\n\n# Som maken\ndata |> \n  mutate(sum_x = sum(x, na.rm = T), \n         sum_y = sum(y, na.rm = T))\n```\n\nIn zekere zin gaan we voor X hier data 'verzinnen', wat problematisch kan zijn. We weten immers niet wat echt waar is voor deze observatie. In de ANES survey nam niet iedereen mee aan het gedeelte van de survey dat na de verkiezingen werd afgenomen en waarin de campagnevragen stonden. Voor al deze mensen zouden we dus 0 ingeven, hoewel ze geen respons hebben gegeven. we kunnen deze mensen wel uit de data filteren maar dan blijven er nog respondenten voor wie we geen waarden hebben en eigenlijk niet kunnen zeggen wat ze gedaan hebben.[^scales-6] Hieronder tonen we hoe dit aan te pakken.\n\n[^scales-6]: Respondenten kunnen weigeren of 'Don't know' antwoorden geven bijvoorbeeld. Deze antwoorden worden doorgaans op missing gezet.\n\nWe will show how to find these types of observations and how to deal with them below.\n\n### Schalen maken\n\nEigenlijk hebben we vooral nood aan 2 basisfuncties binnen R: `mean()` en `sum()`.[^scales-7] Voorgaand hebben we deze functies op 1 variabele tegelijk toegepast. Nu combineren we meerder variabelen (kolommen in de dataset) tot een gecombineerde variabele (kolom). Dit doen we met behulp van functies uit `tidyverse`: `rowwise()` en `c_across()`. Je kunt meer over deze functies leren via deze [vignette](https://dplyr.tidyverse.org/articles/rowwise.html){target=\"_blank\"}.\n\n[^scales-7]: Probeer een index niet manueel te maken (bv., `newvar = var1 + var2 + var3`). Dit werkt als er geen missing data is, maar dit is in de praktijk vaak niet het geval.\n\n#### Een index gebaseerd op een gemiddelde\n\nWe maken 2 indexen op basis van gemiddelden: eentje voor de positieve emoties en eentje voor de negatieve emoties.\n\n```{r}\nscale_data <- scale_data |> \n  rowwise() |> \n  mutate(\n    positive_emotions = mean(c(hopeful, happy, proud), na.rm = T), \n    negative_emotions = mean(c(afraid, outraged, angry, worried, \n                               irritated, nervous), na.rm =T)) |> \n  ungroup()\n\n```\n\nZo lees je de syntax:\n\n`scale_data |> rowwise() |>`\n\n:   de nieuwe functie hier is `rowwise()`. Zonder deze functie zou `mutate()` gewoon gemiddelden berekenen op basis van alle rijen in de dataset en deze gemiddelden toevoegen aan de dataset (iedereen zou dus dezelfde algemene waarden krijgen voor de variabelen). Met `rowwise()` vragen we R om gemiddelden per rij te berekenen zodat elke observatie zijn eigen gemiddelde score toegevoegd krijgt.\n\n`mutate(positive_emotions = mean(c(hopeful, happy, proud), na.rm = T), ...))`\n\n:   We vragen R om met `mutate()` nieuwe variabelen (kolommen) te maken. De eerste variabele noemen we `positive_emotions`, de tweede `negative_emotions`. Dit is de gemiddelde score voor de waarden van de variabelen aangegeven met `c(...)`. Het gedeelte `na.rm = T` vraagt R missing waarden te negeren bij de berekening.\n\n`ungroup()`\n\n:   We vragen R om de groepen (gemaakt met `rowwise()`) te vergeten zodat dit groeperen per rij niet gebruikt wordt in verdere syntax die gebruikmaakt van `mutate()`.\n\nWe kunnen de data bekijken:\n\n```{r}\nscale_data |> \n  select(hopeful:negative_emotions) |> \n  head() |> # <1> \n  kable(digits = 2) # <2>\n```\n\n1.  Automatisch selecteren van de eerste rijen van de data voor presentatie.\n2.  `kable()` wordt gebruikt voor het maken van tabellen in html files. Hier gebruiken we het om ervoor te zorgen dat alle kolommen zichtbaar zijn voor de lezer.\n\nDe eerste respondent was duidelijk ongelukkig met de toestand in de VS. Voor alle positieve emoties wordt de laagste score van 1 gegeven (het gemiddelde voor positieve emoties is dan ook 1). Voor de negatieve emoties werd telkens de maximale score van 5 gegeven (en 5 is dus ook het gemiddelde). Respondent 6 is zowat de tegenpool van respondent 1 terwijl andere respondenten zich meer in het midden bevinden.\n\nMet een Pearson correlatie kunnen we nagaan hoe de twee schalen zich tot elkaar verhouden:\n\n```{r}\ncor.test(scale_data$positive_emotions, \n         scale_data$negative_emotions, \n         method = \"pearson\")\n\n```\n\nDe schalen zijn negatief gecorreleerd met een gemiddeld sterke samenhang. Dit betekent dat respondenten ook ambivalent kunnen zijn en zowel positieve als negatieve gevoelens ervaren.\n\n#### Een index gebaseerd op een som\n\nHet proces voor een index gebaseerd op een som is gelijkaardig, behalve dat we moeten opletten met observaties die ontbrekende waarden hebben voor de variabelen die de schaal/index gaan vormen, zoals hierboven uitgelegd. Deze observaties mogen we niet meenemen in de berekening. We bekijken eerst of er missing waarden zijn over de cases heen:\n\n```{r}\nscale_data <- scale_data |> \n  rowwise() |> \n  mutate(engage_missing = sum(is.na(c(persuade, online_meetings, rallies, \n                                      campaign_button, other_work, \n                                      contribute_money_party, contribute_money_group)))) |> \n  ungroup()\n```\n\n`sum(is.na(c(persuade, ..., contribute_money_group))))`\n\n:   We gebruiken hier `rowwise()` gevolgd door `mutate()` zoals we hierboven al deden. Nu gebruiken we echter `sum()` om totalen te berekenen. We willen hier berekenen hoeveel van de observaties ontbrekende waarden hebben en voor hoeveel van de onderliggende variabelen. We maken dus ook gebruik van de `is.na()` functie. Deze functie transformeert achter de schermen de kolommen (variabelen) aangeduid met `c()` tot binaire variabelen waarbij 0 staat voor valide waarden en 1 voor ontbrekende waarden. Zo berekenen we hoeveel ontbrekende waarden een observatie heeft.\n\nLaten we eens kijken of er observaties zijn met ontbrekende waarden via de `table()` functie:\n\n```{r}\ntable(scale_data$engage_missing)\n```\n\nDe meeste observaties (4752) hebben geen enkele (0) ontbrekende waarde. Sommige respondenten (9) hebben er 1. Er is ook een respondent die voor alle 7 de variabelen een ontbrekende waarde geeft. Deze zouden we eruit kunnen filteren op de volgende manier:[^scales-8]\n\n[^scales-8]: We zouden hier ook de `complete.cases()` functie kunnen gebruiken zoals we dat doen om model fit statistieken over modellen heen te kunnen analyseren (zie @sec-linear-comparing-models). Daarmee zouden we ook observaties wegdoen die maar voor een of enkele variabelen een ontbrekende waarde hebben. Wat we nu doen is ervan uitgaan dat een ontbrekende waarde een probleem vormt als alles ontbreekt, maar dat we in een situatie met zowel valide als ontbrekende waarden mogen uitgaan van een '0' score voor de variabele waar een ontbrekende waarde wordt genoteerd. Dit kunnen we natuurlijk ter discussie stellen. Vaak moeten we een afweging maken over hoe we zoveel data als mogelijk kunnen gebruiken en hoe we zo accuraat mogelijk met de data kunnen omgaan. we zouden ook kunnen beslissen om observaties weg te doen die ontbrekende waarden hebben voor meer dan de helft van de variabelen enz.\n\n```{r}\nscale_data <- scale_data |> \n  filter(engage_missing < 7)  \n```\n\nNu kunnen we dan onze index maken. We gebruiken hiervoor de functie `c_across()`:\n\n```{r}\nscale_data <- scale_data |> \n  rowwise() |> \n  mutate(campaign_engagement = sum(c_across(persuade:contribute_money_group))) |> \n  ungroup()\n```\n\n`campaign_engagement = sum(c_across(persuade:contribute_money_group)))`\n\n:   Toen we het gemiddelde over een aantal variabelen heen wilden berekenen gebruikten we gewoon de functie `c()`. Dat werkt prima, maar kan omslachtig zijn als er veel variabelen zijn om uit te schrijven. Met `c_across` kunnen we de eerste variabele en de laatste schrijven met daartussen een dubbelpunt (`persuade:contribute_money_group`). Zo selecteert R ook alle tussenliggende variabelen. Deze functie is natuurlijk enkel nuttig als de relevante variabelen netjes bij elkaar staan in de dataset.\n\nLaten we een kijkje nemen naar de uiteindelijke index:\n\n```{r}\ntable(scale_data$campaign_engagement)\n```\n\nHet merendeel van de respondenten is niet betrokken bij campagneactiviteiten. Zij scoren 0 op de index. Een groot aantal respondenten doet 1 activiteit (1345). Hoe meer activiteiten, hoe minder respondenten. Slechts 11 respondenten hebben deelgenomen aan alle 7 de activiteiten.\n\n### Model schatten\n\nNu we al onze schalen gecreëerd hebben kunnen we een regressiemodel schatten. Hier gebruiken we een lineair model met positieve en negatieve emoties als onafhankelijke variabelen en campagne engagement als afhankelijke variabele:[^scales-9]\n\n[^scales-9]: OLS modellen zijn niet altijd geschikt voor variabelen waarbij een telling wordt gemaakt ('count data'). Meer toepasselijke modellen (poisson regressie en negative binomial modellen) vallen echter buiten dit handboek.\n\n```{r}\n# Model \nengagement_model <- lm(campaign_engagement ~ positive_emotions + negative_emotions, \n                       data = scale_data)\n\n# Coefficients\ntidy(engagement_model)\n```\n\nEr bestaat voor beide predictoren een positieve, significante relatie met de afhankelijke variabele. Zowel positieve als negatieve emoties zijn geassocieerd met politieke participatie.\n\n## Voorbeeld 2: verschillende meeteenheden\n\nDe schalen die we hierboven hebben gemaakt waren gebaseerd op variabelen die zelf op dezelfde schaal waren gemeten (binaire 0/1 variabelen voor campagneactiviteiten en emotiebelevenis op een schaal van 1 tot 5 voor de emotievariabelen). Het kan echter voorkomen dat we een index willen maken van variabelen die op verschillende schalen gemeten zijn. Dat vergt een enigszins andere aanpak.\n\n### Twee benaderingen: normaliseren en standaardiseren\n\nHet tweede voorbeeld richt zich op de Human Development Index (HDI). De [HDI](https://hdr.undp.org/data-center/human-development-index#/indicies/HDI){target=\"_blank\"} is \"a summary measure of average achievement in key dimensions of human development: a long and healthy life, being knowledgeable and having a decent standard of living\".\n\nDe HDI van landen wordt gemeten op basis van de volgende variabelen: levensverwachting in jaren, scholingsgraad (verwacht en gemiddeld aantal jaren onderwijs genoten), en de welvaart van een land gemeten met het natuurlijk logaritme van het BNI per capita. Deze figuur legt het berekeningsproces uit:\n\n![](figures/hdi_measurement.png){fig-alt=\"An image showing the main components of HDI: life expectancy, educational attainment, and gross national income.\"}\n\nIn dit voorbeeld gaan we zelf de HDI scores van landen berekenen op basis van onderliggende data afkomstig van de [Verenigde Naties](https://hdr.undp.org/data-center/documentation-and-downloads){target=\"_blank\"}. We richten ons op het jaar 2023.\n\nDe volgende variabelen worden gebruikt: levensverwachting bij geboorte in jaren (`life_expectancy`), het verwachte aantal jaren onderwijs genoten (`expected_schooling`), het gemiddelde aantal jaren onderwijs genoten (`mean_schooling`), en het gelogde BNI per capita (`gni_percap_logged`):[^scales-10]\n\n[^scales-10]: De VN nemen enkele datamanagement stappen vooraleer de HDI te berekenen. Deze hebben wij hier ook genomen. Voor landen met een levensverwachting groter dan 85 wordt de waarde vastgezet op een maximum van 85. Voor landen met een BNI onder 100 wordt de waarde vastgezet op 100 (vooraleer het natuurlijk logaritme wordt genomen). De redenen hiervoor staan uitgelegd [hier](https://hdr.undp.org/data-center/documentation-and-downloads){target=\"_blank\"}.\n\n```{r}\ndatasummary(life_expectancy + expected_schooling + mean_schooling + gni_percap_logged ~ \n              Mean + SD + Min + Max + N, data = hdi_data)\n\n```\n\nDe variabelen zijn duidelijk op verschillende schalen gemeten. Het bereik van levensverwachting loopt van 54 tot 85, terwijl dat van gemiddelde scholing loopt van 1.41 tot 14.30.\n\nEen index met een gemiddelde score over alle variabelen heen zou ons weinig leren. Eerst moeten de variabelen op eenzelfde schaal worden gezet. Hier bestaan twee manieren voor: normaliseren of standaardiseren.\n\nBij normaliseren herschalen we de variabelen zodat ze allemaal dezelfde minimum- en maximum waarden hebben. De onderstaande formule herschaalt de variabelen zodat ze een bereik van 0 tot 1 hebben. De score van 0 wordt geven aan observaties die de minimumwaarde hadden op de originele variabele. De score van 1 wordt gegeven voor de maximumwaarde op de originele variabele. Moesten we de variabele op een schaal van 0 tot 10 willen brengen, zouden we een vermenigvuldiging met 10 aan de formule kunnen toevoegen.\n\n$$\\text{(0-1) Normalized Variable} = \\frac{X_{i} - min(X)}{max(X) - min(X)}$$\n\nDe HDI maakt grotendeels gebruik van dergelijk normaliseringsproces. Echter worden voor de variabelen niet de minimum- en maximumwaarden in de data gebruikt om het bereik te bepalen, maar zelfgekozen waarden. Voor levensverwachting worden 20 en 85 als minimum en maximum aangeduid. Dit doen ze omdat het aansluit bij de realiteit: \"no country in the 20th century had a life expectancy at birth of less than 20 years\" and \"85 \\[is\\] a realistic aspirational target for many countries over the last 30 years.\" Voor BNI per capita wordt het minimum gezet op log(\\$100) en het maximum op log(\\$75000). Voor de onderwijsvariabelen is het iets makkelijker. De maxima worden vastgezet op 18 (expected schooling) en 15 (mean schooling) en dan worden de variabelen gedeeld door 18 en 15 respectievelijk om ze te normaliseren.\n\nWe blijven in dit voorbeeld trouw aan de VN aanpak en gebruiken manueel deze vastgezette waarden om te normaliseren. We tonen echter ook hoe je met de `rescale()` functie uit het `scales` package automatisch kunt normaliseren op basis van de minimum en maximumwaarden die je vindt in de data.\n\nNormalisatie zorgt ervoor dat alle variabelen hetzelfde bereik hebben en kan gebruikt worden voor interval/ratio, ordinale, en binaire variabelen. Normaliseren heeft echter geen impact op de variantie van variabelen. Gezien sommige variabelen een grotere variantie hebben dan anderen kan het zijn dat sommigen meer bijdragen tot de eindscore dan anderen. Een alternatief is om eerst de variabelen te standaardiseren:\n\n$$\\text{Standardized Variable} = \\frac{X_{i} - \\bar{X}}{\\text{Std. Dev}(X)}$$\n\nVoor elke observatie trekken we de gemiddelde score over de data heen af van de waarde voor de observatie. Dan delen we de uitkomst door de standaarddeviatie van de variabele. De nieuwe variabele heeft altijd een gemiddelde van 0, waarbij 0 staat voor de gemiddelde score op de oorspronkelijke variabele. Afwijkingen van 0 worden uitgedrukt in standaarddeviaties. De variatie van variabelen wordt hierbij gelijkgezet en zo dragen ze gelijk bij aan de uiteindelijke index. De interpretatie van de gestandaardiseerde variabele is wel anders. Een eenheid hoger op deze variabele betekent 1 standaarddeviatie hoger op de oorspronkelijke schaal. Een gestandaardiseerde variabele met een waarde hoger dan 0 betekent dat de waarde hoger ligt dan het gemiddelde op de oorspronkelijke schaal. Dit betekent echter niet noodzakelijk een 'hoge' waarde op de oorspronkelijke schaal gezien het gemiddelde zich niet noodzakelijk in het midden bevindt (cfr. verschil gemiddelde en mediaan). Standaardiseren is vooral nuttig bij interval/ratio variabelen.\n\n### Schalen maken\n\nWe maken in onderstaande secties de HDI door gebruik te maken van zowel normalisering als standaardisering. We bestuderen ook de verschillen.\n\n#### Normalisering\n\nVoor de HDI wordt gebruik gemaakt van 3 genormaliseerde variabelen: levensverwachting, het gemiddelde van verwachte en gemiddelde scholing in een land, en het natuurlijk logaritme van het BNI per capita (zie bovenstaande uitleg). We zullen eerste manueel normaliseren en dan gebruik maken van de `rescale()` functie uit het `scales` package.\n\nOnze eerste stap is het berekenen van het gemiddelde van de onderwijsvariabelen. Eerst normaliseren we beide variabelen. De VN deelt verwachte scholing door 18 en gemiddelde scholing door 15 om een 0-1 schaal te maken (zie uitleg boven). Dan nemen ze het gemiddelde van de twee variabelen. Dit doen we met de volgende syntax, waarbij we de `rowwise()` functie gebruiken.\n\n```{r}\n# Onderwijsvariabele voor gebruik in HDI\nhdi_data <- hdi_data |> \n  mutate(\n    expected_yrs_rescale1 = expected_schooling / 18, \n    mean_yrs_rescale1 = mean_schooling / 15) |> \n  rowwise() |> \n  mutate(\n    education_index_1 = mean(c(expected_yrs_rescale1, mean_yrs_rescale1), na.rm = T)\n  ) |> \n  ungroup()\n\n# Statistieken bekijken\nsummary(hdi_data$education_index_1)\n\n# Blik op de dataset\nhdi_data |> \n  select(expected_schooling, mean_schooling, expected_yrs_rescale1, mean_yrs_rescale1, education_index_1) |>\n  head()\n\n```\n\nDe uiteindelijke indexvariabele heeft een bereik tussen 0 en 1 met een minimum van 0.25 en een maximum van 0.96. Door te kijken naar de relevante variabelen in de dataset kunnen we de berekening volgen. Voor de eerste observatie vinden we het maximum van 18 jaar verwachte scholing. Als we dit delen door 18 vinden we voor `expected_yrs_rescale1` het maximum van 1. Voor gemiddelde scholing heeft deze observatie echter niet het maximum maar 13.91.Als we dit getal delen door 15 vinden we voor `mean_yrs_rescale1` een getal dichtbij het maximum: 0.93. Het gemiddelde van 1 en 0.93 vinden we bij `education_index_1`.\n\nWe normaliseren nu ook levensverwachting met het VN minimum van 20 en maximum van 85. Voor (log) BNI per capita gebruiken we het VN minimum van log(100) en maximum van log(75000). Hier kunnen we meer de standaardformule voor normaliseren toepassen.\n\n```{r}\n# Normaliseren van variabelen\nhdi_data <- hdi_data |> \n  mutate(\n    life_rescale1 = (life_expectancy - 20) / (85 - 20), \n    gni_rescale1 = (gni_percap_logged - log(100)) / (log(75000) - log(100)))\n\n# Statsitieken bekijken\nsummary(hdi_data$life_rescale1)\nsummary(hdi_data$gni_rescale1)\n\n```\n\nWe kunnen zien dat het nieuwe maximum van de variabelen 1 is, de minima zijn hierbij wel niet precies 0 (dat zijn ze wel met de `scales` methode hieronder besproken).\n\nTen slotte kunnen we onze index samenstellen door het gemiddelde te nemen van onze 3 variabelen met de `rowwise()` en `mean(c(), na.rm =T)`) syntax.[^scales-11]\n\n[^scales-11]: We berekenen hier gewoon het gemiddelde, maar de VN gebruikt het geometrisch gemiddelde. Hierdoor wijkt onze berekening wat af. Het `psych` package bevat een functie om het geometrisch gemiddelde te berekenen.\n\n```{r}\n# Uiteindelijke schaal\nhdi_data <- hdi_data |> \n  rowwise() |> \n  mutate(hdi_normalize_un = mean(c(life_rescale1, gni_rescale1, \n                                   education_index_1), na.rm = T)) |> \n  ungroup()\n\n# Statistieken bekijken\nsummary(hdi_data$hdi_normalize_un)\n\n```\n\nDe schaal loopt van 0.41 tot 0.97. Hogere waarden staan voor hogere scholingsgraad, levensverwachting en welvaart.\n\nIn bovenstaande syntax maakten we gebruik van de minimum- en maximumwaarden bepaald door de VN. Maar we kunnen deze ook uit de data halen. Dit is vaak eenvoudiger, zeker als je geen theoretische basis hebt voor je keuzes zoals de VN. We kunnen de `scales::rescale()` functie gebruiken om dit automatisch te doen:\n\n```{r}\nhdi_data <- hdi_data |> \n  mutate(\n    expected_yrs_rescale2 = scales::rescale(expected_schooling, to = c(0,1)), # <1>\n    mean_yrs_rescale2 = scales::rescale(mean_schooling, to = c(0,1)), \n    life_rescale2 = scales::rescale(life_expectancy, to = c(0,1)), \n    gni_rescale2 = scales::rescale(gni_percap_logged, to = c(0,1)))\n\n```\n\n1.  We noemen het package hier in de syntax (`scales::`) zodat we het niet hoeven te laden. Het `scales` package heeft namelijk ook een aantal functies die conflicteren met andere packages die we gebruiken.\n\nZo lees je de syntax:\n\n`scales::rescale(`\n\n:   We gebruiken de functie `rescale()` uit het `scales` package. We noemen het package in de syntax (`scales::`) om het niet te hoeven laden.\n\n`expected_schooling, to = c(0,1))`\n\n:   We noemen de variabele die we willen normaliseren. Met de `to = c(0,1)`vertellen we R dat we de variabele willen herschalen zodat ze een bereik van 0 tot 1 heeft. We zouden deze waarden kunnen veranderen, bv. naar `c(0,10)` voor een bereik van 0 tot 10.\n\nLaten we kijken naar het verschil tussen de VN-methode en `rescale`:\n\n```{r}\n# Originele variabele en VN normalisering\np1 <- ggplot(hdi_data, aes(x = life_expectancy, y = life_rescale1)) + geom_point() + \n  scale_y_continuous(limits = c(0,1)) + \n  labs(title = \"Normalisering met VN min(x) en max(x)\") \n\n# Originele variabele en scales::rescale() normalisering\np2 <- ggplot(hdi_data, aes(x = life_expectancy, y = life_rescale2)) + geom_point() + \n  labs(title = \"Normalisering met scales::rescale()\")\n\n# Plots combineren met patchwork library\np1 + p2 \n\n```\n\nBeide genormaliseerde variabelen hebben een theoretisch bereik van 0 tot 1. Maar met `rescale` wordt er altijd een echt minimum en maximum gevonden in de data en zul je altijd de waarden 0 en 1 terugvinden. De VN heeft echter door het zelf bepalen van minima en maxima in plaats van ze door de data te laten bepalen, het minimum voor de data in de praktijk hoger gelegd (bij 0.53). In 2023 had geen enkel land een levensverwachting van 20, het theoretische minimum van de VN, dus vinden we 0 niet terug. Het theoretische maximum van 85 werd dan wel weer bereikt.\n\nWe berekenen nu de index met de `scales::rescale()` genormaliseerde variabelen:\n\n```{r}\n# Index berekenen\nhdi_data <- hdi_data |> \n  rowwise() |> \n  mutate(\n    education_index_2 = mean(c(expected_yrs_rescale2, mean_yrs_rescale2), na.rm = T),\n    hdi_normalize_scales = mean(c(education_index_2, life_rescale2, gni_rescale2), na.rm = T)\n    ) |> \n  ungroup()\n```\n\nLaten we de twee versies vergelijken:\n\n```{r}\n# Statistieken vergelijken\nsummary(hdi_data$hdi_normalize_scales) # scales::rescale() \nsummary(hdi_data$hdi_normalize_un) # VN waarden\n\n# Correlatie\ncor.test(x = hdi_data$hdi_normalize_un, \n         y = hdi_data$hdi_normalize_scales, \n         method = 'pearson')\n```\n\nDe schalen lopen van 0 tot 1 maar zijn niet volledig identiek. In lijn met wat we hierboven al zagen ligt het minimum hoger bij de VN versie. Toch correleren de twee versies zeer sterk en positief met een pearson correlatie van 0.998. Verschillen zullen dan ook weinig uitmaken in regressieanalyses.\n\n#### Standaardisering\n\nOm te standaardiseren trekken we van een variabele de gemiddelde waarde af en delen we door de standaardafwijking. Hier kunnen we de ingebouwde R-functie `scale()` voor gebruiken. je hoeft geen package te laden.\n\n```{r}\n# Standaardiseren\nhdi_data <- hdi_data |> \n  mutate(\n    life_std = scale(life_expectancy, center = TRUE, scale = TRUE), \n    expected_yrs_std = scale(expected_schooling, center = TRUE, scale = TRUE), \n    mean_yrs_std = scale(mean_schooling, center = TRUE, scale = TRUE), \n    gni_std = scale(gni_percap_logged, center = TRUE, scale = TRUE)\n  )\n```\n\nZo lees je de syntax:\n\n`scale(`\n\n:   We gebruiken de functie `scale()` op de variabele tussen haakjes.\n\n`life_expectancy, center = TRUE, scale = TRUE)`\n\n:   We benoemen de variabele en vragen R eerst het gemiddelde van de variabele van elke waarde af te trekken met `center = TRUE` en dan te standaardiseren door te delen door de standaardafwijking met `scale = TRUE`.\n\nLaten we de statistieken van de variabelen bekijken:\n\n```{r}\n# Descriptieve statistieken opvragen\nhdi_data |>\n  select(life_std, expected_yrs_std, mean_yrs_std, gni_std) |>\n  psych::describe() \n```\n\nAlle variabelen hebben een gemiddelde van 0 en een standaardafwijking van 1. De minima en maxima zijn niet dezelfde maar de waarden hebben dezelfde betekenis: hoeveel verschilt de observatie van de gemiddelde waarde van de originele variabele.\n\nWe maken nu de index door het gemiddelde van de variabelen te nemen:\n\n```{r}\n# Schaal maken\nhdi_data <- hdi_data |> \n  rowwise() |> \n  mutate(\n    hdi_standardized = mean(c(life_std, expected_yrs_std, \n                              mean_yrs_std, gni_std), \n                            na.rm = T))\n\n# Statistieken bekijken\nsummary(hdi_data$hdi_standardized)\n```\n\nde schaal loopt van -2.12 tot 1.44 met een gemiddelde waarde van 0. Observaties dichter bij het maximum hebben scores hoger dan het gemiddelde voor (bijna) alle onderliggende variabelen.\n\n## Referenties\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"scales.html"},"language":{"toc-title-document":"Inhoudsopgave","toc-title-website":"Op deze pagina","related-formats-title":"Andere formaten","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Bron","other-links-title":"Andere Links","code-links-title":"Code Links","launch-dev-container-title":"Dev Container starten","launch-binder-title":"Binder starten","article-notebook-label":"Artikel Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Broncode downloaden","notebook-preview-back":"Terug naar Artikel","manuscript-meca-bundle":"MECA Archief","section-title-abstract":"Samenvatting","section-title-appendices":"Bijlagen","section-title-footnotes":"Voetnoten","section-title-references":"Referenties","section-title-reuse":"Hergebruik","section-title-copyright":"Auteursrechten","section-title-citation":"Citaat","appendix-attribution-cite-as":"Citeer dit werk als:","appendix-attribution-bibtex":"BibTeX citaat:","appendix-view-license":"Licentie Bekijken","title-block-author-single":"Auteur","title-block-author-plural":"Auteurs","title-block-affiliation-single":"Affiliatie","title-block-affiliation-plural":"Affiliaties","title-block-published":"Publicatiedatum","title-block-modified":"Gewijzigd","title-block-keywords":"Trefwoorden","callout-tip-title":"Tip","callout-note-title":"Opmerking","callout-warning-title":"Waarschuwing","callout-important-title":"Belangrijk","callout-caution-title":"Opgelet","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Alle code tonen","code-tools-hide-all-code":"Alle code verbergen","code-tools-view-source":"Broncode bekijken","code-tools-source-code":"Broncode","tools-share":"Share","tools-download":"Download","code-line":"Regel","code-lines":"Regels","copy-button-tooltip":"Kopieer naar klembord","copy-button-tooltip-success":"Gekopieerd!","repo-action-links-edit":"Pagina bewerken","repo-action-links-source":"Broncode bekijken","repo-action-links-issue":"Een probleem melden","back-to-top":"Terug naar boven","search-no-results-text":"Geen resultaten","search-matching-documents-text":"Gevonden documenten","search-copy-link-title":"Kopieer link om te zoeken","search-hide-matches-text":"Extra overeenkomsten verbergen","search-more-match-text":"meer overeenkomst in dit document","search-more-matches-text":"meer overeenkomsten in dit document","search-clear-button-title":"Wissen","search-text-placeholder":"","search-detached-cancel-button-title":"Annuleren","search-submit-button-title":"Verzenden","search-label":"Zoeken","toggle-section":"Schakel sectie","toggle-sidebar":"Schakel zijbalknavigatie","toggle-dark-mode":"Schakel donkere modus","toggle-reader-mode":"Schakel leesmodus","toggle-navigation":"Schakel navigatie","crossref-fig-title":"Figuur","crossref-tbl-title":"Tabel","crossref-lst-title":"Listing","crossref-thm-title":"Stelling","crossref-lem-title":"Lemma","crossref-cor-title":"Conclusie","crossref-prp-title":"Voorstel","crossref-cnj-title":"Aanname","crossref-def-title":"Definitie","crossref-exm-title":"Voorbeeld","crossref-exr-title":"Oefening","crossref-ch-prefix":"Hoofdstuk","crossref-apx-prefix":"Bijlage","crossref-sec-prefix":"Paragraaf","crossref-eq-prefix":"Vergelijking","crossref-lof-title":"Lijst van figuren","crossref-lot-title":"Lijst van tabellen","crossref-lol-title":"Lijst van listings","environment-proof-title":"Bewijs","environment-remark-title":"Opmerking","environment-solution-title":"Oplossing","listing-page-order-by":"Sorteer op","listing-page-order-by-default":"Standaard","listing-page-order-by-date-asc":"Oudste","listing-page-order-by-date-desc":"Nieuwste","listing-page-order-by-number-desc":"Aflopend","listing-page-order-by-number-asc":"Oplopend","listing-page-field-date":"Datum","listing-page-field-title":"Titel","listing-page-field-description":"Beschrijving","listing-page-field-author":"Auteur","listing-page-field-filename":"Bestandsnaam","listing-page-field-filemodified":"Gewijzigd","listing-page-field-subtitle":"Subtitel","listing-page-field-readingtime":"Leestijd","listing-page-field-wordcount":"Woordentelling","listing-page-field-categories":"Categorieën","listing-page-minutes-compact":"{0} min","listing-page-category-all":"Alle","listing-page-no-matches":"Geen overeenkomsten","listing-page-words":"{0} woorden","listing-page-filter":"Filter","draft":"Ontwerp"},"metadata":{"lang":"nl","fig-responsive":true,"quarto-version":"1.5.57","bibliography":["references.bib"],"editor":"visual","theme":{"light":"cosmo","dark":"darkly"},"code-annotations":"hover","execution":{"error":true}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}