{
  "hash": "89fc888fb4b219f78a3b834cc4158869",
  "result": {
    "engine": "knitr",
    "markdown": "# Model Fit en Modellen Vergelijken {#sec-logit-comparing}\n\n\n\n::: {.cell}\n\n:::\n\n\n\nIn vorige hoofdstukken lag de focus op de effecten van de onafhaneklijke variabelen en hoe ze te begrijpen op basis van coëfficiënten, odds ratios, marginale effecten en voorspelde kansen. In dit hoofdstuk richten we ons op het model als geheel en hoe goed het bij de data past ('fit').\n\nWe laden de packages en data:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Packages\n#Packages\nlibrary(rio)             #laden van data\nlibrary(tidyverse)       #datamanipulatie en grafieken\nlibrary(performance)     #goodness-of-fit statistieken en tests\n\n#Data\nESS9NL <- import(\"ESS9e03, Netherlands.sav\")\n```\n:::\n\n\n\n## Fit statistieken met `summary()`\n\nLaten we teruggaan naar het logistisch model waar we ook in vorige hoofdstukken mee werkten: wat is de kans dat iemand gaat stemmen op basis van informatie over gender, leeftijd, vertouwen in politici en links-rechtsideologie?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Data management\nESS9NL <- ESS9NL |>\n  #Factor maken van categorische variabelen\n  mutate(gndr_F = factorize(gndr), \n         vote_F = factorize(vote))  |> \n  #Not Eligible op missing zetten\n  mutate(vote_F = na_if(vote_F,\"Not eligible to vote\")) |> \n  #Relevel van variabelen\n  mutate(vote_F = relevel(vote_F, \"No\"), \n         gndr_F = relevel(gndr_F, \"Female\"))\n\n#Het model\nVote_model_mp <- glm(vote_F ~ gndr_F + agea + trstplt + lrscale, \n                data = ESS9NL, family = \"binomial\")\n\n#Resultaten printen\nsummary(Vote_model_mp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = vote_F ~ gndr_F + agea + trstplt + lrscale, family = \"binomial\", \n    data = ESS9NL)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -0.284194   0.380455  -0.747    0.455    \ngndr_FMale   0.043281   0.154201   0.281    0.779    \nagea         0.018349   0.004503   4.075 4.61e-05 ***\ntrstplt      0.195020   0.038706   5.039 4.69e-07 ***\nlrscale      0.029257   0.039306   0.744    0.457    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1173.9  on 1424  degrees of freedom\nResidual deviance: 1135.3  on 1420  degrees of freedom\n  (248 observations deleted due to missingness)\nAIC: 1145.3\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n\n\n::: callout-note\n#### Output uitleg\n\nZoals bij een lineair model (`lm`), zal de `summary()` functie in het onderste gedeelte van de output informatie bevatten over model fit. We krijgen informatie over de \"Null\" en \"Residual Deviance\" statistieken. De Residual Deviance statistiek duidt het verschil (\"deviance\") aan tussen het geschatte model en een \"perfect' model dat precies bij de data past. De Null Deviance statistiek doet dezelfde vergelijking, maar ten opzichte van een nulmodel dat enkel het intercept bevat.\n\n*Kleinere* Residual Deviance waarden duiden beter passende modellen aan. Echter is het niet gewenst om de deviance statistiek op zich te interpreteren gezien de schaal onduidelijk is en er geen maximumwaarde is. Daarom maken we gebruik van andere statistieken en een test gebaseerd op de deviance statistiek (zie onder).\n:::\n\n## Modellen vergelijken: Likelihood Ratio Test\n\nWe kunnen de likelihood ratio test gebruiken om verschillende logistische regressiemodellen te vergelijken met elkaar en na te gaan welke beter past. De LRT berekent de ratio tussen de deviance statistieken van de modellen en gaat na of er een significant verschil is.\n\nAls we modellen willen verglijken moeten we net zoals bij lineaire regressie (zie @sec-linear-comparing-models) zorgen dat de modellen een gelijke N hebben en dat complexere modellen alle predictors bevatten van simpelere modellen (nested). We zorgen dat we eerst een dataset maken met complete observaties voor het meest complexe model (alle predictors).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nESS9NL_glm <- ESS9NL |>\n  filter(complete.cases(vote_F,  gndr_F,  agea,  trstplt,  lrscale))\n```\n:::\n\n\n\nDan schatten we een reeks modellen waaraan we telkens 1 van de onafhankelijke varaibelen toevoegen. We beginnen met een nulmodel dat enkel het intercept bevat. Het model met 1 onafhankelijke variabele kan daar dan mee vergeleken worden.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Nulmodel\nVote_model0 <- glm(vote_F ~ 1,\n                      data = ESS9NL_glm, family = \"binomial\")\n# + gndr\nVote_model1 <- glm(vote_F ~ gndr_F , \n                data = ESS9NL_glm, family = \"binomial\")\n# + agea\nVote_model2 <- glm(vote_F ~ gndr_F + agea , \n                data = ESS9NL_glm, family = \"binomial\")\n\n# + trst\nVote_model3 <- glm(vote_F ~ gndr_F + agea + trstplt, \n                data = ESS9NL_glm, family = \"binomial\")\n\n# + lrscale\nVote_model4 <- glm(vote_F ~ gndr_F + agea + trstplt + lrscale, \n                data = ESS9NL_glm, family = \"binomial\")\n```\n:::\n\n\n\nNu kunnen we de likelihood ratios van deze modellen met elkaar vergelijken en significantietoetsen uitvoeren. We gebruiken het `performance` package met de `test_likelihoodratio` functie. De test vergelijkt de deviance statistiek (-2LL) van elk model, de verandering in vrijheidsgraden (df= degrees of freedom) per model, en gebruikt een Chi^2^ ($\\chi^2$) toets.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_likelihoodratio(Vote_model0,\n                     Vote_model1,\n                     Vote_model2,\n                     Vote_model3,\n                     Vote_model4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName        | Model | df | df_diff |  Chi2 |      p\n---------------------------------------------------\nVote_model0 |   glm |  1 |         |       |       \nVote_model1 |   glm |  2 |       1 |  0.11 |  0.744\nVote_model2 |   glm |  3 |       1 | 13.59 | < .001\nVote_model3 |   glm |  4 |       1 | 24.38 | < .001\nVote_model4 |   glm |  5 |       1 |  0.55 |  0.457\n```\n\n\n:::\n:::\n\n\n\n`test_likelihoodratio(`\n\n:   : We voeren de likelihood ratio test uit op de modellen tussen haakjes. Er moeten minstens twee modellen aangeduid zijn en de volgorde bepaalt welke vergelijking gemaakt wordt.\n\n::: callout-note\n#### Output uitleg\n\nDe output lees je als volgt:\n\n-   `Name`: naam van het object waarin het model is opgeslagen\n-   `Model`: informatie over het type model. Te negeren.\n-   `df`: Geeft weer hoeveel termen gebruikt werden in het model. `Vote_model0` heeft een `df` van 1 gezien er maar 1 term is: het intercept. `Vote_model4` heeft 5 `df` omdat er 5 termen zijn: het intercept en de coëfficiënten voor de 4 onafhankelijke variabelen.\n-   `df_diff`: Geeft weer hoeveel het model verschilt van het vorige model in termen van `df`. Dit is telkens 1 hier omdat we telkens maar 1 nieuwe predictor hebben toegevoegd.\n-   `Chi2` & `p`: Dit is de Chi^2^ statistiek en bijhorende p-waarde. De test gaat na of de fit van een model beter is dan de fit van het model in de rij erboven. De nulhypothese is dat er geen verschil is in fit. Een significante toets betekent dat het model beter past.\n:::\n\nIn dit voorbeeld:\n\n-   Model 1 heeft *geen* significant betere fit dan een nulmodel (`vote_model0`)\n-   Model 2 heeft een betere fit dan Model 1\n-   Model 3 heeft een betere fit dan Model 1 Model 2\n-   Model 4 heeft *geen* significant betere fit dan Model 3.\n\nWe kunnen concluderen dat Model 3 (`vote_model3`) het best passende model is zonder inclusie van nietszeggende variabelen (i.e. het model is het meest 'parsimonious').\n\nZoals het geval was voor de `anova()` functie bij lineaire regressie kun je ook specifieke groepen van modellen vergelijken:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Past Model 4 beter dan Model 1?: Ja!\ntest_likelihoodratio(Vote_model1, Vote_model4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName        | Model | df | df_diff |  Chi2 |      p\n---------------------------------------------------\nVote_model1 |   glm |  2 |         |       |       \nVote_model4 |   glm |  5 |       3 | 38.53 | < .001\n```\n\n\n:::\n\n```{.r .cell-code}\n#Past Model 3 beter dan een nulmodel?: Ja!\ntest_likelihoodratio(Vote_model0, Vote_model3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName        | Model | df | df_diff |  Chi2 |      p\n---------------------------------------------------\nVote_model0 |   glm |  1 |         |       |       \nVote_model3 |   glm |  4 |       3 | 38.08 | < .001\n```\n\n\n:::\n:::\n\n\n\n::: callout-important\n#### Waarschuwing!\n\nDe volgorde waarin we onze modellen aanduiden in de `test_likelihoodratio()` syntax bepaalt welke modellen precies vergeleken worden net zoals met `anova()` bij lineaire regressie ( @sec-linear-comparing-models). Bij een verkeerde volgorde krijg je een error in R. Een juiste volgorde houdt in dat je van minder naar meer complex gaat:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_likelihoodratio(Vote_model0,\n                     Vote_model4,\n                     Vote_model2,\n                     Vote_model1,\n                     Vote_model3)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError: The models are not nested, which is a prerequisite for\n  `test_likelihoodratio()`.\n  See the 'Details' section.\n  You may try `test_vuong()` instead.\n```\n\n\n:::\n:::\n\n\n\nAls we 2 modellen testen en de eerste in de syntax is de meest complexe, dan krijgen we dezelfde Chi^2^ en p-waarde vergeleken met een juiste volgorde, maar de `df_diff` zal negatief zijn (-3 ipv +3 in dit voorbeeld). Op zich is dit geen probleem, zolang we maar weten wat we precies aan het vergelijken zijn zodat we geen interpretatiefouten maken.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_likelihoodratio(Vote_model4, Vote_model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName        | Model | df | df_diff |  Chi2 |      p\n---------------------------------------------------\nVote_model4 |   glm |  5 |         |       |       \nVote_model1 |   glm |  2 |      -3 | 38.53 | < .001\n```\n\n\n:::\n:::\n\n\n:::\n\n## Pseudo R^2^\n\nBij een lineair regressiemodel beoordelen we fit met de R^2^ waarde. Een logistisch model is anders geschat en dus hebben we deze waarde niet. Verschillende zogenaamde *pseudo* R^2^ statistieken werden ontwikkeld om meer intuïtief inzicht te verkrijgen in de verklarende kracht van een model. De *pseudo* R^2^ maatstaven zijn gebaseerd op de likelihood ratio test en kunnen *niet* als 'proportie verklaarde variantie' geïnterpreteerd worden.\n\nHier gebruiken we de Nagelkerke R². De waarde van deze maatstaf ligt tussen 0 en 1. Lage waarden wijzen op een lage verklarende kracht, hoge waarden op een hoge verklarende kracht.\n\nWe kunnen de Nagelkerke R² statistiek opvragen met de `r2_nagelkerke()` functie uit het `performance` package.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Nagelkerke R2: Model 3\nr2_nagelkerke(Vote_model3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNagelkerke's R2 \n     0.04698189 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Nagelkerke R2: Model 4\nr2_nagelkerke(Vote_model4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNagelkerke's R2 \n     0.04765513 \n```\n\n\n:::\n:::\n\n\n\n`r2_nagelkerke(`\n\n:   Deze functie berekent de Nagelkerke R^2^ voor het model tussen haakjes. Er kan slecht 1 model opgegeven worden.\n\nDe Nagelkerke R^2^ is hoger voor Model 4 dan Model 3. Echter is een likelihood ratio test nodig om te weten of dit verschil significant is. Zoals we hierboven zagen is dit niet het geval.\n\n::: callout-important\n#### Waarschuwing!\n\nEr bestaan verschillende pseudo R^2^ statistieken om de fit van logistische regressiemodellen te helpen interpreteren. *Geen enkele* van hen kan geïnterpreteerd worden in termen van 'proprotie verklaarde variantie'.\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}